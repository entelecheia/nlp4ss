
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>4.1 Using LLMs for High-Quality Text Generation &#8212; NLP for Social Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'session04/lecture1';</script>
    <script src="../_static/language_switcher.js?v=ff97be19"></script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4.2 Social Bias Inference and Analysis" href="lecture2.html" />
    <link rel="prev" title="Session 4: Generative Explanations and Summaries in Social Science" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          English <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">NLP for Social Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../session01/index.html">Session 1 - Introduction to NLP for Social Science</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session01/lecture1.html">1.1 Fundamentals of NLP and its Evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session01/lecture2.html">1.2 Overview of Generative LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session01/lecture3.html">1.3 Ethical Considerations and Challenges in Using LLMs for Research</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session02/index.html">Session 2: Traditional NLP Techniques and Text Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture1.html">2.1 Text Cleaning, Normalization, and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture2.html">2.2 Basic NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture3.html">2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session03/index.html">Session 3: LLMs for Data Annotation and Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture1.html">3.1 Zero-shot Learning with LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture2.html">3.2 Few-shot Learning and Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture3.html">3.3 Comparing LLM Performance with Traditional Supervised Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Session 4: Generative Explanations and Summaries in Social Science</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">4.1 Using LLMs for High-Quality Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture2.html">4.2 Social Bias Inference and Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture3.html">4.3 Figurative Language Explanation and Cultural Context</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session05/index.html">Session 5: Advanced Applications of LLMs in Social Science Research</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture1.html">5.1 Analyzing Large-Scale Textual Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture2.html">5.2 Misinformation and Fake News Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture3.html">5.3 Future Directions and Emerging Trends</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../labs/nlp4ss-lab-1.html">Lab Session 1: Introduction to NLP for Social Science</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">Course Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/edit/main/book/en/session04/lecture1.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/issues/new?title=Issue%20on%20page%20%2Fsession04/lecture1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/session04/lecture1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>4.1 Using LLMs for High-Quality Text Generation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-text-generation-with-llms">1. Introduction to Text Generation with LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentals-of-llm-based-text-generation">2. Fundamentals of LLM-based Text Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-text-generation-tasks">3. Types of Text Generation Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-for-text-generation">4. Prompt Engineering for Text Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlling-generation-parameters">5. Controlling Generation Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspect-based-emotion-summarization">6. Aspect-based Emotion Summarization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#misinformation-explanation-generation">7. Misinformation Explanation Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-quality-content-creation">8. High-Quality Content Creation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-for-social-science-research">9. Data Augmentation for Social Science Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-generated-text">10. Evaluation of Generated Text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="using-llms-for-high-quality-text-generation">
<h1>4.1 Using LLMs for High-Quality Text Generation<a class="headerlink" href="#using-llms-for-high-quality-text-generation" title="Link to this heading">#</a></h1>
<section id="introduction-to-text-generation-with-llms">
<h2>1. Introduction to Text Generation with LLMs<a class="headerlink" href="#introduction-to-text-generation-with-llms" title="Link to this heading">#</a></h2>
<p>Text generation using Large Language Models (LLMs) has revolutionized natural language processing in recent years. For social science researchers, LLMs offer powerful tools to generate high-quality text for various applications, from creating research hypotheses to synthesizing literature reviews.</p>
<div align="center" class="mermaid align-center">
            graph TD
    A[Traditional Methods] --&gt; B[Rule-based Systems]
    A --&gt; C[Statistical Models]
    D[LLM-based Generation] --&gt; E[Transformer Models]
    D --&gt; F[Few-shot Learning]
    D --&gt; G[Zero-shot Capabilities]
        </div>
        <p>LLMs provide several advantages over traditional text generation methods:</p>
<ol class="arabic simple">
<li><p>Flexibility in handling diverse tasks</p></li>
<li><p>Ability to generate coherent and contextually relevant text</p></li>
<li><p>Adaptation to specific domains with minimal fine-tuning</p></li>
</ol>
</section>
<section id="fundamentals-of-llm-based-text-generation">
<h2>2. Fundamentals of LLM-based Text Generation<a class="headerlink" href="#fundamentals-of-llm-based-text-generation" title="Link to this heading">#</a></h2>
<p>LLMs are based on the Transformer architecture and use autoregressive language modeling to generate text token by token. Here’s a simplified illustration of the process:</p>
<div align="center" class="mermaid align-center">
            sequenceDiagram
    participant User
    participant LLM
    participant Output
    User-&gt;&gt;LLM: Provide prompt
    loop Token Generation
        LLM-&gt;&gt;LLM: Generate next token
        LLM-&gt;&gt;Output: Add token to output
    end
    Output-&gt;&gt;User: Return generated text
        </div>
        <p>Let’s look at a basic example using the Hugging Face Transformers library:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2LMHeadModel</span><span class="p">,</span> <span class="n">GPT2Tokenizer</span>

<span class="c1"># Load pre-trained model and tokenizer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GPT2Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;The impact of social media on political discourse&quot;</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="types-of-text-generation-tasks">
<h2>3. Types of Text Generation Tasks<a class="headerlink" href="#types-of-text-generation-tasks" title="Link to this heading">#</a></h2>
<p>LLMs can be used for various text generation tasks in social science research:</p>
<ol class="arabic simple">
<li><p>Open-ended generation (e.g., creating research hypotheses)</p></li>
<li><p>Constrained generation (e.g., summarization, paraphrasing)</p></li>
<li><p>Dialogue generation (e.g., simulating interview responses)</p></li>
<li><p>Data augmentation (e.g., generating synthetic survey responses)</p></li>
</ol>
</section>
<section id="prompt-engineering-for-text-generation">
<h2>4. Prompt Engineering for Text Generation<a class="headerlink" href="#prompt-engineering-for-text-generation" title="Link to this heading">#</a></h2>
<p>Effective prompt engineering is crucial for generating high-quality text. Here’s an example of using a structured prompt for generating a research hypothesis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_research_hypothesis</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">variables</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Generate a research hypothesis for a study on </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">    Include the following variables: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">variables</span><span class="p">)</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">    Format: &quot;If [independent variable], then [dependent variable].&quot;</span>
<span class="s2">    Hypothesis:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">topic</span> <span class="o">=</span> <span class="s2">&quot;the effect of remote work on employee productivity&quot;</span>
<span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;remote work frequency&quot;</span><span class="p">,</span> <span class="s2">&quot;productivity metrics&quot;</span><span class="p">,</span> <span class="s2">&quot;job satisfaction&quot;</span><span class="p">]</span>
<span class="n">hypothesis</span> <span class="o">=</span> <span class="n">generate_research_hypothesis</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="controlling-generation-parameters">
<h2>5. Controlling Generation Parameters<a class="headerlink" href="#controlling-generation-parameters" title="Link to this heading">#</a></h2>
<p>To control the quality and creativity of generated text, you can adjust parameters like temperature and top-k/top-p sampling:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">generate_text_with_params</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
        <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
        <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;The long-term effects of social media use on mental health include&quot;</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">generate_text_with_params</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="aspect-based-emotion-summarization">
<h2>6. Aspect-based Emotion Summarization<a class="headerlink" href="#aspect-based-emotion-summarization" title="Link to this heading">#</a></h2>
<p>LLMs can be used to generate emotion-focused summaries of text, which is particularly useful for sentiment analysis research:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">emotion_summary</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">aspect</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Summarize the following text, focusing on emotional content related to </span><span class="si">{</span><span class="n">aspect</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">    Highlight key emotions and their intensity.</span>

<span class="s2">    Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>

<span class="s2">    Emotion-focused summary:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">The new policy has sparked heated debates among citizens. While some praise it as a</span>
<span class="s2">step towards progress, others express deep concerns about its potential negative impacts</span>
<span class="s2">on their daily lives. Social media is flooded with passionate arguments from both sides.</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">aspect</span> <span class="o">=</span> <span class="s2">&quot;public reaction to policy change&quot;</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">emotion_summary</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">aspect</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="misinformation-explanation-generation">
<h2>7. Misinformation Explanation Generation<a class="headerlink" href="#misinformation-explanation-generation" title="Link to this heading">#</a></h2>
<p>LLMs can be used to generate explanations for misinformation, which is valuable for studying the spread and impact of false information:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">explain_misinformation</span><span class="p">(</span><span class="n">claim</span><span class="p">,</span> <span class="n">truth</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Claim: </span><span class="si">{</span><span class="n">claim</span><span class="si">}</span>
<span class="s2">    Factual information: </span><span class="si">{</span><span class="n">truth</span><span class="si">}</span>

<span class="s2">    Explain why the claim is misinformation and provide a detailed correction:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">claim</span> <span class="o">=</span> <span class="s2">&quot;5G networks are responsible for the spread of COVID-19.&quot;</span>
<span class="n">truth</span> <span class="o">=</span> <span class="s2">&quot;COVID-19 is caused by the SARS-CoV-2 virus and is not related to 5G technology.&quot;</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="n">explain_misinformation</span><span class="p">(</span><span class="n">claim</span><span class="p">,</span> <span class="n">truth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">explanation</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="high-quality-content-creation">
<h2>8. High-Quality Content Creation<a class="headerlink" href="#high-quality-content-creation" title="Link to this heading">#</a></h2>
<p>LLMs can assist in creating high-quality content for research purposes, such as generating literature review syntheses:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">literature_review_synthesis</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">key_papers</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Generate a synthesis of the literature on </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">, incorporating the following key papers:</span>
<span class="s2">    </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">key_papers</span><span class="p">)</span><span class="si">}</span>

<span class="s2">    Include:</span>
<span class="s2">    1. Main findings</span>
<span class="s2">    2. Contradictions or debates in the field</span>
<span class="s2">    3. Gaps in current research</span>

<span class="s2">    Literature review synthesis:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">topic</span> <span class="o">=</span> <span class="s2">&quot;the impact of social media on political polarization&quot;</span>
<span class="n">key_papers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Smith et al. (2020)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Johnson &amp; Lee (2019)&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Garcia (2021)&quot;</span>
<span class="p">]</span>
<span class="n">synthesis</span> <span class="o">=</span> <span class="n">literature_review_synthesis</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">key_papers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">synthesis</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="data-augmentation-for-social-science-research">
<h2>9. Data Augmentation for Social Science Research<a class="headerlink" href="#data-augmentation-for-social-science-research" title="Link to this heading">#</a></h2>
<p>LLMs can be used to generate synthetic data, which is useful for balancing datasets or exploring potential research scenarios:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_survey_response</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">demographic</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Generate a realistic survey response for the following question:</span>
<span class="s2">    &quot;</span><span class="si">{</span><span class="n">question</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="s2">    Respondent demographic: </span><span class="si">{</span><span class="n">demographic</span><span class="si">}</span>

<span class="s2">    Response:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">generate_text</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;How has the COVID-19 pandemic affected your work-life balance?&quot;</span>
<span class="n">demographic</span> <span class="o">=</span> <span class="s2">&quot;35-year-old working parent with two children&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">generate_survey_response</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">demographic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="evaluation-of-generated-text">
<h2>10. Evaluation of Generated Text<a class="headerlink" href="#evaluation-of-generated-text" title="Link to this heading">#</a></h2>
<p>When using LLMs for text generation in research, it’s crucial to evaluate the quality of the output. Here’s an example of how you might implement a simple evaluation using the ROUGE metric:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">rouge</span> <span class="kn">import</span> <span class="n">Rouge</span>

<span class="k">def</span> <span class="nf">evaluate_generated_text</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">generated</span><span class="p">):</span>
    <span class="n">rouge</span> <span class="o">=</span> <span class="n">Rouge</span><span class="p">()</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="o">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">reference</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;rouge-l&#39;</span><span class="p">][</span><span class="s1">&#39;f&#39;</span><span class="p">]</span>

<span class="n">reference</span> <span class="o">=</span> <span class="s2">&quot;The study found a strong correlation between social media use and political polarization.&quot;</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">generate_text</span><span class="p">(</span><span class="s2">&quot;The relationship between social media and political polarization&quot;</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">evaluate_generated_text</span><span class="p">(</span><span class="n">reference</span><span class="p">,</span> <span class="n">generated</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ROUGE-L F1 score: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>LLMs offer powerful capabilities for generating high-quality text in social science research contexts. By leveraging techniques such as prompt engineering, parameter tuning, and task-specific adaptations, researchers can use LLMs to assist in various aspects of their work, from hypothesis generation to literature review synthesis and data augmentation.</p>
<p>However, it’s important to note that while LLMs can be incredibly useful tools, they should be used judiciously and with careful evaluation. Researchers should always verify the accuracy of generated content and consider the ethical implications of using AI-generated text in their studies.</p>
<p>As LLM technology continues to advance, we can expect even more sophisticated and tailored applications in social science research, potentially revolutionizing how we approach text-based tasks in the field.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/nlp4ss",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./session04"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/nlp4ss"        data-repo-id="R_kgDOMTcakg"        data-category="Q&A"        data-category-id="DIC_kwDOMTcaks4Cgwzd"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="transparent_dark"        data-lang="en"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Session 4: Generative Explanations and Summaries in Social Science</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4.2 Social Bias Inference and Analysis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-text-generation-with-llms">1. Introduction to Text Generation with LLMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fundamentals-of-llm-based-text-generation">2. Fundamentals of LLM-based Text Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-text-generation-tasks">3. Types of Text Generation Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-for-text-generation">4. Prompt Engineering for Text Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#controlling-generation-parameters">5. Controlling Generation Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aspect-based-emotion-summarization">6. Aspect-based Emotion Summarization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#misinformation-explanation-generation">7. Misinformation Explanation Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-quality-content-creation">8. High-Quality Content Creation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-augmentation-for-social-science-research">9. Data Augmentation for Social Science Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-of-generated-text">10. Evaluation of Generated Text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
