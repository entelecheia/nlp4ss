Search.setIndex({"alltitles": {"1. Introduction to Ethics in AI and NLP Research": [[5, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Fundamental NLP Tasks": [[8, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[4, "introduction-to-generative-llms"]], "1. Introduction to Natural Language Processing (NLP)": [[3, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Text Preprocessing": [[7, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[9, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[11, "introduction-to-zero-shot-learning"]], "1.1 Definition of NLP": [[3, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[3, "fundamentals-of-nlp-and-its-evolution"]], "1.1 Fundamentals of Natural Language Processing and its evolution": [[22, "fundamentals-of-natural-language-processing-and-its-evolution"]], "1.2 Basic Concepts": [[3, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[4, "overview-of-generative-llms"]], "1.2 Overview of Generative Large Language Models (LLMs)": [[22, "overview-of-generative-large-language-models-llms"]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[5, "ethical-considerations-and-challenges-in-using-llms-for-research"], [22, "ethical-considerations-and-challenges-in-using-llms-for-research"]], "1.3 Importance in Social Science Research": [[3, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[9, "applications-in-social-science-research"], [11, "applications-in-social-science-research"]], "10. Current State and Future Directions": [[3, "current-state-and-future-directions"]], "10. Future Directions": [[4, "future-directions"]], "10. Responsible Development and Deployment": [[5, "responsible-development-and-deployment"]], "10.1 Ongoing Developments in LLMs": [[3, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[3, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations of LDA": [[9, "challenges-and-limitations-of-lda"]], "11. Future Challenges and Opportunities": [[5, "future-challenges-and-opportunities"]], "12. Combining Topic Modeling with Other NLP Techniques": [[9, "combining-topic-modeling-with-other-nlp-techniques"]], "13. Future Directions in Topic Modeling": [[9, "future-directions-in-topic-modeling"]], "2. Bias in LLMs": [[5, "bias-in-llms"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[9, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Historical Perspective of NLP": [[3, "historical-perspective-of-nlp"]], "2. Key Components of LLMs": [[4, "key-components-of-llms"]], "2. Text Classification": [[8, "text-classification"]], "2. Text Cleaning": [[7, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[11, "theoretical-foundations-of-zero-shot-learning"]], "2.1 Early Approaches (1950s-1980s)": [[3, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[7, "text-cleaning-normalization-and-representation"], [22, "text-cleaning-normalization-and-representation"]], "2.2 Basic NLP Tasks": [[8, "basic-nlp-tasks"], [22, "basic-nlp-tasks"]], "2.2 Statistical Revolution (1980s-2000s)": [[3, "statistical-revolution-1980s-2000s"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[9, "topic-modeling-and-latent-dirichlet-allocation-lda"], [22, "topic-modeling-and-latent-dirichlet-allocation-lda"]], "3. Lowercase Conversion": [[7, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[9, "mathematical-foundation-of-lda"]], "3. Notable Examples of LLMs": [[4, "notable-examples-of-llms"]], "3. Privacy Concerns": [[5, "privacy-concerns"]], "3. Sentiment Analysis": [[8, "sentiment-analysis"]], "3. Traditional NLP Pipeline": [[3, "traditional-nlp-pipeline"]], "3. Zero-shot Capabilities of LLMs": [[11, "zero-shot-capabilities-of-llms"]], "3.1 Text Preprocessing": [[3, "text-preprocessing"]], "3.1 Zero-shot Learning with LLMs": [[11, "zero-shot-learning-with-llms"], [22, "zero-shot-learning-with-llms"]], "3.2 Feature Extraction": [[3, "feature-extraction"]], "3.2 Few-shot Learning and Prompt Engineering": [[12, "few-shot-learning-and-prompt-engineering"], [22, "few-shot-learning-and-prompt-engineering"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[13, "comparing-llm-performance-with-traditional-supervised-learning"], [22, "comparing-llm-performance-with-traditional-supervised-learning"]], "3.3 Model Training and Evaluation": [[3, "model-training-and-evaluation"]], "4. Capabilities of LLMs in Social Science Contexts": [[4, "capabilities-of-llms-in-social-science-contexts"]], "4. Challenges in Traditional NLP": [[3, "challenges-in-traditional-nlp"]], "4. LDA Algorithm": [[9, "lda-algorithm"]], "4. Named Entity Recognition (NER)": [[8, "named-entity-recognition-ner"]], "4. Prompt Engineering for Zero-shot Tasks": [[11, "prompt-engineering-for-zero-shot-tasks"]], "4. Tokenization": [[7, "tokenization"]], "4. Transparency and Interpretability": [[5, "transparency-and-interpretability"]], "4.1 Handling Language Ambiguity": [[3, "handling-language-ambiguity"]], "4.1 Using LLMs for High-Quality Text Generation": [[15, "using-llms-for-high-quality-text-generation"], [22, "using-llms-for-high-quality-text-generation"]], "4.2 Dealing with Context and Semantics": [[3, "dealing-with-context-and-semantics"]], "4.2 Social Bias Inference and Analysis": [[16, "social-bias-inference-and-analysis"], [22, "social-bias-inference-and-analysis"]], "4.3 Computational Complexity": [[3, "computational-complexity"]], "4.3 Figurative Language Explanation and Cultural Context": [[17, "figurative-language-explanation-and-cultural-context"], [22, "figurative-language-explanation-and-cultural-context"]], "5. Evolution Towards Modern NLP": [[3, "evolution-towards-modern-nlp"]], "5. Part-of-Speech (POS) Tagging": [[8, "part-of-speech-pos-tagging"]], "5. Preparing Data for LDA": [[9, "preparing-data-for-lda"]], "5. Reliability and Reproducibility": [[5, "reliability-and-reproducibility"]], "5. Stop Word Removal": [[7, "stop-word-removal"]], "5. Training Process of LLMs": [[4, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[11, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[19, "analyzing-large-scale-textual-data"], [22, "analyzing-large-scale-textual-data"]], "5.1 Introduction of Word Embeddings": [[3, "introduction-of-word-embeddings"]], "5.2 Misinformation and Fake News Detection": [[20, "misinformation-and-fake-news-detection"], [22, "misinformation-and-fake-news-detection"]], "5.2 Rise of Deep Learning in NLP": [[3, "rise-of-deep-learning-in-nlp"]], "5.3 Future Directions and Emerging Trends": [[21, "future-directions-and-emerging-trends"], [22, "future-directions-and-emerging-trends"]], "6. Advantages of LLMs in Social Science Research": [[4, "advantages-of-llms-in-social-science-research"]], "6. Emergence of Transformer Models": [[3, "emergence-of-transformer-models"]], "6. Implementing LDA": [[9, "implementing-lda"]], "6. Intellectual Property and Attribution": [[5, "intellectual-property-and-attribution"]], "6. Stemming": [[7, "stemming"]], "6. Text Summarization": [[8, "text-summarization"]], "6. Zero-shot Named Entity Recognition (NER)": [[11, "zero-shot-named-entity-recognition-ner"]], "6.1 Key Concepts": [[3, "key-concepts"]], "6.2 Breakthrough Models": [[3, "breakthrough-models"]], "7. Environmental and Resource Considerations": [[5, "environmental-and-resource-considerations"]], "7. Interpreting LDA Results": [[9, "interpreting-lda-results"]], "7. Large Language Models (LLMs)": [[3, "large-language-models-llms"]], "7. Lemmatization": [[7, "lemmatization"]], "7. Limitations and Challenges": [[4, "limitations-and-challenges"]], "7. Text Similarity and Clustering": [[8, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[11, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[3, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[3, "examples-and-their-impact"]], "8. Challenges and Limitations": [[8, "challenges-and-limitations"]], "8. Evaluating Topic Models": [[9, "evaluating-topic-models"]], "8. Paradigm Shift in NLP Tasks": [[3, "paradigm-shift-in-nlp-tasks"]], "8. Recent Advancements": [[4, "recent-advancements"]], "8. Socioeconomic Implications": [[5, "socioeconomic-implications"]], "8. Text Representation Techniques": [[7, "text-representation-techniques"]], "8. Zero-shot Text Summarization and Generation": [[11, "zero-shot-text-summarization-and-generation"]], "8.1 From Task-Specific to General-Purpose Models": [[3, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[3, "few-shot-and-zero-shot-learning"]], "9. Advanced Topic Modeling Techniques": [[9, "advanced-topic-modeling-techniques"]], "9. Applications in Social Science": [[4, "applications-in-social-science"]], "9. Evaluation and Interpretation": [[8, "evaluation-and-interpretation"]], "9. Impact on Social Science Research": [[3, "impact-on-social-science-research"]], "9. Informed Consent and Participant Rights": [[5, "informed-consent-and-participant-rights"]], "9. Zero-shot Question Answering and Information Extraction": [[11, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[3, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[3, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[4, "ability-to-generate-human-like-text"]], "About": [[1, null]], "Access disparities to LLM technologies": [[5, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[4, "adaptability-to-various-domains-and-tasks"]], "Analyzing large-scale textual data": [[4, "analyzing-large-scale-textual-data"]], "BERT and its variants": [[4, "bert-and-its-variants"]], "Bag-of-Words (BoW) model": [[7, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[5, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[5, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[5, "challenges-in-explaining-model-decisions"]], "Changelog": [[1, "changelog"]], "Computational resources required": [[4, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[5, "computational-resources-required-for-training-and-using-llms"]], "Considerations for global and cross-cultural research": [[5, "considerations-for-global-and-cross-cultural-research"]], "Continuous monitoring and evaluation of ethical implications": [[5, "continuous-monitoring-and-evaluation-of-ethical-implications"]], "Contributing": [[1, "contributing"]], "Copyright issues with training data and generated content": [[5, "copyright-issues-with-training-data-and-generated-content"]], "Course Objectives": [[1, "course-objectives"]], "Course Overview": [[1, "course-overview"]], "Course Structure": [[1, "course-structure"]], "Data annotation and classification": [[4, "data-annotation-and-classification"]], "Data protection and compliance with privacy regulations": [[5, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[7, "dealing-with-numbers-and-dates"]], "Definition and core concept": [[4, "definition-and-core-concept"]], "Disclosure of AI involvement in research studies": [[5, "disclosure-of-ai-involvement-in-research-studies"]], "Distinction from traditional NLP models": [[4, "distinction-from-traditional-nlp-models"]], "Emerging ethical issues with advancing LLM capabilities": [[5, "emerging-ethical-issues-with-advancing-llm-capabilities"]], "Enhanced multi-modal capabilities": [[4, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[5, "environmental-impact-of-large-scale-ai-models"]], "Ethical considerations in deployment": [[4, "ethical-considerations-in-deployment"]], "Ethical considerations in model development and fine-tuning": [[5, "ethical-considerations-in-model-development-and-fine-tuning"]], "Ethical considerations when using LLMs in human subjects research": [[5, "ethical-considerations-when-using-llms-in-human-subjects-research"]], "Example: Document Similarity and Clustering": [[8, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[8, "example-extractive-summarization"]], "Example: Lexicon-based Sentiment Analysis": [[8, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[8, "example-multi-class-classification"]], "Example: NER using spaCy": [[8, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[8, "example-pos-tagging-with-nltk"]], "Few-shot and zero-shot learning capabilities": [[4, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[4, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[4, "gpt-generative-pre-trained-transformer-series"]], "Generating explanations and summaries": [[4, "generating-explanations-and-summaries"]], "Handling URLs and email addresses": [[7, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[4, "handling-complex-language-understanding-tasks"]], "Home": [[1, "home"]], "Impact on research outcomes and societal implications": [[5, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[5, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[5, "importance-of-interpretability-in-scientific-research"]], "Importance of reproducibility in scientific research": [[5, "importance-of-reproducibility-in-scientific-research"]], "Improved interpretability and transparency": [[4, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[4, "improvements-in-model-size-and-efficiency"]], "Inferring social patterns and trends": [[4, "inferring-social-patterns-and-trends"]], "Integration with world knowledge and physical world understanding": [[4, "integration-with-world-knowledge-and-physical-world-understanding"]], "Interdisciplinary collaboration in addressing ethical challenges": [[5, "interdisciplinary-collaboration-in-addressing-ethical-challenges"]], "Issues with hallucination and factual accuracy": [[5, "issues-with-hallucination-and-factual-accuracy"]], "Lack of true understanding or reasoning": [[4, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[1, null]], "License": [[1, "license"]], "Other prominent models": [[4, "other-prominent-models"]], "Participant rights and data usage in LLM-based research": [[5, "participant-rights-and-data-usage-in-llm-based-research"]], "Plagiarism concerns and academic integrity": [[5, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[4, "potential-biases-in-training-data"]], "Potential for LLMs in promoting ethical research practices": [[5, "potential-for-llms-in-promoting-ethical-research-practices"]], "Potential for personal information exposure in training data": [[5, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[5, "potential-impact-on-research-equity-and-diversity"]], "Pre-training on large corpora": [[4, "pre-training-on-large-corpora"]], "Progress in mitigating biases and improving factual accuracy": [[4, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Proper attribution of AI-generated text in research": [[5, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[4, "question-answering-and-information-retrieval"]], "Removing HTML tags and special characters": [[7, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[7, "removing-or-replacing-emojis-and-emoticons"]], "Responsible use of LLMs in different research contexts": [[5, "responsible-use-of-llms-in-different-research-contexts"]], "Risks of re-identification in generated text": [[5, "risks-of-re-identification-in-generated-text"]], "Scaled-up training on massive datasets": [[4, "scaled-up-training-on-massive-datasets"]], "Self-attention mechanism": [[4, "self-attention-mechanism"]], "Sentence tokenization": [[7, "sentence-tokenization"]], "Sentiment analysis and emotion detection": [[4, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[2, "session-1-introduction-to-nlp-for-social-science"]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[22, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[6, "session-2-traditional-nlp-techniques-and-text-preprocessing"], [22, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[10, "session-3-llms-for-data-annotation-and-classification"], [22, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[14, "session-4-generative-explanations-and-summaries-in-social-science"], [22, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[18, "session-5-advanced-applications-of-llms-in-social-science-research"], [22, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Sources of bias": [[5, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[5, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[5, "strategies-for-validating-llm-generated-results"]], "Summarization and paraphrasing": [[4, "summarization-and-paraphrasing"]], "Syllabus": [[22, "syllabus"]], "Table of Contents": [[1, "table-of-contents"]], "Techniques for improving model transparency": [[5, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[7, "term-frequency-inverse-document-frequency-tf-idf"]], "Text generation and completion": [[4, "text-generation-and-completion"]], "The \u201cblack box\u201d nature of LLMs": [[5, "the-black-box-nature-of-llms"]], "Transformer architecture": [[4, "transformer-architecture"]], "Translation and cross-lingual tasks": [[4, "translation-and-cross-lingual-tasks"]], "Types of bias": [[5, "types-of-bias"]], "Types of classification:": [[8, "types-of-classification"]], "Unique challenges posed by LLMs": [[5, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, "who-made-this-book"]], "Why This Course Matters": [[1, "why-this-course-matters"]], "Word Embeddings": [[7, "word-embeddings"]], "Word tokenization": [[7, "word-tokenization"]]}, "docnames": ["about/index", "index", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 6, 7, 8, 9, 11], "0": [1, 8, 9, 11], "002": 11, "04": 7, "05": 8, "1": [1, 6, 10, 14, 18], "10": 7, "100": [7, 11], "15": 7, "1500": 7, "175": 4, "18th": 11, "1966": 3, "2": [1, 2, 10, 14, 18], "2017": 3, "2023": 7, "3": [1, 2, 6, 14, 18], "30": 9, "4": 1, "42": [8, 9], "5": 1, "50": 11, "60": 9, "9": 7, "A": [3, 4, 6, 8, 9, 12], "And": 7, "As": [1, 2, 3, 4, 5, 11], "BY": 1, "Be": [8, 11], "By": [1, 5, 6, 9], "For": [3, 6, 7, 8, 9], "In": [1, 2, 4, 5, 6, 8, 9, 11, 12], "It": [2, 7, 8, 9, 11], "One": 12, "The": [1, 2, 3, 4, 7, 8, 9, 11, 22], "These": [1, 3, 4, 6, 8], "To": 9, "abbrevi": 8, "abil": [3, 5, 6, 8, 11], "about": [2, 5, 7, 9], "absolut": 11, "abstract": [2, 9, 11, 19], "academ": [3, 4, 13], "access": [2, 4], "accord": 8, "account": [5, 13], "accur": [6, 8], "accuraci": [3, 8, 12, 13, 15, 20], "achiev": [3, 4, 6, 11], "across": [3, 4, 9, 13, 16, 17, 19, 20], "activ": 12, "adapt": [2, 3, 5, 12, 13, 15, 21], "add": 9, "address": [3, 9, 13, 19, 20], "adjac": 3, "adject": 8, "advanc": [1, 2, 3, 6, 12, 15, 16, 17, 19, 20, 21], "advantag": 12, "advent": 1, "adversari": 13, "advertis": 17, "affect": 5, "after": 7, "ag": 16, "against": 5, "ageism": 16, "agenc": 5, "agreement": 8, "ai": [3, 19, 20, 21], "aim": [1, 3, 4, 11], "albert": 4, "alert": 20, "algorithm": [3, 5, 7, 12, 13, 16, 20], "alik": 8, "all": [2, 3, 4, 11], "alloc": [1, 5, 6], "allow": [3, 4, 5, 6, 9, 11], "almost": 11, "alon": 9, "alongsid": 5, "also": [1, 2, 3, 4, 6, 11], "alwai": [1, 9], "ambigu": 17, "america": 11, "amount": [1, 3, 4, 8], "amp": 7, "amplif": 5, "amplifi": [4, 5], "an": [1, 3, 4, 5, 9, 11, 21], "analys": [3, 6], "analysi": [1, 2, 3, 5, 6, 7, 9, 12, 13, 14, 15, 17, 19, 20, 21], "analyt": 3, "analyz": [1, 5, 6, 7, 8, 9, 11, 16, 17, 18, 20], "analyze_senti": 8, "anger": 11, "ani": [3, 6], "anim": 4, "annot": [1, 2, 8, 11], "announc": 8, "anonym": [5, 19], "anoth": [7, 13], "answer": [2, 3, 12, 19], "anticip": 21, "api": [7, 11, 19, 20], "api_kei": 11, "append": 11, "appl": 8, "appli": [1, 2, 4, 8, 9, 11, 22], "applic": [1, 3, 6, 7, 8, 12, 13, 15, 17, 21], "approach": [1, 2, 4, 5, 8, 9, 12, 13, 16, 17, 20, 22], "appropri": [3, 4, 5, 8, 17], "ar": [1, 3, 4, 5, 6, 7, 8, 9, 11], "architectur": [3, 5, 15, 22], "archiv": 19, "area": [2, 4, 6], "aren": 5, "aris": 5, "arithmet": 3, "around": 3, "arriv": 5, "art": [1, 3, 21], "articl": [3, 4, 8, 9, 20], "artifact": 4, "artifici": [3, 4, 8], "ask": [2, 4], "aspect": [4, 5, 11, 12, 15, 17, 19, 20, 22], "assess": [3, 5, 9, 12, 20, 21], "assign": 8, "assist": [4, 5, 17, 19, 21], "associ": [5, 9, 16], "assum": 9, "assumpt": 9, "attend": 7, "attent": [3, 5], "attitud": [4, 22], "attribut": 9, "attun": 8, "audio": [3, 20, 21], "audit": 5, "augment": [8, 15, 21], "author": 20, "authorit": 5, "autom": [3, 12, 13, 15, 20, 21], "automat": [3, 4, 9], "autoregress": 15, "avail": 3, "averag": 9, "averaged_perceptron_tagg": 8, "avoid": [16, 17, 20], "awai": 2, "awar": [5, 8, 11, 16, 17, 21], "b": [7, 12], "backbon": 6, "bag": [3, 6, 22], "balanc": [15, 17, 19, 20, 21], "bank": 3, "barrier": 4, "base": [1, 2, 3, 4, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "basi": 6, "basic": [1, 6], "bay": [3, 8], "becaus": [2, 4], "becom": [3, 5], "been": [3, 4, 11], "befor": 9, "began": 11, "begin": [1, 6], "behavior": [1, 3, 20, 21], "behind": [4, 8, 9, 11], "being": 6, "belief": 17, "believ": 11, "benchmark": [3, 20], "benefit": [1, 5, 22], "bert": [3, 20], "best": [2, 8, 11, 13, 15], "better": [4, 5, 9, 11], "between": [1, 2, 3, 4, 5, 8, 9, 11, 13, 19, 22], "beyond": [3, 4], "bia": [1, 2, 3, 13, 14, 19, 20, 21], "bias": [1, 5, 8, 11, 13, 16, 19, 22], "bidirect": [3, 4], "big": 19, "billion": 4, "binari": [8, 13], "biodivers": 8, "bleu": 15, "block": 6, "book": [1, 4], "bot": 20, "both": [1, 2, 4, 9, 13], "boundari": 6, "bow_matrix": 7, "bow_represent": 7, "brand": 17, "breadth": 19, "break": [3, 7], "bridg": [1, 2, 3, 21], "bring": 5, "britain": 11, "broader": 5, "brought": 3, "brown": [7, 8], "buffer": 11, "build": [2, 6, 19, 20], "built": [4, 6], "busi": 19, "c_v": 9, "calcul": [3, 8, 9], "campaign": 20, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "cannot": 7, "capabl": [1, 2, 8, 12, 13, 15, 17, 19, 21, 22], "captur": [3, 4, 7, 11], "car": 5, "carbon": [5, 11], "care": [3, 4, 8], "carefulli": [4, 5, 9], "carri": 7, "case": [7, 13, 16, 19, 20, 22], "cat": [3, 8, 9], "categor": [3, 4, 8, 19], "categori": [3, 4, 8, 11], "causal": 21, "cc": 1, "centuri": 11, "ceo": 8, "certain": 5, "challeng": [1, 2, 12, 15, 16, 17, 19, 20, 21], "championship": 8, "chang": [4, 8, 9, 11, 17, 19, 21], "charact": [3, 9], "character": 9, "characterist": 20, "chase": 9, "chatbot": 3, "check": [7, 15, 20], "child": 7, "children": 7, "choic": 11, "chomski": 3, "choos": [8, 11, 13], "citi": 8, "citizen": 5, "claim": 20, "class": [11, 12, 13, 16, 19], "classif": [1, 3, 6, 12, 13, 16, 19, 20], "classifi": [3, 4, 8, 11], "classification_report": 8, "clean": [1, 6, 9, 19], "clean_html": 7, "clean_text": 7, "cleaned_text": 7, "clear": [5, 11], "clearer": 6, "clf": 8, "climat": [4, 8, 9, 11, 21], "close": 3, "cloud": 19, "cloudi": 8, "cloze": 16, "cluster": 3, "cluster_docu": 8, "cnn": [3, 20], "code": [3, 4, 6, 11, 15, 19], "code_survey_respons": 11, "coded_data": 11, "coded_respons": 11, "coded_them": 11, "cognit": 21, "coher": [3, 4, 8, 9, 12, 13, 15], "coherence_model": 9, "coherence_scor": 9, "coherencemodel": 9, "collabor": [3, 16, 21, 22], "collect": [3, 6, 9, 19, 20], "column": 9, "com": 7, "combin": [3, 5, 8, 12, 13, 15], "come": [1, 5, 6, 8], "comma": 11, "commit": 5, "common": [7, 8, 9, 11, 13], "commun": [3, 8, 17, 19, 22], "compar": [1, 10, 12, 16, 17, 20], "comparison": [12, 13, 15, 16, 17, 19], "complet": [3, 11], "complex": [2, 5, 6, 8, 12, 13, 21], "compon": 12, "composit": 17, "compound": [8, 16], "comprehens": [4, 8], "comput": [8, 13, 17, 19], "concept": [6, 11, 12, 13, 22], "concern": [2, 3, 8, 16, 17, 20], "concis": 8, "conclus": [5, 9, 11], "condens": 4, "confid": 5, "confound": 13, "consent": [4, 19], "consequ": [8, 21], "consid": [2, 3, 4, 5, 7, 9], "consider": [1, 2, 3, 12, 13, 15, 16, 17, 19, 20, 21], "consist": [3, 4, 7, 11, 12, 13, 15, 20], "constantli": 1, "constrain": 15, "constraint": 4, "construct": 19, "consum": 8, "consumpt": 5, "contain": [1, 4, 8], "contemporari": [4, 5], "content": [3, 4, 7, 8, 12, 15, 17, 20, 21], "context": [1, 2, 8, 11, 12, 13, 14, 20, 21], "contextu": [3, 4, 8, 16, 20, 21], "continu": [3, 4, 11], "contribut": 7, "control": [5, 12, 15, 20], "convert": [3, 7, 9], "convolut": 3, "cook": 8, "coordin": 20, "core": 11, "cornerston": 5, "corpora": [3, 6, 9, 11, 19], "corpu": [3, 7, 8, 9, 19], "correct": [7, 15], "correl": 9, "correspond": 8, "cosin": 8, "cosine_similar": 8, "cost": [3, 5], "could": [3, 4, 5], "counter": 20, "countermeasur": 20, "countvector": 7, "cours": [2, 6, 22], "cover": [2, 6], "craft": [3, 15], "creat": [0, 3, 4, 8, 9, 11, 15, 19, 20], "creation": 15, "creativ": [13, 15], "credibl": 20, "crisi": 21, "criteria": 15, "critic": [1, 2, 4, 21, 22], "cross": [3, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "crucial": [2, 3, 4, 5, 6, 7, 8, 11], "csv": [9, 19], "cultur": [1, 4, 8, 11, 14, 15, 16, 19, 20, 21], "curat": 5, "current": 21, "custom": [8, 16], "cut": [1, 2], "d": [7, 9], "dai": 11, "daili": 11, "dall": 4, "data": [1, 2, 6, 7, 8, 11, 13, 15, 16, 18, 20, 21], "databas": 20, "datafram": 9, "dataset": [1, 5, 6, 8, 11, 13, 15, 19, 20, 22], "date": [9, 11], "davinci": 11, "deal": [5, 19, 20], "debat": 9, "debias": 16, "decept": [5, 20], "decis": [4, 8, 13, 20], "deep": [2, 9, 20], "deepen": 1, "deeper": 17, "deepfak": 20, "def": [7, 8, 9, 11], "definit": [12, 16, 17, 19, 20], "delv": 6, "demograph": 13, "demoj": 7, "demonstr": [3, 8, 9, 11, 12], "dens": [3, 7], "depend": [3, 4, 5, 7, 13, 17, 20], "deploi": 16, "deploy": 16, "depth": 19, "describ": 3, "descript": [4, 11, 12], "design": [1, 2, 4, 5, 11, 12, 16, 22], "despit": 4, "detail": [4, 5, 7], "detect": [1, 9, 16, 17, 18, 19, 21], "determin": [8, 9], "develop": [1, 4, 9, 15, 16, 17, 20, 21, 22], "devic": 17, "df": 9, "diachron": [17, 19], "diagram": 9, "dialogu": [5, 15], "dictionari": [8, 9], "didn": 4, "differ": [4, 8, 9, 11, 13, 15, 16, 17, 19], "difficult": [8, 9], "diffus": 20, "digit": [3, 19], "dimens": [5, 7], "dimension": 3, "direct": [1, 12, 13, 15, 16, 17, 18, 19, 20], "dirichlet": [1, 6], "disadvantag": 5, "discours": [3, 9, 17, 21], "discov": [1, 8, 9], "discuss": [2, 4, 6, 9], "distant": 8, "distribut": [9, 13, 19], "dive": [1, 6], "divers": [4, 15, 19], "do": 1, "doc": [8, 9], "doc2bow": 9, "doc_lda": 9, "document": [1, 3, 4, 6, 9, 19, 22], "dog": [7, 8, 9], "domain": [3, 8, 9, 11, 12, 13, 15, 16, 19, 20], "domin": 9, "dominant_top": 9, "don": [2, 4, 7], "dot": 9, "download": [7, 8, 9], "downstream": [7, 16], "dr": 11, "draw": 9, "driven": [3, 21], "due": 3, "dure": [11, 20], "dynam": [1, 9, 19, 20], "e": [3, 4, 5, 7, 8, 9, 15, 16, 19, 20], "each": [1, 3, 4, 7, 9, 22], "earli": 20, "easier": 7, "easili": [7, 9], "econom": [9, 11, 16], "economi": 11, "edg": [1, 2], "educ": [11, 20], "effect": [1, 5, 6, 11, 12, 13, 15, 20, 22], "effici": [3, 6, 8, 13, 19, 21], "elect": 20, "element": [7, 9], "elicit": 16, "elif": 8, "elimin": 3, "eliza": 3, "els": 8, "embark": [1, 2], "embed": [9, 11, 16, 19, 22], "emerg": [1, 4, 13, 18, 19, 20], "emiss": 11, "emot": [8, 9, 15, 17, 19, 22], "emphas": [1, 2, 3], "emploi": 5, "en_core_web_sm": 8, "enabl": 3, "encod": [3, 4, 11], "encompass": [3, 8], "encount": 3, "encourag": [2, 22], "end": [1, 3, 4, 6, 8, 11, 15], "energi": [5, 11, 21], "engag": [2, 20], "engin": [1, 3, 10, 13, 15, 20], "english": [5, 7, 8, 9], "enhanc": [3, 6, 9, 11, 15, 21], "enorm": 4, "ensembl": [12, 13, 20], "ensur": [2, 4, 15, 19], "ent": 8, "enthusiasm": 4, "entir": 5, "entiti": [4, 6, 7, 12, 13, 19, 22], "entity_typ": 11, "entitytyp": 11, "enumer": 8, "environ": [11, 21], "environment": [3, 11, 21], "equal": [5, 6], "equip": 1, "equival": 5, "era": 3, "especi": [6, 7], "essenti": 6, "etc": [17, 19, 20], "ethic": [1, 2, 3, 13, 15, 16, 17, 19, 20, 21], "ethicist": 5, "ethnic": 16, "eu": 5, "euphem": 17, "europ": 11, "evalu": [1, 12, 13, 15, 17, 20, 22], "even": [2, 4, 6, 11], "event": [5, 7, 19, 21], "everi": 11, "evid": 21, "evolut": [1, 2, 17, 20], "evolv": [3, 4, 5, 9, 11, 12, 16, 17, 20, 21], "exacerb": 5, "exactli": 5, "exampl": [5, 6, 7, 9, 11, 12, 13, 16, 22], "excel": 4, "excit": [1, 2, 4], "exclus": 8, "execut": 19, "exercis": 22, "exhibit": [3, 9], "exist": [5, 16], "expand": 4, "expect": 11, "experi": [1, 6, 9], "experiment": [9, 15], "expert": 3, "expertis": [9, 20], "explain": [4, 13, 17, 20, 21, 22], "explan": [1, 3, 5, 15, 20], "explanatori": 5, "explicit": 13, "explicitli": [3, 4, 11], "explor": [1, 2, 3, 4, 6, 7, 9], "exploratori": 11, "express": [4, 7, 8, 11, 17], "extend": 12, "extern": 20, "extract": [4, 12, 13, 15, 19], "f": [7, 8, 9, 11], "f1": [3, 8, 13], "fabric": 5, "face": [3, 15], "facebook": 19, "facilit": [4, 12], "fact": [15, 19, 20], "factor": 16, "factual": [3, 15], "fail": 3, "fair": [13, 21], "fake": [1, 18], "fallaci": 20, "fals": [15, 22], "fascin": 1, "favor": 5, "fear": 11, "featur": [8, 13, 20], "feature_extract": [7, 8], "feature_nam": 7, "feedback": 8, "few": [1, 10, 11, 13, 15, 16, 20, 21], "fewer": 4, "field": [1, 2, 3, 11], "figur": [1, 14], "file": 9, "filtered_text": 7, "final": [1, 6], "financ": 8, "financi": [3, 19, 22], "find": [4, 5, 16], "fine": [3, 11, 12, 13, 15], "first": [7, 9], "fit": 8, "fit_transform": [7, 8], "five": 1, "flaw": 5, "floor": 8, "flow": 19, "flower": 8, "focu": [3, 4, 6, 9, 11, 22], "focus": [3, 4, 6, 15], "follow": 11, "footprint": 5, "forest": 20, "form": [3, 6, 7, 15], "formal": 3, "format": [3, 7, 11, 19], "formul": [4, 12, 21], "forward": 4, "foster": [5, 21], "foundat": 6, "fox": [7, 8], "frame": [2, 4], "framework": [13, 16, 19, 21], "free": [3, 20], "frequenc": [3, 8], "friendli": 3, "from": [1, 2, 5, 7, 8, 9, 11, 19], "full": [3, 8], "fulli": 12, "function": 9, "fundament": [1, 2, 6, 7, 12, 15], "further": [4, 11], "futur": [1, 12, 13, 15, 16, 17, 18, 19, 20], "g": [3, 4, 5, 7, 8, 9, 15, 16, 19, 20], "gain": [1, 2, 8, 9, 11], "game": 8, "gap": [1, 2, 3, 4], "gather": 20, "gaug": 3, "gdpr": 5, "gender": [4, 5, 16], "gener": [1, 2, 8, 9, 12, 13, 16, 17, 19, 20, 21], "gensim": [6, 7, 9], "get": [8, 9], "get_coher": 9, "get_dominant_top": 9, "get_feature_names_out": 7, "get_senti": 9, "get_word_embed": 7, "gibb": 9, "gigaword": 7, "given": [3, 4, 8, 9], "global": 3, "glove": 7, "go": [4, 8], "goal": [2, 3, 8], "govern": [11, 19], "gpt": [3, 11, 22], "grain": 11, "gram": 3, "grammar": 3, "grammat": [3, 8], "graph": [19, 20], "grasp": [3, 4], "great": [1, 11], "green": 21, "grew": 3, "groundbreak": 11, "group": [5, 7, 8], "groupbi": 9, "grow": 2, "growth": 3, "guidelin": [1, 13], "ha": [1, 2, 3, 5, 6, 9, 11], "had": 2, "hadoop": 19, "hallucin": [3, 15], "hand": [1, 3, 6, 22], "handl": [9, 11, 12, 13, 15, 17, 19, 20], "har": [1, 2, 3, 4, 5], "hardwar": 13, "harm": 5, "harvard": 11, "hasn": 4, "have": [1, 2, 3, 5, 6, 8, 9], "haven": 11, "health": [19, 20], "healthcar": [11, 16], "heapq": 8, "held": 3, "help": [4, 5, 7, 8, 9], "here": [1, 7, 8, 11], "hesit": 2, "hidden": [3, 9], "hierarch": [3, 9, 19], "hierarchi": 9, "high": [1, 3, 5, 14], "higher": 9, "hill": 3, "histor": [1, 4, 5, 8, 9, 16, 17, 20], "histori": 11, "hold": 3, "hop": 12, "how": [1, 2, 4, 5, 6, 8, 9, 11, 12], "howev": [1, 4, 6, 7, 11], "html": 9, "html_text": 7, "http": 7, "hug": 15, "human": [1, 3, 8, 9, 13, 15, 17, 20, 21], "humor": 17, "hundr": 4, "hybrid": [12, 13], "hypothes": [3, 4, 15], "hypothesi": [19, 21], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "id2word": 9, "idea": [4, 11], "identif": 20, "identifi": [3, 4, 5, 8, 9, 11, 17, 19, 20, 22], "idf": [3, 6, 8, 22], "idiom": [17, 22], "idiomat": [4, 17], "idx": 9, "illustr": 6, "imag": [3, 4, 15, 17, 20, 21], "imagin": 21, "imbal": 19, "imbalanc": [13, 15], "immers": 21, "impact": [2, 4, 8, 16, 19, 20, 21, 22], "implement": [6, 8, 15, 19], "impli": 3, "implic": [2, 3, 4, 13, 16, 21], "implicit": 13, "import": [2, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "improv": [3, 7, 9, 12, 20, 21], "inadvert": 5, "inauthent": 20, "inc": 8, "includ": [2, 3, 5, 6, 7, 8, 9, 11, 22], "inconsist": [5, 20], "incorpor": [9, 12, 20], "incorrect": [4, 5], "increas": [3, 4], "increasingli": 3, "index": 19, "indic": 9, "individu": [3, 5, 21], "industri": 11, "inequ": 5, "infeas": 3, "infer": [1, 9, 13, 14, 21], "influenc": [3, 11, 19], "info": 7, "inform": [1, 7, 8, 12, 13, 15, 19, 20, 22], "infrastructur": 13, "inher": 3, "initi": 4, "input": [3, 4, 5, 13], "insight": [2, 3, 4, 6, 8, 9], "inspir": 21, "instanc": 3, "institut": [3, 5], "instruct": 11, "instrument": 15, "integr": [3, 12, 15, 17, 19, 20, 21, 22], "intellig": [3, 4, 8, 21], "inter": 8, "interact": [8, 19, 21, 22], "interdisciplinari": [3, 20], "interest": [2, 22], "interfer": 7, "intern": [4, 5], "internet": 17, "interpret": [2, 3, 6, 11, 13, 16, 17, 20, 21, 22], "intersect": [1, 2, 16, 22], "intersection": 16, "intervent": [16, 20], "interview": 4, "introduc": [3, 5, 6], "introduct": [1, 12, 13, 15, 16, 17, 19, 20, 21], "introductori": 2, "intuit": 9, "invers": 3, "investig": [19, 20], "involv": [3, 7, 8], "ironi": [3, 8, 17], "irrelev": [3, 7], "isn": 2, "issu": [2, 3, 4, 8, 11, 19, 22], "iter": [4, 12], "its": [1, 2, 5, 8, 11], "jane": 11, "job": 11, "joi": 11, "join": [7, 8, 11], "journal": 11, "journei": [1, 2], "json": 19, "judgment": 20, "jump": [7, 8], "just": [2, 4], "k": [8, 9, 12, 15], "keen": 5, "keep": 1, "kei": [2, 6, 8, 9, 11, 12, 13], "kind": 9, "king": 3, "kmean": 8, "knowledg": [1, 3, 11, 12, 15, 17, 19, 20, 21], "label": [3, 8, 11, 12], "label_": 8, "labels_": 8, "lambda": 9, "landscap": 3, "languag": [1, 2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21], "larg": [1, 2, 6, 8, 9, 11, 12, 18, 21], "last": 11, "late": 11, "latent": [1, 6], "later": 6, "latest": 4, "lazi": [7, 8], "lda": [1, 6, 19], "lda_model": 9, "lda_result": 9, "lda_visu": 9, "ldamodel": 9, "lead": [5, 11], "leap": 4, "learn": [1, 2, 6, 7, 8, 9, 10, 16, 20, 21], "lectur": 22, "legal": [5, 8, 16], "lemmat": [3, 6, 9, 22], "lemmatize_word": 7, "lemmatized_text": 7, "len": 9, "length": 15, "less": [5, 8], "lesson": 13, "let": [1, 2, 6, 7, 8, 11], "level": [3, 16, 21], "leverag": [1, 2, 6, 11, 13, 20], "lexic": 3, "li": 8, "librari": [1, 6, 8, 9, 15, 19, 22], "life": 11, "lifecycl": 20, "lifetim": 5, "like": [3, 5, 6, 8, 9], "lime": 5, "limit": [1, 2, 3, 5, 12, 17, 19, 20, 22], "line": 9, "lingual": [3, 9, 12, 13, 15, 17, 19, 20, 21], "linguist": [3, 7, 8, 20], "link": [17, 20], "list": 11, "liter": [3, 17], "literaci": 20, "literari": 17, "literatur": [3, 4, 15, 17], "ll": [1, 2, 6, 8, 9], "llm": [1, 2, 6, 12, 14, 16, 17, 19, 20, 21], "load": [7, 8], "local": [8, 15], "locat": [3, 8], "logic": 20, "long": [3, 4, 6, 11, 15, 21], "long_text": 11, "longer": 8, "look": 11, "lotteri": 11, "love": [7, 8, 11], "low": [8, 12, 20, 21], "lower": [7, 8, 9], "lowercas": [3, 9], "lowercased_text": 7, "lstm": 3, "m": 9, "machin": [3, 7, 8, 9, 11, 12, 19, 20], "made": [1, 2], "mai": [4, 5, 7, 8, 9], "main": [4, 6, 9, 11], "maintain": [5, 15], "major": 11, "make": [4, 5, 7, 8, 11, 13], "man": 3, "manag": [19, 21], "mani": [6, 7, 8], "manifest": 16, "manipul": [5, 20], "manual": [3, 8, 9], "map": 13, "mark": [8, 11], "market": [8, 11, 17], "markov": 3, "massiv": [3, 11], "master": 6, "mat": [3, 8, 9], "match": 3, "materi": 5, "matrix": 8, "max": 9, "max_token": 11, "max_word": 11, "mean": [3, 4, 7, 8, 9, 17], "meaning": [6, 9], "measur": [8, 16, 17], "mechan": [3, 12], "media": [1, 3, 4, 5, 7, 8, 9, 16, 17, 19, 20, 21, 22], "medic": [8, 19, 22], "meme": 17, "memor": 5, "memori": 3, "meta": 12, "metaphor": [17, 22], "meteor": 15, "method": [1, 3, 5, 6, 8, 9, 12, 13, 15, 16, 19, 20], "methodolog": 13, "methodologi": [1, 2, 3, 4, 5, 11, 13, 15, 16, 21, 22], "metric": [3, 8, 9, 12, 13, 15, 16, 17, 20], "might": [2, 3, 4, 5, 7, 8, 9], "mind": 1, "mine": [3, 12, 13], "minim": 4, "misinform": [1, 15, 18], "mislead": 5, "misrepres": 5, "misus": 4, "mitig": [13, 16, 19, 20, 21], "mix": 19, "mixtur": 9, "modal": [12, 15, 21], "model": [1, 2, 6, 8, 11, 12, 13, 15, 16, 19, 20, 21], "model_nam": 7, "model_select": 8, "modern": [1, 2, 22], "monitor": [16, 21], "month": [8, 11], "more": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "most": [9, 11], "move": 1, "movi": [3, 7], "much": [2, 7], "multi": [11, 12, 13, 15, 19], "multilingu": [15, 16, 19, 20, 21], "multimod": [3, 4, 17, 19, 20, 21], "multinomi": 9, "multinomialnb": 8, "multipl": [3, 4, 5, 8, 9, 17], "must": [4, 5], "mutual": 8, "my": 11, "n": [3, 8, 9, 11], "n_cluster": 8, "naiv": [3, 8], "naive_bay": 8, "name": [4, 6, 7, 12, 13, 19, 22], "narr": 20, "natur": [1, 2, 4, 6, 7, 8, 11, 16], "navig": 5, "ncategori": 11, "necessari": [5, 6], "need": [3, 4, 7, 9, 11], "neg": [3, 4, 8, 11], "ner": [12, 13], "network": [3, 4, 19, 20, 21], "neural": [3, 4, 9, 21], "neuro": 21, "neutral": [8, 11], "never": [3, 11], "new": [1, 2, 4, 5, 8, 9, 11, 12, 13, 18, 19], "newer": 4, "next": [4, 8], "nlargest": 8, "nlp": [1, 7, 12, 16, 17, 21], "nltk": [6, 7, 9], "noam": 3, "nois": [3, 7, 19], "non": [8, 17], "none": 11, "nonstandard": 8, "normal": [1, 6, 19], "north": 11, "notabl": 5, "notat": 9, "noun": 8, "novel": [3, 11], "now": [2, 3, 4, 11], "nsimilar": 8, "ntext": 11, "ntopic": 9, "nuanc": [3, 4, 8, 13, 17], "num": 7, "num_clust": 8, "num_sent": 8, "num_top": 9, "number": 9, "numer": [3, 6], "observ": 9, "occup": 16, "occur": [3, 9], "offer": [1, 3, 4, 5, 6, 11], "often": [3, 4, 5, 6, 8, 9], "one": [3, 7, 9, 11, 13], "ongo": [4, 5, 9], "onli": [1, 3, 4], "onlin": [8, 17, 21], "open": [1, 3, 4, 8, 11, 15], "openai": 11, "opinion": [3, 4, 8, 12, 13, 19, 20, 21, 22], "opportun": [1, 2, 19], "optim": [9, 12], "order": 12, "organ": [8, 9, 11], "origin": 3, "other": [5, 8, 11, 12, 19, 20], "our": [1, 2, 3, 6, 7, 9], "out": [3, 7, 13, 19], "outdat": 5, "output": [4, 7, 11, 12, 13], "over": [5, 7, 8, 9, 12, 13, 17], "overst": 7, "overview": [2, 13, 15, 16, 19, 21], "own": [2, 22], "ownership": 5, "p": [7, 15], "pairwis": 8, "panda": 9, "pandem": 20, "paper": [4, 11], "paradigm": [11, 13, 21], "paragraph": 4, "parallel": 4, "paramet": [4, 9, 15], "paramount": 5, "paraphras": 15, "pars": 3, "part": [3, 11], "partial": 4, "particular": [4, 5, 8], "particularli": [1, 2, 3, 5, 7, 8, 9, 11], "pattern": [3, 8, 9, 12, 20, 22], "pd": 9, "penalti": 15, "peopl": [7, 8], "per": [8, 9], "perform": [1, 3, 4, 7, 8, 9, 10, 11, 12, 20], "perform_n": 8, "perpetu": [4, 5], "person": [8, 11, 19, 21], "perspect": 5, "phenomena": [1, 4, 12, 19], "piec": 8, "pipelin": [7, 16, 19], "place": 7, "placehold": 7, "plai": [7, 8], "plan": 8, "planet": 8, "plate": 9, "platform": [19, 20], "plausibl": [4, 5], "pleas": 1, "plot": 9, "point": [2, 4, 11], "polar": [4, 9], "polarity_scor": 8, "polici": [8, 9, 11, 19, 20, 21], "policymak": [5, 21], "polit": [3, 4, 8, 9, 11, 17], "poorli": [8, 9], "popul": 5, "popular": [6, 8, 9], "porterstemm": 7, "pos_tag": 8, "pos_tag_text": 8, "pose": 2, "posit": [3, 4, 8, 9, 11, 22], "possibl": [1, 4, 6, 11], "post": [1, 3, 4, 5, 8, 16, 22], "potenti": [1, 3, 8, 11, 12, 13, 15, 17, 19, 20, 21], "power": [1, 2, 3, 4, 5, 8, 9, 11], "practic": [1, 6, 13, 15, 21, 22], "pragmat": 3, "pre": [2, 3, 9, 11], "precis": [3, 13], "predefin": [8, 11], "predic": 3, "predict": [4, 8, 11, 13], "prepar": [6, 21], "preprocess": [1, 9, 19, 20], "preprocess_text": 9, "presenc": 9, "present": [3, 4, 5], "preserv": [8, 17, 21], "press": 11, "preval": 9, "prevent": 5, "previous": 3, "primari": [3, 11], "primarili": [3, 5], "principl": [2, 5, 11, 22], "print": [7, 8, 9, 11], "print_top": 9, "prior": 9, "privaci": [2, 3, 4, 16, 17, 19, 20, 21, 22], "prob": 9, "probabilist": [3, 9], "probabl": 9, "probe": [5, 16], "problem": [3, 4, 9], "process": [1, 2, 5, 6, 7, 8, 9, 13, 15, 16, 17, 19, 20, 21], "processed_doc": 9, "processed_text": [7, 9], "produc": [4, 5, 7], "product": 19, "profess": 5, "profil": 20, "program": [3, 8], "progress": [2, 3, 21], "project": 1, "prompt": [1, 3, 4, 10, 13, 15, 16, 20], "propag": [16, 20], "proper": 6, "proport": 9, "propos": 3, "protect": 11, "protocol": [15, 17], "prototyp": 12, "proverb": 17, "proverbi": 17, "provid": [3, 4, 5, 6, 7, 8, 11], "psycholinguist": 21, "psychotherapist": 3, "public": [3, 4, 8, 11, 13, 19, 20, 21, 22], "publish": 11, "punkt": [8, 9], "purpos": [5, 8], "push": 6, "pyldavi": 9, "python": [1, 6, 22], "qa": 12, "qualit": [3, 4, 6, 8, 9, 15], "qualiti": [1, 9, 14, 19], "quantifi": [16, 17, 19], "quantit": 9, "queen": 3, "question": [1, 2, 3, 5, 7, 8, 9, 12, 15, 19], "quick": [3, 7, 8], "quickli": [3, 7, 8, 11], "r": [7, 9], "racial": [5, 16], "rais": 5, "ralli": 11, "random": [9, 20], "random_st": [8, 9], "rang": [2, 3, 4, 8, 9, 11], "rapid": [3, 11, 12, 20], "rapidli": 17, "raw": [6, 7], "re": [1, 2, 6, 7, 9], "read_csv": 9, "real": [1, 3, 11, 13, 16, 19, 20, 21], "realiti": 21, "reason": [3, 6, 8, 21], "recal": [3, 13], "recap": [13, 15], "receiv": 4, "recent": [1, 2, 6], "recognit": [4, 6, 7, 12, 13, 19, 22], "recommend": 13, "record": [19, 22], "recurr": 3, "reddit": 19, "redefin": 21, "reduc": [3, 4, 7, 11, 19], "reduct": 16, "refer": [4, 8], "referenc": 5, "refin": 12, "reflect": 5, "refram": 22, "regardless": 6, "region": 5, "regress": 13, "regular": [5, 7], "reinforc": [5, 16], "rel": 16, "relat": [13, 16, 17, 19, 20], "relationship": [3, 7, 9, 11, 12, 19], "releas": 1, "relev": [1, 3, 6, 7, 9, 12, 13, 22], "reli": 3, "reliabl": [4, 12, 20], "remain": [6, 8], "remark": 3, "rememb": [2, 6, 8, 9], "remov": [3, 9], "remove_stopword": 7, "remove_urls_email": 7, "renew": 11, "repeat": 9, "repetit": 15, "rephras": 4, "replac": 8, "replace_emoji": 7, "report": [13, 16, 19], "repres": [3, 4, 5, 6, 7, 9, 19], "represent": [1, 3, 4, 5, 6, 13], "reproduc": [15, 19], "requir": [2, 3, 9, 13], "researc": 20, "research": [1, 2, 6, 8, 12, 13, 15, 16, 17, 19, 20, 21], "resourc": [8, 12, 13, 19, 20, 21], "respect": 17, "respons": [1, 2, 3, 4, 8, 9, 11, 16, 21, 22], "responsibli": 1, "result": [2, 3, 6, 8, 11, 12, 13, 22], "retriev": [15, 19], "return": [7, 8, 9, 11], "reveal": [3, 8], "revers": 9, "review": [3, 4, 15, 19], "revolut": 11, "revolution": 3, "revolutionari": [1, 2], "rewrit": 4, "right": 11, "rigor": 5, "rise": 8, "river": 3, "rnn": [3, 20], "roberta": 4, "robust": [12, 13], "role": [5, 12, 17, 21], "root": [3, 7], "roug": 15, "rule": [2, 3], "run": [3, 4, 5, 7], "runner": 7, "sad": 11, "same": 5, "sampl": [7, 8, 9, 15, 19], "sample_text": 7, "sarcasm": [3, 8, 17], "sat": [3, 8, 9], "save": [3, 9], "save_html": 9, "saw": [3, 8, 11], "scalabl": [3, 12, 13, 19], "scale": [1, 2, 3, 9, 12, 18, 21], "scenario": [4, 8, 11, 12, 13, 21], "scheme": 15, "scienc": [1, 6, 7, 8, 12, 13, 15, 16, 17, 19, 20, 21], "scientist": [1, 2, 4, 5, 8, 9, 21, 22], "scikit": [6, 8], "score": [3, 8, 9, 13], "scrape": [5, 7, 19, 20], "scratch": 2, "scrutini": 4, "search": 19, "seat": 16, "second": 7, "section": 9, "sector": 11, "see": [1, 3], "seek": 1, "seen": [8, 11], "select": [8, 12, 13], "self": 3, "semant": [7, 11, 19, 20], "sens": 4, "sensit": [5, 12, 17, 20], "sensori": 17, "sent_token": [7, 8], "sentenc": [3, 4, 8], "sentence_scor": 8, "sentiment": [3, 6, 7, 9, 12, 13, 15, 16, 17, 19, 22], "sentiment_by_top": 9, "sentimentintensityanalyz": 8, "separ": [3, 11], "sequenc": [3, 4], "sequenti": 3, "seri": [3, 8, 19, 20], "session": 1, "set": [3, 7, 8, 9, 12], "sever": [3, 5, 6], "shap": 5, "shape": 17, "share": 19, "shift": [2, 4, 17, 21], "short": [3, 9], "shot": [1, 10, 13, 15, 16, 20, 21], "should": [5, 8, 11], "show": [8, 9], "sia": 8, "signal": 20, "signific": [3, 4, 5, 8, 11, 13, 16], "significantli": [3, 7], "simil": 17, "similar": [3, 7, 19], "similarity_matrix": 8, "simpl": [4, 8], "simul": [3, 21], "singl": [4, 5], "situat": 16, "size": [7, 9, 13], "skew": 5, "skill": [1, 6, 21], "sklearn": [7, 8], "slang": [8, 17], "small": 9, "smaller": [6, 7], "smiling_face_with_heart_ey": 7, "smith": 11, "snippet": 6, "so": [1, 8], "social": [1, 6, 7, 8, 12, 13, 15, 17, 19, 20, 21], "social_media_data": 9, "societ": [1, 21], "societi": [3, 5, 20, 21], "socioeconom": 16, "sociolinguist": 17, "sociologi": 7, "solar": 8, "sole": 11, "solid": 6, "solut": 19, "solv": 3, "some": [4, 8, 9, 11], "sophist": [3, 4, 5, 9, 11], "sound": [4, 5], "sourc": [4, 16, 19, 20], "space": [3, 21], "spam": 8, "spark": 19, "speaker": 3, "special": [8, 9, 15, 20, 21], "specif": [2, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17], "specul": 21, "speech": [3, 17, 20], "speed": [13, 20], "split": [8, 11], "spoken": 8, "sport": [8, 11], "spread": [11, 20, 22], "spreader": 20, "stage": 3, "stanc": 20, "standard": [7, 16], "standardize_numb": 7, "state": [1, 21], "statist": [5, 9, 13, 16], "statu": 16, "stem": [3, 6, 9, 22], "stem_word": 7, "stemmed_text": 7, "step": [6, 7], "stereotyp": [5, 16, 17], "stimuli": 15, "stock": [8, 11], "stop": [8, 11], "stop_word": [7, 8, 9], "stopword": [7, 8, 9], "store": [3, 8], "stori": 20, "strategi": [4, 12, 13, 15, 16, 19, 20], "stream": [19, 21], "street": 4, "strength": 13, "strip": 11, "strong": 6, "structur": [3, 8, 9, 12, 13, 20, 21], "struggl": [3, 5], "student": 22, "studi": [3, 4, 8, 11, 12, 13, 16, 17, 19, 20, 21, 22], "style": [12, 15], "stylist": [15, 17], "sub": [7, 9], "subfield": 8, "subject": [3, 16, 20], "substitut": 3, "subword": 3, "suitabl": 8, "summar": [3, 12, 15, 16, 19, 22], "summari": [1, 5, 8, 11, 15, 19], "summarize_text": 8, "summary_sent": 8, "supervis": [1, 3, 10, 12], "support": [3, 8], "surpris": 11, "survei": [3, 4, 8, 9, 11, 15], "survey_respons": 11, "sustain": 21, "svm": 20, "syllabu": 1, "symbol": [17, 21], "syntact": 3, "synthesi": 15, "synthet": [4, 15], "system": [2, 3, 4, 5, 8, 11, 16, 19, 20], "t": [2, 4, 5, 7, 9, 11], "t5": 4, "taboo": 17, "tackl": 3, "tactic": 20, "tag": 3, "tagged_text": 8, "task": [1, 2, 5, 6, 7, 12, 13, 15, 16, 17, 21], "taxonomi": 19, "teach": 1, "team": 8, "tech": 11, "techniqu": [1, 2, 3, 8, 12, 13, 15, 16, 17, 19, 20, 21], "technolog": [5, 20], "technologi": [1, 3, 4, 8, 11, 21], "telescop": 3, "temperatur": [11, 15], "templat": 12, "tempor": [17, 19, 20], "tendenc": 5, "tension": 8, "term": [3, 9, 21], "terribl": 8, "test": [3, 12, 13, 16, 21], "test_siz": 8, "text": [1, 2, 9, 12, 13, 14, 16, 17, 19, 20, 21], "textblob": 9, "textual": [1, 2, 3, 8, 11, 18], "tf": [3, 6, 8, 22], "tfidf_matrix": [7, 8], "tfidf_represent": 7, "tfidfvector": [7, 8], "th": 9, "than": [8, 11], "thei": [2, 4, 5, 8, 11], "them": [4, 7, 8, 11], "theme": [3, 4, 6, 8, 9, 11], "themselv": 8, "theoret": 22, "theori": [3, 4, 15, 21], "thi": [2, 3, 4, 5, 6, 7, 8, 9, 11], "think": [1, 2, 11, 21], "third": 7, "thorough": 6, "those": [1, 2], "thoughtfulli": 9, "thousand": 3, "three": [1, 2, 6], "through": [1, 3, 7, 9, 11, 16, 17, 19], "throughout": [1, 2, 6, 22], "thumbs_up": 7, "tim": 8, "time": [3, 8, 9, 13, 16, 17, 19, 20, 21], "to_lowercas": 7, "toarrai": 7, "todai": [8, 11], "togeth": [3, 8], "toi": 7, "token": [3, 6, 8, 9, 15, 19, 22], "tokenize_sent": 7, "tokenize_word": 7, "tone": [8, 9, 15], "too": 4, "took": 7, "tool": [1, 2, 3, 4, 5, 6, 8, 9, 15, 16, 17], "toolkit": 16, "top": [8, 15], "topic": [1, 4, 5, 6, 8, 17, 19], "topic_trend": 9, "toward": [4, 20], "track": [4, 7, 8, 17, 19, 20, 21], "tradit": [1, 2, 5, 10, 12, 15, 17, 20], "tradition": 2, "train": [2, 8, 9, 11, 13, 15, 16], "train_test_split": 8, "transcript": 4, "transfer": [4, 11, 12, 13, 20, 21], "transform": [1, 2, 7, 8, 15, 20, 22], "translat": [3, 11, 15, 17, 19], "transpar": [2, 13, 19, 21], "trend": [1, 3, 9, 13, 17, 18, 19, 20], "truli": 4, "trust": [5, 20], "tune": [3, 11, 12, 13, 15], "turn": 11, "tweet": [3, 9], "twitter": 19, "two": [8, 9], "type": [11, 12, 15, 16, 17, 20], "typic": [3, 7, 9], "u": [2, 6, 7], "ultim": 6, "uncov": [6, 9], "under": 1, "undergon": [1, 2], "underli": 2, "understand": [1, 2, 3, 5, 6, 7, 8, 9, 11, 16, 17, 21], "unfamiliar": 3, "unintend": 21, "unintent": 5, "unit": 7, "univers": 11, "unlik": 4, "unpreced": [1, 3], "unseen": 11, "unstack": 9, "unstructur": 8, "unsupervis": 9, "up": [1, 8], "uphold": 5, "upon": 6, "us": [1, 2, 3, 4, 6, 7, 9, 11, 12, 14, 16, 17, 19, 20, 21], "usag": [8, 9, 11, 19, 20], "user": 20, "usual": 7, "util": 2, "v": [8, 13, 22], "vader": 8, "vadersenti": 8, "valenc": 8, "valid": [2, 3, 4, 11, 12, 13, 22], "valu": 17, "valuabl": [4, 6, 8, 9], "vari": [5, 13], "variat": [9, 12, 17], "varieti": 3, "variou": [3, 6, 8], "vast": [1, 3, 4, 11], "ve": 1, "vector": [3, 7, 8, 9], "verb": 8, "veri": 9, "verif": [19, 20], "version": 4, "video": [20, 21], "virtual": 21, "vis_data": 9, "visionari": 21, "visual": [4, 5, 9, 17, 19], "vocabulari": [3, 7, 19], "volum": [4, 8], "vulner": 5, "w": 9, "wa": [0, 4, 8, 9], "wage": 4, "wai": [1, 6], "want": 9, "warn": 20, "wasn": 11, "wd": 9, "we": [1, 2, 4, 6, 7, 8, 9, 11], "weak": 13, "weat": 16, "weather": 8, "web": [5, 7, 19, 20], "websit": [4, 7, 20], "weigh": 4, "weight": 3, "welcom": [1, 2, 6], "well": [6, 8], "were": [3, 11], "western": 5, "what": [1, 4, 6, 7, 11], "when": [3, 4, 6, 7, 8, 9], "where": [9, 11], "which": [3, 4, 5, 6, 7, 8, 9], "while": [2, 3, 4, 5, 6, 8, 9, 11, 22], "who": [1, 5], "why": 5, "wide": [2, 3, 4, 8, 9, 11], "wiki": 7, "wisdom": 17, "within": [8, 9], "without": [3, 4, 11], "woman": 3, "won": [8, 11], "word": [4, 6, 8, 9, 11, 12, 16, 19, 22], "word2vec": 3, "word_freq": 8, "word_token": [7, 8, 9], "wordnet": 9, "wordnetlemmat": [7, 9], "work": [1, 2, 6, 9], "workflow": [8, 15], "world": [1, 3, 13, 20, 21], "write": [3, 15], "www": 7, "x": 9, "x_test": 8, "x_test_vector": 8, "x_train": 8, "x_train_vector": 8, "xml": 19, "y_pred": 8, "y_test": 8, "y_train": 8, "yard": 8, "year": [1, 2, 4, 6], "york": 8, "you": [1, 2, 6], "your": [2, 6, 8, 9, 11], "z": 9, "z0": 7, "za": [7, 9], "zd": 9, "zero": [1, 10, 12, 13, 20, 21], "zero_shot_classif": 11, "zero_shot_emotion_detect": 11, "zero_shot_multi_label_classif": 11, "zero_shot_n": 11, "zero_shot_qa": 11, "zero_shot_sentiment_analysi": 11, "zero_shot_summar": 11, "\u03b1": 9, "\u03b2": 9, "\u03b8": 9, "\u03b8d": 9, "\u03c6": 9, "\u03c6k": 9, "\u03c6zd": 9}, "titles": ["Who made this book?", "Home", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Syllabus"], "titleterms": {"1": [2, 3, 4, 5, 7, 8, 9, 11, 15, 19, 22], "10": [3, 4, 5, 9, 11], "11": [5, 9], "12": 9, "13": 9, "1950": 3, "1980": 3, "2": [3, 4, 5, 6, 7, 8, 9, 11, 12, 16, 20, 22], "2000": 3, "3": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 17, 21, 22], "4": [3, 4, 5, 7, 8, 9, 11, 14, 15, 16, 17, 22], "5": [3, 4, 5, 7, 8, 9, 11, 18, 19, 20, 21, 22], "6": [3, 4, 5, 7, 8, 9, 11], "7": [3, 4, 5, 7, 8, 9, 11], "8": [3, 4, 5, 7, 8, 9, 11], "9": [3, 4, 5, 8, 9, 11], "Its": 22, "The": 5, "Their": 3, "abil": 4, "about": 1, "academ": 5, "access": 5, "accuraci": [4, 5], "adapt": 4, "address": [5, 7], "advanc": [4, 5, 9, 18, 22], "advantag": 4, "ai": 5, "algorithm": 9, "alloc": [9, 22], "ambigu": 3, "analysi": [4, 8, 11, 16, 22], "analyz": [3, 4, 19, 22], "annot": [4, 10, 22], "answer": [4, 11], "applic": [4, 9, 11, 18, 22], "approach": 3, "architectur": 4, "attent": 4, "attribut": 5, "bag": 7, "balanc": 5, "base": [5, 8], "basic": [3, 8, 22], "bert": 4, "bia": [5, 16, 22], "bias": 4, "black": 5, "book": 0, "bow": 7, "box": 5, "breakthrough": 3, "capabl": [3, 4, 5, 11], "challeng": [3, 4, 5, 8, 9, 22], "changelog": 1, "charact": 7, "class": 8, "classif": [4, 8, 10, 11, 22], "clean": [7, 22], "cluster": 8, "collabor": 5, "combin": 9, "compar": [13, 22], "complet": 4, "complex": [3, 4], "complianc": 5, "compon": 4, "comput": [3, 4, 5], "concept": [3, 4], "concern": 5, "consent": 5, "consider": [4, 5, 22], "consist": 5, "content": [1, 5], "context": [3, 4, 5, 17, 22], "continu": 5, "contribut": 1, "convers": 7, "copyright": 5, "core": 4, "corpora": 4, "cours": 1, "cross": [4, 5], "cultur": [5, 17, 22], "current": 3, "data": [3, 4, 5, 9, 10, 19, 22], "dataset": [3, 4], "date": 7, "deal": [3, 7], "decis": 5, "deep": 3, "definit": [3, 4], "deploy": [4, 5], "detect": [4, 5, 11, 20, 22], "develop": [3, 5], "differ": 5, "direct": [3, 4, 9, 21, 22], "dirichlet": [9, 22], "disclosur": 5, "dispar": 5, "distinct": 4, "divers": 5, "document": [7, 8], "domain": 4, "earli": 3, "effici": 4, "email": 7, "embed": [3, 7], "emerg": [3, 5, 21, 22], "emoji": 7, "emot": [4, 11], "emoticon": 7, "engin": [11, 12, 22], "enhanc": 4, "ensur": 5, "entiti": [8, 11], "environment": 5, "equiti": 5, "ethic": [4, 5, 22], "evalu": [3, 5, 8, 9], "evolut": [3, 22], "exampl": [3, 4, 8], "explain": 5, "explan": [4, 14, 17, 22], "exposur": 5, "extract": [3, 8, 11], "factual": [4, 5], "fake": [20, 22], "featur": 3, "few": [3, 4, 12, 22], "figur": [17, 22], "fine": [4, 5], "foundat": [9, 11], "frequenc": 7, "from": [3, 4], "fundament": [3, 8, 9, 22], "futur": [3, 4, 5, 9, 21, 22], "gener": [3, 4, 5, 11, 14, 15, 22], "global": 5, "gpt": 4, "hallucin": 5, "handl": [3, 4, 7], "high": [15, 22], "histor": 3, "home": 1, "html": 7, "human": [4, 5], "identif": 5, "idf": 7, "impact": [3, 5], "implement": 9, "implic": 5, "import": [3, 5], "improv": [4, 5], "infer": [4, 16, 22], "inform": [4, 5, 11], "integr": [4, 5], "intellectu": 5, "interdisciplinari": 5, "interpret": [4, 5, 8, 9], "introduct": [2, 3, 4, 5, 7, 8, 9, 11, 22], "invers": 7, "involv": 5, "issu": 5, "its": [3, 4, 22], "kei": [3, 4], "knowledg": 4, "lack": 4, "languag": [3, 4, 17, 22], "larg": [3, 4, 5, 19, 22], "larger": 3, "latent": [9, 22], "lda": [9, 22], "learn": [3, 4, 11, 12, 13, 22], "lectur": 1, "lemmat": 7, "lexicon": 8, "licens": 1, "like": 4, "limit": [4, 8, 9], "lingual": 4, "llm": [3, 4, 5, 10, 11, 13, 15, 18, 22], "lowercas": 7, "made": 0, "massiv": 4, "mathemat": 9, "matter": 1, "mechan": 4, "misinform": [20, 22], "mitig": [4, 5], "modal": 4, "model": [3, 4, 5, 7, 9, 22], "modern": 3, "monitor": 5, "multi": [4, 8], "name": [8, 11], "natur": [3, 5, 22], "need": 5, "ner": [8, 11], "new": [3, 20, 22], "nlp": [2, 3, 4, 5, 6, 8, 9, 22], "nltk": 8, "normal": [7, 22], "notabl": 4, "note": 1, "number": 7, "object": 1, "ongo": 3, "opportun": [3, 5], "other": [4, 9], "outcom": 5, "output": 5, "overview": [1, 4, 22], "paradigm": 3, "paraphras": 4, "part": 8, "particip": 5, "pattern": 4, "perform": [13, 22], "person": 5, "perspect": 3, "physic": 4, "pipelin": 3, "plagiar": 5, "po": 8, "pose": 5, "possibl": 3, "potenti": [4, 5], "practic": 5, "pre": 4, "prepar": 9, "preprocess": [3, 6, 7, 22], "privaci": 5, "process": [3, 4, 22], "progress": 4, "promin": 4, "promot": 5, "prompt": [11, 12, 22], "proper": 5, "properti": 5, "protect": 5, "purpos": 3, "qualiti": [15, 22], "question": [4, 11], "re": 5, "reason": 4, "recent": 4, "recognit": [8, 11], "regul": 5, "reliabl": 5, "remov": 7, "replac": 7, "represent": [7, 22], "reproduc": 5, "requir": [4, 5], "research": [3, 4, 5, 9, 11, 18, 22], "resourc": [4, 5], "respons": 5, "result": [5, 9], "retriev": 4, "revolut": 3, "right": 5, "rise": 3, "risk": 5, "scale": [4, 5, 19, 22], "scienc": [2, 3, 4, 5, 9, 11, 14, 18, 22], "scientif": 5, "scientist": 3, "self": 4, "semant": 3, "sentenc": 7, "sentiment": [4, 8, 11], "seri": 4, "session": [2, 6, 10, 14, 18, 22], "shift": 3, "shot": [3, 4, 11, 12, 22], "similar": 8, "size": 4, "social": [2, 3, 4, 5, 9, 11, 14, 16, 18, 22], "societ": 5, "socioeconom": 5, "sourc": 5, "spaci": 8, "special": 7, "specif": [3, 4], "speech": 8, "state": 3, "statist": 3, "stem": 7, "stop": 7, "strategi": 5, "structur": 1, "studi": 5, "subject": 5, "summar": [4, 8, 11], "summari": [4, 14, 22], "supervis": [13, 22], "sustain": 5, "syllabu": 22, "tabl": 1, "tag": [7, 8], "task": [3, 4, 8, 11, 22], "techniqu": [5, 6, 7, 9, 22], "technologi": 5, "term": 7, "text": [3, 4, 5, 6, 7, 8, 11, 15, 22], "textual": [4, 19, 22], "tf": 7, "theoret": 11, "thi": [0, 1], "token": 7, "topic": [9, 22], "toward": 3, "tradit": [3, 4, 6, 13, 22], "train": [3, 4, 5], "transform": [3, 4], "translat": 4, "transpar": [4, 5], "trend": [4, 21, 22], "true": 4, "tune": [4, 5], "type": [5, 8], "understand": 4, "uniqu": 5, "unstructur": 3, "up": 4, "url": 7, "us": [5, 8, 15, 22], "usag": 5, "valid": 5, "variant": 4, "variou": 4, "when": 5, "who": 0, "why": 1, "word": [3, 7], "world": 4, "zero": [3, 4, 11, 22]}})