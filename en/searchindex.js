Search.setIndex({"alltitles": {"0. Installation": [[6, "installation"]], "1. Cost Management": [[3, "cost-management"]], "1. Introduction": [[6, "introduction"], [22, "introduction"]], "1. Introduction to Emerging Trends in NLP for Social Science": [[30, "introduction-to-emerging-trends-in-nlp-for-social-science"]], "1. Introduction to Ethics in AI and NLP Research": [[14, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Few-shot Learning": [[21, "introduction-to-few-shot-learning"]], "1. Introduction to Figurative Language": [[26, "introduction-to-figurative-language"]], "1. Introduction to Fundamental NLP Tasks": [[17, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[13, "introduction-to-generative-llms"]], "1. Introduction to Large-Scale Text Analysis": [[28, "introduction-to-large-scale-text-analysis"]], "1. Introduction to Misinformation and Fake News": [[29, "introduction-to-misinformation-and-fake-news"]], "1. Introduction to Natural Language Processing (NLP)": [[12, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Social Bias in NLP": [[25, "introduction-to-social-bias-in-nlp"]], "1. Introduction to Text Generation with LLMs": [[24, "introduction-to-text-generation-with-llms"]], "1. Introduction to Text Preprocessing": [[16, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[18, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[20, "introduction-to-zero-shot-learning"]], "1. Setting up LLM Access": [[7, "setting-up-llm-access"]], "1. Text Classification: Comparing Traditional Methods": [[8, "text-classification-comparing-traditional-methods"]], "1. The Importance of Text Representation in NLP": [[2, "the-importance-of-text-representation-in-nlp"]], "1. The Paradigm Shift in NLP": [[1, "the-paradigm-shift-in-nlp"]], "1. Zero-shot vs. Few-shot Learning": [[4, "zero-shot-vs-few-shot-learning"]], "1.1 Definition of NLP": [[12, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[12, null]], "1.2 Basic Concepts": [[12, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[13, null]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[14, null]], "1.3 Importance in Social Science Research": [[12, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[18, "applications-in-social-science-research"], [20, "applications-in-social-science-research"]], "10. Computational Efficiency and Resource Requirements": [[22, "computational-efficiency-and-resource-requirements"]], "10. Current State and Future Directions": [[12, "current-state-and-future-directions"]], "10. Evaluation Metrics for Figurative Language Processing": [[26, "evaluation-metrics-for-figurative-language-processing"]], "10. Evaluation and Interpretation": [[17, "evaluation-and-interpretation"]], "10. Evaluation of Generated Text": [[24, "evaluation-of-generated-text"]], "10. Few-shot Text Generation and Summarization": [[21, "few-shot-text-generation-and-summarization"]], "10. Network Analysis in Misinformation Spread": [[29, "network-analysis-in-misinformation-spread"]], "10.1 Ongoing Developments in LLMs": [[12, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[12, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations": [[26, "challenges-and-limitations"]], "11. Challenges and Limitations of LDA": [[18, "challenges-and-limitations-of-lda"]], "11. Few-shot Question Answering and Information Extraction": [[21, "few-shot-question-answering-and-information-extraction"]], "11. Scalability and Adaptability": [[22, "scalability-and-adaptability"]], "12. Combining Topic Modeling with Other NLP Techniques": [[18, "combining-topic-modeling-with-other-nlp-techniques"]], "12. Interpretability and Explainability": [[22, "interpretability-and-explainability"]], "12. Prompt Optimization Techniques": [[21, "prompt-optimization-techniques"]], "13. Future Directions in Topic Modeling": [[18, "future-directions-in-topic-modeling"]], "2. Advancements in Large Language Models": [[30, "advancements-in-large-language-models"]], "2. Bias in LLMs": [[14, "bias-in-llms"]], "2. Characteristics of Misinformation and Fake News": [[29, "characteristics-of-misinformation-and-fake-news"]], "2. Cultural Context in Figurative Language": [[26, "cultural-context-in-figurative-language"]], "2. Data Sources for Large-Scale Text Analysis": [[28, "data-sources-for-large-scale-text-analysis"]], "2. Evolution of Text Representation Techniques": [[2, "evolution-of-text-representation-techniques"]], "2. Few-shot Learning Capabilities of LLMs": [[21, "few-shot-learning-capabilities-of-llms"]], "2. Fundamentals of LLM-based Text Generation": [[24, "fundamentals-of-llm-based-text-generation"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[18, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Handling Imbalanced Datasets": [[4, "handling-imbalanced-datasets"]], "2. Historical Perspective of NLP": [[12, "historical-perspective-of-nlp"]], "2. Key Capabilities of LLMs for Social Science": [[1, "key-capabilities-of-llms-for-social-science"]], "2. Key Components of LLMs": [[13, "key-components-of-llms"]], "2. Recap of Traditional Supervised Learning": [[22, "recap-of-traditional-supervised-learning"]], "2. Setup and Data Loading": [[6, "setup-and-data-loading"]], "2. Sources of Bias in LLMs": [[25, "sources-of-bias-in-llms"]], "2. Technical Setup": [[3, "technical-setup"]], "2. Text Classification": [[17, "text-classification"]], "2. Text Cleaning": [[16, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[20, "theoretical-foundations-of-zero-shot-learning"]], "2. Topic Modeling with LDA": [[8, "topic-modeling-with-lda"]], "2. Zero-shot Classification for Environmental Topics": [[7, "zero-shot-classification-for-environmental-topics"]], "2.1 Bag-of-Words (BoW) Approach": [[2, "bag-of-words-bow-approach"]], "2.1 Early Approaches (1950s-1980s)": [[12, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[16, null]], "2.2 Basic NLP Tasks": [[17, null]], "2.2 Statistical Revolution (1980s-2000s)": [[12, "statistical-revolution-1980s-2000s"]], "2.2 Word Embeddings": [[2, "word-embeddings"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[18, null]], "3. Challenges and Considerations": [[1, "challenges-and-considerations"]], "3. Controlling Text Generation Parameters": [[4, "controlling-text-generation-parameters"]], "3. Data Collection and Preprocessing for Large Datasets": [[28, "data-collection-and-preprocessing-for-large-datasets"]], "3. Data Handling": [[3, "data-handling"]], "3. Data Sources for Misinformation Research": [[29, "data-sources-for-misinformation-research"]], "3. Few-shot Learning for Sentiment Analysis": [[7, "few-shot-learning-for-sentiment-analysis"]], "3. LLM Approaches in Comparison": [[22, "llm-approaches-in-comparison"]], "3. LLMs and Figurative Language Understanding": [[26, "llms-and-figurative-language-understanding"]], "3. Lowercase Conversion": [[16, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[18, "mathematical-foundation-of-lda"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[12, "modern-nlp-and-deep-learning-2010s-present"]], "3. Multimodal Analysis": [[30, "multimodal-analysis"]], "3. Notable Examples of LLMs": [[13, "notable-examples-of-llms"]], "3. Privacy Concerns": [[14, "privacy-concerns"]], "3. Required Libraries": [[6, "required-libraries"]], "3. Sentiment Analysis": [[17, "sentiment-analysis"]], "3. Techniques for Detecting Bias in LLMs": [[25, "techniques-for-detecting-bias-in-llms"]], "3. The NLP Pipeline: Traditional vs. Modern Approaches": [[2, "the-nlp-pipeline-traditional-vs-modern-approaches"]], "3. Types of Few-shot Learning": [[21, "types-of-few-shot-learning"]], "3. Types of Text Generation Tasks": [[24, "types-of-text-generation-tasks"]], "3. Word Co-occurrence Analysis": [[8, "word-co-occurrence-analysis"]], "3. Zero-shot Capabilities of LLMs": [[20, "zero-shot-capabilities-of-llms"]], "3.1 Traditional NLP Pipeline": [[2, "traditional-nlp-pipeline"]], "3.1 Zero-shot Learning with LLMs": [[20, null]], "3.2 Few-shot Learning and Prompt Engineering": [[21, null]], "3.2 Modern LLM-based Approach": [[2, "modern-llm-based-approach"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[22, null]], "4. Capabilities of LLMs in Social Science Contexts": [[13, "capabilities-of-llms-in-social-science-contexts"]], "4. Data Collection and Preprocessing": [[29, "data-collection-and-preprocessing"]], "4. Evaluation Metrics and Methodologies": [[22, "evaluation-metrics-and-methodologies"]], "4. Explainable AI and Interpretable NLP": [[30, "explainable-ai-and-interpretable-nlp"]], "4. Fundamentals of Prompt Engineering": [[21, "fundamentals-of-prompt-engineering"]], "4. LDA Algorithm": [[18, "lda-algorithm"]], "4. LLM-based Data Annotation: Key Environmental Issues": [[7, "llm-based-data-annotation-key-environmental-issues"]], "4. Metaphor Detection and Interpretation": [[26, "metaphor-detection-and-interpretation"]], "4. Named Entity Recognition (NER)": [[17, "named-entity-recognition-ner"]], "4. Practical Considerations in Social Science Research": [[2, "practical-considerations-in-social-science-research"]], "4. Prompt Engineering": [[3, "prompt-engineering"]], "4. Prompt Engineering for Text Generation": [[24, "prompt-engineering-for-text-generation"]], "4. Prompt Engineering for Zero-shot Tasks": [[20, "prompt-engineering-for-zero-shot-tasks"]], "4. Quantifying Bias in LLMs": [[25, "quantifying-bias-in-llms"]], "4. Scalable Text Processing Techniques": [[28, "scalable-text-processing-techniques"]], "4. Sentiment Analysis Comparison": [[8, "sentiment-analysis-comparison"]], "4. Text Preprocessing": [[6, "text-preprocessing"]], "4. The Changing Nature of NLP Skills": [[1, "the-changing-nature-of-nlp-skills"]], "4. Tokenization": [[16, "tokenization"]], "4. Traditional NLP Pipeline": [[12, "traditional-nlp-pipeline"]], "4. Transparency and Interpretability": [[14, "transparency-and-interpretability"]], "4.1 Choosing the Right Representation": [[2, "choosing-the-right-representation"]], "4.1 Text Preprocessing": [[12, "text-preprocessing"]], "4.1 Using LLMs for High-Quality Text Generation": [[24, null]], "4.2 Balancing Sophistication and Interpretability": [[2, "balancing-sophistication-and-interpretability"]], "4.2 Feature Extraction": [[12, "feature-extraction"]], "4.2 Social Bias Inference and Analysis": [[25, null]], "4.3 Figurative Language Explanation and Cultural Context": [[26, null]], "4.3 Model Training and Evaluation": [[12, "model-training-and-evaluation"]], "5. Basic NLP Tasks": [[6, "basic-nlp-tasks"]], "5. Challenges in Traditional NLP": [[12, "challenges-in-traditional-nlp"]], "5. Controlling Generation Parameters": [[24, "controlling-generation-parameters"]], "5. Ethical AI and Responsible NLP": [[30, "ethical-ai-and-responsible-nlp"]], "5. Future Directions": [[2, "future-directions"]], "5. Generating Summaries with LLMs": [[7, "generating-summaries-with-llms"]], "5. Idiom Processing with LLMs": [[26, "idiom-processing-with-llms"]], "5. Key Issue Extraction Evaluation": [[8, "key-issue-extraction-evaluation"]], "5. Output Validation": [[3, "output-validation"]], "5. Part-of-Speech (POS) Tagging": [[17, "part-of-speech-pos-tagging"]], "5. Performance Comparison in Classification Tasks": [[22, "performance-comparison-in-classification-tasks"]], "5. Preparing Data for LDA": [[18, "preparing-data-for-lda"]], "5. Prompt Design Strategies": [[21, "prompt-design-strategies"]], "5. Reliability and Reproducibility": [[14, "reliability-and-reproducibility"]], "5. Social Bias Inference Using LLMs": [[25, "social-bias-inference-using-llms"]], "5. Stop Word Removal": [[16, "stop-word-removal"]], "5. The Importance of Research Design": [[1, "the-importance-of-research-design"]], "5. Topic Modeling at Scale": [[28, "topic-modeling-at-scale"]], "5. Traditional Machine Learning Approaches": [[29, "traditional-machine-learning-approaches"]], "5. Training Process of LLMs": [[13, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[20, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[28, null]], "5.1 Handling Language Ambiguity": [[12, "handling-language-ambiguity"]], "5.1 Word Frequency Analysis": [[6, "word-frequency-analysis"]], "5.2 Dealing with Context and Semantics": [[12, "dealing-with-context-and-semantics"]], "5.2 Misinformation and Fake News Detection": [[29, null]], "5.2 Named Entity Recognition": [[6, "named-entity-recognition"]], "5.3 Computational Complexity": [[12, "computational-complexity"]], "5.3 Future Directions and Emerging Trends": [[30, null]], "5.3 Sentiment Analysis": [[6, "sentiment-analysis"]], "6. Advantages of LLMs in Social Science Research": [[13, "advantages-of-llms-in-social-science-research"]], "6. Alternatives to Commercial APIs": [[3, "alternatives-to-commercial-apis"]], "6. Analysis and Interpretation": [[7, "analysis-and-interpretation"], [8, "analysis-and-interpretation"]], "6. Analyzing Gender Bias": [[25, "analyzing-gender-bias"]], "6. Aspect-based Emotion Summarization": [[24, "aspect-based-emotion-summarization"]], "6. Comparing Text Generation Capabilities": [[22, "comparing-text-generation-capabilities"]], "6. Deep Learning Techniques": [[29, "deep-learning-techniques"]], "6. Evolution Towards Modern NLP": [[12, "evolution-towards-modern-nlp"]], "6. Implementing LDA": [[18, "implementing-lda"]], "6. In-context Learning": [[21, "in-context-learning"]], "6. Intellectual Property and Attribution": [[14, "intellectual-property-and-attribution"]], "6. Large-Scale Sentiment Analysis": [[28, "large-scale-sentiment-analysis"]], "6. Multilingual and Cross-cultural NLP": [[30, "multilingual-and-cross-cultural-nlp"]], "6. Sarcasm and Irony Detection": [[26, "sarcasm-and-irony-detection"]], "6. Stemming": [[16, "stemming"]], "6. Text Representation": [[6, "text-representation"]], "6. Text Summarization": [[17, "text-summarization"]], "6. The Future of NLP in Social Science": [[1, "the-future-of-nlp-in-social-science"]], "6. Zero-shot Named Entity Recognition (NER)": [[20, "zero-shot-named-entity-recognition-ner"]], "6.1 Introduction of Word Embeddings": [[12, "introduction-of-word-embeddings"]], "6.2 Rise of Deep Learning in NLP": [[12, "rise-of-deep-learning-in-nlp"]], "6.3 Emergence of Transformer Models": [[12, "emergence-of-transformer-models"]], "7. Balancing Automation and Human Insight": [[1, "balancing-automation-and-human-insight"]], "7. Conclusion": [[6, "conclusion"]], "7. Environmental and Resource Considerations": [[14, "environmental-and-resource-considerations"]], "7. Exercise": [[7, "exercise"], [8, "exercise"]], "7. Few-shot Classification Techniques": [[21, "few-shot-classification-techniques"]], "7. Figurative Language in Social Media Analysis": [[26, "figurative-language-in-social-media-analysis"]], "7. Interpreting LDA Results": [[18, "interpreting-lda-results"]], "7. LLM-based Approaches to Misinformation Detection": [[29, "llm-based-approaches-to-misinformation-detection"]], "7. Large Language Models (LLMs)": [[12, "large-language-models-llms"]], "7. Lemmatization": [[16, "lemmatization"]], "7. Limitations and Challenges": [[13, "limitations-and-challenges"]], "7. Misinformation Explanation Generation": [[24, "misinformation-explanation-generation"]], "7. Named Entity Recognition (NER) Performance": [[22, "named-entity-recognition-ner-performance"]], "7. Named Entity Recognition and Relation Extraction": [[28, "named-entity-recognition-and-relation-extraction"]], "7. Racial and Ethnic Bias Analysis": [[25, "racial-and-ethnic-bias-analysis"]], "7. Real-time Language Processing and Analysis": [[30, "real-time-language-processing-and-analysis"]], "7. Reproducibility": [[3, "reproducibility"]], "7. Text Similarity and Clustering": [[17, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[20, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[12, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[12, "examples-and-their-impact"]], "8. Content-based Analysis": [[29, "content-based-analysis"]], "8. Evaluating Topic Models": [[18, "evaluating-topic-models"]], "8. Exercise": [[6, "exercise"]], "8. Few-shot Named Entity Recognition (NER)": [[21, "few-shot-named-entity-recognition-ner"]], "8. High-Quality Content Creation": [[24, "high-quality-content-creation"]], "8. Hybrid Approaches": [[3, "hybrid-approaches"]], "8. Mitigating Bias in LLMs": [[25, "mitigating-bias-in-llms"]], "8. Neuro-symbolic AI in NLP": [[30, "neuro-symbolic-ai-in-nlp"]], "8. Paradigm Shift in NLP Tasks": [[12, "paradigm-shift-in-nlp-tasks"]], "8. Proverbs and Cultural Wisdom": [[26, "proverbs-and-cultural-wisdom"]], "8. Recent Advancements": [[13, "recent-advancements"]], "8. Sentiment Analysis and Opinion Mining": [[22, "sentiment-analysis-and-opinion-mining"]], "8. Socioeconomic Implications": [[14, "socioeconomic-implications"]], "8. Text Classification and Categorization": [[28, "text-classification-and-categorization"]], "8. Text Representation Techniques": [[16, "text-representation-techniques"]], "8. Text-to-Number Transformation: A Crucial Step in NLP": [[1, "text-to-number-transformation-a-crucial-step-in-nlp"]], "8. Topic Modeling": [[17, "topic-modeling"]], "8. Zero-shot Text Summarization and Generation": [[20, "zero-shot-text-summarization-and-generation"]], "8.1 Bag-of-Words (BoW) and TF-IDF": [[1, "bag-of-words-bow-and-tf-idf"]], "8.1 From Task-Specific to General-Purpose Models": [[12, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[12, "few-shot-and-zero-shot-learning"]], "8.2 N-grams": [[1, "n-grams"]], "8.3 Word Embeddings": [[1, "word-embeddings"]], "8.4 Challenges in Text-to-Number Transformation": [[1, "challenges-in-text-to-number-transformation"]], "8.5 Relevance to LLMs": [[1, "relevance-to-llms"]], "9. Advanced Topic Modeling Techniques": [[18, "advanced-topic-modeling-techniques"]], "9. Challenges and Limitations": [[17, "challenges-and-limitations"]], "9. Data Augmentation for Social Science Research": [[24, "data-augmentation-for-social-science-research"]], "9. Ethical Considerations and Challenges": [[25, "ethical-considerations-and-challenges"]], "9. Few-shot Sentiment Analysis and Opinion Mining": [[21, "few-shot-sentiment-analysis-and-opinion-mining"]], "9. Figurative Language in Political Discourse": [[26, "figurative-language-in-political-discourse"]], "9. Future Directions": [[13, "future-directions"]], "9. Human-AI Collaboration in Research": [[30, "human-ai-collaboration-in-research"]], "9. Impact on Social Science Research": [[12, "impact-on-social-science-research"]], "9. Information Extraction and Relation Classification": [[22, "information-extraction-and-relation-classification"]], "9. Source Credibility Assessment": [[29, "source-credibility-assessment"]], "9. Zero-shot Question Answering and Information Extraction": [[20, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[12, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[12, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[13, "ability-to-generate-human-like-text"]], "About": [[5, null]], "Access disparities to LLM technologies": [[14, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[13, "adaptability-to-various-domains-and-tasks"]], "Additional Resources": [[31, "additional-resources"]], "Advantages of Word Embeddings:": [[2, "advantages-of-word-embeddings"]], "Assessment": [[31, "assessment"]], "BERT and its variants": [[13, "bert-and-its-variants"]], "BERT-based Analysis": [[10, "bert-based-analysis"]], "Bag-of-Words (BoW) model": [[16, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[14, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[14, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[14, "challenges-in-explaining-model-decisions"]], "Changelog": [[5, "changelog"]], "Climate Risk Analysis of Sierra Club Press Releases": [[10, null]], "Computational resources required": [[13, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[14, "computational-resources-required-for-training-and-using-llms"]], "Conclusion": [[9, "conclusion"], [10, "conclusion"], [12, "conclusion"], [14, "conclusion"], [16, "conclusion"], [17, "conclusion"], [21, "conclusion"], [22, "conclusion"], [24, "conclusion"], [25, "conclusion"], [26, "conclusion"], [28, "conclusion"], [29, "conclusion"], [30, "conclusion"]], "Considerations for global and cross-cultural research": [[14, "considerations-for-global-and-cross-cultural-research"]], "Contributing": [[5, "contributing"]], "Copyright issues with training data and generated content": [[14, "copyright-issues-with-training-data-and-generated-content"]], "Course Description": [[31, "course-description"]], "Course Objectives": [[5, "course-objectives"], [31, "course-objectives"]], "Course Overview": [[5, "course-overview"]], "Course Structure": [[5, "course-structure"], [31, "course-structure"]], "Course Syllabus": [[31, null]], "Data protection and compliance with privacy regulations": [[14, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[16, "dealing-with-numbers-and-dates"]], "Define Initial Climate Risk Keywords": [[10, "define-initial-climate-risk-keywords"]], "Definition and core concept": [[13, "definition-and-core-concept"]], "Distinction from traditional NLP models": [[13, "distinction-from-traditional-nlp-models"]], "Enhanced multi-modal capabilities": [[13, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[14, "environmental-impact-of-large-scale-ai-models"]], "Ethical Considerations": [[7, "ethical-considerations"], [23, "ethical-considerations"]], "Ethical considerations in deployment": [[13, "ethical-considerations-in-deployment"]], "Example: Document Similarity and Clustering": [[17, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[17, "example-extractive-summarization"]], "Example: Latent Dirichlet Allocation (LDA) with Gensim": [[17, "example-latent-dirichlet-allocation-lda-with-gensim"]], "Example: Lexicon-based Sentiment Analysis": [[17, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[17, "example-multi-class-classification"]], "Example: NER using spaCy": [[17, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[17, "example-pos-tagging-with-nltk"]], "Expand Keywords Using Word Embeddings": [[10, "expand-keywords-using-word-embeddings"]], "Extra 1: The Evolution and Impact of LLMs in Social Science Research": [[1, null]], "Extra 2: Text Representation and NLP Pipeline": [[2, null]], "Extra 3: Practical Considerations for Using LLMs in Social Science Research": [[3, null]], "Extra 4: Advanced Considerations for LLMs in Social Science Research": [[4, null]], "Extras": [[5, null]], "Few-shot Learning": [[4, "few-shot-learning"]], "Few-shot and zero-shot learning capabilities": [[13, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[13, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[13, "gpt-generative-pre-trained-transformer-series"]], "Handling URLs and email addresses": [[16, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[13, "handling-complex-language-understanding-tasks"]], "Home": [[5, null]], "Impact on research outcomes and societal implications": [[14, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[14, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[14, "importance-of-interpretability-in-scientific-research"]], "Improved interpretability and transparency": [[13, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[13, "improvements-in-model-size-and-efficiency"]], "Installation": [[7, "installation"], [8, "installation"], [9, "installation"], [10, "installation"]], "Instructor": [[0, "instructor"]], "Integration with domain-specific knowledge": [[13, "integration-with-domain-specific-knowledge"]], "Issues with hallucination and factual accuracy": [[14, "issues-with-hallucination-and-factual-accuracy"]], "Key Topics We\u2019ll Explore": [[23, "key-topics-we-ll-explore"], [27, "key-topics-we-ll-explore"]], "Keyword Frequency Analysis": [[10, "keyword-frequency-analysis"]], "Lab Session 1: Introduction to NLP for Social Science": [[6, null]], "Lab Session 2: LLMs for Data Annotation and Classification": [[7, null]], "Lab Session 3: Applying Traditional NLP Techniques": [[8, null]], "Labs": [[5, null]], "Lack of true understanding or reasoning": [[13, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[5, null]], "License": [[5, "license"]], "Limitations of BoW:": [[2, "limitations-of-bow"]], "NLP Analysis of Sierra Club Press Releases": [[9, null]], "Named Entity Recognition": [[9, "named-entity-recognition"]], "Objectives": [[7, "objectives"], [8, "objectives"]], "Other prominent models": [[13, "other-prominent-models"]], "Plagiarism concerns and academic integrity": [[14, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[13, "potential-biases-in-training-data"]], "Potential for personal information exposure in training data": [[14, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[14, "potential-impact-on-research-equity-and-diversity"]], "Practical Applications": [[23, "practical-applications"]], "Practical Applications and Ethical Considerations": [[27, "practical-applications-and-ethical-considerations"]], "Pre-training on large corpora": [[13, "pre-training-on-large-corpora"]], "Preparing for the Future of Social Science Research": [[27, "preparing-for-the-future-of-social-science-research"]], "Prerequisites": [[31, "prerequisites"]], "Progress in mitigating biases and improving factual accuracy": [[13, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Project Overview": [[10, "project-overview"]], "Projects": [[5, null]], "Proper attribution of AI-generated text in research": [[14, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[13, "question-answering-and-information-retrieval"]], "Recommended Textbooks": [[31, "recommended-textbooks"]], "Removing HTML tags and special characters": [[16, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[16, "removing-or-replacing-emojis-and-emoticons"]], "Required Materials": [[31, "required-materials"]], "Results Analysis and Visualization": [[10, "results-analysis-and-visualization"]], "Risks of re-identification in generated text": [[14, "risks-of-re-identification-in-generated-text"]], "Saving Results": [[9, "saving-results"]], "Scaled-up training on massive datasets": [[13, "scaled-up-training-on-massive-datasets"]], "Schedule": [[31, "schedule"]], "Self-attention mechanism": [[13, "self-attention-mechanism"]], "Sentence tokenization": [[16, "sentence-tokenization"]], "Sentiment Analysis": [[9, "sentiment-analysis"]], "Sentiment analysis and emotion detection": [[13, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[11, null]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[31, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[15, null], [31, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[19, null], [31, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[23, null], [31, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[27, null], [31, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Setup and Data Loading": [[7, "setup-and-data-loading"], [8, "setup-and-data-loading"], [9, "setup-and-data-loading"], [10, "setup-and-data-loading"]], "Sources of bias": [[14, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[14, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[14, "strategies-for-validating-llm-generated-results"]], "Students": [[0, "students"]], "Summarization and paraphrasing": [[13, "summarization-and-paraphrasing"]], "TF-IDF Analysis": [[9, "tf-idf-analysis"], [10, "tf-idf-analysis"]], "Table of Contents": [[5, "table-of-contents"]], "Techniques for improving model transparency": [[14, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[16, "term-frequency-inverse-document-frequency-tf-idf"]], "Text Preprocessing": [[9, "text-preprocessing"], [10, "text-preprocessing"]], "Text generation and completion": [[13, "text-generation-and-completion"]], "Time Series Analysis": [[10, "time-series-analysis"]], "Topic Modeling": [[9, "topic-modeling"]], "Topic-Sentiment Analysis": [[9, "topic-sentiment-analysis"]], "Transformer architecture": [[13, "transformer-architecture"]], "Translation and cross-lingual tasks": [[13, "translation-and-cross-lingual-tasks"]], "Types of bias": [[14, "types-of-bias"]], "Types of classification:": [[17, "types-of-classification"]], "Unique challenges posed by LLMs": [[14, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, null]], "Why Advanced Applications Matter in Social Science Research": [[27, "why-advanced-applications-matter-in-social-science-research"]], "Why Generative Explanations and Summaries Matter in Social Science": [[23, "why-generative-explanations-and-summaries-matter-in-social-science"]], "Why Text Representation Matters:": [[2, "why-text-representation-matters"]], "Why This Course Matters": [[5, "why-this-course-matters"]], "Word Clouds": [[9, "word-clouds"]], "Word Embedding Association Test (WEAT)": [[25, "word-embedding-association-test-weat"]], "Word Embeddings": [[16, "word-embeddings"]], "Word Frequency Analysis": [[9, "word-frequency-analysis"]], "Word tokenization": [[16, "word-tokenization"]], "Young Joon Lee": [[0, "young-joon-lee"]], "Zero-shot Learning": [[4, "zero-shot-learning"]]}, "docnames": ["about/index", "extras/extra01", "extras/extra02", "extras/extra03", "extras/extra04", "index", "labs/nlp4ss-lab-1", "labs/nlp4ss-lab-2", "labs/nlp4ss-lab-3", "projects/nlp4ss-project-1", "projects/nlp4ss-project-2", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "extras/extra01.md", "extras/extra02.md", "extras/extra03.md", "extras/extra04.md", "index.md", "labs/nlp4ss-lab-1.ipynb", "labs/nlp4ss-lab-2.ipynb", "labs/nlp4ss-lab-3.ipynb", "projects/nlp4ss-project-1.ipynb", "projects/nlp4ss-project-2.ipynb", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "0": [4, 5, 7, 8, 9, 10, 12, 13, 14, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "00": 8, "000000": 10, "002": [4, 12, 13, 14, 20, 21, 22, 26, 29, 30], "004": 8, "005": 8, "006": 8, "007": 8, "008": 8, "009": 8, "010": 8, "011": 8, "012": 8, "013": 8, "015": 8, "016": 8, "018": 8, "04": 16, "05": [8, 10, 17], "06": 8, "08": 10, "09": [8, 10], "0x16dcfcb90": 9, "0x16f794680": 7, "0x16fea3020": 6, "0x177910e30": 8, "0x7f1b3fe9b2b0": 10, "1": [5, 9, 10, 15, 19, 23, 27], "10": [4, 6, 7, 8, 9, 10, 13, 16, 28], "100": [3, 4, 6, 7, 8, 9, 12, 13, 14, 16, 20, 21, 22, 24, 26, 29, 30], "1000": [6, 7, 8, 9, 22, 25, 28, 30], "10000": [13, 22], "1000x600": 8, "1029": 10, "10th": 10, "11": [8, 10], "111": 10, "117": 10, "1199": 10, "12": [6, 7, 8, 9, 10], "123": [10, 14], "1247": 9, "1268": 9, "128": 28, "12952396179718417": 6, "13": [9, 10], "1305": 9, "13363707315372284": 6, "14": [8, 10], "1400x700": 10, "1419": 10, "1421": 10, "14915865499620834": 6, "15": [6, 7, 9, 10, 16], "150": [13, 22, 30], "1500": [7, 16], "15154887003653952": 6, "153": 10, "1533": 10, "1538819754578188": 6, "1557": 10, "15a5": [6, 7, 9, 10], "1703": 10, "175": 13, "1752966664790094": 6, "1784": 9, "179": 10, "18": 10, "1840": [7, 9, 10], "18951266c182": [6, 7, 9, 10], "18th": [20, 21], "19": [24, 29], "1901": 9, "1919": 21, "1964": 21, "1966": 12, "1988": 9, "19th": 21, "1f": 7, "1h": 10, "1min": 10, "2": [5, 9, 10, 11, 19, 23, 27], "20": [6, 7, 8, 9, 10, 22], "200": [12, 26, 30], "2009832958865476": 6, "201": 10, "2017": [7, 8, 10, 12], "2018": [7, 8, 10], "2019": [10, 24], "2020": [7, 8, 10, 24, 30, 31], "2021": [7, 8, 10, 24], "2022": [10, 31], "2023": [6, 10, 16, 30], "2024": [6, 7, 9, 10], "2030": 21, "208": 10, "208b731ebb2b": [6, 7, 9, 10], "21": [7, 9, 10], "21455232095761398": 6, "21min": 10, "22": 10, "221": 10, "2247": 9, "2288625126017953": 6, "236": 9, "237": 10, "239": 10, "23t12": 10, "24": [7, 8, 10], "2464": 10, "25": 31, "256": 13, "258": 10, "26": [8, 10], "27": [8, 10], "2715": 10, "2755": 10, "27622023052939987": 6, "28": [7, 8], "2847": 10, "29": [8, 10], "2e": 13, "2f": [9, 14, 30], "2h": 10, "2min": 10, "3": [5, 9, 10, 11, 15, 23, 27], "30": [8, 9, 10, 18, 21], "300": [7, 8, 10, 13], "3000000": 10, "306": 10, "31": [8, 10], "3101051886326014": 6, "3133": [7, 9, 10], "319a": [6, 7, 9, 10], "32": [10, 28], "32a0": [6, 7, 9, 10], "33": 10, "3386": 10, "3417": 9, "347": [6, 7, 10], "3494": 10, "35": [8, 10, 24, 31], "350": [7, 8], "3544": 10, "3551": 10, "36": 10, "375": 10, "38": 10, "3864": 10, "3896": 10, "390": 10, "393": 10, "3ebc6ab6": [6, 7, 9, 10], "3f": 25, "3rd": [10, 31], "4": [5, 9, 10], "40": [6, 8, 9, 10, 31], "400": 9, "4050": 10, "4087": [6, 7, 9, 10], "4094": 9, "42": [7, 8, 9, 10, 12, 17, 18, 22, 29], "420": 30, "425": 10, "4272": [7, 9, 10], "4411": 10, "4420": 10, "4442": 10, "447547": 10, "45": [6, 7, 8, 9, 10, 14], "450": 10, "450095": 10, "4541": 10, "456": 14, "4578": 10, "45min": 10, "46": [8, 9], "4607": [6, 7, 9, 10], "461239": 10, "4617": [6, 7, 9, 10], "469511": 10, "469790": 10, "46c8": [6, 7, 9, 10], "472": 10, "48": 10, "4872": 10, "487295": 10, "4ccc": [6, 7, 9, 10], "4f": [9, 12, 22, 30], "4min": 10, "4o": 7, "5": [5, 9, 10], "50": [4, 9, 12, 13, 14, 20, 21, 22, 24, 25], "500": [7, 9, 10, 14, 29], "5000": 8, "503": 10, "503703": 10, "503922": 10, "5058": 10, "51": 10, "512": [10, 12, 13, 29], "5139": 10, "52": 8, "538403": 10, "54": [9, 10], "543": 10, "55": 9, "5512": 9, "56bdd61fd9e5": [6, 7, 9, 10], "57": 10, "5775": [7, 9, 10], "577527": 10, "578368": 10, "58": 14, "586d": [6, 7, 9, 10], "5889": 10, "5925": 10, "593965ae0ad8": [6, 7, 9, 10], "5g": [24, 29], "6": [9, 10], "60": 18, "62": 10, "63": 10, "6353": [6, 7, 10], "6354": [6, 7, 9, 10], "65": 10, "651": 10, "654130": 10, "655046": 10, "669556": 10, "6789": 14, "68": 10, "680237": 10, "681": 10, "681453": 10, "682795": 10, "697268": 10, "6min": 10, "7": [4, 9, 10, 31], "705046": 10, "705275": 10, "705285": 10, "706397": 10, "710342": 10, "711288": 10, "712532": 10, "714806": 10, "718412": 10, "732336": 10, "732780": 10, "751936": 10, "753404": 10, "76": 9, "767211": 10, "77": 10, "777": 10, "779621": 10, "7890": 14, "8": [4, 7, 8, 10], "80": [7, 9, 10], "800": [9, 10], "801": 10, "802": 10, "823180": 10, "843045": 10, "845": 7, "868247": 10, "880798": 10, "9": [4, 8, 10, 14, 16], "90": [8, 10], "9000": 12, "924abe2c": [6, 7, 9, 10], "94d2": [6, 7, 9, 10], "95": [4, 9, 10, 24], "953b": [6, 7, 9, 10], "9622": [6, 7, 9, 10], "97": 9, "9c0e": [6, 7, 9, 10], "9ee69b6c": [6, 7, 9, 10], "9min": 10, "A": [7, 10, 13, 14, 15, 17, 18, 21, 22, 25, 26, 29], "And": [16, 28], "As": [1, 4, 5, 6, 7, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "BY": 5, "Be": [3, 14, 17, 20], "By": [4, 5, 7, 8, 10, 12, 14, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 28, 29, 31], "For": [1, 7, 8, 9, 12, 15, 16, 17, 18, 22, 24, 28], "IN": 12, "If": [24, 26], "In": [4, 5, 6, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25, 27, 28], "It": [2, 4, 9, 11, 12, 16, 17, 18, 20, 21, 22, 23, 26], "Its": 2, "NOT": 29, "No": [4, 14, 22, 26], "One": [1, 21, 25], "The": [4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "There": 12, "These": [5, 6, 10, 12, 13, 15, 16, 17, 19, 21, 23], "To": [14, 16, 18, 22, 24, 25], "_": [10, 14, 21, 22, 25], "___": 12, "____": 12, "_______": 12, "________________________": 12, "__getitem__": 28, "__init__": [13, 28], "__len__": 28, "_wra": [6, 7, 9, 10], "a_refriger": 10, "ab_test_prompt": 21, "aband": 10, "abbrevi": 17, "abil": [1, 12, 14, 15, 17, 20, 21, 23, 24, 28], "abl": [7, 8, 19, 31], "about": [1, 6, 7, 8, 11, 12, 13, 14, 16, 18, 19, 21, 22, 24, 25, 28, 29], "about_musicnotes_musicnot": 10, "abov": 25, "absolut": [12, 20], "abstract": [11, 17, 18, 20], "ac": 0, "academ": [3, 12, 13], "acc": 22, "access": [1, 11, 13, 23], "access_token": [28, 29, 30], "access_token_secret": [28, 29, 30], "accomplish": 9, "accord": [12, 14, 17, 22, 29], "account": 14, "accumul": 3, "accur": [4, 15, 17, 21, 25, 26], "accuraci": [1, 3, 8, 12, 17, 21, 22, 23, 24, 26, 29], "accuracy_scor": 22, "achiev": [12, 13, 15, 20], "acknowledg": 25, "across": [1, 7, 12, 13, 18, 23, 26, 28], "act": [6, 12, 21], "action": [7, 10], "actual": 21, "ad": 10, "ada": 6, "adam": 10, "adambeitmansi": 10, "adamw": 13, "adap": 10, "adapat": 10, "adapt": [1, 4, 10, 11, 12, 19, 21, 24, 27, 30], "adaptation_opt": 10, "adaptation_plan": 10, "adaptation_respons": 10, "add": [9, 18, 21, 28], "add_edg": 29, "addit": [3, 4, 6, 7, 26], "addition": 25, "address": [1, 4, 10, 12, 14, 18, 25, 27, 29, 30, 31], "adher": [14, 30], "adjac": [1, 12], "adject": [9, 17], "adjust": [4, 24], "adopt": [10, 12, 30], "ador": 30, "adult": 13, "advanc": [1, 2, 5, 6, 9, 11, 12, 14, 15, 16, 17, 21, 24, 26, 28], "advantag": [21, 24], "advent": [1, 5, 19], "advisori": [6, 7, 9, 10], "advocaci": [7, 8], "ad\u00e9lie_penguin": 10, "aerosol": 10, "aerosol_sprai": 10, "affect": [14, 21, 24], "affidavit": 10, "affili": 7, "after": [13, 16, 21], "ag": [12, 25], "against": [7, 14], "agenc": 14, "agent": 10, "agreement": [6, 17], "ahead": [1, 13], "ai": [0, 7, 12, 21, 22, 23, 24, 27, 29, 31], "ai_research_assist": 30, "aim": [5, 10, 12, 13, 20, 21], "air": 8, "al": 24, "albert": 13, "algorithm": [1, 12, 14, 16, 21, 22, 25], "align": [2, 7], "alik": 17, "all": [1, 6, 9, 11, 12, 13, 14, 20, 21, 25], "all_ent": 28, "all_issu": 7, "all_target": 25, "all_text": 6, "alloc": [5, 8, 9, 14, 15, 28, 31], "allow": [10, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 28], "almost": 20, "alon": 18, "along": [3, 7], "alpha": [9, 10], "alphabet": [12, 28], "alreadi": [6, 9, 10], "also": [1, 5, 7, 9, 11, 12, 13, 14, 16, 19, 20, 21, 23, 26, 27], "alter": 21, "altern": 14, "alternative_fuel": 10, "alwai": [5, 17, 18, 24], "am": 12, "amaz": [22, 29, 30], "amazon": 22, "ambianc": 10, "ambienc": 10, "america": [6, 9, 20, 21], "among": [13, 24, 30], "amount": [1, 3, 5, 12, 13, 17, 21, 23, 27, 28], "amp": 16, "amplif": [14, 23], "amplifi": [1, 13, 14], "amus": 26, "amydominguezsierracl": 10, "an": [1, 2, 4, 5, 6, 9, 10, 12, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "analys": [6, 7, 8, 12, 16, 17, 26], "analysi": [1, 2, 5, 11, 12, 14, 15, 16, 18, 19, 23, 24, 31], "analyt": [12, 16], "analyz": [1, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31], "analyze_cont": 29, "analyze_emot": 13, "analyze_keyword_frequ": 10, "analyze_language_divers": 14, "analyze_occupation_bia": 25, "analyze_political_metaphor": 26, "analyze_proverb": 26, "analyze_senti": [12, 17], "analyze_sentiment_multilingu": 12, "analyze_social_concept": 13, "analyze_social_media_post": 30, "analyze_social_trend": 30, "analyze_spread_network": 29, "anger": 20, "angri": 29, "ani": [3, 4, 7, 8, 12, 14, 15, 25, 26], "anim": [13, 17], "annot": [5, 8, 11, 17, 20], "announc": [7, 10, 17, 21, 22, 29], "annual": 7, "anonym": 14, "anoth": [10, 14, 16, 26], "answer": [1, 6, 11, 12], "answer_quest": 13, "antarct": 10, "antarctica": 10, "antart": 10, "anthropogen": 10, "anthropogenic_clim": 10, "anticip": 27, "apach": 28, "api": [7, 10, 12, 13, 14, 16, 20, 21, 22, 26, 28, 29, 30], "api_kei": [7, 12, 13, 14, 20, 21, 22, 26, 29, 30], "apolog": 12, "append": [9, 14, 20, 22, 25, 28, 29, 30], "appl": [17, 21, 22], "appli": [5, 6, 7, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 25, 31], "applic": [4, 5, 12, 13, 15, 16, 17, 21, 22, 24, 30], "apply_rul": 30, "appnam": 28, "approach": [1, 5, 7, 8, 10, 11, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 30, 31], "appropri": [1, 4, 12, 13, 14, 17, 21, 22], "approv": 10, "april": [6, 7, 8, 9, 10], "aquatic_ecosystem": 10, "ar": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29], "architectur": [12, 14, 24, 25], "archiv": 28, "arctic": [7, 8], "arctic_permafrost": 10, "area": [0, 1, 4, 7, 9, 10, 11, 13, 15, 23, 25, 26], "aren": 14, "argmax": [12, 13, 29], "argsort": 8, "argument": 24, "arid": 10, "arid_desert": 10, "arid_land": 10, "arid_region": 10, "aris": 25, "arithmet": 12, "around": 12, "arowana": 10, "arrai": [8, 10, 30], "art": [5, 12], "articl": [6, 7, 9, 10, 13, 17, 18, 27, 29], "artifact": 13, "artifici": [0, 4, 12, 13, 17], "artist": [25, 30], "as_list": [14, 22, 30], "as_posix": [6, 7, 9, 10], "ascend": 10, "ask": [4, 11], "aspect": [10, 20, 21, 26, 31], "assembli": 7, "assess": [10, 18], "assessm": 10, "assign": [12, 17, 21, 31], "assist": [7, 14, 24, 26, 27, 30], "associ": [9, 10, 14, 18], "association_1": 25, "association_2": 25, "assum": [12, 14, 18, 22, 28, 29, 30], "assumpt": [14, 16, 18], "assura": [6, 7, 9, 10], "asthma": 10, "astronom": 10, "atlantic_ocean": 10, "atmopsher": 10, "atmospher": 10, "atmospheric_co2": 10, "atmostpher": 10, "attend": 16, "attent": [10, 12, 14, 21], "attention_mask": [13, 28], "attention_output": 13, "attention_scor": 10, "attribut": [18, 25, 26], "attribute_set1": 25, "attribute_set2": 25, "attun": 17, "audienc": [23, 26], "audio": [2, 12, 30], "audit": 14, "augment": [4, 17], "august": 10, "ausgezeichnet": 12, "austin": 6, "auth": [28, 29, 30], "authent": [28, 29], "author": 14, "authorit": 14, "auto": [7, 9, 10], "autom": [3, 12, 19, 22, 29], "automat": [12, 17, 18], "automodel": 25, "automodelforsequenceclassif": [12, 28], "autonotebook": [7, 9, 10], "autopct": 7, "autoregress": 24, "autotim": [6, 9, 10], "autotoken": [12, 25, 28], "avail": [4, 10, 12, 22, 29], "averag": [6, 9, 10, 14, 18, 22], "averaged_perceptron_tagg": [9, 12, 17], "avg": 8, "avoid": [3, 23, 25], "awai": 11, "awar": [2, 3, 7, 10, 12, 13, 14, 16, 17, 20, 21, 26], "ax": [8, 10], "axi": [8, 9, 10, 13], "b": [14, 16, 21, 25, 29], "b4f2": [6, 7, 9, 10], "ba": 9, "backbon": 15, "background": 25, "background_color": 9, "backgrounddespit": 6, "backward": [13, 28], "bad": [14, 30], "bag": [12, 17], "bag_of_word": 8, "balanc": [4, 22, 24, 29], "bank": 12, "bar": [6, 7, 8, 9, 10], "barrier": 13, "base": [3, 5, 6, 8, 11, 12, 13, 14, 18, 20, 21, 22, 25, 28, 30, 31], "basi": 15, "basic": [5, 7, 15, 24, 31], "batch": [13, 28], "batch_ent": 28, "batch_result": 28, "batch_siz": [13, 28], "batcher": [6, 7, 8, 9, 10], "bay": [8, 12, 17], "beach": 30, "beach_selfi": 30, "beat": 22, "beautifulsoup": 29, "becaus": [1, 11, 13, 16, 29], "becom": [1, 10, 12, 14, 17, 28, 29, 30], "been": [1, 14, 19, 20, 21, 22], "befor": [1, 3, 4, 6, 7, 8, 9, 10, 12, 18], "began": [20, 21], "begin": [5, 6, 7, 8, 9, 10, 15, 19, 23], "behavior": [5, 12, 29, 30], "behind": [17, 18, 20], "being": 15, "beitman": 10, "believ": [13, 20, 29], "benchmark": 12, "benefici": [1, 14, 16], "benefit": [5, 14], "bert": [2, 12, 22, 25, 28, 29, 30], "bert_physical_scor": 10, "bert_transition_scor": 10, "bertforsequenceclassif": [12, 13, 29], "bertmodel": 10, "berttoken": [10, 12, 13, 29], "best": [1, 10, 11, 13, 17, 20, 21, 25], "better": [13, 14, 18, 20, 21, 30], "between": [2, 4, 5, 8, 10, 11, 12, 13, 17, 18, 20, 21, 22, 24, 25, 26, 29, 30], "betweenness_c": 29, "betweenness_centr": 29, "beyond": [12, 13], "bezo": 22, "bia": [1, 5, 11, 12, 13, 23, 26, 28, 30, 31], "bias": [1, 5, 7, 12, 14, 16, 17, 20, 21, 23, 25, 26, 27, 29, 30], "bias_analysi": 12, "bias_check": 13, "biased_prompt": 25, "biden": 6, "bidirect": [10, 12, 13], "big": [0, 28], "bigram": [1, 8, 10], "bilinear": 9, "bill": [9, 21, 22], "billion": [6, 13], "bin": [6, 9], "binari": [10, 17], "bio_divers": 10, "bio_fuel": 10, "biodivers": [10, 17], "biodiversity_conserv": 10, "bioenergi": 10, "biofuel": 10, "biological_macromolecul": 10, "biomass": 10, "biomass_feedstock": 10, "biophys": 10, "biorefin": 10, "bipv": 10, "bit": [13, 21], "black": [1, 7, 8, 9, 10, 12, 14, 30], "bleu": 22, "bleu_scor": 22, "blockchain": 30, "blow": 10, "blowing_ag": 10, "board": 14, "boem": [6, 7, 9, 10], "boi": [25, 30], "bold": [10, 29], "book": [5, 13], "bool": 29, "both": [5, 8, 10, 11, 12, 13, 18, 22, 24, 28, 29], "boundari": [2, 15, 27], "bourgo": [7, 8], "bourgoin": [9, 10], "bow": 9, "bow_matrix": 16, "bow_represent": 16, "box": [1, 12, 14, 30], "brad": 25, "break": [12, 16, 21], "breakthrough": 12, "brickei": [6, 7, 9, 10], "bridg": [2, 5, 11, 12, 21, 27], "brief": [7, 8, 12, 13, 29], "bring": 14, "britain": [20, 21], "broader": [7, 10, 14], "brother": 25, "brought": 12, "brown": [7, 8, 10, 16, 17], "bs4": 29, "bua": 10, "bucket": 26, "buffer": [20, 21], "bui": 12, "build": [11, 15], "builder": 28, "built": [13, 15, 27], "burden": [7, 8, 9, 10], "busi": [10, 12, 21, 28], "c": 29, "c0486029": [6, 7, 9, 10], "c_v": [9, 18], "calcul": [10, 14, 17, 18, 25, 29, 30], "california": 9, "call": [3, 7, 10, 14], "cambridg": 31, "can": [1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29], "cannot": [2, 16], "capabl": [2, 5, 11, 14, 17, 19, 23, 24, 26, 27, 30], "capac": 10, "capacity_factor": 10, "capit": 14, "captur": [1, 2, 7, 10, 12, 13, 16, 20], "car": 14, "carbon": [7, 10, 14, 20, 21], "carbon_dioxid": 10, "carbon_dioxide_capture_storag": 10, "carbon_dioxide_co2": 10, "carbon_emiss": 10, "carbon_footprint_kg": 14, "cardin": 6, "care": [1, 3, 12, 13, 16, 17, 24, 25, 28], "carefulli": [13, 14, 16, 18, 22, 25, 29], "caregiv": 25, "carri": 16, "case": [16, 22], "cat": [12, 14, 17, 18, 26], "categor": [12, 17], "categori": [4, 7, 8, 10, 12, 13, 17, 20, 21, 22], "categorize_senti": 8, "caus": [7, 21, 24, 29], "caution": 25, "cc": 5, "cd7a": [6, 7, 9, 10], "ce": 30, "ceci": 14, "cell": [6, 7, 8, 9, 10], "cellulosic_ethanol": 10, "central": 29, "centuri": [20, 21], "ceo": [17, 22, 25], "certain": [4, 14, 16, 29], "cett": 12, "cfcs_chlorofluorocarbon": 10, "chairman": 14, "challeng": [2, 5, 11, 19, 21, 28, 29, 30, 31], "chamber": 30, "championship": [17, 21, 22], "chang": [6, 7, 8, 9, 10, 12, 13, 17, 18, 20, 21, 22, 24, 26, 28, 29, 30], "change_clim": 10, "change_impact": 10, "change_mitig": 10, "changer": 23, "chapter": 6, "charact": [2, 6, 9, 10, 12, 18, 29], "character": [12, 18], "characterist": [2, 4, 16, 22, 26], "charg": 3, "chase": [7, 12, 17, 18], "chat": 7, "chatbot": 12, "cheap": 21, "cheaper": 3, "check": [3, 10, 13, 14, 16, 29, 30], "check_consist": 14, "check_domain_cred": 29, "check_for_pii": 14, "check_gender_bia": 13, "check_misinformation_ind": 29, "check_profession_gender_bia": 14, "cheju": 0, "child": 16, "children": [16, 24], "chines": 30, "chip": 6, "chlorofluorocarbon": 10, "chlorofluorocarbon_cfc": 10, "chlorofluorocarbons_cfc": 10, "choic": [1, 2, 4, 7, 12, 13, 14, 16, 17, 20, 21, 22, 26, 29, 30], "chomski": 12, "choos": [4, 17, 20, 22], "chu": 0, "chunk": 28, "chunk_siz": 28, "chunksiz": 9, "cinematic_adapt": 10, "circul": 10, "citat": 29, "citi": [10, 17, 22], "citizen": [14, 24], "civil": 21, "claim": 24, "clariti": 26, "class": [4, 6, 7, 10, 12, 13, 20, 21, 22, 28, 30], "class_": 29, "class_nam": [14, 22, 30], "classif": [5, 12, 13, 29, 30], "classifi": [4, 7, 8, 12, 13, 14, 17, 19, 20, 21, 22, 29, 30], "classification_report": [8, 12, 17, 22, 29], "classify_text": [13, 29], "clean": [5, 6, 8, 9, 12, 15, 18, 31], "clean_html": 16, "clean_text": [6, 16], "cleaned_text": 16, "clear": [1, 8, 14, 20, 21], "clearer": 15, "clf": [12, 17, 29, 30], "client": 7, "climat": [5, 7, 8, 17, 18, 20, 21, 28, 29, 30], "climate_chang": 10, "climate_model": 10, "climate_rel": 10, "climate_system": 10, "climate_vari": 10, "climb": 17, "close": [9, 12, 21, 29], "closer": 30, "cloudi": [4, 17], "club": [5, 6, 7, 8], "cluster_docu": 17, "cnn": 12, "co": 7, "co2": 10, "co2_emiss": 10, "co2e": 14, "coal": 8, "coast": 10, "coastal": 10, "coastal_zon": 10, "coaster": 26, "coastlin": 10, "cod_fisheri": 10, "code": [6, 7, 8, 12, 13, 15, 20, 23, 25, 28, 31], "code_interview_respons": 12, "code_survey_respons": 20, "coded_data": 20, "coded_respons": 20, "coded_them": 20, "coding_schem": 12, "coerc": 10, "coher": [9, 12, 13, 17, 18, 24], "coherence_model": 18, "coherence_scor": 18, "coherence_valu": 9, "coherencemodel": [9, 18], "col": 10, "colab": [6, 31], "cold": 26, "collabor": [12, 27, 29], "collect": [7, 12, 14, 17, 18], "collect_tweet": 29, "collected_tweet": 29, "color": [8, 21], "column": [6, 7, 9, 10, 18], "com": [14, 16, 29], "combat": [27, 29], "combin": [1, 2, 3, 8, 9, 10, 12, 14, 17, 21, 22, 29, 30], "come": [5, 10, 12, 15, 17, 19], "comfort": 17, "comma": [20, 21], "commerc": [6, 7, 9, 10], "commissio": [6, 7, 9, 10], "commit": [6, 21], "common": [1, 4, 6, 7, 9, 10, 12, 16, 17, 18, 20, 25, 26, 29], "commun": [6, 7, 8, 9, 10, 12, 17, 21, 22, 23, 26], "commut": 30, "compani": [22, 25], "compar": [2, 5, 7, 9, 10, 16, 19, 25, 26, 31], "comparison": [10, 26], "compat": 3, "complementar": [8, 10], "complet": [1, 4, 7, 8, 9, 12, 14, 20, 21, 22, 25, 26, 28, 29, 30], "complex": [1, 3, 4, 7, 8, 10, 11, 14, 15, 16, 17, 21, 23, 25, 26, 27, 28, 29, 30, 31], "compon": [21, 28], "composit": 26, "compound": 17, "comprehens": [1, 9, 10, 13, 17, 19, 21, 27, 29, 30], "comput": [1, 2, 9, 17, 25, 28], "computation": 13, "computational_algorithm": 10, "computational_method": 10, "compute_coherence_valu": 9, "compute_hour": 14, "compute_tim": 14, "con": 8, "conc": [6, 7, 9, 10], "concept": [2, 4, 8, 15, 20, 22, 23, 31], "concern": [1, 7, 11, 12, 17, 21, 24, 29], "concis": [7, 17, 30], "conclus": [1, 13, 18, 20], "condens": 13, "conduct": [8, 9, 25, 27], "confid": 14, "config": [6, 9, 10], "configur": [3, 10], "congress": 21, "conll03": 22, "connect": 21, "consciou": 12, "consecut": 1, "consent": [1, 13, 25, 27], "consequ": [4, 14, 17], "conserv": [7, 8], "consid": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 21, 22, 24, 25, 26, 27, 29], "consider": [5, 11, 12, 16, 19, 28, 29, 30, 31], "consist": [1, 3, 4, 12, 16, 20, 21, 31], "conspiraci": 29, "constantli": 5, "constrain": 24, "constraint": 3, "construct": 10, "consult": 10, "consum": [3, 17, 19], "consumer_kei": [28, 29, 30], "consumer_secret": [28, 29, 30], "consumpt": 14, "contact": [6, 9, 10, 14], "contacto": 10, "contain": [5, 13, 14, 17, 26, 29, 30], "contamin": [7, 8], "contaminated_sedi": 10, "contemporari": [13, 14], "content": [6, 7, 8, 9, 10, 12, 13, 16, 17, 23, 30], "context": [1, 2, 4, 5, 7, 8, 10, 11, 14, 16, 17, 19, 20, 23, 24, 25, 29, 30, 31], "contextu": [1, 2, 12, 13, 17, 24, 26, 29], "contextual_keyword_import": 10, "continu": [1, 2, 10, 12, 13, 14, 20, 21, 22, 24, 26, 28, 29, 30], "contradict": 24, "contribut": [13, 14, 16, 25, 27, 30], "controversi": 13, "convei": 26, "converg": 8, "convert": [1, 10, 12, 16, 18, 29], "convolut": 12, "cook": [17, 22], "coral": 10, "coral_reef": 10, "core": [6, 7, 10, 20], "corenlp": 12, "corenlppars": 12, "corpora": [6, 8, 9, 12, 17, 18, 20, 21, 28], "corpu": [1, 6, 8, 9, 10, 12, 16, 17, 18, 28, 29], "correct": [16, 24, 26], "correctli": 3, "correl": [8, 18, 24], "correspond": 17, "corrugated_contain": 10, "cosin": [10, 17], "cosine_similar": [10, 17, 25, 30], "cosmic_ray_flux": 10, "cost": [10, 12, 14], "costal": 10, "could": [7, 8, 10, 12, 13, 14, 16, 19, 21], "couldn": 13, "council": 10, "count": [1, 2, 6, 7, 8, 9, 10, 14, 21, 28, 29], "counter": [7, 14, 27, 28], "counti": [6, 7, 9, 10], "countri": [10, 13], "countvector": [6, 8, 12, 16], "coupl": 10, "coupled_model": 10, "cours": [6, 7, 8, 9, 10, 11, 15, 19, 23, 27], "court": 7, "courtnei": [9, 10], "courtneyb": 10, "cov": 24, "cover": [4, 9, 11, 15, 19, 27, 31], "coverag": [10, 21], "covid": [24, 29], "cpu": [10, 28], "cpu_count": 28, "craft": [1, 12, 25], "creat": [1, 4, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "createdatafram": 28, "creativ": [4, 24], "creator": 29, "credenti": [28, 29, 30], "crise": 27, "criteria": 26, "criterion": 26, "critic": [1, 5, 11, 12, 14, 21, 25, 27, 29, 30, 31], "critically_endang": 10, "cross": [4, 12, 18, 20, 26, 29], "crosstab": 8, "crucial": [2, 3, 4, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "cryptocurr": 30, "csv": [7, 8, 9, 18], "cuda": [10, 28], "cultur": [5, 17, 20, 21, 23, 25, 27, 29, 31], "cultural_context": 26, "cumul": 4, "curat": 14, "current": [13, 24, 27], "cursor": [28, 29], "curtain": 26, "custom": [9, 17, 21], "custom_stopword": 9, "cut": [5, 8, 11, 27, 30, 31], "cycad": 10, "cycl": 10, "cyclon": 10, "cyclone_giri": 10, "cyclone_nargi": 10, "cywinski": 10, "d": [10, 14, 16, 18, 29, 31], "d_model": 13, "dai": [14, 20], "daili": [20, 24], "dall": 13, "dam": 10, "damag": [7, 8], "danger": [10, 29], "data": [0, 1, 2, 4, 5, 11, 16, 17, 20, 21, 22, 23, 25, 26, 27, 30], "data_fil": [6, 7, 9, 10], "databas": 29, "datafram": [6, 7, 8, 9, 10, 18, 28], "dataload": [13, 28], "dataset": [1, 3, 5, 6, 7, 9, 14, 15, 16, 17, 20, 21, 22, 23, 24, 27, 31], "date": [6, 9, 10, 18, 20], "datetim": 10, "daughter": 25, "davinci": [4, 12, 13, 14, 20, 21, 22, 26, 29, 30], "dbmdz": 22, "dc": [6, 9], "de": [8, 10], "deal": [14, 21, 23, 26, 28], "debat": [7, 13, 18, 24], "debias": 25, "debiased_gener": 25, "debiased_prompt": 25, "debiased_result": 25, "debiasing_prefix": 25, "decad": 13, "decemb": [7, 8, 10], "decid": 16, "decis": [1, 4, 10, 12, 13, 17, 19, 22], "decod": [24, 25], "deduc": 26, "deed5268": [6, 7, 9, 10], "deep": [11, 18, 24], "deepen": 5, "deeper": [4, 9, 12, 13, 26, 27, 28], "def": [4, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "defin": 7, "definit": 4, "degrad": 10, "degre": 29, "degree_c": 29, "degree_centr": 29, "delici": 21, "delv": [4, 13, 15, 23, 27], "demand": 7, "demograph": [12, 24, 30], "demographic_group": 12, "demoj": 16, "demonstr": [3, 9, 10, 12, 13, 14, 17, 18, 20, 21, 31], "dens": [1, 2, 12, 16], "depart": [6, 7, 9, 10], "depend": [2, 3, 12, 13, 16, 24, 26, 29], "deplet": 10, "deploy": 25, "deprecationwarn": 8, "depth": 23, "depu": [6, 7, 9, 10], "deputi": 6, "deq": 10, "describ": [12, 14, 21], "descript": [13, 14, 20, 21], "design": [3, 5, 11, 13, 14, 20, 27, 31], "desir": [1, 3, 21], "despit": [1, 12, 13], "destruct": [7, 8], "detach": 25, "detail": [14, 16, 21, 24], "detect": [1, 5, 6, 10, 18, 23, 27, 28, 31], "detect_and_explain_metaphor": 26, "detect_bia": 14, "detect_misinform": 29, "detect_sarcasm": 26, "detected_term": 14, "determin": [9, 17, 18, 21, 26], "determinist": 4, "devast": 7, "develop": [1, 3, 5, 10, 13, 14, 18, 21, 25, 27, 29, 30], "devic": [10, 28], "devop": 0, "df": [7, 9, 10, 18, 28], "df_column": 10, "df_sampl": 7, "diagnosi": 22, "diagnost": 21, "diagram": 18, "dialogu": [14, 24], "diatom": 10, "dict": [6, 9], "dictionari": [8, 9, 17, 18, 28], "did": 21, "didn": 13, "dies": 30, "dieser": 12, "differ": [7, 8, 9, 10, 13, 14, 16, 17, 18, 20, 22, 23, 25], "difficult": [1, 17, 18, 21, 26], "difficulti": 21, "digit": [6, 12, 28, 29], "dim": [10, 12, 13, 25, 29], "dimens": [14, 16], "dimension": [1, 2, 12], "dioxid": 10, "dioxide_captur": 10, "dioxide_capture_storag": 10, "dipole_mo": 10, "direct": [5, 10, 22, 26, 27, 31], "direct_solar": 10, "directl": 10, "directli": 7, "directori": 10, "dirichlet": [5, 8, 9, 15, 28, 31], "disadvantag": 14, "disappoint": [13, 22], "disast": 7, "disclaim": 14, "disclos": 14, "discount": 3, "discours": [7, 10, 12, 18, 24, 27, 30], "discov": [5, 8, 9, 17, 18, 29], "discoveri": [28, 29, 31], "discret": 10, "discrimin": [7, 8, 21], "discriminatori": 14, "discuss": [7, 8, 9, 10, 11, 18, 19, 23, 27], "disin": [7, 8], "dispers": 10, "displai": [6, 7, 8, 9, 10], "disproportion": [7, 8, 10], "disregard": [1, 2], "dissolved_oxygen": 10, "dissolved_oxygen_level": 10, "distant": 17, "distort": 29, "distribut": [6, 7, 9, 14, 18, 28], "district": 7, "div": 29, "dive": [5, 9, 27], "divers": [4, 7, 8, 13, 16, 21, 23, 24, 26, 27, 28, 30], "dizzying_height": 10, "do": [5, 7, 8, 12, 25, 28], "do_sampl": 25, "doc": [6, 9, 12, 17, 18, 22, 28, 29], "doc2bow": [8, 9, 17, 18, 28], "doc_ent": 28, "doc_lda": 18, "doctor": [13, 25, 30], "document": [1, 2, 3, 5, 6, 9, 10, 12, 18, 27, 28, 31], "doe": [6, 7, 14, 21], "doesn": 7, "dog": [12, 16, 17, 18, 26], "dollar": 6, "domain": [1, 2, 4, 9, 10, 12, 17, 18, 20, 21, 24, 29, 30], "domest": 21, "domin": [12, 18], "dominant_top": [9, 18], "dominguez": 10, "don": [7, 11, 13, 16, 30], "donat": 7, "done": 4, "dot": [13, 18, 25], "down": 26, "download": [6, 9, 10, 12, 16, 17, 18, 28, 30], "downstream": 16, "dr": [7, 20], "draft": 31, "dramat": 12, "draw": [1, 18, 29], "drawback": 16, "drill": [7, 8], "drive": [6, 7, 8, 9, 10], "driven": [10, 12, 27, 31], "dropna": 10, "drug": 21, "dt": 12, "dtype": [6, 7, 9, 10], "due": [12, 14, 21, 26, 28, 29, 30], "duplic": [4, 10], "dure": [1, 4, 13, 16, 20, 21, 27], "dynam": [4, 5, 14, 18, 27], "dynowski": 10, "d\u00e9cision": 12, "e": [0, 2, 3, 4, 7, 8, 10, 12, 13, 14, 16, 17, 18, 21, 22, 24, 29], "e4f565b189f7": [6, 7, 9, 10], "each": [1, 5, 7, 8, 9, 10, 12, 13, 16, 18, 21, 22, 31], "earli": [21, 28], "earliest": 2, "earn": 13, "earth": 29, "earth_ozone_lay": 10, "earthju": 9, "earthjustic": 10, "easier": 16, "easili": [16, 18, 21], "echelon": 10, "echo": 30, "econom": [4, 12, 13, 18, 20, 21, 22], "economi": [20, 22], "ecosystem": [7, 10], "ecosystem_servic": 10, "ecosytem": 10, "ecstat": 29, "ed": 31, "edg": [5, 11, 27, 30, 31], "educ": 20, "educational_attain": 10, "effect": [1, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 26, 28, 29, 30], "effici": [1, 3, 7, 8, 9, 12, 15, 17, 19, 23, 28], "effort": 19, "eiffel": 29, "either": 29, "ej": 10, "ejyr": 10, "elabor": 12, "electr": [7, 8, 9], "element": [16, 18], "elicit": 21, "elif": [8, 14, 17, 30], "elimin": [12, 25], "eliza": 12, "eliza_respons": 12, "elon": 22, "els": [6, 7, 8, 9, 10, 12, 13, 14, 17, 26, 28, 29, 30], "email": 14, "email_pattern": 14, "embark": [5, 11, 27], "embed": [13, 18, 20, 30], "embed_s": 13, "embedding_dim": 13, "emerg": [5, 21, 27, 31], "emili": [7, 8, 10, 25], "emilypomiliosi": 10, "emilypomiliosierra": 10, "emilypomiliosierracluborg": 9, "emin": 8, "emiss": [7, 10, 20], "emmiss": 10, "emot": [1, 17, 18, 23, 26, 29], "emotion_analysi": 13, "emotion_summari": 24, "emotional_languag": 29, "emphas": [5, 11, 12, 26, 30], "emphasi": [10, 26, 30], "emploi": [4, 14, 25], "employe": 24, "empow": 21, "en": [7, 9, 10, 14, 28, 29], "en_core_web_sm": [6, 9, 17, 22, 28, 29], "enabl": [1, 12, 13, 16, 23, 26, 30], "enact": 7, "encapsul": 26, "encod": [10, 12, 13, 20, 24, 25, 28], "encoded_data": 13, "encompass": [12, 17], "encount": [4, 12], "encourag": [11, 19], "end": [5, 7, 8, 12, 15, 17, 19, 20, 21, 23, 24, 27, 31], "end_tim": 22, "ener": 8, "energi": [6, 7, 8, 9, 10, 14, 20, 21], "energy_consumption_kwh": 14, "energy_system": 10, "enero": 10, "engag": [7, 11, 30], "engin": [0, 1, 4, 5, 12, 13, 14, 19, 22, 25, 26, 29, 30, 31], "english": [6, 8, 9, 10, 12, 14, 16, 17, 18, 22, 26, 28, 29, 30], "enhanc": [10, 12, 15, 18, 19, 20, 21, 23, 27, 28, 30], "enjoi": 12, "enorm": 13, "ensembl": [22, 29], "ensur": [1, 3, 4, 7, 11, 16, 19, 23, 25, 27, 30], "ent": [6, 9, 17, 22, 28, 29], "ent1": 29, "ent2": 29, "entelecheia": 0, "entir": [10, 14, 21, 23], "entiti": [8, 13, 16, 29], "entity_count": 28, "entity_df": 9, "entity_typ": [20, 21], "entitytyp": [20, 21], "entri": [6, 7, 10], "entropi": 4, "enumer": [12, 14, 17], "environ": [3, 6, 7, 8, 10, 20, 26], "environment": [8, 9, 10, 12, 20, 22, 30], "epa": [9, 10], "epoch": [13, 28], "eq": 10, "equal": [10, 14, 15, 25], "equat": 10, "equip": [5, 16, 23, 27], "equit": 25, "equival": [10, 14, 26], "equivil": 10, "eqyr": 10, "era": [12, 26, 27], "error": [10, 14, 22, 29], "espa\u00f1ol": 14, "especi": [1, 2, 3, 4, 14, 15, 16, 23], "essenti": [1, 15, 26, 28], "est": [12, 14], "estim": 14, "estimate_carbon_footprint": 14, "esto": 14, "estuari": 10, "et": 24, "ethanol": 10, "ethic": [1, 5, 11, 12, 19, 24, 28, 29, 31], "eu": 14, "europ": [20, 21], "european": 10, "evalu": [1, 2, 5, 27, 28, 29, 31], "evaluate_generated_text": 24, "evaluate_perform": 22, "evaluate_scal": 22, "even": [11, 13, 14, 15, 20, 23, 24, 26], "event": [10, 14, 16], "ever": 12, "everi": 20, "evolut": [5, 11, 27, 31], "evolv": [10, 12, 13, 14, 18, 20, 21, 22, 25, 26, 27, 29, 30], "ex": 10, "ex_answ": 21, "ex_context": 21, "ex_quest": 21, "exacerb": 14, "exact": 3, "exagger": 26, "exajoul": 10, "examin": [7, 9, 10, 23, 25, 28, 29], "exampl": [1, 3, 4, 8, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30], "exce": 4, "excel": [21, 23], "except": [10, 29], "excess": 4, "excit": [5, 11, 14, 26, 27, 30], "exclus": 17, "exercis": [23, 31], "exhibit": [12, 18, 29], "exist": [4, 13, 14], "exist_ok": 7, "exp": [13, 14, 22, 30], "expand": [1, 13], "expand_keyword": 10, "expanded_keyword": 10, "expanded_physical_keyword": 10, "expanded_transition_keyword": 10, "expans": 10, "expect": [3, 20, 21, 24, 25, 26], "expens": 3, "experi": [5, 10, 12, 13, 15, 16, 18, 26], "experiment": 18, "expert": [12, 21, 22, 31], "expertis": [1, 9, 10, 12, 18, 26], "explain": [1, 13, 23, 24, 26], "explain_figurative_languag": 26, "explain_idiom": 26, "explain_inst": [14, 22, 30], "explain_llm_predict": 22, "explain_misinform": 24, "explain_traditional_predict": 22, "explan": [3, 5, 12, 13, 14, 22, 28, 29, 30], "explanatori": 14, "explicit": [3, 25], "explicitli": [12, 20, 26], "explor": [1, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 24, 31], "exploratori": 20, "export": 10, "express": [13, 16, 17, 20, 23, 24, 26, 29], "extend": [10, 21, 28], "extens": [1, 6, 9, 10, 13], "extern": 10, "extract": [2, 6, 7, 9, 23, 27, 31], "extract_ent": [6, 9], "extract_key_issu": 7, "extract_keyword": 8, "extracted_groundnut": 10, "f": [6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "f1": [8, 17, 22, 24], "fabric": [14, 29], "face": [7, 8, 10, 12, 22, 24, 26], "facebook": [28, 29], "facil": 6, "facilit": 13, "fact": 29, "factor": [10, 12, 13, 22], "factual": [1, 4, 12, 23, 24, 29], "fail": [10, 12], "fair": [1, 12, 25, 30], "fake": [5, 27, 31], "fals": [7, 9, 10, 24, 27, 28, 29, 30], "familiar": 31, "fantast": 12, "far": 14, "fascin": 5, "faster": 21, "fasttext": [1, 2], "father": 25, "favor": 14, "fc": 13, "fear": [20, 26], "featur": [2, 4, 6, 14, 17, 22, 28, 29, 30], "feature_arrai": 8, "feature_extract": [6, 8, 9, 10, 12, 14, 16, 17, 22, 29, 30], "feature_nam": [6, 9, 12, 16], "februari": [7, 8, 9, 10], "feder": 6, "feedback": 17, "feedstock": 10, "femal": [25, 30], "female_assoc": 25, "female_associ": 25, "female_prob": 25, "female_prompt": 25, "female_sim": 30, "female_term": 25, "female_vec": 30, "few": [1, 3, 5, 8, 19, 20, 22, 29, 30, 31], "few_shot_aspect_senti": 21, "few_shot_classif": [21, 22], "few_shot_multi_label_classif": 21, "few_shot_n": 21, "few_shot_qa": 21, "few_shot_senti": [7, 8], "few_shot_sentiment_analysi": 7, "few_shot_summar": 21, "fewer": 13, "field": [1, 2, 5, 11, 12, 13, 14, 20, 21, 22, 24, 25, 27, 29, 30], "fight": 7, "figsiz": [6, 7, 8, 9, 10], "figur": [5, 6, 7, 8, 9, 10, 23, 31], "file": [6, 7, 9, 10, 12, 18], "film": 12, "filter": [9, 28, 30], "filtered_text": 16, "filterwarn": 8, "final": [5, 10, 13, 15, 21, 27, 31], "financ": [10, 17], "financi": [6, 7, 9, 10, 12, 28], "find": [6, 7, 8, 9, 10, 12, 14, 16, 23, 24, 29, 30], "findal": [14, 22, 29], "fine": [1, 2, 4, 12, 14, 20, 22, 24], "fine_particle_pollut": 10, "finetun": 22, "fireman": 14, "first": [6, 8, 9, 10, 13, 16, 18, 28], "first_doc_vector": [6, 9], "fisheri": 10, "fit": [8, 12, 14, 17, 22, 29, 30], "fit_resampl": 22, "fit_transform": [6, 8, 9, 10, 12, 16, 17, 22, 29], "five": [5, 31], "flat": 29, "flatten": [8, 10, 28], "flaw": 14, "flexibl": [12, 24, 30], "flo": [7, 8], "float": 26, "float32": 10, "flood": 24, "floodplain": 10, "floor": 17, "flower": 17, "fluid": 10, "fluorocarbon": 10, "foam": 10, "foam_insul": 10, "focal": 4, "focu": [6, 7, 9, 10, 12, 13, 18, 20, 23, 27, 30, 31], "focus": [3, 4, 9, 10, 12, 13, 15, 16, 24], "follow": [4, 6, 7, 8, 9, 10, 12, 13, 20, 21, 22, 24, 26, 29, 30], "font_siz": 29, "font_weight": 29, "food": 21, "footprint": [10, 14], "forc": 10, "forefront": [12, 27, 30], "foreign": 13, "forest": [10, 12, 22, 29], "form": [2, 12, 15, 16, 17, 26], "formal": [12, 21], "format": [3, 12, 16, 20, 21, 22, 24, 26], "formul": 13, "forward": [13, 16], "fossil": 8, "foster": 14, "found": [6, 7, 9, 10, 24], "foundat": [6, 15, 17, 27, 28], "founder": 22, "fox": [16, 17], "frack": 8, "frame": [6, 7, 9, 10, 11, 13, 29], "framework": [1, 28, 30], "franc": [14, 29], "fran\u00e7ai": 14, "frase": 14, "free": 12, "freedom": 29, "french": [12, 30], "freq": 6, "frequenc": [1, 2, 8, 12, 17, 24], "frequency_penalti": 4, "frequent": [6, 8, 9, 10, 26], "freshwat": 10, "freshwater_habitat": 10, "freshwater_lak": 10, "freshwater_wetland": 10, "friendli": 12, "fringing_reef": 10, "from": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "from_pretrain": [10, 12, 13, 24, 25, 28, 29], "fu": 10, "fuel": 8, "full": [10, 12, 17, 22, 27, 30], "fulli": [10, 30], "fullyconstruct": 10, "function": [4, 6, 10, 12, 14, 18, 25, 26, 29], "fundament": [1, 5, 6, 11, 15, 16, 19, 31], "furiou": 29, "further": [9, 10, 13, 14, 16, 20, 21], "futur": [5, 6, 7, 9, 10, 22, 31], "future_clim": 10, "fzqarj": 29, "g": [2, 3, 4, 7, 8, 10, 12, 13, 14, 16, 17, 18, 21, 22, 24, 29], "ga": [7, 8], "gabbi": [9, 10], "gabbyb": 10, "gabbybrownsierrac": 10, "gabbybrownsierraclu": 9, "gain": [5, 10, 11, 12, 17, 18, 20, 26, 27], "game": [17, 23], "gap": [5, 11, 12, 13, 21, 24], "garcia": [8, 24], "gase": 10, "gaug": [12, 17], "gcc": 10, "gdp": 21, "gdpr": 14, "gender": [12, 13, 14, 30], "gender_association_test": 25, "gender_bias_check": 30, "gendered_pronoun": 14, "gener": [0, 1, 2, 3, 5, 8, 9, 10, 11, 17, 18, 25, 26, 28, 29], "general_circulation_model": 10, "generate_complet": 25, "generate_llm_disclaim": 14, "generate_research_hypothesi": [13, 24], "generate_research_quest": 13, "generate_summari": 7, "generate_survey_respons": 24, "generate_text": [4, 12, 24], "generate_text_llm": 22, "generate_text_tradit": 22, "generate_text_with_param": 24, "generate_wordcloud": 9, "generated_text": [12, 22, 24], "gensim": [8, 9, 10, 12, 15, 16, 18, 28, 30, 31], "gensim_model": 9, "genuin": 29, "geo_therm": 10, "geolog": 10, "geological_storag": 10, "georgi": 7, "geotherm": 10, "german": [12, 30], "germani": 21, "get": [1, 3, 6, 10, 12, 13, 17, 18, 26, 29], "get_bert_embed": 10, "get_coher": [9, 18], "get_complet": 7, "get_document_top": 9, "get_dominant_top": [9, 18], "get_embed": 25, "get_feature_names_out": [6, 8, 9, 12, 16], "get_scor": 24, "get_senti": [6, 8, 9, 18], "get_top_n_bigram": 8, "get_word_embed": 16, "get_word_freq": 6, "getenv": 7, "getorcr": 28, "gf": 26, "ghg": 10, "gibb": 18, "gigajoul": 10, "gigawatts_gw": 10, "gigaword": [16, 30], "girl": [25, 30], "give": [4, 7, 9], "given": [14, 17, 18, 21], "glacial_ic": 10, "glacier": 10, "glibc2": 10, "global": [1, 2, 10, 12, 21, 27], "global_warm": 10, "global_warming_potenti": 10, "glove": [1, 2, 12, 16, 30], "go": [4, 13, 17], "goal": [2, 11, 12, 16, 17], "good": [13, 14, 21, 30], "googl": [6, 10, 31], "govern": [4, 10, 20, 21, 27, 28], "governor": 9, "gpe": [6, 29], "gpt": [3, 7, 12, 14, 20, 21, 22, 26, 29, 30], "gpt2": [24, 25], "gpt2lmheadmodel": [24, 25], "gpt2token": [24, 25], "gpt3_complet": 13, "gpu": [10, 14], "grade": 3, "grain": 20, "gram": 12, "grammar": [1, 2, 12], "grammat": [12, 17], "grant": 13, "granular": 10, "graph": 29, "grasp": [12, 13, 19], "grassroot": 8, "great": [5, 12, 13, 20, 21, 26, 29], "greater": 30, "green": 21, "greenhouse_gas": 10, "greenhouse_gas_emiss": 10, "greenhouse_warm": 10, "grew": 12, "grid": 14, "grid_carbon_intens": 14, "gross": 21, "groundbreak": 20, "groundwater_aquif": 10, "group": [4, 10, 12, 14, 16, 17, 25], "groupbi": [9, 18], "grow": [1, 11, 22, 28, 30], "growth": 12, "gtco": 10, "gtco2": 10, "guest": 31, "guid": [1, 17, 25, 26], "guidelin": [1, 5, 14], "gz": 10, "h": [6, 7, 8, 9, 10, 31], "ha": [1, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 26, 28, 29, 30], "habit": 12, "habitat": [7, 8], "had": [11, 30], "halla": 0, "hallucin": 12, "halon": 10, "hammer": 26, "hand": [5, 12, 15, 23], "handl": [1, 2, 18, 20, 21, 22, 24, 26, 28, 29, 30], "hanoi": 6, "har": [5, 11, 12, 14], "hard": 13, "hardwar": [3, 22], "harm": 14, "harri": 6, "harvard": 20, "hasattr": 30, "hate": 12, "have": [1, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 26, 27, 28, 29, 30], "haven": 20, "hazard": 10, "hazzard": 10, "hcfc": 10, "he": [13, 14, 25], "head": [6, 7, 8, 9, 10], "headlin": 29, "health": [8, 21, 24, 28, 30], "healthcar": [20, 21], "heapq": 17, "hear": [6, 7, 9, 10], "heartbroken": 29, "heat": [10, 24], "heat_pump": 10, "heavi": 21, "height": 9, "hello": 12, "help": [1, 2, 4, 7, 9, 10, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30], "her": 14, "here": [5, 9, 12, 13, 14, 16, 17, 20, 21, 22, 24, 25, 26, 28, 29], "hernand": [7, 8], "hernandez": [9, 10], "herring_fisheri": 10, "hesit": 11, "hfc_": 10, "hi": 14, "hidden": [12, 18, 23, 27, 29], "hidden_layer_s": 30, "hidden_s": 13, "hierarch": [12, 18], "hierarchi": 18, "high": [2, 5, 7, 8, 9, 10, 12, 14, 22, 23, 26, 31], "higher": [4, 18, 31], "highli": [12, 26], "highlight": [9, 24], "hill": 12, "him": 14, "hint": 6, "hist": [6, 9], "histo": 9, "histor": [5, 7, 8, 13, 14, 17, 18, 26, 28], "histori": 20, "hoax": 29, "hold": [6, 7, 9, 10, 12], "home": [6, 7, 8, 9, 10], "hop": 21, "host": 7, "hour": 14, "household": [7, 8, 9, 10], "hovi": 31, "how": [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 31], "howev": [5, 12, 13, 15, 16, 19, 20, 21, 24, 25, 26, 30], "html": [6, 7, 8, 9, 10, 18, 29, 30], "html_text": 16, "http": [6, 7, 9, 10, 12, 16, 29], "hug": [22, 24], "human": [5, 10, 12, 14, 17, 18, 19, 21, 22, 26], "human_evalu": 26, "human_system": 10, "hundr": [6, 13], "hybrid": 22, "hydro": 10, "hydro_electr": 10, "hydro_electric_pow": 10, "hydroelectr": 10, "hydrofluorocarbon": 10, "hydrogen": 10, "hydrogen_fuel": 10, "hydrogen_pow": 10, "hydrolog": 10, "hydrological_vari": 10, "hydropow": 10, "hydropower_pl": 10, "hyfi": [6, 7, 8, 9, 10], "hyperbol": 26, "hypothes": [1, 12, 13, 23, 24, 28], "hypothesi": [13, 24], "i": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "ian": [6, 7, 9, 10], "ianbrickeysierraclub": 6, "ic": 10, "icecap": 10, "icefield": 10, "ich": 30, "id": 28, "id2word": [8, 9, 17, 18, 28], "idea": [1, 13, 20, 23, 26], "ident": 14, "identifi": [1, 8, 9, 10, 12, 13, 14, 17, 18, 20, 21, 26, 27, 28, 29], "idf": [2, 6, 8, 12, 17, 29], "idiom": 23, "idiomat": 13, "idx": [8, 9, 17, 18, 28], "iea": 10, "ignor": [2, 8], "ignorecas": 29, "illustr": [13, 15, 24], "iloc": 6, "imag": [1, 2, 12, 13, 29, 30], "image_classifi": 30, "image_cont": 30, "image_path": 30, "image_result": 30, "image_scor": 30, "imagin": 28, "imbalanc": 22, "imblearn": 22, "immedi": 7, "impact": [5, 10, 11, 13, 16, 17, 21, 22, 24, 25, 26, 27, 29, 30], "imperson": 29, "implement": [2, 3, 7, 8, 10, 13, 14, 15, 17, 21, 24, 25, 26, 27, 28, 31], "impli": 12, "implic": [1, 3, 7, 8, 10, 11, 12, 13, 23, 24, 25, 26, 27, 29], "import": [4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "importance_scor": 10, "impos": 21, "imposs": 13, "impost": 29, "impract": 13, "impress": 26, "improv": [1, 3, 8, 10, 12, 16, 18, 21, 23, 26, 30], "imshow": 9, "inaccess": 28, "inadvert": 14, "inc": [17, 21, 22], "includ": [1, 3, 4, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30], "inclus": 30, "inconsist": [21, 29], "incorpor": [10, 14, 18, 21, 24], "incorrect": [13, 14], "increas": [4, 6, 7, 8, 9, 10, 12, 13, 14, 21, 30], "increasingli": [12, 28, 29, 30], "incredibli": 24, "independ": [17, 24], "index": [7, 9, 10], "indic": [9, 18, 25, 29], "individu": [9, 12, 14, 25, 26, 29], "industri": [6, 12, 13, 20, 21], "ineffici": 1, "inequ": 14, "infeas": [12, 16], "infer": [5, 18, 22, 23, 31], "influenc": [7, 10, 12, 14, 20, 26, 30], "info": [6, 7, 8, 9, 10, 16], "inform": [1, 2, 5, 6, 7, 8, 9, 10, 16, 17, 19, 23, 24, 25, 27, 29, 30], "inher": 12, "initi": [3, 6, 7, 8, 9, 13, 28], "initial_physical_risk_keyword": 10, "initial_transition_risk_keyword": 10, "inland": 10, "innov": [21, 27], "inplac": 10, "input": [1, 2, 4, 10, 12, 13, 14, 21, 24, 25, 26, 28, 29], "input_data": 22, "input_id": [13, 25, 28], "input_text": 12, "inputcol": 28, "insight": [8, 9, 10, 11, 12, 13, 15, 17, 18, 23, 26, 27, 28, 31], "instal": 3, "instanc": 12, "instant": [21, 30], "instead": 3, "institut": [12, 14], "instruct": [3, 20], "insulating_foam": 10, "insulation_foam": 10, "int64": [6, 7, 9, 10], "integr": [1, 12, 23, 30], "intellig": [0, 12, 13, 17], "intens": [13, 14, 24], "inter": 17, "interact": [12, 17, 21, 26, 29, 30], "intercomparison": 10, "intercomparison_project": 10, "interdisciplinari": [1, 12, 27, 29], "interest": [0, 9, 11, 19], "interfer": 16, "intermedi": 3, "intern": [1, 13, 14], "internet": 26, "interpol": 9, "interpret": [1, 11, 12, 15, 20, 23, 25], "interpret_internet_slang": 26, "intersect": [5, 11], "intersection": 13, "interview": [1, 12, 13, 24], "introduc": [10, 12, 14, 16, 31], "introduct": 5, "introductori": 11, "intuit": 18, "invers": [1, 2, 9, 10, 12], "invest": [10, 13, 21], "investig": [8, 14, 27], "investment_cost": 10, "involv": [10, 12, 13, 16, 17, 22, 23, 25, 29, 30], "io": [7, 9, 10], "ionospher": 10, "ipcc": 10, "iphon": 21, "iprogress": [7, 9, 10], "ipywidget": [7, 9, 10], "iron": 26, "ironi": [12, 17], "irrelev": [12, 16], "is_avail": [10, 28], "is_colab": [6, 7, 8, 9, 10], "isalpha": [8, 12, 17, 28], "isn": [10, 11], "isol": 30, "issu": [1, 3, 4, 9, 11, 12, 13, 17, 20, 25, 27, 28, 29, 30], "issue_count": 7, "issues_df": 8, "item": [6, 8, 10, 12, 13, 21, 25, 28, 29], "iter": [3, 8, 13], "its": [5, 7, 8, 11, 17, 20, 21, 24, 26, 27, 28, 29, 30, 31], "j": [12, 30, 31], "jamal": 25, "jane": [20, 21], "januari": 10, "japanes": 26, "javier": 10, "javiersierrasierr": 10, "jeff": 22, "jeju": 0, "jeopard": 10, "jj": 9, "job": [12, 20, 24], "joblib": [6, 7, 8, 9, 10], "john": [14, 21], "johndo": 14, "johnson": [21, 24], "joi": 20, "join": [6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 20, 21, 22, 24, 29], "journal": [10, 20], "journei": [5, 11], "jpg": 30, "jpmorgan": 7, "json": [6, 7, 9, 10, 22], "jsonl": [6, 7, 9, 10], "ju": 8, "judg": 7, "judgment": 26, "judici": 24, "jump": [16, 17], "junquera": 10, "jupyt": [7, 9, 10, 31], "jurafski": 31, "just": [7, 11, 16, 26], "justic": [7, 8], "k": [4, 10, 17, 18, 21, 24, 28], "kapp": 10, "kb": [6, 7, 10], "keep": [5, 9, 26], "keepdim": 13, "kei": [3, 4, 6, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 28, 29, 30, 31], "kentucki": 10, "key_issu": [7, 8], "key_pap": 24, "keyedvector": 10, "keyerror": 10, "keyword": 8, "keyword_count": 10, "keyword_embed": 10, "keyword_freq": 10, "kg": 14, "kick": 26, "kilowatthour": 10, "kim": 6, "kimpettysi": 6, "kind": [7, 8, 9, 10, 18], "king": [12, 30], "kmean": 17, "knowledg": [1, 4, 5, 12, 17, 20, 21, 27], "known": 13, "korea": [0, 6], "kr": 0, "kw_h": 10, "kwh": [10, 14], "l": [10, 24], "la": 8, "lab": [9, 10], "label": [3, 6, 7, 9, 12, 13, 17, 20, 21, 22, 28, 29, 30], "label_": [6, 9, 17, 22, 28, 29], "labels_": 17, "lack": 29, "lack_of_sourc": 29, "lake": 10, "lakisha": 25, "lambda": [6, 7, 8, 9, 10, 18, 22], "land": [8, 10], "land_degrad": 10, "landscap": 12, "lang": [14, 28, 29], "lang_count": 14, "langid": 14, "languag": [0, 1, 2, 4, 5, 8, 9, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "lantri": 10, "larg": [1, 2, 3, 4, 5, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "large_dataset": 28, "larger": 23, "largescaletextprocess": 28, "larisa": 10, "larisamanescu": 10, "last": [20, 21], "last_hidden_st": [10, 25], "late": [20, 21], "latent": [5, 8, 9, 12, 15, 28, 31], "later": 15, "latest": [4, 13, 25], "latitud": 10, "latitude_coordin": 10, "lattitud": 10, "lauren": 10, "laurenlantrysi": 10, "law": [6, 21, 22], "layer": 10, "lazi": [16, 17], "lda": [5, 9, 15, 28, 31], "lda_model": [8, 9, 17, 18, 28], "lda_result": 18, "lda_visu": [8, 9, 18], "ldamodel": [8, 9, 17, 18], "ldamulticor": 28, "lead": [1, 12, 14, 16, 20, 21, 27, 28], "leak": 10, "leakag": 10, "leap": 13, "learn": [1, 2, 3, 5, 6, 8, 11, 15, 16, 17, 18, 19, 23, 27, 30, 31], "lectur": 31, "led": 13, "lee": [6, 7, 9, 10, 24], "leewai": 10, "leezieschesierraclub": 6, "legal": [14, 17], "legend": [8, 10], "legisl": [7, 9], "lemmat": [2, 6, 9, 10, 12, 18, 29], "lemmatize_token": 6, "lemmatize_word": 16, "lemmatized_text": 16, "lemmatized_token": 12, "len": [7, 8, 9, 10, 14, 18, 25, 28, 29], "length": [2, 4], "less": [2, 4, 14, 17, 21], "let": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 27, 28, 29], "level": [1, 10, 12, 21, 28], "level_cost": 10, "leverag": [3, 4, 5, 11, 13, 15, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31], "levi": 10, "lexic": [8, 12], "lexicon": 8, "li": [17, 28], "lib": [7, 9, 10], "librari": [3, 5, 7, 8, 9, 10, 14, 15, 17, 18, 24, 28, 31], "lieb": 30, "life": [10, 14, 20, 24, 26, 30], "life_cycle_climate_perform": 10, "lifecycl": 10, "lifecycle_manag": 10, "lifecyl": 10, "lifetim": 14, "lightblu": 29, "lignol_modifi": 10, "like": [1, 2, 3, 4, 9, 12, 14, 15, 16, 17, 18, 21, 24, 25, 26, 27, 28, 29, 30], "lime": [14, 22, 30], "lime_text": [14, 22, 30], "limetextexplain": [14, 22, 30], "limit": [1, 4, 5, 9, 10, 11, 12, 14, 19, 21, 22, 27, 30, 31], "linalg": 25, "line": [12, 18], "linear": 13, "linear_model": [8, 22], "linesent": 12, "lingual": [12, 18], "linguist": [12, 16, 17, 29], "link": 26, "linux": 10, "list": [9, 10, 20, 21, 28, 29], "listen": 30, "liter": [12, 26], "literatur": [1, 12, 13, 23, 24, 30], "literature_review_synthesi": 24, "live": [24, 29, 30], "ll": [5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 18, 19], "llm": [5, 8, 11, 15, 23, 28, 30], "llm_bleu": 22, "llm_entiti": 22, "llm_explan": 22, "llm_gener": 22, "llm_ner": 22, "llm_perform": 22, "llm_predict": 22, "llm_relat": 22, "llm_relation_extract": 22, "llm_sent": 22, "llm_sentiment": 22, "llm_sentiment_analysi": 13, "llm_time": 22, "lng": 9, "load": [3, 12, 13, 16, 17, 22, 24, 28, 29, 30], "load_dataset": [6, 7, 9, 10], "load_word2vec_format": 10, "loc": 10, "local": [3, 7, 12, 17, 21], "localhost": 12, "locat": [9, 17, 21, 29], "logging_level": [6, 7, 8, 9, 10], "logist": [8, 12, 22], "logisticregress": [8, 22], "logit": [12, 13, 25, 29], "lone": 6, "long": [4, 12, 13, 15, 17, 20, 21, 24], "long_text": 20, "longer": 17, "look": [1, 7, 12, 13, 20, 24, 27, 28], "lose": [1, 2], "loss": [1, 4, 13, 16, 28], "lotteri": 20, "loui": 10, "louisiana": 10, "love": [4, 12, 13, 16, 17, 20, 22, 30], "low": [17, 21, 26, 30], "lower": [2, 4, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 28, 29], "lowercas": [2, 9, 10, 12, 18, 29], "lowercased_text": 16, "loyal": 17, "lr": 13, "lr_classifi": 8, "lr_predict": 8, "lstm": 12, "lyndon": 21, "m": [6, 9, 10, 12, 13, 18, 22], "machin": [1, 2, 4, 8, 12, 16, 17, 18, 20, 21], "macro": 8, "made": [1, 3, 5, 11, 16], "mai": [1, 2, 3, 4, 6, 10, 13, 14, 16, 17, 18, 21, 22, 26, 28, 30], "mail": 0, "main": [4, 6, 7, 8, 9, 10, 15, 18, 19, 20, 24, 27], "maintain": [4, 12, 13, 14, 23, 27], "major": [7, 20, 21], "make": [1, 7, 12, 13, 16, 17, 19, 20, 21, 22, 29, 30], "make_pipelin": [14, 30], "makedir": 7, "male": [25, 30], "male_assoc": 25, "male_associ": 25, "male_prob": 25, "male_prompt": 25, "male_sim": 30, "male_term": 25, "male_vec": 30, "man": [12, 25, 30], "manag": 16, "manesc": 10, "manescu": 10, "mani": [1, 4, 12, 13, 15, 16, 17, 19, 22, 26, 29], "manifest": 25, "manin": 6, "manipul": [13, 29], "mankind": 14, "manmade_global_warm": 10, "manual": [3, 12, 16, 17, 18], "map": [1, 28], "march": 10, "marilyn": 7, "marine_biodivers": 10, "marine_ecosystem": 10, "mark": [17, 20], "market": [10, 12, 17, 20, 21, 22], "markov": 12, "martin": 31, "maryland": [7, 9], "mask": 13, "massachus": 10, "massiv": [12, 20, 27], "master": [15, 16, 17, 27], "mat": [12, 17, 18], "match": [8, 12, 21, 22], "materi": 14, "matplotlib": [6, 7, 8, 9, 10, 29], "matrix": [10, 17], "max": [4, 9, 10, 18], "max_featur": [6, 8, 9], "max_it": [8, 30], "max_length": [4, 7, 10, 12, 13, 22, 24, 25, 28, 29], "max_token": [4, 12, 13, 14, 20, 21, 22, 26, 29, 30], "max_word": [20, 21], "maximum": 4, "me": [0, 6, 7, 9, 10, 12], "mean": [6, 9, 10, 12, 13, 16, 17, 18, 22, 25, 26, 30], "meaning": [1, 15, 16, 18, 23, 27, 28], "meaningless": 26, "measur": [8, 14, 17, 21, 29], "measure_inference_tim": 22, "mechan": [1, 12], "media": [5, 6, 7, 9, 10, 12, 13, 14, 16, 17, 18, 21, 22, 23, 24, 27, 28, 29, 30], "medic": [17, 22, 28], "meet": [6, 7, 9, 10, 26], "megan": 6, "meganwittmansierra": 6, "melting_permafrost": 10, "meme": 26, "memor": 14, "memori": [6, 7, 10, 12], "men": 13, "mental": [21, 24, 30], "mention": [6, 7, 8, 9, 10], "merg": 8, "merged_df": 8, "mesospher": 10, "messag": [7, 10], "messi": 16, "metabolom": 10, "metal_hydrid": 10, "metaphor": 23, "methan": [8, 10], "methane_ga": 10, "method": [1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 17, 18, 19, 22, 24, 25, 29, 31], "methodolog": 10, "methodologi": [5, 11, 12, 20, 27, 30], "metric": [8, 10, 12, 17, 18, 24, 25, 29, 30], "microbial_ecologi": 10, "microchip": 29, "micronutri": 10, "midterm": 31, "might": [7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 24, 26], "million": [6, 9, 28], "min": [7, 9, 10, 30], "min_count": 12, "mind": [5, 14], "mine": [7, 8, 12], "minim": [1, 2, 13, 21, 24], "minimum_prob": 9, "minor": 4, "misinform": [5, 21, 27, 30, 31], "misinformation_top": 29, "mislead": [14, 29], "mismatch": 29, "misrepres": 14, "miss": 2, "misus": [1, 13], "mitig": [10, 12, 23, 30], "mitigation_opt": 10, "mitigation_scenario": 10, "mix": [4, 21], "mixtur": 18, "ml": [2, 21, 28, 29], "mlop": 0, "mlpclassifi": 30, "modal": 30, "model": [1, 2, 3, 4, 5, 7, 10, 11, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "model_list": 9, "model_nam": [12, 13, 14, 16, 25, 28, 29], "model_output": 26, "model_select": [8, 12, 17, 22, 29], "moder": 10, "modern": [5, 10, 11, 31], "modernizat": 10, "modifi": 4, "modul": 13, "moham": 25, "molecular_pathwai": 10, "monei": 6, "monitor": 30, "montana": 7, "month": [7, 13, 17, 20, 22], "monthli": 10, "monthly_risk": 10, "montreal": 10, "montreal_protocol": 10, "more": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30], "moreov": 17, "morn": 10, "morrisro": 10, "most": [4, 6, 7, 9, 10, 12, 16, 18, 20, 21], "most_common": [7, 14], "most_similar": [10, 12], "mother": 25, "mount_google_dr": [6, 7, 8, 9, 10], "mountain": 10, "move": [5, 16], "movi": [12, 14, 16, 30], "mp": 28, "mse": 22, "msg": 10, "mtco": 10, "mtco2": 10, "mtld": 8, "mtoe": 10, "much": [11, 16], "multi": [6, 20, 21, 28], "multidisciplinari": 29, "multilingu": [12, 29], "multilingual_senti": 30, "multimod": [0, 1, 2, 12, 13, 29], "multinomi": 18, "multinomialnb": [8, 12, 14, 17, 30], "multipl": [12, 13, 14, 17, 18, 23, 28, 30], "multiprocess": 28, "musk": 22, "must": [1, 6, 12, 13, 14, 25, 29], "mutual": 17, "my": [7, 12, 13, 20], "mydriv": [6, 7, 8, 9, 10], "mystream": 30, "mystreamlisten": 30, "mywot": 29, "n": [6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 20, 21, 22, 26, 29, 30], "n_cluster": 17, "n_estim": 29, "n_run": 22, "n_sampl": 22, "n_test": 21, "nada": [6, 7, 9, 10], "nadam": 10, "nail": 26, "naiv": [8, 12, 17], "naive_bay": [8, 12, 14, 17, 30], "nall": 14, "name": [7, 8, 12, 13, 16, 25, 29], "name_senti": 25, "name_sentiment_analysi": 25, "nami": 10, "nanswer": 21, "naqui": 10, "nation": [10, 21], "natur": [0, 2, 4, 5, 9, 11, 13, 14, 15, 16, 17, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31], "navig": [1, 14], "nb_classifi": 8, "nb_predict": 8, "ncarolyn": 10, "ncategori": [12, 20, 21, 22], "ncontact": [6, 7, 8, 9, 10], "ncontacto": 10, "ncourtnei": [7, 8, 10], "nearbi": 1, "necessari": [6, 7, 8, 9, 10, 15, 17], "need": [1, 3, 6, 12, 13, 16, 18, 20, 21, 28, 30], "neg": [4, 7, 8, 12, 13, 14, 17, 20, 21, 22, 24, 30], "nemili": 10, "nentiti": 21, "ner": [9, 28], "ner_pipelin": 22, "network": [12, 13, 24, 30], "networkx": 29, "neural": [12, 13, 18, 30], "neural_network": 30, "neuro_symbolic_analysi": 30, "neutral": [4, 7, 8, 12, 13, 14, 17, 20, 21, 22, 25, 30], "never": 20, "new": [3, 4, 5, 7, 8, 10, 11, 13, 14, 17, 18, 19, 20, 21, 22, 24, 27, 28, 30, 31], "newer": 13, "next": [4, 7, 12, 13, 17, 22], "next_word": 22, "next_word_vec": 22, "ngabbi": [7, 8, 10], "ngener": 14, "ngrace": 10, "ngram": 4, "ngram_rang": 8, "nhead": 13, "nian": [6, 7, 9, 10], "nice": 22, "nitrogen": 10, "njavier": 10, "njune": 10, "nkim": [6, 7, 9, 10], "nking": 12, "nlargest": 17, "nlarisa": 10, "nlauren": 10, "nlda": 9, "nlee": [6, 7, 9, 10], "nllm": 13, "nlp": [3, 5, 10, 16, 22, 26, 27, 28, 29], "nlp4ss": [6, 7, 8, 9, 10], "nlptown": [12, 30], "nltk": [6, 8, 9, 10, 12, 15, 16, 18, 22, 28, 29, 31], "nltk_data": [6, 9, 10], "nmegan": [6, 7, 9, 10], "nn": [9, 12, 13, 29], "nnote": 14, "no_grad": [10, 12, 13], "no_repeat_ngram_s": 24, "noam": 12, "node_color": 29, "node_s": 29, "nois": [8, 10, 12, 16], "nolan": 10, "non": [6, 7, 10, 12, 17, 26, 28], "none": [6, 7, 8, 10, 12, 13, 14, 20, 21, 22, 26, 29, 30], "nonsens": 4, "nonstandard": 17, "norm": [25, 27], "normal": [5, 6, 9, 10, 15, 28, 31], "norman": 10, "north": [20, 21], "notabl": [7, 14], "notat": 18, "note": [4, 12, 24], "notebook": [3, 6, 9, 10, 31], "notebook_tqdm": [7, 9, 10], "noth": 12, "notic": 12, "noun": [7, 9, 17], "nov": 10, "novel": [12, 20, 21], "now": [4, 6, 7, 8, 9, 11, 12, 13, 20, 27], "np": [8, 9, 10, 12, 13, 22, 25, 30], "nquestion": 21, "nrespons": 14, "nsamantha": 10, "nsampl": [6, 7, 9, 10], "nsentiment": [21, 22], "nshane": 10, "nshiloh": [7, 8], "nsimilar": 17, "nsummari": 21, "ntext": [12, 20, 21, 22], "ntim": 10, "ntop": 10, "ntopic": 18, "nuanc": [1, 2, 10, 12, 13, 16, 17, 23, 26], "nucleu": 4, "null": [6, 7, 10], "num": 16, "num_clust": 17, "num_featur": [14, 22, 30], "num_label": [12, 13, 28, 29], "num_permut": 25, "num_process": 28, "num_quest": 13, "num_return_sequ": [24, 25], "num_run": 14, "num_sent": 17, "num_top": [8, 9, 17, 18, 28], "number": [2, 4, 8, 9, 10, 13, 14, 18, 21, 22], "numer": [1, 2, 12, 16], "numpi": [3, 8, 9, 10, 13, 22, 25, 30], "nurs": [14, 25, 30], "nutrient": 10, "nvidia": 10, "nwarn": 14, "nx": 29, "o": 7, "oauthhandl": [28, 29, 30], "object": [1, 6, 9, 10, 28], "obscur": 16, "observ": [3, 8, 10, 18, 25], "observed_chang": 10, "observed_scor": 25, "obviou": 14, "occ": 30, "occup": [25, 30], "occur": [12, 17, 18, 25], "occurr": [2, 10], "ocean": 10, "ocean_energi": 10, "ocean_storag": 10, "ocean_upwel": 10, "octob": [7, 8, 9, 10], "off": [9, 22], "offens": 26, "offer": [1, 2, 3, 5, 10, 12, 13, 14, 15, 19, 20, 22, 23, 24, 26, 27, 28], "offic": 26, "offici": 10, "often": [1, 2, 4, 12, 13, 14, 15, 16, 17, 18, 19, 22, 23, 26, 29], "oh": 26, "oil": [7, 8], "okai": 12, "old": 24, "omiss": 14, "on_error": 30, "on_statu": 30, "onc": 12, "one": [2, 7, 10, 12, 13, 14, 16, 18, 20, 21, 22, 26, 28], "ones": 10, "ongo": [7, 13, 14, 18], "onli": [3, 5, 7, 9, 12, 13, 14, 21, 27, 28], "onlin": [12, 17, 28, 29, 30, 31], "open": [3, 5, 12, 13, 17, 19, 20, 22, 24, 30], "openai": [3, 4, 7, 12, 13, 14, 20, 21, 22, 26, 29, 30], "openai_api_kei": 7, "oper": [2, 3], "opinion": [12, 14, 17, 27, 29], "opportun": [5, 11, 28], "optim": [9, 10, 13, 18, 19, 28], "optimal_num_top": 9, "option": [3, 10, 26], "order": [1, 2, 8], "oregon": [6, 7, 9, 10], "org": [6, 7, 9, 10, 29], "organ": [7, 8, 9, 10, 17, 18, 20, 21, 29], "origin": [4, 7, 10, 12, 21, 25], "ormat": 10, "other": [1, 2, 9, 10, 14, 17, 20, 21, 23, 24], "our": [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 21, 23, 27, 28, 29, 30], "out": [1, 2, 16, 26], "outcom": [25, 27], "outdat": 14, "outperform": [21, 26], "output": [1, 2, 4, 10, 12, 13, 16, 20, 21, 22, 23, 24, 25, 26, 28, 29], "output_fil": [7, 9], "outputcol": 28, "over": [4, 6, 7, 9, 10, 14, 16, 17, 18, 21, 24, 27], "over_sampl": 22, "overal": [9, 13, 22, 26], "overall_scor": 26, "overload": 27, "overpr": 21, "oversampl": 4, "oversight": [1, 14], "oversimplifi": 7, "overst": [2, 16], "overview": [9, 11, 31], "overwhelm": 13, "own": [11, 12, 19, 30], "ownership": 14, "ozon": 10, "ozone_concentr": 10, "ozone_deplet": 10, "ozone_depleting_subst": 10, "ozone_lay": 10, "ozone_pollut": 10, "ozone_smog": 10, "ozonedepleting_subst": 10, "p": [4, 10, 16, 24, 25], "p_valu": 25, "pacific_ocean": 10, "packag": [3, 6, 7, 8, 9, 10], "pad": [10, 12, 13, 28, 29], "page": [6, 7, 9, 10], "page_url": [6, 7, 9, 10], "pair": 1, "pairwis": [10, 17, 30], "panda": [6, 7, 8, 9, 10, 18, 28], "pandem": [12, 24], "pangolin": 10, "paper": [1, 13, 20, 23, 24, 31], "paradigm": [4, 20, 21, 22], "paragraph": 13, "parallel": 13, "parallel_preprocess": 28, "paramet": [13, 18, 21, 30], "paramount": 14, "paraphras": [1, 24], "parch": 10, "parent": [7, 24], "park": 26, "pars": [12, 28], "parser": [12, 29], "part": [12, 20, 30], "partial": 13, "particip": [10, 13, 14], "particular": [13, 14, 17, 21], "particularli": [1, 4, 5, 11, 12, 13, 14, 16, 17, 18, 20, 21, 24, 26, 29], "pass": [8, 9], "passion": 24, "past": 8, "path": 10, "pathwai": 10, "pattern": [1, 7, 8, 10, 12, 13, 14, 16, 17, 18, 21, 22, 26, 27, 28, 29], "pd": [7, 8, 9, 10, 18, 28], "penalti": 21, "peopl": [4, 9, 16, 17, 29], "per": [3, 12, 17, 18, 21, 22], "per_word_top": 9, "percent": 6, "perform": [1, 4, 5, 6, 7, 8, 10, 12, 13, 16, 17, 18, 19, 20, 21, 26, 31], "perform_n": 17, "pericardial_sac": 10, "period": 21, "perm_scor": 25, "perm_target1": 25, "perm_target2": 25, "permafrost": 10, "permut": 25, "permutation_scor": 25, "perpetu": [1, 13, 14, 26], "perplex": 22, "persist": 13, "person": [6, 12, 17, 20, 21, 22], "personif": 26, "perspect": 14, "pet": 17, "petit": 10, "petrochemical_feedstock": 10, "petti": [6, 7, 9, 10], "phase": 13, "phd": 6, "phenolog": 10, "phenologi": 10, "phenomena": [5, 12, 13, 21, 23, 25, 26, 27, 28], "phenomenon": 29, "phone": 14, "phone_pattern": 14, "phosphoru": 10, "photoperiod": 10, "photovolta": 10, "photovoltaics_pv": 10, "phrase": [4, 7, 10, 14, 26], "physic": 10, "physical_freq": 10, "physical_risk_keyword": 10, "physical_risk_keywords_vector": 10, "physicalinitial_physical_risk_keywords_risk_keyword": 10, "phytoplankton": 10, "phytoplankton_bloom": 10, "pie": 7, "piec": 17, "pii": 14, "pil": 30, "pip": [6, 7, 8, 9, 10], "pipe": 28, "pipelin": [5, 8, 10, 14, 16, 22, 28, 30], "place": [16, 21, 30], "placehold": 16, "plai": [16, 17, 26], "plan": [10, 17, 22], "planet": [17, 21], "plankton": 10, "plankton_bloom": 10, "plate": 18, "platform": [10, 26, 28, 29], "plausibl": [13, 14], "pleas": [5, 7, 8, 9, 10], "plot": [6, 7, 8, 9, 10, 12, 18, 22], "plot_word_frequ": 9, "plt": [6, 7, 8, 9, 10, 22, 29], "po": [9, 12, 29], "point": [1, 7, 8, 11, 13, 16, 19, 20], "polar": [6, 8, 9, 13, 18, 22, 24, 30], "polariton": 10, "polarity_scor": 17, "poli": 7, "policeman": 14, "polici": [4, 6, 7, 10, 12, 13, 14, 17, 18, 20, 21, 22, 24], "polit": [12, 13, 17, 18, 20, 21, 22, 24, 27, 29, 30], "politifact": 29, "poll": 10, "pollard": 10, "pollin": 10, "pollut": 8, "polyurethane_foam": 10, "pomilio": [7, 8, 10], "pool": 28, "poorli": [17, 18], "popul": [1, 14, 28], "popular": [1, 2, 15, 17, 18], "porterstemm": [6, 12, 16], "pos_tag": [9, 12, 17], "pos_tag_text": 17, "pose": [11, 29], "posit": [4, 7, 8, 12, 13, 14, 17, 18, 20, 21, 22, 25, 27, 30], "possibl": [5, 13, 14, 15, 19, 20, 26, 27, 28], "possibli": 28, "post": [5, 12, 13, 14, 16, 17, 27], "potenti": [1, 5, 7, 8, 10, 12, 16, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31], "power": [1, 2, 5, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30], "power_usage_effect": 14, "pp": 12, "practic": [1, 5, 13, 14, 15, 21, 25, 28], "pragmat": 12, "prais": 24, "pre": [4, 10, 11, 12, 18, 20, 21, 22, 24, 28, 29, 30], "precip": 10, "precipit": 10, "precis": [4, 8, 22], "precision_recall_fscore_support": 22, "predefin": [17, 20], "predict": [8, 12, 13, 14, 17, 20, 21, 22, 29, 30], "predict_proba": [14, 22, 30], "predicted_class": [12, 13, 29], "prefer": 22, "prefix": 25, "prejud": 25, "prepar": [3, 8, 9, 13, 16, 17, 19], "preprocess": [1, 2, 3, 5, 8, 17, 18], "preprocess_chunk": 28, "preprocess_text": [6, 8, 9, 10, 12, 18, 28, 29], "preprocess_text_with_bigram": 10, "preprocessed_data": 28, "presenc": 18, "presence_penalti": 4, "present": [1, 10, 13, 14, 23, 25, 26, 28], "preserv": [1, 17, 30], "presid": [21, 22, 29], "press": [5, 6, 7, 8, 20, 27, 31], "pretty_print": 12, "preval": 18, "prevent": [4, 7, 14], "previou": [8, 21], "previous": [12, 13, 27, 28], "price": [10, 21], "primari": [0, 7, 10, 12, 13, 20], "primarili": [12, 14], "primary_energi": 10, "principl": [1, 11, 20], "print": [6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "print_top": [8, 9, 17, 18, 28], "prior": 18, "prioriti": 10, "privaci": [1, 11, 12, 13, 21, 25, 27, 30], "pro": 8, "prob": 18, "probabilist": [12, 18], "probabl": [4, 12, 18, 25, 29], "probe": [12, 14], "probe_model_bia": 12, "problem": [12, 13, 18], "problemat": 1, "process": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 27, 29, 31], "process_batch": 28, "processed_chunk": 28, "processed_cont": 6, "processed_content_bigram": 10, "processed_doc": [17, 18, 28], "processed_str": 9, "processed_text": [8, 9, 16, 18, 29], "processeddf": 28, "produc": [4, 13, 14, 16, 21], "product": [10, 13, 21, 22, 24, 30], "product_carbon_footprint": 10, "produit": 30, "produkt": 30, "profess": [13, 14, 25], "professor": 0, "profound": 22, "program": [1, 9, 12, 17, 30, 31], "progress": [11, 12, 19, 24, 25, 27], "prohibit": 21, "project": [3, 6, 7, 8, 9, 13, 16, 19, 27, 31], "project_budburst": 10, "project_dir": [6, 9], "project_nam": [6, 7, 8, 9, 10], "project_root": [6, 7, 8, 9, 10], "project_workspace_dir": [6, 9], "projected_chang": 10, "prolifer": 28, "promin": 10, "promis": [22, 29], "prompt": [1, 4, 5, 7, 12, 13, 14, 19, 22, 25, 26, 29, 30, 31], "prompt_vari": 21, "pronoun": 14, "propag": 29, "proper": 15, "properli": [3, 14], "proport": 18, "propos": [12, 21, 31], "protect": [7, 8, 20], "protective_ozone_lay": 10, "protocol": [10, 14, 26], "provid": [1, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 26, 28, 29, 30], "psychotherapist": 12, "pt": [10, 12, 13, 24, 25, 28, 29], "public": [7, 8, 12, 14, 17, 20, 21, 24, 27, 28, 29], "publish": 20, "pump": 10, "punkt": [6, 9, 10, 12, 17, 18, 28], "punkt_tab": 10, "purpos": [1, 14, 17, 24], "push": [2, 10, 15, 27], "py": [7, 9, 10], "pyldavi": [8, 9, 18], "pyplot": [6, 7, 8, 9, 10, 29], "pyspark": 28, "python": [4, 5, 6, 7, 9, 10, 12, 13, 15, 31], "python3": [7, 9, 10], "pytorch": [13, 31], "q": [28, 29], "quadrillion_btu": 10, "qualit": [12, 14, 17, 18, 23], "qualiti": [4, 5, 7, 8, 18, 21, 23, 31], "quantifi": 10, "quantit": 18, "queen": 30, "queri": [13, 29], "question": [1, 2, 4, 5, 6, 7, 11, 12, 14, 16, 17, 18, 22, 23, 24, 27, 28, 31], "quick": [4, 9, 16, 17], "quickli": [3, 12, 16, 17, 19, 20, 21], "quit": [12, 22], "quot": [7, 8], "r": [6, 9, 10, 12, 14, 16, 18, 22, 29], "r_": 10, "race": [12, 21, 25], "racial": 14, "radi": 10, "radiative_forc": 10, "raimondo": 6, "rain": 26, "rainfal": 10, "rais": [14, 21], "ralli": [12, 20], "ramella": 10, "randint": 13, "randn": 13, "random": [4, 12, 13, 18, 21, 22, 25, 29], "random_st": [7, 8, 9, 10, 12, 17, 18, 22, 29], "randomforestclassifi": [22, 29], "rang": [4, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 25, 28], "rangeindex": [6, 7, 10], "rapid": [12, 20, 21, 30], "rapidli": [13, 22, 25, 26, 27, 30], "rate": [6, 7, 9, 10, 26, 29], "ratio": 8, "raw": [2, 3, 6, 7, 9, 10, 12, 16, 22], "raw_data_fil": [6, 7, 9, 10], "raw_pars": 12, "raw_text": 29, "rcp": 10, "rdata": [6, 7, 9, 10], "rdata_df": 6, "re": [3, 5, 6, 9, 10, 11, 12, 15, 16, 18, 22, 27, 29], "reach": [14, 22], "reaction": 24, "read": [9, 21], "read_csv": [8, 18], "readabl": 2, "readi": 27, "readthedoc": [7, 9, 10], "real": [5, 12, 20, 25, 29], "realist": 24, "realli": [12, 14, 30], "reason": [12, 15, 17, 22, 30], "recal": [4, 8, 22], "recap": 16, "receding_glaci": 10, "receiv": [10, 13], "recent": [5, 7, 11, 15, 24, 29, 30], "recino": [6, 7, 9, 10], "recogn": 25, "recognit": [8, 13, 16, 29], "recommend": 12, "record": [3, 28], "recreational_fisheri": 10, "recurr": 12, "reddit": [28, 29], "redefin": 30, "reduc": [3, 7, 12, 13, 16, 20, 21, 30], "reduct": [7, 8], "reef": 10, "refer": [9, 13, 17, 21, 22, 24, 25, 26, 28, 29], "referenc": 14, "reference_explan": 26, "refin": [3, 10], "reflect": [10, 14, 25, 26], "reform": 21, "refriger": 10, "regardless": [15, 25], "region": 14, "regress": [8, 12, 22], "regul": [6, 7, 9, 10], "regular": [14, 16], "reinforc": [14, 25], "rel": [1, 25], "relat": [6, 10, 21, 24, 29, 30], "relationship": [2, 10, 12, 16, 18, 20, 22, 24], "releas": [5, 6, 7, 8, 22], "relev": [2, 5, 12, 13, 15, 16, 18, 21, 22, 23, 24, 27, 31], "reli": [4, 12, 29], "reliabl": [1, 13], "religion": 21, "remain": [1, 2, 14, 15, 17, 26], "remark": [12, 26], "rememb": [9, 11, 15, 16, 17, 18, 19, 27], "remot": [24, 30], "remov": [2, 6, 9, 10, 12, 18, 28, 29], "remove_stopword": [6, 16], "remove_urls_email": 16, "renew": [7, 8, 20, 21], "renewable_feedstock": 10, "renewable_fuel": 10, "renov": 29, "repeat": [4, 18], "repetit": 4, "rephras": [12, 13], "replac": [10, 17, 29, 30], "replace_emoji": 16, "report": [4, 7, 8, 10, 28], "report_safeguard": 10, "repres": [1, 2, 9, 12, 13, 14, 16, 18, 21, 27], "represent": [1, 5, 9, 10, 12, 13, 14, 15, 17, 31], "reproduc": [1, 27], "request": [7, 29], "requir": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 16, 18, 19, 21, 26, 29], "resampl": 10, "rescu": 14, "research": [0, 5, 7, 8, 10, 11, 15, 16, 17, 19, 21, 22, 23, 25, 26, 28], "reservoir": 10, "reshap": [10, 30], "resourc": [2, 10, 17, 21, 28, 30], "resp": 14, "respect": 23, "respond": [3, 7, 24], "respons": [1, 4, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 26, 29], "responsibli": [5, 12, 19], "restart": 3, "result": [1, 3, 4, 7, 8, 11, 12, 13, 15, 16, 17, 20, 21, 22, 25, 26, 28, 29, 30], "retriev": 1, "return": [4, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "return_tensor": [10, 12, 13, 24, 25, 28, 29], "retweeted_statu": 30, "reveal": [9, 10, 12, 16, 17], "revers": [6, 8, 9, 18], "review": [1, 3, 13, 14, 23, 24, 30], "revolut": [20, 21], "revolution": [12, 13, 19, 21, 24, 30], "revolutionari": [1, 5, 11], "rewrit": 13, "rewrite_prompt": 13, "rf_model": 22, "rf_perform": 22, "rf_predict": 22, "rich": 26, "richer": 2, "ricki": 10, "rickyjunquerasi": 10, "ride": 26, "right": [6, 7, 9, 10, 20, 21], "rigor": 14, "rio": 8, "rise": [1, 17, 30], "risk": 5, "river": 12, "rnn": 12, "roberta": 13, "robot": 0, "robust": 14, "rognon": 10, "role": [1, 7, 14, 22, 26, 30], "roller": 26, "room": [13, 25], "root": [12, 16], "root_dir": [6, 9, 10], "rotat": [6, 7, 8, 9, 10], "roug": [22, 24], "row": 8, "rstrip": 12, "rule": [3, 7, 8, 11, 12, 30], "rule_result": 30, "run": [3, 6, 7, 8, 9, 10, 12, 13, 14, 16], "runner": 16, "ryospher": 10, "sad": 20, "safeguard": 10, "safeti": 6, "sai": [10, 12, 29], "salin": 10, "salmon_fisheri": 10, "saltwat": 10, "same": [14, 21], "sampl": [3, 4, 6, 7, 8, 9, 10, 12, 16, 17, 18, 22, 24], "sample_comparison": 8, "sample_ent": 9, "sample_s": [7, 9, 22], "sample_text": [6, 16, 24], "samsung": 6, "sar": 24, "sarcasm": [12, 17], "sarcast": 26, "sat": [12, 17, 18], "satisfact": 24, "save": [3, 7, 8, 12, 18, 29], "save_html": [8, 9, 18], "save_to_fil": 30, "saw": [12, 17, 20], "sc": 29, "scalabl": 12, "scale": [1, 3, 5, 11, 12, 16, 18, 27, 30, 31], "scari": 26, "scatter": [8, 10], "scenario": [10, 13, 17, 20, 21, 22, 24], "scheme": 12, "scienc": [5, 7, 8, 15, 16, 17, 19, 21, 22, 25, 26, 28, 29], "scientist": [5, 11, 17, 18, 19, 23, 25, 26, 28, 29, 30, 31], "scikit": [12, 15, 17, 22], "scipi": 25, "scope": 14, "score": [6, 8, 9, 10, 12, 13, 17, 18, 22, 24, 25, 26, 30], "scorecard": 29, "scrape": [14, 16], "scratch": 11, "scrutini": 13, "sea": 10, "seaborn": [7, 8, 9], "search": 29, "search_tweet": [28, 29], "second": [16, 22, 28], "secreta": 6, "section": [13, 18], "sector": 20, "secur": 14, "sediment": 10, "see": [5, 7, 9, 10, 12], "seek": 5, "seen": [1, 12, 17, 20], "seepag": 10, "select": [1, 4, 10, 17, 21, 22, 28], "self": [12, 28, 30], "self_attent": 13, "semant": [1, 2, 10, 16, 20, 29], "semi_arid": 10, "semicolon": 7, "senat": 21, "sens": [13, 26], "sensation": 29, "sensational_titl": 29, "sensit": [14, 21, 23, 26], "sensitive_term": 14, "sent": 3, "sent_token": [6, 16, 17], "sentenc": [7, 12, 13, 14, 17, 26], "sentence_bleu": 22, "sentence_scor": 17, "sentiment": [1, 3, 4, 12, 16, 18, 23, 24, 25, 26, 30], "sentiment_analyz": 28, "sentiment_by_top": 18, "sentiment_df": 8, "sentiment_scor": [12, 30], "sentimentintensityanalyz": 17, "separ": [1, 7, 10, 12, 20, 21], "septemb": 10, "sequenc": [1, 12, 13], "sequence_length": 13, "sequenti": 12, "seri": [9, 17], "serv": 2, "server": 14, "server_power_kw": 14, "servic": [9, 10, 21, 22], "session": [3, 5, 28], "set": [1, 2, 4, 6, 8, 9, 10, 12, 14, 16, 17, 18, 19, 28, 29], "set_access_token": [28, 29, 30], "set_index": 10, "setup": 31, "sever": [1, 4, 10, 12, 13, 14, 15, 22, 24, 25, 26], "sex": 21, "shane": 10, "shanelevysierraclu": 10, "shap": 14, "shape": [1, 9, 13], "share": [22, 29], "she": [13, 14, 25], "sheet": 10, "shift": 11, "shiloh": [9, 10], "shock": 29, "shop": 12, "short": [10, 12, 18], "shot": [1, 3, 5, 8, 19, 22, 29, 30, 31], "should": [1, 2, 7, 9, 12, 14, 17, 20, 21, 22, 24, 25, 26], "show": [4, 6, 7, 8, 9, 10, 17, 18, 21, 22, 26, 28, 29], "show_top": 9, "showcas": 10, "shown": [25, 26, 29], "shuffl": [13, 25, 28], "si": 10, "sia": 17, "siberian_permafrost": 10, "side": 24, "sier": 10, "sierra": [5, 6, 7, 8], "sierra_club_analysi": 9, "sierra_club_key_issu": [7, 8], "sierra_club_senti": [7, 8], "sierra_club_summari": 7, "sierra_club_top": [7, 8], "sierraclub": [6, 7, 9, 10], "sign": [21, 22], "signaling_pathwai": 10, "signific": [1, 2, 9, 12, 13, 14, 17, 19, 20, 25, 29], "significantli": [2, 7, 12, 16, 21, 22, 23, 26, 28], "silt": 10, "simil": 26, "similar": [1, 10, 12, 16, 25, 26, 30], "similar_word": [10, 12], "similarity_matrix": 17, "simpl": [1, 12, 13, 14, 17, 21, 22, 24, 26, 29, 30], "simple_preprocess": 28, "simple_senti": 13, "simplemaskedlanguagemodel": 13, "simplest": 2, "simplifi": [2, 13, 14, 24, 28, 30], "simul": [12, 13, 24], "sinc": 12, "singl": [1, 10, 13, 14, 21], "sister": 25, "site": [7, 9, 10], "size": [1, 4, 8, 10, 16, 18, 22, 30], "skew": 14, "skill": [5, 15, 21, 27, 30, 31], "skip": 10, "skip_special_token": [24, 25], "sklearn": [6, 8, 9, 10, 12, 14, 16, 17, 22, 29, 30], "slang": [17, 26], "small": [3, 4, 17, 18, 21, 22], "smaller": [3, 15, 16, 28], "smallest": 4, "smiling_face_with_heart_ey": 16, "smith": [20, 21, 24], "smote": [4, 22], "sn": [7, 8, 9], "sniffing_glue_light": 10, "snippet": 15, "snope": 29, "snowfal": 10, "snowpack": 10, "so": [4, 5, 17, 25], "social": [5, 7, 8, 15, 16, 17, 19, 21, 22, 28, 29], "social_media_data": 18, "societ": [5, 12, 25, 27, 30], "societi": [12, 14, 22, 29, 30], "socio_econom": 10, "socioeconom": [10, 12, 25], "socioeconomic_background": 10, "socioeconomic_statu": 10, "sociologi": 16, "softmax": [12, 13, 25, 29], "soil_salin": 10, "solar": [10, 17], "solar_cel": 10, "solar_energi": 10, "solar_irradi": 10, "solar_photovolta": 10, "solar_therm": 10, "sole": [4, 20], "solid": [15, 19, 23], "solut": [1, 3], "solv": 12, "solvent": 10, "some": [1, 3, 4, 6, 10, 13, 16, 17, 18, 20, 21, 24, 29], "sometim": 26, "son": 25, "sophist": [12, 13, 18, 20, 24, 25, 27, 28, 29], "sorri": 12, "sort": [6, 8, 9], "sort_valu": 10, "sound": [4, 13, 14], "soup": 29, "sourc": [1, 3, 13, 23, 26, 27], "source_languag": 26, "south": 6, "space": [1, 2, 4, 10, 12, 28], "spacex": 22, "spaci": [6, 9, 22, 28, 29, 31], "spacial": 10, "spam": 17, "spanish": 26, "spark": [24, 28], "sparksess": 28, "spars": 1, "sparsiti": 1, "spatial": 10, "spatio_tempor": 10, "spatiotempor": 10, "speak": 26, "speaker": [7, 12], "speci": 10, "special": [1, 2, 4, 6, 7, 9, 10, 12, 13, 17, 18, 29, 30], "specif": [1, 2, 3, 4, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 30, 31], "speech": [12, 26, 31], "speed": 22, "sphere": 29, "spill": 7, "spitzbergen": 10, "split": [7, 8, 9, 10, 12, 17, 20, 21, 22, 29], "spoken": 17, "sport": [12, 13, 17, 20, 21, 22], "spread": [20, 21, 24, 27, 30], "spring_layout": 29, "sql": 28, "sqrt": 13, "squar": 22, "ssn": 14, "ssn_pattern": 14, "stabl": [7, 9, 10], "stack": 8, "stage": 12, "stai": [13, 25, 27, 30], "stand": 21, "standard": [12, 16], "standardize_numb": 16, "stanford": 12, "star": 6, "start": [3, 7, 9, 10, 21, 25, 30], "start_tim": 22, "startswith": 9, "stat": 25, "state": [5, 9, 10], "statement": [6, 7, 9, 10, 26], "statist": [14, 17, 18, 25, 31], "statu": [12, 25, 30], "status_cod": 30, "stem": [2, 6, 9, 10, 12, 18, 29], "stem_token": 6, "stem_word": 16, "stemmed_text": 16, "stemmed_token": 12, "stemmer": [6, 12], "step": [2, 3, 6, 9, 10, 12, 13, 15, 16, 22, 24, 28], "stereotyp": [14, 25], "stewardess": 14, "stick": 26, "still": [1, 13, 22], "stock": [12, 17, 20, 21, 22], "stop": [2, 12, 13, 14, 17, 20, 21, 22, 26, 28, 29, 30], "stop_word": [6, 8, 10, 12, 16, 17, 18, 28, 29], "stopword": [6, 8, 9, 10, 12, 16, 17, 18, 28, 29], "stopwordsremov": 28, "storag": 10, "store": [12, 17, 22], "strateg": 10, "strategi": [1, 4, 7, 8, 9, 12, 13, 27], "stratospher": 10, "stratospheric_ozon": 10, "stratospheric_ozone_deplet": 10, "stratospheric_ozone_lay": 10, "stream": 30, "streamflow": 10, "streamflow_forecast": 10, "streamlisten": 30, "street": 13, "strength": [8, 10, 12, 19, 22], "strip": [4, 7, 8, 12, 13, 14, 20, 21, 22, 26, 29, 30], "strive": 14, "strong": [10, 14, 15, 24, 27], "structur": [12, 17, 18, 24, 28, 29], "struggl": [12, 14, 26], "stuck": 14, "student": 31, "studi": [1, 7, 10, 12, 13, 14, 17, 20, 21, 24, 27, 28, 29, 30, 31], "sub": [6, 9, 10, 16, 18, 29], "subfield": 17, "subject": [9, 26], "sublist": 28, "submit": [6, 7, 8], "subset": [3, 10], "substanc": 10, "substitut": 12, "subtl": [1, 28], "subword": 12, "success": [12, 21], "sugar_cane_bagass": 10, "suggest": [23, 26], "suitabl": [16, 17], "sulfate_aerosol": 10, "sum": [8, 10, 13, 25], "sum_word": 8, "summar": [1, 7, 12, 23, 28, 30], "summari": [5, 9, 14, 17, 20, 21, 24, 28], "summarize_text": 17, "summary_sent": 17, "super": 13, "superior": 22, "supervis": [3, 5, 19, 21, 31], "supply_chain": 10, "support": [8, 10, 12, 17, 21], "sure": [7, 12], "surfactant_replacement_therapi": 10, "surpris": 20, "surround": 13, "survei": [12, 16, 17, 18, 20, 23, 24], "survey_respons": 20, "sustain": [0, 10], "sustainable_develop": 10, "sven": 25, "svm": [12, 22], "sy": 10, "syllabu": 5, "syntact": 12, "synthes": [23, 24], "synthesi": 24, "synthet": [4, 13, 24], "system": [3, 7, 10, 11, 12, 13, 17, 20, 21, 22, 29, 30], "systemat": 25, "t": [7, 10, 11, 13, 14, 16, 18, 20, 25, 29, 30], "t5": 13, "tackl": [12, 16, 23, 26, 27], "tactic": 29, "tag": [6, 12], "tagged_text": 17, "tailor": [1, 2, 4, 24], "take": 10, "takeawai": [12, 26, 28, 29], "target": 29, "target_languag": 26, "target_nam": 12, "target_set1": 25, "target_set2": 25, "task": [1, 2, 3, 4, 5, 7, 8, 10, 11, 14, 15, 16, 19, 21, 26, 28, 30, 31], "taylor": 6, "tco2": 10, "teach": [0, 5], "teacher": [25, 30], "team": [17, 21, 22], "teap": 10, "tech": [12, 20], "technic": [10, 16, 25], "technical_potenti": 10, "techniqu": [1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 17, 19, 23, 24, 27], "technolog": 30, "technologi": [1, 2, 5, 12, 13, 17, 20, 21, 22, 24, 26, 27, 28, 30], "telescop": 12, "tell": 7, "temperatur": [4, 7, 10, 12, 13, 14, 20, 21, 22, 24, 26, 29, 30], "temperature_increas": 10, "tempor": 10, "tend": 21, "tendenc": 14, "tension": 17, "tensor": [13, 28], "tensordataset": 13, "tensorflow": 31, "terawatt": 10, "term": [1, 2, 6, 9, 10, 12, 14, 18, 21, 24, 25], "terminologi": 10, "terresti": 10, "terrestri": 10, "terrestrial_analogu": 10, "terrestrial_transmitt": 10, "terribl": [4, 12, 13, 17, 22], "tesla": 22, "test": [3, 12, 21, 22], "test_result": 21, "test_siz": [8, 12, 17, 22, 29], "texa": 6, "text": [3, 5, 7, 11, 18, 23, 25, 26, 27, 29, 30], "text_classifi": 30, "text_embed": 10, "text_low": 14, "text_result": 30, "text_scor": 30, "text_senti": 30, "text_to_classifi": 21, "text_to_explain": [14, 30], "text_to_summar": 21, "textblob": [6, 8, 9, 18, 22, 30], "textblob_senti": 8, "textblob_sentiment_categori": 8, "textdataset": 28, "textual": [1, 2, 5, 11, 12, 13, 16, 17, 19, 20, 23, 27, 31], "tf": [2, 6, 8, 12, 17, 29], "tfidf": 8, "tfidf_keyword": 8, "tfidf_matrix": [6, 9, 10, 12, 16, 17], "tfidf_physical_scor": 10, "tfidf_physical_score_sim": 10, "tfidf_physical_score_sum": 10, "tfidf_represent": 16, "tfidf_sort": 8, "tfidf_transition_scor": 10, "tfidf_transition_score_sim": 10, "tfidf_transition_score_sum": 10, "tfidf_vector": [6, 8, 9, 10], "tfidfvector": [6, 8, 9, 10, 12, 14, 16, 17, 22, 29, 30], "tfw": 26, "th": 18, "than": [6, 7, 12, 17, 20, 21], "thawing_permafrost": 10, "thei": [1, 3, 7, 9, 11, 12, 13, 16, 17, 19, 20, 21, 24, 25, 26, 27], "them": [12, 13, 16, 17, 19, 20, 21, 23, 26], "theme": [6, 8, 9, 12, 17, 18, 20], "themselv": [17, 25], "theori": [12, 29], "therefor": 16, "thermal": [7, 8], "thi": [1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "thing": 26, "think": [5, 11, 19, 20, 30], "third": [6, 7, 9, 10, 16, 28], "thorough": 15, "those": [5, 11], "though": 3, "thoughtfulli": 18, "thousand": 12, "three": [1, 4, 5, 6, 7, 9, 10, 11, 15, 19, 23, 27], "threshold": [4, 10], "thrill": [7, 13, 21, 26], "through": [1, 5, 7, 12, 14, 16, 18, 19, 20, 25, 27, 29], "throughout": [5, 11, 15, 19, 21, 23, 27], "thumbs_up": 16, "tight_layout": [6, 7, 8, 9, 10], "tiktok": 29, "tim": [17, 22], "timcywinskisierraclubo": 10, "time": [6, 7, 9, 12, 17, 18, 19, 21, 22, 27, 28], "timestamp": [6, 7, 9, 10], "titl": [6, 7, 8, 9, 10, 22, 29], "to_csv": [7, 9], "to_datetim": 10, "to_lowercas": 16, "to_panda": [6, 7, 9, 10], "toarrai": [6, 8, 9, 16], "todai": [4, 9, 12, 17, 20, 22, 30], "togeth": [8, 17], "toi": 16, "token": [2, 3, 4, 6, 8, 9, 10, 12, 13, 17, 18, 24, 25, 28, 29], "tokenize_sent": 16, "tokenize_text": 6, "tokenize_word": 16, "toll": 8, "tone": [9, 17, 18], "tongass": 10, "too": [8, 13], "took": 16, "tool": [5, 11, 12, 13, 15, 17, 18, 19, 23, 24, 26, 27, 28], "toolkit": 12, "top": [4, 6, 7, 8, 9, 10, 17, 24], "top_bigram": 8, "top_k": [4, 24], "top_p": [4, 24], "top_term": [6, 9], "topic": [5, 10, 13, 14, 15, 19, 24, 29, 30, 31], "topic_id": 9, "topic_prob": 9, "topic_senti": 9, "topic_trend": 18, "topic_word": 9, "topics_df": 8, "topn": [9, 10, 12], "topolog": 10, "torch": [10, 12, 13, 24, 28, 29], "total": [6, 7, 10], "toward": [14, 24, 25], "tower": 29, "tqdm": [7, 9, 10], "tqdmwarn": [7, 9, 10], "tr": 10, "track": [16, 17, 29, 30], "trad_explan": 22, "trad_rel": 22, "trad_sent": 22, "trad_tim": 22, "trade": [6, 22], "tradit": [1, 3, 4, 5, 10, 11, 14, 19, 21, 24, 26], "tradition": [11, 19], "traditional_bleu": 22, "traditional_ent": 22, "traditional_gener": 22, "traditional_n": 22, "traditional_perform": 22, "traditional_predict": 22, "traditional_relation_extract": 22, "traditional_senti": 22, "train": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30], "train_label": [14, 30], "train_test_split": [8, 12, 17, 22, 29], "train_text": [14, 30], "transcript": [1, 13], "transfer": [13, 20], "transform": [5, 6, 8, 10, 11, 16, 17, 21, 22, 24, 25, 27, 28, 29, 30, 31], "transformerencoderlay": 13, "transit": [10, 12], "transition_freq": 10, "transition_risk_keyword": 10, "transition_risk_keywords_vector": 10, "translat": [12, 20, 22, 26], "transpar": [11, 23, 27, 30], "treati": 21, "treatment": 25, "tree": [12, 14, 17], "trei": 10, "trend": [1, 5, 10, 12, 13, 16, 18, 21, 27, 28, 31], "trend_descript": 30, "treypollardsierra": 10, "trigram": 1, "trillion": 30, "tripping_hazard": 10, "tropic": 10, "tropical_cyclon": 10, "tropical_depress": 10, "tropical_storm": 10, "tropopaus": 10, "tropospher": 10, "true": [6, 7, 8, 9, 10, 12, 24, 25, 28, 29], "truli": [13, 28], "trump": 9, "truncat": [10, 12, 13, 28, 29], "trust": 14, "truth": 24, "try": [6, 10, 29], "tune": [1, 2, 4, 12, 14, 20, 22, 24], "turbin": 10, "turn": 20, "tutori": 31, "tweepi": [28, 29, 30], "tweet": [4, 12, 18, 28, 29, 30], "twh": 10, "twhyr": 10, "twitter": [26, 28, 29, 30], "two": [4, 10, 17, 18, 24, 26], "txt": 12, "type": [1, 2, 8, 10, 19, 20, 25, 26, 28, 29], "typic": [3, 4, 9, 12, 13, 14, 16, 18, 21, 28], "typing_optical_trackpad": 10, "u": [6, 7, 9, 10, 11, 14, 16, 25], "ultim": [15, 25], "un": 14, "una": 14, "unanim": 10, "unbeliev": 29, "uncas": [10, 12, 13, 25, 28, 29, 30], "uncov": [12, 18, 23, 27, 28], "under": 5, "undergon": [1, 5, 11], "underli": 11, "underrepres": 4, "underscor": 10, "understand": [1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 30, 31], "unep": 10, "unfair": [14, 25], "unfamiliar": 12, "unfccc": 10, "unhelp": 21, "unigram": [1, 10], "unimagin": 27, "unintend": 14, "unintent": 14, "unit": [6, 16], "univers": [0, 20, 21, 31], "unlik": [4, 13, 26], "unlock": 12, "unord": 2, "unpreced": [5, 12, 13, 23, 27], "unpredict": 26, "unproduct": 26, "unseen": [20, 22], "unstack": 18, "unstructur": [16, 17], "unsupervis": [13, 18], "unzip": 6, "up": [3, 5, 6, 8, 9, 10, 12, 17, 19, 26], "upda": 7, "updat": [7, 8, 9, 10], "update_everi": 9, "upon": 15, "upper_tropospher": 10, "upwel": 10, "urg": [6, 7, 9, 10], "url": [6, 7, 9, 10, 12, 29], "us": [1, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31], "usag": [6, 7, 8, 10, 12, 13, 14, 17, 18, 20, 21, 22, 25, 26, 28, 29, 30], "usage_descript": 14, "usd": 10, "usdkwh": 10, "used_pronoun": 14, "user": [6, 7, 9, 10, 29], "user_input": 12, "user_instal": [7, 9, 10], "uses_perpendicular_lenticular": 10, "usual": 16, "utf8": 10, "util": [6, 9, 10, 11, 13, 14, 25, 28], "uuid": [6, 7, 9, 10], "v": [8, 10, 17, 28], "vaccin": 29, "vader": 17, "vadersenti": 17, "valenc": 17, "valid": [1, 11, 12, 13, 20, 21, 22, 25, 28], "vallei": 10, "valu": [4, 13, 21, 25, 26], "valuabl": [1, 9, 10, 13, 17, 18, 21, 24], "value_count": [7, 9, 28], "vapor_degreas": 10, "vari": [10, 14, 22], "variabl": [7, 10, 16, 24], "variant": 12, "variat": [18, 21], "varieti": 12, "variou": [1, 6, 7, 9, 12, 17, 19, 21, 22, 23, 24, 25, 26, 28, 29], "vast": [1, 5, 12, 13, 20, 21, 23, 27, 28], "vbd": 12, "ve": [5, 6, 7, 9, 12, 27], "vec": 8, "vector": [1, 2, 6, 8, 10, 12, 14, 16, 17, 18, 22, 29, 30], "vector_s": 12, "venv": [7, 9, 10], "verb": 17, "verbos": [6, 7, 8, 9, 10], "veri": [1, 13, 14, 18, 21, 22, 28, 30], "verifi": 24, "versail": 21, "version": [3, 13], "versu": [10, 19], "vi": [8, 9], "via": 10, "victori": 7, "video": [29, 30], "vietnam": 6, "view": [10, 12], "virtual": 3, "viru": [24, 29], "vis_data": 18, "visibl": 28, "visual": [7, 8, 9, 13, 14, 18, 29, 30], "vivid": 26, "vocab_s": 13, "vocabulari": [1, 2, 10, 12, 16], "vocabulary_": [8, 10], "volum": [1, 13, 17, 21, 23, 26], "vp": 12, "vulner": 14, "w": [10, 14, 18, 22], "wa": [12, 13, 14, 17, 18, 21, 29, 30], "wage": 13, "wai": [5, 13, 15, 22, 23, 25], "waiter": 21, "wake": 10, "walk": [13, 25], "wall": 10, "want": [10, 18, 26], "war": [12, 21, 26], "warm": 10, "warn": [7, 8, 14], "washington": [6, 9], "wasn": 20, "wast": 12, "watch": 12, "water": [7, 8, 10], "water_resourc": 10, "water_vapor": 10, "wd": 18, "we": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30], "weak": 8, "weat_scor": 25, "weat_signific": 25, "weat_test": 25, "weather": [4, 17, 21, 22], "web": [14, 16], "websit": [13, 16, 29], "week": [21, 31], "weekli": 31, "wei": 25, "weigh": [1, 13], "weight": [4, 8, 10, 12, 13, 22], "welcom": [5, 11, 15, 19, 23, 27], "well": [15, 16, 17], "were": [12, 13, 20, 28], "western": [14, 21], "wetland": 10, "wetland_habitat": 10, "what": [5, 6, 7, 8, 9, 13, 14, 15, 16, 20, 21, 26, 27, 29], "when": [1, 3, 4, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "where": [1, 2, 4, 18, 20, 21, 23], "which": [1, 4, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 28], "while": [1, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 24, 25, 26], "white": 9, "who": [5, 9, 14, 21], "whole": 21, "whose": 4, "why": [12, 13, 14, 24], "wide": [11, 12, 13, 17, 18, 20, 21], "width": 9, "wiggle_room": 10, "wiki": [16, 30], "wildlif": [7, 8], "win": 22, "wind": 10, "wind_energi": 10, "window": 12, "with_label": 29, "within": [2, 10, 17, 18, 26], "without": [1, 3, 4, 7, 12, 13, 19, 20, 21, 25], "wittman": [6, 7, 9, 10], "woman": [12, 25, 30], "women": 13, "won": [17, 20, 21, 29], "woody_biomass": 10, "word": [4, 7, 13, 17, 18, 20, 21, 22, 26, 28, 29, 30], "word2vec": [1, 2, 10, 12], "word2vec_model": 10, "word_freq": [6, 9, 17], "word_pair": 30, "word_token": [6, 8, 9, 10, 12, 16, 17, 18, 28, 29], "wordcloud": 9, "wordnet": [6, 9, 10, 12, 18], "wordnetlemmat": [6, 9, 10, 12, 16, 18, 29], "words_freq": 8, "wordsdf": 28, "work": [1, 3, 4, 5, 7, 10, 11, 13, 14, 15, 18, 19, 24, 28, 30], "work_of_art": 6, "worker": [6, 12, 28], "workflow": [17, 23], "workforc": 13, "workspac": [6, 7, 8, 9, 10], "workspace_dir": [6, 7, 8, 9, 10], "world": [5, 12, 13, 21, 25], "worst": 12, "would": [16, 28], "write": [7, 8, 12], "written": [0, 7, 8], "wv": 12, "www": [6, 7, 9, 10, 16, 29], "x": [6, 7, 8, 9, 10, 13, 18, 22, 30], "x86_64": 10, "x_subset": 22, "x_test": [8, 12, 17, 22, 29], "x_test_tfidf": [8, 12, 29], "x_test_vec": [12, 22], "x_test_vector": 17, "x_train": [8, 12, 17, 22, 29], "x_train_balanc": 22, "x_train_tfidf": [8, 12, 29], "x_train_vec": [12, 22], "x_train_vector": 17, "xlabel": [6, 7, 8, 9, 10, 22], "xtick": [6, 7, 8, 9, 10], "y": [8, 22, 30], "y_pred": [12, 17, 22, 29], "y_subset": 22, "y_test": [8, 12, 17, 22, 29], "y_train": [8, 12, 17, 22, 29], "y_train_balanc": 22, "y_true": 22, "yard": 17, "ye": 26, "year": [5, 6, 11, 15, 24], "yesterdai": 21, "yield": 21, "yj": [0, 6, 7, 9], "yjlee": 10, "ylabel": [6, 7, 8, 9, 10, 22], "york": [17, 22, 29], "you": [5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 19, 21, 23, 24, 27, 28, 29], "young": 13, "younger": 30, "your": [2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30], "your_access_token": [28, 30], "your_access_token_secret": [28, 30], "your_api_kei": 7, "your_consumer_kei": [28, 30], "your_consumer_secret": [28, 30], "youtub": 29, "yr": 10, "z": [6, 9, 10, 14, 18, 29], "z0": [14, 16], "za": [6, 9, 10, 14, 16, 18, 29], "zd": 18, "zero": [1, 5, 8, 19, 21, 22, 29, 30, 31], "zero_grad": [13, 28], "zero_shot_classif": [7, 12, 13, 20], "zero_shot_emotion_detect": 20, "zero_shot_multi_label_classif": 20, "zero_shot_n": 20, "zero_shot_qa": 20, "zero_shot_sentiment_analysi": 20, "zero_shot_summar": 20, "zero_shot_top": [7, 8], "zhang": 25, "ziesch": [6, 7, 9, 10], "zip": [6, 7, 8, 9, 25, 30], "zone": 10, "zooplankton": 10, "\u03b1": 18, "\u03b2": 18, "\u03b8": 18, "\u03b8d": 18, "\u03bc": 10, "\u03c6": 18, "\u03c6k": 18, "\u03c6zd": 18, "\u6211\u559c\u6b22\u8fd9\u4e2a\u4ea7\u54c1": 30, "\u8fd9\u662f\u4e00\u4e2a\u4e2d\u6587\u53e5\u5b50": 14}, "titles": ["Who made this book?", "Extra 1: The Evolution and Impact of LLMs in Social Science Research", "Extra 2: Text Representation and NLP Pipeline", "Extra 3: Practical Considerations for Using LLMs in Social Science Research", "Extra 4: Advanced Considerations for LLMs in Social Science Research", "Home", "Lab Session 1: Introduction to NLP for Social Science", "Lab Session 2: LLMs for Data Annotation and Classification", "Lab Session 3: Applying Traditional NLP Techniques", "NLP Analysis of Sierra Club Press Releases", "Climate Risk Analysis of Sierra Club Press Releases", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Course Syllabus"], "titleterms": {"0": 6, "1": [1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31], "10": [12, 17, 18, 20, 21, 22, 24, 26, 29], "11": [18, 21, 22, 26], "12": [18, 21, 22], "13": 18, "1950": 12, "1980": 12, "2": [1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31], "2000": 12, "2010": 12, "3": [1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31], "4": [1, 2, 3, 4, 6, 7, 8, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "5": [1, 2, 3, 6, 7, 8, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "6": [1, 3, 6, 7, 8, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "7": [1, 3, 6, 7, 8, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "8": [1, 3, 6, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30], "9": [12, 13, 17, 18, 20, 21, 22, 24, 25, 26, 29, 30], "A": 1, "In": 21, "Its": 31, "The": [1, 2], "Their": 12, "abil": 13, "about": 5, "academ": 14, "access": [7, 14], "accuraci": [13, 14], "adapt": [13, 22], "addit": 31, "address": 16, "advanc": [4, 13, 18, 27, 30, 31], "advantag": [2, 13], "ai": [14, 30], "algorithm": 18, "alloc": [17, 18], "altern": 3, "ambigu": 12, "analysi": [6, 7, 8, 9, 10, 13, 17, 20, 21, 22, 25, 26, 28, 29, 30], "analyz": [12, 25, 28], "annot": [7, 19, 31], "answer": [13, 20, 21], "api": 3, "appli": 8, "applic": [18, 20, 23, 27, 31], "approach": [2, 3, 12, 22, 29], "architectur": 13, "aspect": 24, "assess": [29, 31], "associ": 25, "attent": 13, "attribut": 14, "augment": 24, "autom": 1, "bag": [1, 2, 16], "balanc": [1, 2, 14], "base": [2, 7, 10, 17, 24, 29], "basic": [6, 12, 17], "bert": [10, 13], "bia": [14, 25], "bias": 13, "book": 0, "bow": [1, 2, 16], "capabl": [1, 12, 13, 20, 21, 22], "categor": 28, "challeng": [1, 12, 13, 14, 17, 18, 25, 26], "chang": 1, "changelog": 5, "charact": 16, "characterist": 29, "choos": 2, "class": 17, "classif": [7, 8, 17, 19, 20, 21, 22, 28, 31], "clean": 16, "climat": 10, "cloud": 9, "club": [9, 10], "cluster": 17, "co": 8, "collabor": 30, "collect": [28, 29], "combin": 18, "commerci": 3, "compar": [8, 22], "comparison": [8, 22], "complet": 13, "complex": [12, 13], "complianc": 14, "compon": 13, "comput": [12, 13, 14, 22], "concept": [12, 13], "concern": 14, "conclus": [6, 9, 10, 12, 14, 16, 17, 21, 22, 24, 25, 26, 28, 29, 30], "consider": [1, 2, 3, 4, 7, 13, 14, 23, 25, 27], "consist": 14, "content": [5, 14, 24, 29], "context": [12, 13, 21, 26], "contribut": 5, "control": [4, 24], "convers": 16, "copyright": 14, "core": 13, "corpora": 13, "cost": 3, "cours": [5, 31], "creation": 24, "credibl": 29, "cross": [13, 14, 30], "crucial": 1, "cultur": [14, 26, 30], "current": 12, "data": [3, 6, 7, 8, 9, 10, 12, 13, 14, 18, 19, 24, 28, 29, 31], "dataset": [4, 12, 13, 28], "date": 16, "deal": [12, 16], "decis": 14, "deep": [12, 29], "defin": 10, "definit": [12, 13], "deploy": 13, "descript": 31, "design": [1, 21], "detect": [13, 14, 20, 25, 26, 29], "develop": 12, "direct": [2, 12, 13, 18, 30], "dirichlet": [17, 18], "discours": 26, "dispar": 14, "distinct": 13, "divers": 14, "document": [16, 17], "domain": 13, "earli": 12, "effici": [13, 22], "email": 16, "embed": [1, 2, 10, 12, 16, 25], "emerg": [12, 30], "emoji": 16, "emot": [13, 20, 24], "emoticon": 16, "engin": [3, 20, 21, 24], "enhanc": 13, "ensur": 14, "entiti": [6, 9, 17, 20, 21, 22, 28], "environment": [7, 14], "equiti": 14, "ethic": [7, 13, 14, 23, 25, 27, 30], "ethnic": 25, "evalu": [8, 12, 17, 18, 22, 24, 26], "evolut": [1, 2, 12], "exampl": [12, 13, 17], "exercis": [6, 7, 8], "expand": 10, "explain": [14, 22, 30], "explan": [23, 24, 26, 31], "explor": [23, 27], "exposur": 14, "extra": [1, 2, 3, 4, 5], "extract": [8, 12, 17, 20, 21, 22, 28], "factual": [13, 14], "fake": 29, "featur": 12, "few": [4, 7, 12, 13, 21], "figur": 26, "fine": 13, "foundat": [18, 20], "frequenc": [6, 9, 10, 16], "from": [12, 13], "fundament": [12, 17, 18, 21, 24], "futur": [1, 2, 12, 13, 18, 27, 30], "gender": 25, "gener": [4, 7, 12, 13, 14, 20, 21, 22, 23, 24, 31], "gensim": 17, "global": 14, "gpt": 13, "gram": 1, "hallucin": 14, "handl": [3, 4, 12, 13, 16], "high": 24, "histor": 12, "home": 5, "html": 16, "human": [1, 13, 30], "hybrid": 3, "identif": 14, "idf": [1, 9, 10, 16], "idiom": 26, "imbalanc": 4, "impact": [1, 12, 14], "implement": 18, "implic": 14, "import": [1, 2, 12, 14], "improv": [13, 14], "infer": 25, "inform": [13, 14, 20, 21, 22], "initi": 10, "insight": 1, "instal": [6, 7, 8, 9, 10], "instructor": 0, "integr": [13, 14], "intellectu": 14, "interpret": [2, 7, 8, 13, 14, 17, 18, 22, 26, 30], "introduct": [6, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31], "invers": 16, "ironi": 26, "issu": [7, 8, 14], "its": [12, 13], "joon": 0, "kei": [1, 7, 8, 13, 23, 27], "keyword": 10, "knowledg": 13, "lab": [5, 6, 7, 8], "lack": 13, "languag": [12, 13, 26, 30], "larg": [12, 13, 14, 28, 30], "larger": 12, "latent": [17, 18], "lda": [8, 17, 18], "learn": [4, 7, 12, 13, 20, 21, 22, 29], "lectur": 5, "lee": 0, "lemmat": 16, "lexicon": 17, "librari": 6, "licens": 5, "like": 13, "limit": [2, 13, 17, 18, 26], "lingual": 13, "ll": [23, 27], "llm": [1, 2, 3, 4, 7, 12, 13, 14, 19, 20, 21, 22, 24, 25, 26, 27, 29, 31], "load": [6, 7, 8, 9, 10], "lowercas": 16, "machin": 29, "made": 0, "manag": 3, "massiv": 13, "materi": 31, "mathemat": 18, "matter": [2, 5, 23, 27], "mechan": 13, "media": 26, "metaphor": 26, "method": 8, "methodologi": 22, "metric": [22, 26], "mine": [21, 22], "misinform": [24, 29], "mitig": [13, 14, 25], "modal": 13, "model": [8, 9, 12, 13, 14, 16, 17, 18, 28, 30], "modern": [2, 12], "multi": [13, 17], "multilingu": 30, "multimod": 30, "n": 1, "name": [6, 9, 17, 20, 21, 22, 28], "natur": [1, 12], "need": 14, "ner": [17, 20, 21, 22], "network": 29, "neuro": 30, "new": [12, 29], "nlp": [1, 2, 6, 8, 9, 11, 12, 13, 14, 15, 17, 18, 25, 30, 31], "nltk": 17, "normal": 16, "notabl": 13, "note": 5, "number": [1, 16], "object": [5, 7, 8, 31], "occurr": 8, "ongo": 12, "opinion": [21, 22], "opportun": 12, "optim": 21, "other": [13, 18], "outcom": 14, "output": [3, 14], "overview": [5, 10, 13], "paradigm": [1, 12], "paramet": [4, 24], "paraphras": 13, "part": 17, "perform": 22, "person": 14, "perspect": 12, "pipelin": [2, 12], "plagiar": 14, "po": 17, "polit": 26, "pose": 14, "possibl": 12, "potenti": [13, 14], "practic": [2, 3, 23, 27], "pre": 13, "prepar": [18, 27], "preprocess": [6, 9, 10, 12, 15, 16, 28, 29, 31], "prerequisit": 31, "present": 12, "press": [9, 10], "privaci": 14, "process": [12, 13, 26, 28, 30], "progress": 13, "project": [5, 10], "promin": 13, "prompt": [3, 20, 21, 24], "proper": 14, "properti": 14, "protect": 14, "proverb": 26, "purpos": 12, "qualiti": 24, "quantifi": 25, "question": [13, 20, 21], "racial": 25, "re": 14, "real": 30, "reason": 13, "recap": 22, "recent": 13, "recognit": [6, 9, 17, 20, 21, 22, 28], "recommend": 31, "regul": 14, "relat": [22, 28], "releas": [9, 10], "relev": 1, "reliabl": 14, "remov": 16, "replac": 16, "represent": [2, 6, 16], "reproduc": [3, 14], "requir": [6, 13, 14, 22, 31], "research": [1, 2, 3, 4, 12, 13, 14, 18, 20, 24, 27, 29, 30, 31], "resourc": [13, 14, 22, 31], "respons": 30, "result": [9, 10, 14, 18], "retriev": 13, "revolut": 12, "right": 2, "rise": 12, "risk": [10, 14], "sarcasm": 26, "save": 9, "scalabl": [22, 28], "scale": [13, 14, 28], "schedul": 31, "scienc": [1, 2, 3, 4, 6, 11, 12, 13, 14, 18, 20, 23, 24, 27, 30, 31], "scientif": 14, "scientist": 12, "self": 13, "semant": 12, "sentenc": 16, "sentiment": [6, 7, 8, 9, 13, 17, 20, 21, 22, 28], "seri": [10, 13], "session": [6, 7, 8, 11, 15, 19, 23, 27, 31], "set": 7, "setup": [3, 6, 7, 8, 9, 10], "shift": [1, 12], "shot": [4, 7, 12, 13, 20, 21], "sierra": [9, 10], "similar": 17, "size": 13, "skill": 1, "social": [1, 2, 3, 4, 6, 11, 12, 13, 14, 18, 20, 23, 24, 25, 26, 27, 30, 31], "societ": 14, "socioeconom": 14, "sophist": 2, "sourc": [14, 25, 28, 29], "spaci": 17, "special": 16, "specif": [12, 13], "speech": 17, "spread": 29, "state": 12, "statist": 12, "stem": 16, "step": 1, "stop": 16, "strategi": [14, 21], "structur": [5, 31], "student": 0, "summar": [13, 17, 20, 21, 24], "summari": [7, 23, 31], "supervis": 22, "sustain": 14, "syllabu": 31, "symbol": 30, "tabl": 5, "tag": [16, 17], "task": [6, 12, 13, 17, 20, 22, 24], "technic": 3, "techniqu": [2, 8, 14, 15, 16, 18, 21, 25, 28, 29, 31], "technologi": 14, "term": 16, "test": 25, "text": [1, 2, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 28, 31], "textbook": 31, "textual": 28, "tf": [1, 9, 10, 16], "theoret": 20, "thi": [0, 5], "time": [10, 30], "token": 16, "topic": [7, 8, 9, 17, 18, 23, 27, 28], "toward": 12, "tradit": [2, 8, 12, 13, 15, 22, 29, 31], "train": [12, 13, 14], "transform": [1, 12, 13], "translat": 13, "transpar": [13, 14], "trend": 30, "true": 13, "tune": 13, "type": [14, 17, 21, 24], "understand": [13, 26], "uniqu": 14, "unstructur": 12, "up": [7, 13], "url": 16, "us": [3, 10, 14, 17, 24, 25], "v": [2, 4], "valid": [3, 14], "variant": 13, "variou": 13, "visual": 10, "we": [23, 27], "weat": 25, "who": 0, "why": [2, 5, 23, 27], "wisdom": 26, "word": [1, 2, 6, 8, 9, 10, 12, 16, 25], "young": 0, "zero": [4, 7, 12, 13, 20]}})