Search.setIndex({"alltitles": {"0. Installation": [[5, "installation"]], "1. Cost Management": [[3, "cost-management"]], "1. Introduction": [[5, "introduction"], [19, "introduction"]], "1. Introduction to Emerging Trends in NLP for Social Science": [[27, "introduction-to-emerging-trends-in-nlp-for-social-science"]], "1. Introduction to Ethics in AI and NLP Research": [[11, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Few-shot Learning": [[18, "introduction-to-few-shot-learning"]], "1. Introduction to Figurative Language": [[23, "introduction-to-figurative-language"]], "1. Introduction to Fundamental NLP Tasks": [[14, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[10, "introduction-to-generative-llms"]], "1. Introduction to Large-Scale Text Analysis": [[25, "introduction-to-large-scale-text-analysis"]], "1. Introduction to Misinformation and Fake News": [[26, "introduction-to-misinformation-and-fake-news"]], "1. Introduction to Natural Language Processing (NLP)": [[9, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Social Bias in NLP": [[22, "introduction-to-social-bias-in-nlp"]], "1. Introduction to Text Generation with LLMs": [[21, "introduction-to-text-generation-with-llms"]], "1. Introduction to Text Preprocessing": [[13, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[15, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[17, "introduction-to-zero-shot-learning"]], "1. Setting up LLM Access": [[6, "setting-up-llm-access"]], "1. Text Classification: Comparing Traditional Methods": [[7, "text-classification-comparing-traditional-methods"]], "1. The Importance of Text Representation in NLP": [[2, "the-importance-of-text-representation-in-nlp"]], "1. The Paradigm Shift in NLP": [[1, "the-paradigm-shift-in-nlp"]], "1.1 Definition of NLP": [[9, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[9, null]], "1.2 Basic Concepts": [[9, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[10, null]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[11, null]], "1.3 Importance in Social Science Research": [[9, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[15, "applications-in-social-science-research"], [17, "applications-in-social-science-research"]], "10. Computational Efficiency and Resource Requirements": [[19, "computational-efficiency-and-resource-requirements"]], "10. Current State and Future Directions": [[9, "current-state-and-future-directions"]], "10. Evaluation Metrics for Figurative Language Processing": [[23, "evaluation-metrics-for-figurative-language-processing"]], "10. Evaluation and Interpretation": [[14, "evaluation-and-interpretation"]], "10. Evaluation of Generated Text": [[21, "evaluation-of-generated-text"]], "10. Few-shot Text Generation and Summarization": [[18, "few-shot-text-generation-and-summarization"]], "10. Network Analysis in Misinformation Spread": [[26, "network-analysis-in-misinformation-spread"]], "10.1 Ongoing Developments in LLMs": [[9, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[9, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations": [[23, "challenges-and-limitations"]], "11. Challenges and Limitations of LDA": [[15, "challenges-and-limitations-of-lda"]], "11. Few-shot Question Answering and Information Extraction": [[18, "few-shot-question-answering-and-information-extraction"]], "11. Scalability and Adaptability": [[19, "scalability-and-adaptability"]], "12. Combining Topic Modeling with Other NLP Techniques": [[15, "combining-topic-modeling-with-other-nlp-techniques"]], "12. Interpretability and Explainability": [[19, "interpretability-and-explainability"]], "12. Prompt Optimization Techniques": [[18, "prompt-optimization-techniques"]], "13. Future Directions in Topic Modeling": [[15, "future-directions-in-topic-modeling"]], "2. Advancements in Large Language Models": [[27, "advancements-in-large-language-models"]], "2. Bias in LLMs": [[11, "bias-in-llms"]], "2. Characteristics of Misinformation and Fake News": [[26, "characteristics-of-misinformation-and-fake-news"]], "2. Cultural Context in Figurative Language": [[23, "cultural-context-in-figurative-language"]], "2. Data Sources for Large-Scale Text Analysis": [[25, "data-sources-for-large-scale-text-analysis"]], "2. Evolution of Text Representation Techniques": [[2, "evolution-of-text-representation-techniques"]], "2. Few-shot Learning Capabilities of LLMs": [[18, "few-shot-learning-capabilities-of-llms"]], "2. Fundamentals of LLM-based Text Generation": [[21, "fundamentals-of-llm-based-text-generation"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[15, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Historical Perspective of NLP": [[9, "historical-perspective-of-nlp"]], "2. Key Capabilities of LLMs for Social Science": [[1, "key-capabilities-of-llms-for-social-science"]], "2. Key Components of LLMs": [[10, "key-components-of-llms"]], "2. Recap of Traditional Supervised Learning": [[19, "recap-of-traditional-supervised-learning"]], "2. Setup and Data Loading": [[5, "setup-and-data-loading"]], "2. Sources of Bias in LLMs": [[22, "sources-of-bias-in-llms"]], "2. Technical Setup": [[3, "technical-setup"]], "2. Text Classification": [[14, "text-classification"]], "2. Text Cleaning": [[13, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[17, "theoretical-foundations-of-zero-shot-learning"]], "2. Topic Modeling with LDA": [[7, "topic-modeling-with-lda"]], "2. Zero-shot Classification for Environmental Topics": [[6, "zero-shot-classification-for-environmental-topics"]], "2.1 Bag-of-Words (BoW) Approach": [[2, "bag-of-words-bow-approach"]], "2.1 Early Approaches (1950s-1980s)": [[9, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[13, null]], "2.2 Basic NLP Tasks": [[14, null]], "2.2 Statistical Revolution (1980s-2000s)": [[9, "statistical-revolution-1980s-2000s"]], "2.2 Word Embeddings": [[2, "word-embeddings"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[15, null]], "3. Challenges and Considerations": [[1, "challenges-and-considerations"]], "3. Data Collection and Preprocessing for Large Datasets": [[25, "data-collection-and-preprocessing-for-large-datasets"]], "3. Data Handling": [[3, "data-handling"]], "3. Data Sources for Misinformation Research": [[26, "data-sources-for-misinformation-research"]], "3. Few-shot Learning for Sentiment Analysis": [[6, "few-shot-learning-for-sentiment-analysis"]], "3. LLM Approaches in Comparison": [[19, "llm-approaches-in-comparison"]], "3. LLMs and Figurative Language Understanding": [[23, "llms-and-figurative-language-understanding"]], "3. Lowercase Conversion": [[13, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[15, "mathematical-foundation-of-lda"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[9, "modern-nlp-and-deep-learning-2010s-present"]], "3. Multimodal Analysis": [[27, "multimodal-analysis"]], "3. Notable Examples of LLMs": [[10, "notable-examples-of-llms"]], "3. Privacy Concerns": [[11, "privacy-concerns"]], "3. Required Libraries": [[5, "required-libraries"]], "3. Sentiment Analysis": [[14, "sentiment-analysis"]], "3. Techniques for Detecting Bias in LLMs": [[22, "techniques-for-detecting-bias-in-llms"]], "3. The NLP Pipeline: Traditional vs. Modern Approaches": [[2, "the-nlp-pipeline-traditional-vs-modern-approaches"]], "3. Types of Few-shot Learning": [[18, "types-of-few-shot-learning"]], "3. Types of Text Generation Tasks": [[21, "types-of-text-generation-tasks"]], "3. Word Co-occurrence Analysis": [[7, "word-co-occurrence-analysis"]], "3. Zero-shot Capabilities of LLMs": [[17, "zero-shot-capabilities-of-llms"]], "3.1 Traditional NLP Pipeline": [[2, "traditional-nlp-pipeline"]], "3.1 Zero-shot Learning with LLMs": [[17, null]], "3.2 Few-shot Learning and Prompt Engineering": [[18, null]], "3.2 Modern LLM-based Approach": [[2, "modern-llm-based-approach"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[19, null]], "4. Capabilities of LLMs in Social Science Contexts": [[10, "capabilities-of-llms-in-social-science-contexts"]], "4. Data Collection and Preprocessing": [[26, "data-collection-and-preprocessing"]], "4. Evaluation Metrics and Methodologies": [[19, "evaluation-metrics-and-methodologies"]], "4. Explainable AI and Interpretable NLP": [[27, "explainable-ai-and-interpretable-nlp"]], "4. Fundamentals of Prompt Engineering": [[18, "fundamentals-of-prompt-engineering"]], "4. LDA Algorithm": [[15, "lda-algorithm"]], "4. LLM-based Data Annotation: Key Environmental Issues": [[6, "llm-based-data-annotation-key-environmental-issues"]], "4. Metaphor Detection and Interpretation": [[23, "metaphor-detection-and-interpretation"]], "4. Named Entity Recognition (NER)": [[14, "named-entity-recognition-ner"]], "4. Practical Considerations in Social Science Research": [[2, "practical-considerations-in-social-science-research"]], "4. Prompt Engineering": [[3, "prompt-engineering"]], "4. Prompt Engineering for Text Generation": [[21, "prompt-engineering-for-text-generation"]], "4. Prompt Engineering for Zero-shot Tasks": [[17, "prompt-engineering-for-zero-shot-tasks"]], "4. Quantifying Bias in LLMs": [[22, "quantifying-bias-in-llms"]], "4. Scalable Text Processing Techniques": [[25, "scalable-text-processing-techniques"]], "4. Sentiment Analysis Comparison": [[7, "sentiment-analysis-comparison"]], "4. Text Preprocessing": [[5, "text-preprocessing"]], "4. The Changing Nature of NLP Skills": [[1, "the-changing-nature-of-nlp-skills"]], "4. Tokenization": [[13, "tokenization"]], "4. Traditional NLP Pipeline": [[9, "traditional-nlp-pipeline"]], "4. Transparency and Interpretability": [[11, "transparency-and-interpretability"]], "4.1 Choosing the Right Representation": [[2, "choosing-the-right-representation"]], "4.1 Text Preprocessing": [[9, "text-preprocessing"]], "4.1 Using LLMs for High-Quality Text Generation": [[21, null]], "4.2 Balancing Sophistication and Interpretability": [[2, "balancing-sophistication-and-interpretability"]], "4.2 Feature Extraction": [[9, "feature-extraction"]], "4.2 Social Bias Inference and Analysis": [[22, null]], "4.3 Figurative Language Explanation and Cultural Context": [[23, null]], "4.3 Model Training and Evaluation": [[9, "model-training-and-evaluation"]], "5. Basic NLP Tasks": [[5, "basic-nlp-tasks"]], "5. Challenges in Traditional NLP": [[9, "challenges-in-traditional-nlp"]], "5. Controlling Generation Parameters": [[21, "controlling-generation-parameters"]], "5. Ethical AI and Responsible NLP": [[27, "ethical-ai-and-responsible-nlp"]], "5. Future Directions": [[2, "future-directions"]], "5. Generating Summaries with LLMs": [[6, "generating-summaries-with-llms"]], "5. Idiom Processing with LLMs": [[23, "idiom-processing-with-llms"]], "5. Key Issue Extraction Evaluation": [[7, "key-issue-extraction-evaluation"]], "5. Output Validation": [[3, "output-validation"]], "5. Part-of-Speech (POS) Tagging": [[14, "part-of-speech-pos-tagging"]], "5. Performance Comparison in Classification Tasks": [[19, "performance-comparison-in-classification-tasks"]], "5. Preparing Data for LDA": [[15, "preparing-data-for-lda"]], "5. Prompt Design Strategies": [[18, "prompt-design-strategies"]], "5. Reliability and Reproducibility": [[11, "reliability-and-reproducibility"]], "5. Social Bias Inference Using LLMs": [[22, "social-bias-inference-using-llms"]], "5. Stop Word Removal": [[13, "stop-word-removal"]], "5. The Importance of Research Design": [[1, "the-importance-of-research-design"]], "5. Topic Modeling at Scale": [[25, "topic-modeling-at-scale"]], "5. Traditional Machine Learning Approaches": [[26, "traditional-machine-learning-approaches"]], "5. Training Process of LLMs": [[10, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[17, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[25, null]], "5.1 Handling Language Ambiguity": [[9, "handling-language-ambiguity"]], "5.1 Word Frequency Analysis": [[5, "word-frequency-analysis"]], "5.2 Dealing with Context and Semantics": [[9, "dealing-with-context-and-semantics"]], "5.2 Misinformation and Fake News Detection": [[26, null]], "5.2 Named Entity Recognition": [[5, "named-entity-recognition"]], "5.3 Computational Complexity": [[9, "computational-complexity"]], "5.3 Future Directions and Emerging Trends": [[27, null]], "5.3 Sentiment Analysis": [[5, "sentiment-analysis"]], "6. Advantages of LLMs in Social Science Research": [[10, "advantages-of-llms-in-social-science-research"]], "6. Alternatives to Commercial APIs": [[3, "alternatives-to-commercial-apis"]], "6. Analysis and Interpretation": [[6, "analysis-and-interpretation"], [7, "analysis-and-interpretation"]], "6. Analyzing Gender Bias": [[22, "analyzing-gender-bias"]], "6. Aspect-based Emotion Summarization": [[21, "aspect-based-emotion-summarization"]], "6. Comparing Text Generation Capabilities": [[19, "comparing-text-generation-capabilities"]], "6. Deep Learning Techniques": [[26, "deep-learning-techniques"]], "6. Evolution Towards Modern NLP": [[9, "evolution-towards-modern-nlp"]], "6. Implementing LDA": [[15, "implementing-lda"]], "6. In-context Learning": [[18, "in-context-learning"]], "6. Intellectual Property and Attribution": [[11, "intellectual-property-and-attribution"]], "6. Large-Scale Sentiment Analysis": [[25, "large-scale-sentiment-analysis"]], "6. Multilingual and Cross-cultural NLP": [[27, "multilingual-and-cross-cultural-nlp"]], "6. Sarcasm and Irony Detection": [[23, "sarcasm-and-irony-detection"]], "6. Stemming": [[13, "stemming"]], "6. Text Representation": [[5, "text-representation"]], "6. Text Summarization": [[14, "text-summarization"]], "6. The Future of NLP in Social Science": [[1, "the-future-of-nlp-in-social-science"]], "6. Zero-shot Named Entity Recognition (NER)": [[17, "zero-shot-named-entity-recognition-ner"]], "6.1 Introduction of Word Embeddings": [[9, "introduction-of-word-embeddings"]], "6.2 Rise of Deep Learning in NLP": [[9, "rise-of-deep-learning-in-nlp"]], "6.3 Emergence of Transformer Models": [[9, "emergence-of-transformer-models"]], "7. Balancing Automation and Human Insight": [[1, "balancing-automation-and-human-insight"]], "7. Conclusion": [[5, "conclusion"]], "7. Environmental and Resource Considerations": [[11, "environmental-and-resource-considerations"]], "7. Exercise": [[6, "exercise"], [7, "exercise"]], "7. Few-shot Classification Techniques": [[18, "few-shot-classification-techniques"]], "7. Figurative Language in Social Media Analysis": [[23, "figurative-language-in-social-media-analysis"]], "7. Interpreting LDA Results": [[15, "interpreting-lda-results"]], "7. LLM-based Approaches to Misinformation Detection": [[26, "llm-based-approaches-to-misinformation-detection"]], "7. Large Language Models (LLMs)": [[9, "large-language-models-llms"]], "7. Lemmatization": [[13, "lemmatization"]], "7. Limitations and Challenges": [[10, "limitations-and-challenges"]], "7. Misinformation Explanation Generation": [[21, "misinformation-explanation-generation"]], "7. Named Entity Recognition (NER) Performance": [[19, "named-entity-recognition-ner-performance"]], "7. Named Entity Recognition and Relation Extraction": [[25, "named-entity-recognition-and-relation-extraction"]], "7. Racial and Ethnic Bias Analysis": [[22, "racial-and-ethnic-bias-analysis"]], "7. Real-time Language Processing and Analysis": [[27, "real-time-language-processing-and-analysis"]], "7. Reproducibility": [[3, "reproducibility"]], "7. Text Similarity and Clustering": [[14, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[17, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[9, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[9, "examples-and-their-impact"]], "8. Content-based Analysis": [[26, "content-based-analysis"]], "8. Evaluating Topic Models": [[15, "evaluating-topic-models"]], "8. Exercise": [[5, "exercise"]], "8. Few-shot Named Entity Recognition (NER)": [[18, "few-shot-named-entity-recognition-ner"]], "8. High-Quality Content Creation": [[21, "high-quality-content-creation"]], "8. Hybrid Approaches": [[3, "hybrid-approaches"]], "8. Mitigating Bias in LLMs": [[22, "mitigating-bias-in-llms"]], "8. Neuro-symbolic AI in NLP": [[27, "neuro-symbolic-ai-in-nlp"]], "8. Paradigm Shift in NLP Tasks": [[9, "paradigm-shift-in-nlp-tasks"]], "8. Proverbs and Cultural Wisdom": [[23, "proverbs-and-cultural-wisdom"]], "8. Recent Advancements": [[10, "recent-advancements"]], "8. Sentiment Analysis and Opinion Mining": [[19, "sentiment-analysis-and-opinion-mining"]], "8. Socioeconomic Implications": [[11, "socioeconomic-implications"]], "8. Text Classification and Categorization": [[25, "text-classification-and-categorization"]], "8. Text Representation Techniques": [[13, "text-representation-techniques"]], "8. Text-to-Number Transformation: A Crucial Step in NLP": [[1, "text-to-number-transformation-a-crucial-step-in-nlp"]], "8. Topic Modeling": [[14, "topic-modeling"]], "8. Zero-shot Text Summarization and Generation": [[17, "zero-shot-text-summarization-and-generation"]], "8.1 Bag-of-Words (BoW) and TF-IDF": [[1, "bag-of-words-bow-and-tf-idf"]], "8.1 From Task-Specific to General-Purpose Models": [[9, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[9, "few-shot-and-zero-shot-learning"]], "8.2 N-grams": [[1, "n-grams"]], "8.3 Word Embeddings": [[1, "word-embeddings"]], "8.4 Challenges in Text-to-Number Transformation": [[1, "challenges-in-text-to-number-transformation"]], "8.5 Relevance to LLMs": [[1, "relevance-to-llms"]], "9. Advanced Topic Modeling Techniques": [[15, "advanced-topic-modeling-techniques"]], "9. Challenges and Limitations": [[14, "challenges-and-limitations"]], "9. Data Augmentation for Social Science Research": [[21, "data-augmentation-for-social-science-research"]], "9. Ethical Considerations and Challenges": [[22, "ethical-considerations-and-challenges"]], "9. Few-shot Sentiment Analysis and Opinion Mining": [[18, "few-shot-sentiment-analysis-and-opinion-mining"]], "9. Figurative Language in Political Discourse": [[23, "figurative-language-in-political-discourse"]], "9. Future Directions": [[10, "future-directions"]], "9. Human-AI Collaboration in Research": [[27, "human-ai-collaboration-in-research"]], "9. Impact on Social Science Research": [[9, "impact-on-social-science-research"]], "9. Information Extraction and Relation Classification": [[19, "information-extraction-and-relation-classification"]], "9. Source Credibility Assessment": [[26, "source-credibility-assessment"]], "9. Zero-shot Question Answering and Information Extraction": [[17, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[9, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[9, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[10, "ability-to-generate-human-like-text"]], "About": [[4, null]], "Access disparities to LLM technologies": [[11, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[10, "adaptability-to-various-domains-and-tasks"]], "Additional Resources": [[28, "additional-resources"]], "Advantages of Word Embeddings:": [[2, "advantages-of-word-embeddings"]], "Assessment": [[28, "assessment"]], "BERT and its variants": [[10, "bert-and-its-variants"]], "Bag-of-Words (BoW) model": [[13, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[11, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[11, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[11, "challenges-in-explaining-model-decisions"]], "Changelog": [[4, "changelog"]], "Computational resources required": [[10, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[11, "computational-resources-required-for-training-and-using-llms"]], "Conclusion": [[9, "conclusion"], [11, "conclusion"], [13, "conclusion"], [14, "conclusion"], [18, "conclusion"], [19, "conclusion"], [21, "conclusion"], [22, "conclusion"], [23, "conclusion"], [25, "conclusion"], [26, "conclusion"], [27, "conclusion"]], "Considerations for global and cross-cultural research": [[11, "considerations-for-global-and-cross-cultural-research"]], "Contributing": [[4, "contributing"]], "Copyright issues with training data and generated content": [[11, "copyright-issues-with-training-data-and-generated-content"]], "Course Description": [[28, "course-description"]], "Course Objectives": [[4, "course-objectives"], [28, "course-objectives"]], "Course Overview": [[4, "course-overview"]], "Course Structure": [[4, "course-structure"], [28, "course-structure"]], "Course Syllabus": [[28, null]], "Data protection and compliance with privacy regulations": [[11, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[13, "dealing-with-numbers-and-dates"]], "Definition and core concept": [[10, "definition-and-core-concept"]], "Distinction from traditional NLP models": [[10, "distinction-from-traditional-nlp-models"]], "Enhanced multi-modal capabilities": [[10, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[11, "environmental-impact-of-large-scale-ai-models"]], "Ethical Considerations": [[6, "ethical-considerations"], [20, "ethical-considerations"]], "Ethical considerations in deployment": [[10, "ethical-considerations-in-deployment"]], "Example: Document Similarity and Clustering": [[14, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[14, "example-extractive-summarization"]], "Example: Latent Dirichlet Allocation (LDA) with Gensim": [[14, "example-latent-dirichlet-allocation-lda-with-gensim"]], "Example: Lexicon-based Sentiment Analysis": [[14, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[14, "example-multi-class-classification"]], "Example: NER using spaCy": [[14, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[14, "example-pos-tagging-with-nltk"]], "Extra 1: The Evolution and Impact of LLMs in Social Science Research": [[1, null]], "Extra 2: Text Representation and NLP Pipeline": [[2, null]], "Extra 3: Practical Considerations for Using LLMs in Social Science Research": [[3, null]], "Extras": [[4, null]], "Few-shot and zero-shot learning capabilities": [[10, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[10, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[10, "gpt-generative-pre-trained-transformer-series"]], "Handling URLs and email addresses": [[13, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[10, "handling-complex-language-understanding-tasks"]], "Home": [[4, null]], "Impact on research outcomes and societal implications": [[11, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[11, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[11, "importance-of-interpretability-in-scientific-research"]], "Improved interpretability and transparency": [[10, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[10, "improvements-in-model-size-and-efficiency"]], "Installation": [[6, "installation"], [7, "installation"]], "Instructor": [[0, "instructor"]], "Integration with domain-specific knowledge": [[10, "integration-with-domain-specific-knowledge"]], "Issues with hallucination and factual accuracy": [[11, "issues-with-hallucination-and-factual-accuracy"]], "Key Topics We\u2019ll Explore": [[20, "key-topics-we-ll-explore"], [24, "key-topics-we-ll-explore"]], "Lab Session 1: Introduction to NLP for Social Science": [[5, null]], "Lab Session 2: LLMs for Data Annotation and Classification": [[6, null]], "Lab Session 3: Applying Traditional NLP Techniques": [[7, null]], "Labs": [[4, null]], "Lack of true understanding or reasoning": [[10, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[4, null]], "License": [[4, "license"]], "Limitations of BoW:": [[2, "limitations-of-bow"]], "Objectives": [[6, "objectives"], [7, "objectives"]], "Other prominent models": [[10, "other-prominent-models"]], "Plagiarism concerns and academic integrity": [[11, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[10, "potential-biases-in-training-data"]], "Potential for personal information exposure in training data": [[11, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[11, "potential-impact-on-research-equity-and-diversity"]], "Practical Applications": [[20, "practical-applications"]], "Practical Applications and Ethical Considerations": [[24, "practical-applications-and-ethical-considerations"]], "Pre-training on large corpora": [[10, "pre-training-on-large-corpora"]], "Preparing for the Future of Social Science Research": [[24, "preparing-for-the-future-of-social-science-research"]], "Prerequisites": [[28, "prerequisites"]], "Progress in mitigating biases and improving factual accuracy": [[10, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Proper attribution of AI-generated text in research": [[11, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[10, "question-answering-and-information-retrieval"]], "Recommended Textbooks": [[28, "recommended-textbooks"]], "Removing HTML tags and special characters": [[13, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[13, "removing-or-replacing-emojis-and-emoticons"]], "Required Materials": [[28, "required-materials"]], "Risks of re-identification in generated text": [[11, "risks-of-re-identification-in-generated-text"]], "Scaled-up training on massive datasets": [[10, "scaled-up-training-on-massive-datasets"]], "Schedule": [[28, "schedule"]], "Self-attention mechanism": [[10, "self-attention-mechanism"]], "Sentence tokenization": [[13, "sentence-tokenization"]], "Sentiment analysis and emotion detection": [[10, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[8, null]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[28, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[12, null], [28, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[16, null], [28, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[20, null], [28, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[24, null], [28, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Setup and Data Loading": [[6, "setup-and-data-loading"], [7, "setup-and-data-loading"]], "Sources of bias": [[11, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[11, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[11, "strategies-for-validating-llm-generated-results"]], "Students": [[0, "students"]], "Summarization and paraphrasing": [[10, "summarization-and-paraphrasing"]], "Table of Contents": [[4, "table-of-contents"]], "Techniques for improving model transparency": [[11, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[13, "term-frequency-inverse-document-frequency-tf-idf"]], "Text generation and completion": [[10, "text-generation-and-completion"]], "Transformer architecture": [[10, "transformer-architecture"]], "Translation and cross-lingual tasks": [[10, "translation-and-cross-lingual-tasks"]], "Types of bias": [[11, "types-of-bias"]], "Types of classification:": [[14, "types-of-classification"]], "Unique challenges posed by LLMs": [[11, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, null]], "Why Advanced Applications Matter in Social Science Research": [[24, "why-advanced-applications-matter-in-social-science-research"]], "Why Generative Explanations and Summaries Matter in Social Science": [[20, "why-generative-explanations-and-summaries-matter-in-social-science"]], "Why Text Representation Matters:": [[2, "why-text-representation-matters"]], "Why This Course Matters": [[4, "why-this-course-matters"]], "Word Embedding Association Test (WEAT)": [[22, "word-embedding-association-test-weat"]], "Word Embeddings": [[13, "word-embeddings"]], "Word tokenization": [[13, "word-tokenization"]], "Young Joon Lee": [[0, "young-joon-lee"]]}, "docnames": ["about/index", "extras/extra01", "extras/extra02", "extras/extra03", "index", "labs/nlp4ss-lab-1", "labs/nlp4ss-lab-2", "labs/nlp4ss-lab-3", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "extras/extra01.md", "extras/extra02.md", "extras/extra03.md", "index.md", "labs/nlp4ss-lab-1.ipynb", "labs/nlp4ss-lab-2.ipynb", "labs/nlp4ss-lab-3.ipynb", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "0": [4, 6, 7, 9, 10, 11, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "00": 7, "002": [9, 10, 11, 17, 18, 19, 23, 26, 27], "004": 7, "005": 7, "006": 7, "007": 7, "008": 7, "009": 7, "010": 7, "011": 7, "012": 7, "013": 7, "015": 7, "016": 7, "018": 7, "04": 13, "05": [7, 14], "06": 7, "09": 7, "0x16f794680": 6, "0x16fea3020": 5, "0x177910e30": 7, "1": [4, 12, 16, 20, 24], "10": [5, 6, 7, 10, 13, 25], "100": [3, 5, 6, 7, 9, 10, 11, 13, 17, 18, 19, 21, 23, 26, 27], "1000": [5, 6, 7, 19, 22, 25, 27], "10000": [10, 19], "1000x600": 7, "11": 7, "12": [5, 6, 7], "123": 11, "128": 25, "12952396179718417": 5, "13363707315372284": 5, "14": 7, "14915865499620834": 5, "15": [5, 6, 13], "150": [10, 19, 27], "1500": [6, 13], "15154887003653952": 5, "1538819754578188": 5, "15a5": [5, 6], "175": 10, "1752966664790094": 5, "1840": 6, "18951266c182": [5, 6], "18th": [17, 18], "19": [21, 26], "1919": 18, "1964": 18, "1966": 9, "19th": 18, "1f": 6, "2": [4, 8, 16, 20, 24], "20": [5, 6, 7, 19], "200": [9, 23, 27], "2009832958865476": 5, "2017": [6, 7, 9], "2018": [6, 7], "2019": 21, "2020": [6, 7, 21, 27, 28], "2021": [6, 7, 21], "2022": 28, "2023": [5, 13, 27], "2024": [5, 6], "2030": 18, "208b731ebb2b": [5, 6], "21": 6, "21455232095761398": 5, "2288625126017953": 5, "24": [6, 7], "25": 28, "256": 10, "26": 7, "27": 7, "27622023052939987": 5, "28": [6, 7], "29": 7, "2e": 10, "2f": [11, 27], "3": [4, 8, 12, 20, 24], "30": [7, 15, 18], "300": [6, 7, 10], "31": 7, "3101051886326014": 5, "3133": 6, "319a": [5, 6], "32": 25, "32a0": [5, 6], "347": [5, 6], "35": [7, 21, 28], "350": [6, 7], "3ebc6ab6": [5, 6], "3f": 22, "3rd": 28, "4": 4, "40": [5, 7, 28], "4087": [5, 6], "42": [6, 7, 9, 14, 15, 19, 26], "420": 27, "4272": 6, "45": [5, 6, 7, 11], "456": 11, "46": 7, "4607": [5, 6], "4617": [5, 6], "46c8": [5, 6], "4ccc": [5, 6], "4f": [9, 19, 27], "4o": 6, "5": 4, "50": [9, 10, 11, 17, 18, 19, 21, 22], "500": [6, 11, 26], "5000": 7, "512": [9, 10, 26], "52": 7, "56bdd61fd9e5": [5, 6], "5775": 6, "58": 11, "586d": [5, 6], "593965ae0ad8": [5, 6], "5g": [21, 26], "60": 15, "6353": [5, 6], "6354": [5, 6], "6789": 11, "7": 28, "7890": 11, "8": [6, 7], "80": 6, "845": 6, "9": [7, 11, 13], "90": 7, "9000": 9, "924abe2c": [5, 6], "94d2": [5, 6], "95": 21, "953b": [5, 6], "9622": [5, 6], "9c0e": [5, 6], "9ee69b6c": [5, 6], "A": [6, 10, 11, 12, 14, 15, 18, 19, 22, 23, 26], "And": [13, 25], "As": [1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "BY": 4, "Be": [3, 11, 14, 17], "By": [4, 6, 7, 9, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 28], "For": [1, 6, 7, 9, 12, 13, 14, 15, 19, 21, 25], "IN": 9, "If": [21, 23], "In": [4, 5, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25], "It": [2, 8, 9, 13, 14, 15, 17, 18, 19, 20, 23], "Its": 2, "NOT": 26, "No": [11, 19, 23], "One": [1, 18, 22], "The": [4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "There": 9, "These": [4, 5, 9, 10, 12, 13, 14, 16, 18, 20], "To": [11, 13, 15, 19, 21, 22], "_": [11, 18, 19, 22], "___": 9, "____": 9, "_______": 9, "________________________": 9, "__getitem__": 25, "__init__": [10, 25], "__len__": 25, "_wra": [5, 6], "ab_test_prompt": 18, "abbrevi": 14, "abil": [1, 9, 11, 12, 14, 17, 18, 20, 21, 25], "abl": [6, 7, 16, 28], "about": [1, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 18, 19, 21, 22, 25, 26], "abov": 22, "absolut": [9, 17], "abstract": [8, 14, 15, 17], "ac": 0, "academ": [3, 9, 10], "acc": 19, "access": [1, 8, 10, 20], "access_token": [25, 26, 27], "access_token_secret": [25, 26, 27], "accord": [9, 11, 14, 19, 26], "account": 11, "accumul": 3, "accur": [12, 14, 18, 22, 23], "accuraci": [1, 3, 7, 9, 14, 18, 19, 20, 21, 23, 26], "accuracy_scor": 19, "achiev": [9, 10, 12, 17], "acknowledg": 22, "across": [1, 6, 9, 10, 15, 20, 23, 25], "act": [5, 9, 18], "action": 6, "actual": 18, "ada": 5, "adamw": 10, "adapt": [1, 8, 9, 16, 18, 21, 24, 27], "add": [15, 18, 25], "add_edg": 26, "addit": [3, 5, 6, 23], "addition": 22, "address": [1, 9, 11, 15, 22, 24, 26, 27, 28], "adher": [11, 27], "adjac": [1, 9], "adject": 14, "adjust": 21, "adopt": [9, 27], "ador": 27, "adult": 10, "advanc": [1, 2, 4, 5, 8, 9, 11, 12, 13, 14, 18, 21, 23, 25], "advantag": [18, 21], "advent": [1, 4, 16], "advisori": [5, 6], "advocaci": [6, 7], "affect": [11, 18, 21], "affili": 6, "after": [10, 13, 18], "ag": [9, 22], "against": [6, 11], "agenc": 11, "agreement": [5, 14], "ahead": [1, 10], "ai": [0, 6, 9, 18, 19, 20, 21, 24, 26, 28], "ai_research_assist": 27, "aim": [4, 9, 10, 17, 18], "air": 7, "al": 21, "albert": 10, "algorithm": [1, 9, 11, 13, 18, 19, 22], "align": [2, 6], "alik": 14, "all": [1, 5, 8, 9, 10, 11, 17, 18, 22], "all_ent": 25, "all_issu": 6, "all_target": 22, "all_text": 5, "alloc": [4, 7, 11, 12, 25, 28], "allow": [9, 10, 11, 13, 15, 16, 17, 18, 20, 22, 25], "almost": 17, "alon": 15, "along": [3, 6], "alphabet": [9, 25], "alreadi": 5, "also": [1, 4, 6, 8, 9, 10, 11, 13, 16, 17, 18, 20, 23, 24], "alter": 18, "altern": 11, "alwai": [4, 14, 15, 21], "am": 9, "amaz": [19, 26, 27], "amazon": 19, "america": [5, 17, 18], "among": [10, 21, 27], "amount": [1, 3, 4, 9, 10, 14, 18, 20, 24, 25], "amp": 13, "amplif": [11, 20], "amplifi": [1, 10, 11], "amus": 23, "an": [1, 2, 4, 5, 9, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28], "analys": [5, 6, 7, 9, 13, 14, 23], "analysi": [1, 2, 4, 8, 9, 11, 12, 13, 15, 16, 20, 21, 28], "analyt": [9, 13], "analyz": [1, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28], "analyze_cont": 26, "analyze_emot": 10, "analyze_language_divers": 11, "analyze_occupation_bia": 22, "analyze_political_metaphor": 23, "analyze_proverb": 23, "analyze_senti": [9, 14], "analyze_sentiment_multilingu": 9, "analyze_social_concept": 10, "analyze_social_media_post": 27, "analyze_social_trend": 27, "analyze_spread_network": 26, "anger": 17, "angri": 26, "ani": [3, 6, 7, 9, 11, 12, 22, 23], "anim": [10, 14], "annot": [4, 7, 8, 14, 17], "announc": [6, 14, 18, 19, 26], "annual": 6, "anonym": 11, "anoth": [11, 13, 23], "answer": [1, 5, 8, 9], "answer_quest": 10, "anticip": 24, "apach": 25, "api": [6, 9, 10, 11, 13, 17, 18, 19, 23, 25, 26, 27], "api_kei": [6, 9, 10, 11, 17, 18, 19, 23, 26, 27], "apolog": 9, "append": [11, 17, 19, 22, 25, 26, 27], "appl": [14, 18, 19], "appli": [4, 5, 6, 8, 9, 10, 13, 14, 15, 16, 17, 18, 22, 28], "applic": [4, 9, 10, 12, 13, 14, 18, 19, 21, 27], "apply_rul": 27, "appnam": 25, "approach": [1, 4, 6, 7, 8, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28], "appropri": [1, 9, 10, 11, 14, 18, 19], "april": [5, 6, 7], "ar": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26], "architectur": [9, 11, 21, 22], "archiv": 25, "arctic": [6, 7], "area": [0, 1, 6, 8, 10, 12, 20, 22, 23], "aren": 11, "argmax": [9, 10, 26], "argsort": 7, "argument": 21, "aris": 22, "arithmet": 9, "around": 9, "arrai": [7, 27], "art": [4, 9], "articl": [5, 6, 10, 14, 15, 24, 26], "artifact": 10, "artifici": [0, 9, 10, 14], "artist": [22, 27], "as_list": [11, 19, 27], "as_posix": [5, 6], "ask": 8, "aspect": [17, 18, 23, 28], "assembli": 6, "assess": 15, "assign": [9, 14, 18, 28], "assist": [6, 11, 21, 23, 24, 27], "associ": [11, 15], "association_1": 22, "association_2": 22, "assum": [9, 11, 15, 19, 25, 26, 27], "assumpt": [11, 13, 15], "assura": [5, 6], "attend": 13, "attent": [9, 11, 18], "attention_mask": [10, 25], "attention_output": 10, "attribut": [15, 22, 23], "attribute_set1": 22, "attribute_set2": 22, "attun": 14, "audienc": [20, 23], "audio": [2, 9, 27], "audit": 11, "augment": 14, "ausgezeichnet": 9, "austin": 5, "auth": [25, 26, 27], "authent": [25, 26], "author": 11, "authorit": 11, "auto": 6, "autom": [3, 9, 16, 19, 26], "automat": [9, 14, 15], "automodel": 22, "automodelforsequenceclassif": [9, 25], "autonotebook": 6, "autopct": 6, "autoregress": 21, "autotim": 5, "autotoken": [9, 22, 25], "avail": [9, 19, 26], "averag": [5, 11, 15, 19], "averaged_perceptron_tagg": [9, 14], "avg": 7, "avoid": [3, 20, 22], "awai": 8, "awar": [2, 3, 6, 9, 10, 11, 13, 14, 17, 18, 23], "ax": 7, "axi": [7, 10], "b": [11, 13, 18, 22, 26], "b4f2": [5, 6], "backbon": 12, "background": 22, "backgrounddespit": 5, "backward": [10, 25], "bad": [11, 27], "bag": [9, 14], "bag_of_word": 7, "balanc": [19, 21, 26], "bank": 9, "bar": [5, 6, 7], "barrier": 10, "base": [3, 4, 5, 7, 8, 9, 10, 11, 15, 17, 18, 19, 22, 25, 27, 28], "basi": 12, "basic": [4, 6, 12, 21, 28], "batch": [10, 25], "batch_ent": 25, "batch_result": 25, "batch_siz": [10, 25], "batcher": [5, 6, 7], "bay": [7, 9, 14], "beach": 27, "beach_selfi": 27, "beat": 19, "beautifulsoup": 26, "becaus": [1, 8, 10, 13, 26], "becom": [1, 9, 11, 14, 25, 26, 27], "been": [1, 11, 16, 17, 18, 19], "befor": [1, 3, 5, 6, 7, 9, 15], "began": [17, 18], "begin": [4, 5, 6, 7, 12, 16, 20], "behavior": [4, 9, 26, 27], "behind": [14, 15, 17], "being": 12, "believ": [10, 17, 26], "benchmark": 9, "benefici": [1, 11, 13], "benefit": [4, 11], "bert": [2, 9, 19, 22, 25, 26, 27], "bertforsequenceclassif": [9, 10, 26], "berttoken": [9, 10, 26], "best": [1, 8, 10, 14, 17, 18, 22], "better": [10, 11, 15, 17, 18, 27], "between": [2, 4, 7, 8, 9, 10, 14, 15, 17, 18, 19, 21, 22, 23, 26, 27], "betweenness_c": 26, "betweenness_centr": 26, "beyond": [9, 10], "bezo": 19, "bia": [1, 4, 8, 9, 10, 20, 23, 25, 27, 28], "bias": [1, 4, 6, 9, 11, 13, 14, 17, 18, 20, 22, 23, 24, 26, 27], "bias_analysi": 9, "bias_check": 10, "biased_prompt": 22, "biden": 5, "bidirect": [9, 10], "big": [0, 25], "bigram": [1, 7], "bill": [18, 19], "billion": [5, 10], "bin": 5, "binari": 14, "biodivers": 14, "bit": [10, 18], "black": [1, 6, 7, 9, 11, 27], "bleu": 19, "bleu_scor": 19, "blockchain": 27, "board": 11, "boem": [5, 6], "boi": [22, 27], "bold": 26, "book": [4, 10], "bool": 26, "both": [4, 7, 8, 9, 10, 15, 19, 21, 25, 26], "boundari": [2, 12, 24], "bourgo": [6, 7], "bow_matrix": 13, "bow_represent": 13, "box": [1, 9, 11, 27], "brad": 22, "break": [9, 13, 18], "breakthrough": 9, "brickei": [5, 6], "bridg": [2, 4, 8, 9, 18, 24], "brief": [6, 7, 9, 10, 26], "bring": 11, "britain": [17, 18], "broader": [6, 11], "brother": 22, "brought": 9, "brown": [6, 7, 13, 14], "bs4": 26, "bucket": 23, "buffer": [17, 18], "bui": 9, "build": [8, 12], "builder": 25, "built": [10, 12, 24], "burden": [6, 7], "busi": [9, 18, 25], "c": 26, "c0486029": [5, 6], "c_v": 15, "calcul": [11, 14, 15, 22, 26, 27], "call": [3, 6, 11], "cambridg": 28, "can": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26], "cannot": [2, 13], "capabl": [2, 4, 8, 11, 14, 16, 20, 21, 23, 24, 27], "capit": 11, "captur": [1, 2, 6, 9, 10, 13, 17], "car": 11, "carbon": [6, 11, 17, 18], "carbon_footprint_kg": 11, "cardin": 5, "care": [1, 3, 9, 10, 13, 14, 21, 22, 25], "carefulli": [10, 11, 13, 15, 19, 22, 26], "caregiv": 22, "carri": 13, "case": [13, 19], "cat": [9, 11, 14, 15, 23], "categor": [9, 14], "categori": [6, 7, 9, 10, 14, 17, 18, 19], "categorize_senti": 7, "caus": [6, 18, 21, 26], "caution": 22, "cc": 4, "cd7a": [5, 6], "ce": 27, "ceci": 11, "cell": [5, 6, 7], "central": 26, "centuri": [17, 18], "ceo": [14, 19, 22], "certain": [11, 13, 26], "cett": 9, "chairman": 11, "challeng": [2, 4, 8, 16, 18, 25, 26, 27, 28], "chamber": 27, "championship": [14, 18, 19], "chang": [5, 6, 7, 9, 10, 14, 15, 17, 18, 19, 21, 23, 25, 26, 27], "changer": 20, "chapter": 5, "charact": [2, 5, 9, 15, 26], "character": [9, 15], "characterist": [2, 13, 19, 23], "charg": 3, "chase": [6, 9, 14, 15], "chat": 6, "chatbot": 9, "cheap": 18, "cheaper": 3, "check": [3, 10, 11, 13, 26, 27], "check_consist": 11, "check_domain_cred": 26, "check_for_pii": 11, "check_gender_bia": 10, "check_misinformation_ind": 26, "check_profession_gender_bia": 11, "cheju": 0, "child": 13, "children": [13, 21], "chines": 27, "chip": 5, "choic": [1, 2, 6, 9, 10, 11, 13, 14, 17, 18, 19, 23, 26, 27], "chomski": 9, "choos": [14, 17, 19], "chu": 0, "chunk": 25, "chunk_siz": 25, "citat": 26, "citi": [14, 19], "citizen": [11, 21], "civil": 18, "claim": 21, "clariti": 23, "class": [5, 6, 9, 10, 17, 18, 19, 25, 27], "class_": 26, "class_nam": [11, 19, 27], "classif": [4, 9, 10, 26, 27], "classifi": [6, 7, 9, 10, 11, 14, 16, 17, 18, 19, 26, 27], "classification_report": [7, 9, 14, 19, 26], "classify_text": [10, 26], "clean": [4, 5, 7, 9, 12, 15, 28], "clean_html": 13, "clean_text": [5, 13], "cleaned_text": 13, "clear": [1, 7, 11, 17, 18], "clearer": 12, "clf": [9, 14, 26, 27], "client": 6, "climat": [6, 7, 14, 15, 17, 18, 25, 26, 27], "climb": 14, "close": [9, 18, 26], "closer": 27, "cloudi": 14, "club": [5, 6, 7], "cluster_docu": 14, "cnn": 9, "co": 6, "co2e": 11, "coal": 7, "coaster": 23, "code": [5, 6, 7, 9, 10, 12, 17, 20, 22, 25, 28], "code_interview_respons": 9, "code_survey_respons": 17, "coded_data": 17, "coded_respons": 17, "coded_them": 17, "coding_schem": 9, "coher": [9, 10, 14, 15, 21], "coherence_model": 15, "coherence_scor": 15, "coherencemodel": 15, "colab": [5, 28], "cold": 23, "collabor": [9, 24, 26], "collect": [6, 9, 11, 14, 15], "collect_tweet": 26, "collected_tweet": 26, "color": [7, 18], "column": [5, 6, 15], "com": [11, 13, 26], "combat": [24, 26], "combin": [1, 2, 3, 7, 9, 11, 14, 18, 19, 26, 27], "come": [4, 9, 12, 14, 16], "comfort": 14, "comma": [17, 18], "commerc": [5, 6], "commissio": [5, 6], "commit": [5, 18], "common": [1, 5, 6, 9, 13, 14, 15, 17, 22, 23, 26], "commun": [5, 6, 7, 9, 14, 18, 19, 20, 23], "commut": 27, "compani": [19, 22], "compar": [2, 4, 6, 13, 16, 22, 23, 28], "comparison": 23, "compat": 3, "complementar": 7, "complet": [1, 6, 7, 9, 11, 17, 18, 19, 22, 23, 25, 26, 27], "complex": [1, 3, 6, 7, 8, 11, 12, 13, 14, 18, 20, 22, 23, 24, 25, 26, 27, 28], "compon": [18, 25], "composit": 23, "compound": 14, "comprehens": [1, 10, 14, 16, 18, 24, 26, 27], "comput": [1, 2, 14, 22, 25], "computation": 10, "compute_hour": 11, "compute_tim": 11, "con": 7, "conc": [5, 6], "concept": [2, 7, 12, 17, 19, 20, 28], "concern": [1, 6, 8, 9, 14, 18, 21, 26], "concis": [6, 14, 27], "conclus": [1, 10, 15, 17], "condens": 10, "conduct": [7, 22, 24], "confid": 11, "config": 5, "configur": 3, "congress": 18, "conll03": 19, "connect": 18, "consciou": 9, "consecut": 1, "consent": [1, 10, 22, 24], "consequ": [11, 14], "conserv": [6, 7], "consid": [1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 15, 16, 18, 19, 21, 22, 23, 24, 26], "consider": [4, 8, 9, 13, 16, 25, 26, 27, 28], "consist": [1, 3, 9, 13, 17, 18, 28], "conspiraci": 26, "constantli": 4, "constrain": 21, "constraint": 3, "consum": [3, 14, 16], "consumer_kei": [25, 26, 27], "consumer_secret": [25, 26, 27], "consumpt": 11, "contact": [5, 11], "contain": [4, 10, 11, 14, 23, 26, 27], "contamin": [6, 7], "contemporari": [10, 11], "content": [5, 6, 7, 9, 10, 13, 14, 20, 27], "context": [1, 2, 4, 6, 7, 8, 11, 13, 14, 16, 17, 20, 21, 22, 26, 27, 28], "contextu": [1, 2, 9, 10, 14, 21, 23, 26], "continu": [1, 2, 9, 10, 11, 17, 18, 19, 21, 23, 25, 26, 27], "contradict": 21, "contribut": [10, 11, 13, 22, 24, 27], "controversi": 10, "convei": 23, "converg": 7, "convert": [1, 9, 13, 15, 26], "convolut": 9, "cook": [14, 19], "core": [5, 6, 17], "corenlp": 9, "corenlppars": 9, "corpora": [5, 7, 9, 14, 15, 17, 18, 25], "corpu": [1, 5, 7, 9, 13, 14, 15, 25, 26], "correct": [13, 21, 23], "correctli": 3, "correl": [7, 15, 21], "correspond": 14, "cosin": 14, "cosine_similar": [14, 22, 27], "cost": [9, 11], "could": [6, 7, 9, 10, 11, 13, 16, 18], "couldn": 10, "count": [1, 2, 5, 6, 7, 11, 18, 25, 26], "counter": [6, 11, 24, 25], "counti": [5, 6], "countri": 10, "countvector": [5, 7, 9, 13], "cours": [5, 6, 7, 8, 12, 16, 20, 24], "court": 6, "cov": 21, "cover": [8, 12, 16, 24, 28], "coverag": 18, "covid": [21, 26], "cpu": 25, "cpu_count": 25, "craft": [1, 9, 22], "creat": [1, 5, 6, 7, 9, 10, 11, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "createdatafram": 25, "creativ": 21, "creator": 26, "credenti": [25, 26, 27], "crise": 24, "criteria": 23, "criterion": 23, "critic": [1, 4, 8, 9, 11, 18, 22, 24, 26, 27, 28], "cross": [9, 15, 17, 23, 26], "crosstab": 7, "crucial": [2, 3, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "cryptocurr": 27, "csv": [6, 7, 15], "cuda": 25, "cultur": [4, 14, 17, 18, 20, 22, 24, 26, 28], "cultural_context": 23, "curat": 11, "current": [10, 21, 24], "cursor": [25, 26], "curtain": 23, "custom": [14, 18], "cut": [4, 7, 8, 24, 27, 28], "d": [11, 13, 15, 26, 28], "d_model": 10, "dai": [11, 17], "daili": [17, 21], "dall": 10, "damag": [6, 7], "danger": 26, "data": [0, 1, 2, 4, 8, 13, 14, 17, 18, 19, 20, 22, 23, 24, 27], "data_fil": [5, 6], "databas": 26, "datafram": [5, 6, 7, 15, 25], "dataload": [10, 25], "dataset": [1, 3, 4, 5, 6, 11, 12, 13, 14, 17, 18, 19, 20, 21, 24, 28], "date": [5, 15, 17], "daughter": 22, "davinci": [9, 10, 11, 17, 18, 19, 23, 26, 27], "dbmdz": 19, "dc": 5, "de": 7, "deal": [11, 18, 20, 23, 25], "debat": [6, 10, 15, 21], "debias": 22, "debiased_gener": 22, "debiased_prompt": 22, "debiased_result": 22, "debiasing_prefix": 22, "decad": 10, "decemb": [6, 7], "decid": 13, "decis": [1, 9, 10, 14, 16, 19], "decod": [21, 22], "deduc": 23, "deed5268": [5, 6], "deep": [8, 15, 21], "deepen": 4, "deeper": [9, 10, 23, 24, 25], "def": [5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "defin": 6, "degre": 26, "degree_c": 26, "degree_centr": 26, "delici": 18, "delv": [10, 12, 20, 24], "demand": 6, "demograph": [9, 21, 27], "demographic_group": 9, "demoj": 13, "demonstr": [3, 9, 10, 11, 14, 15, 17, 18, 28], "dens": [1, 2, 9, 13], "depart": [5, 6], "depend": [2, 3, 9, 10, 13, 21, 23, 26], "deploy": 22, "deprecationwarn": 7, "depth": 20, "depu": [5, 6], "deputi": 5, "describ": [9, 11, 18], "descript": [10, 11, 17, 18], "design": [3, 4, 8, 10, 11, 17, 24, 28], "desir": [1, 3, 18], "despit": [1, 9, 10], "destruct": [6, 7], "detach": 22, "detail": [11, 13, 18, 21], "detect": [1, 4, 5, 15, 20, 24, 25, 28], "detect_and_explain_metaphor": 23, "detect_bia": 11, "detect_misinform": 26, "detect_sarcasm": 23, "detected_term": 11, "determin": [14, 15, 18, 23], "devast": 6, "develop": [1, 3, 4, 10, 11, 15, 18, 22, 24, 26, 27], "devic": 25, "devop": 0, "df": [6, 15, 25], "df_sampl": 6, "diagnosi": 19, "diagnost": 18, "diagram": 15, "dialogu": [11, 21], "dict": 5, "dictionari": [7, 14, 15, 25], "did": 18, "didn": 10, "dies": 27, "dieser": 9, "differ": [6, 7, 10, 11, 13, 14, 15, 17, 19, 20, 22], "difficult": [1, 14, 15, 18, 23], "difficulti": 18, "digit": [5, 9, 25, 26], "dim": [9, 10, 22, 26], "dimens": [11, 13], "dimension": [1, 2, 9], "direct": [4, 19, 23, 24, 28], "directli": 6, "dirichlet": [4, 7, 12, 25, 28], "disadvantag": 11, "disappoint": [10, 19], "disast": 6, "disclaim": 11, "disclos": 11, "discount": 3, "discours": [6, 9, 15, 21, 24, 27], "discov": [4, 7, 14, 15, 26], "discoveri": [25, 26, 28], "discrimin": [6, 7, 18], "discriminatori": 11, "discuss": [6, 7, 8, 15, 16, 20, 24], "disin": [6, 7], "displai": [5, 6, 7], "disproportion": [6, 7], "disregard": [1, 2], "distant": 14, "distort": 26, "distribut": [5, 6, 11, 15, 25], "district": 6, "div": 26, "dive": [4, 24], "divers": [6, 7, 10, 13, 18, 20, 21, 23, 24, 25, 27], "do": [4, 6, 7, 9, 22, 25], "do_sampl": 22, "doc": [5, 9, 14, 15, 19, 25, 26], "doc2bow": [7, 14, 15, 25], "doc_ent": 25, "doc_lda": 15, "doctor": [10, 22, 27], "document": [1, 2, 3, 4, 5, 9, 15, 24, 25, 28], "doe": [5, 6, 11, 18], "doesn": 6, "dog": [9, 13, 14, 15, 23], "dollar": 5, "domain": [1, 2, 9, 14, 15, 17, 18, 21, 26, 27], "domest": 18, "domin": [9, 15], "dominant_top": 15, "don": [6, 8, 10, 13, 27], "donat": 6, "dot": [10, 15, 22], "down": 23, "download": [5, 9, 13, 14, 15, 25, 27], "downstream": 13, "dr": [6, 17], "draft": 28, "dramat": 9, "draw": [1, 15, 26], "drawback": 13, "drill": [6, 7], "drive": [5, 6, 7], "driven": [9, 24, 28], "drug": 18, "dt": 9, "dtype": [5, 6], "due": [9, 11, 18, 23, 25, 26, 27], "dure": [1, 10, 13, 17, 18, 24], "dynam": [4, 11, 15, 24], "d\u00e9cision": 9, "e": [0, 2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 18, 19, 21, 26], "e4f565b189f7": [5, 6], "each": [1, 4, 6, 7, 9, 10, 13, 15, 18, 19, 28], "earli": [18, 25], "earliest": 2, "earn": 10, "earth": 26, "easier": 13, "easili": [13, 15, 18], "echo": 27, "econom": [9, 10, 15, 17, 18, 19], "economi": [17, 19], "ecosystem": 6, "ecstat": 26, "ed": 28, "edg": [4, 8, 24, 27, 28], "educ": 17, "effect": [1, 3, 4, 6, 7, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 25, 26, 27], "effici": [1, 3, 6, 7, 9, 12, 14, 16, 20, 25], "effort": 16, "eiffel": 26, "either": 26, "elabor": 9, "electr": [6, 7], "element": [13, 15], "elicit": 18, "elif": [7, 11, 14, 27], "elimin": [9, 22], "eliza": 9, "eliza_respons": 9, "elon": 19, "els": [5, 6, 7, 9, 10, 11, 14, 23, 25, 26, 27], "email": 11, "email_pattern": 11, "embark": [4, 8, 24], "embed": [10, 15, 17, 27], "embed_s": 10, "embedding_dim": 10, "emerg": [4, 18, 24, 28], "emili": [6, 7, 22], "emin": 7, "emiss": [6, 17], "emot": [1, 14, 15, 20, 23, 26], "emotion_analysi": 10, "emotion_summari": 21, "emotional_languag": 26, "emphas": [4, 8, 9, 23, 27], "emphasi": [23, 27], "emploi": [11, 22], "employe": 21, "empow": 18, "en": [6, 11, 25, 26], "en_core_web_sm": [5, 14, 19, 25, 26], "enabl": [1, 9, 10, 13, 20, 23, 27], "enact": 6, "encapsul": 23, "encod": [9, 10, 17, 21, 22, 25], "encoded_data": 10, "encompass": [9, 14], "encount": 9, "encourag": [8, 16], "end": [4, 6, 7, 9, 12, 14, 16, 17, 18, 20, 21, 24, 28], "end_tim": 19, "ener": 7, "energi": [5, 6, 7, 11, 17, 18], "energy_consumption_kwh": 11, "engag": [6, 8, 27], "engin": [0, 1, 4, 9, 10, 11, 16, 19, 22, 23, 26, 27, 28], "english": [5, 7, 9, 11, 13, 14, 15, 19, 23, 25, 26, 27], "enhanc": [9, 12, 15, 16, 17, 18, 20, 24, 25, 27], "enjoi": 9, "enorm": 10, "ensembl": [19, 26], "ensur": [1, 3, 6, 8, 13, 16, 20, 22, 24, 27], "ent": [5, 14, 19, 25, 26], "ent1": 26, "ent2": 26, "entelecheia": 0, "entir": [11, 18, 20], "entiti": [7, 10, 13, 26], "entity_count": 25, "entity_typ": [17, 18], "entitytyp": [17, 18], "entri": [5, 6], "enumer": [9, 11, 14], "environ": [3, 5, 6, 7, 17, 23], "environment": [7, 9, 17, 19, 27], "epoch": [10, 25], "equal": [11, 12, 22], "equip": [4, 13, 20, 24], "equit": 22, "equival": [11, 23], "era": [9, 23, 24], "error": [11, 19, 26], "espa\u00f1ol": 11, "especi": [1, 2, 3, 11, 12, 13, 20], "essenti": [1, 12, 23, 25], "est": [9, 11], "estim": 11, "estimate_carbon_footprint": 11, "esto": 11, "et": 21, "ethic": [1, 4, 8, 9, 16, 21, 25, 26, 28], "eu": 11, "europ": [17, 18], "evalu": [1, 2, 4, 24, 25, 26, 28], "evaluate_generated_text": 21, "evaluate_perform": 19, "evaluate_scal": 19, "even": [8, 10, 11, 12, 17, 20, 21, 23], "event": [11, 13], "ever": 9, "everi": 17, "evolut": [4, 8, 24, 28], "evolv": [9, 10, 11, 15, 17, 18, 19, 22, 23, 24, 26, 27], "ex_answ": 18, "ex_context": 18, "ex_quest": 18, "exacerb": 11, "exact": 3, "exagger": 23, "examin": [6, 20, 22, 25, 26], "exampl": [1, 3, 7, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27], "excel": [18, 20], "except": 26, "excit": [4, 8, 11, 23, 24, 27], "exclus": 14, "exercis": [20, 28], "exhibit": [9, 15, 26], "exist": [10, 11], "exist_ok": 6, "exp": [10, 11, 19, 27], "expand": [1, 10], "expect": [3, 17, 18, 21, 22, 23], "expens": 3, "experi": [4, 9, 10, 12, 13, 15, 23], "experiment": 15, "expert": [9, 18, 19, 28], "expertis": [1, 9, 15, 23], "explain": [1, 10, 20, 21, 23], "explain_figurative_languag": 23, "explain_idiom": 23, "explain_inst": [11, 19, 27], "explain_llm_predict": 19, "explain_misinform": 21, "explain_traditional_predict": 19, "explan": [3, 4, 9, 10, 11, 19, 25, 26, 27], "explanatori": 11, "explicit": [3, 22], "explicitli": [9, 17, 23], "explor": [1, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 21, 28], "exploratori": 17, "express": [10, 13, 14, 17, 20, 21, 23, 26], "extend": [18, 25], "extens": [1, 5, 10], "extract": [2, 5, 6, 20, 24, 28], "extract_ent": 5, "extract_key_issu": 6, "extract_keyword": 7, "f": [5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "f1": [7, 14, 19, 21], "fabric": [11, 26], "face": [6, 7, 9, 19, 21, 23], "facebook": [25, 26], "facil": 5, "facilit": 10, "fact": 26, "factor": [9, 10, 19], "factual": [1, 9, 20, 21, 26], "fail": 9, "fair": [1, 9, 22, 27], "fake": [4, 24, 28], "fals": [6, 21, 24, 25, 26, 27], "familiar": 28, "fantast": 9, "far": 11, "fascin": 4, "faster": 18, "fasttext": [1, 2], "father": 22, "favor": 11, "fc": 10, "fear": [17, 23], "featur": [2, 5, 11, 14, 19, 25, 26, 27], "feature_arrai": 7, "feature_extract": [5, 7, 9, 11, 13, 14, 19, 26, 27], "feature_nam": [5, 9, 13], "februari": [6, 7], "feder": 5, "feedback": 14, "femal": [22, 27], "female_assoc": 22, "female_associ": 22, "female_prob": 22, "female_prompt": 22, "female_sim": 27, "female_term": 22, "female_vec": 27, "few": [1, 3, 4, 7, 16, 17, 19, 26, 27, 28], "few_shot_aspect_senti": 18, "few_shot_classif": [18, 19], "few_shot_multi_label_classif": 18, "few_shot_n": 18, "few_shot_qa": 18, "few_shot_senti": [6, 7], "few_shot_sentiment_analysi": 6, "few_shot_summar": 18, "fewer": 10, "field": [1, 2, 4, 8, 9, 10, 11, 17, 18, 19, 21, 22, 24, 26, 27], "fight": 6, "figsiz": [5, 6, 7], "figur": [4, 5, 6, 7, 20, 28], "file": [5, 6, 9, 15], "film": 9, "filter": [25, 27], "filtered_text": 13, "filterwarn": 7, "final": [4, 10, 12, 18, 24, 28], "financ": 14, "financi": [5, 6, 9, 25], "find": [5, 6, 7, 9, 11, 13, 20, 21, 26, 27], "findal": [11, 19, 26], "fine": [1, 2, 9, 11, 17, 19, 21], "finetun": 19, "fireman": 11, "first": [5, 7, 10, 13, 15, 25], "first_doc_vector": 5, "fit": [7, 9, 11, 14, 19, 26, 27], "fit_resampl": 19, "fit_transform": [5, 7, 9, 13, 14, 19, 26], "five": [4, 28], "flat": 26, "flatten": [7, 25], "flaw": 11, "flexibl": [9, 21, 27], "flo": [6, 7], "float": 23, "flood": 21, "floor": 14, "flower": 14, "focu": [5, 6, 9, 10, 15, 17, 20, 24, 27, 28], "focus": [3, 9, 10, 12, 13, 21], "follow": [5, 6, 7, 9, 10, 17, 18, 19, 21, 23, 26, 27], "font_siz": 26, "font_weight": 26, "food": 18, "footprint": 11, "forefront": [9, 24, 27], "foreign": 10, "forest": [9, 19, 26], "form": [2, 9, 12, 13, 14, 23], "formal": [9, 18], "format": [3, 9, 13, 17, 18, 19, 21, 23], "formul": 10, "forward": [10, 13], "fossil": 7, "foster": 11, "found": [5, 6, 21], "foundat": [5, 12, 14, 24, 25], "founder": 19, "fox": [13, 14], "frack": 7, "frame": [5, 6, 8, 10, 26], "framework": [1, 25, 27], "franc": [11, 26], "fran\u00e7ai": 11, "frase": 11, "free": 9, "freedom": 26, "french": [9, 27], "freq": 5, "frequenc": [1, 2, 7, 9, 14, 21], "frequent": [5, 7, 23], "friendli": 9, "from": [1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "from_pretrain": [9, 10, 21, 22, 25, 26], "fuel": 7, "full": [9, 14, 19, 24, 27], "fulli": 27, "function": [5, 9, 11, 15, 22, 23, 26], "fundament": [1, 4, 5, 8, 12, 13, 16, 28], "furiou": 26, "further": [10, 11, 13, 17, 18], "futur": [4, 5, 6, 19, 28], "fzqarj": 26, "g": [2, 3, 6, 7, 9, 10, 11, 13, 14, 15, 18, 19, 21, 26], "ga": [6, 7], "gain": [4, 8, 9, 14, 15, 17, 23, 24], "game": [14, 20], "gap": [4, 8, 9, 10, 18, 21], "garcia": [7, 21], "gaug": [9, 14], "gdp": 18, "gdpr": 11, "gender": [9, 10, 11, 27], "gender_association_test": 22, "gender_bias_check": 27, "gendered_pronoun": 11, "gener": [0, 1, 2, 3, 4, 7, 8, 14, 15, 22, 23, 25, 26], "generate_complet": 22, "generate_llm_disclaim": 11, "generate_research_hypothesi": [10, 21], "generate_research_quest": 10, "generate_summari": 6, "generate_survey_respons": 21, "generate_text": [9, 21], "generate_text_llm": 19, "generate_text_tradit": 19, "generate_text_with_param": 21, "generated_text": [9, 19, 21], "gensim": [7, 9, 12, 13, 15, 25, 27, 28], "genuin": 26, "georgi": 6, "german": [9, 27], "germani": 18, "get": [1, 3, 5, 9, 10, 14, 15, 23, 26], "get_coher": 15, "get_complet": 6, "get_dominant_top": 15, "get_embed": 22, "get_feature_names_out": [5, 7, 9, 13], "get_scor": 21, "get_senti": [5, 7, 15], "get_top_n_bigram": 7, "get_word_embed": 13, "get_word_freq": 5, "getenv": 6, "getorcr": 25, "gf": 23, "gibb": 15, "gigaword": [13, 27], "girl": [22, 27], "give": 6, "given": [11, 14, 15, 18], "global": [1, 2, 9, 18, 24], "glove": [1, 2, 9, 13, 27], "go": [10, 14], "goal": [2, 8, 9, 13, 14], "good": [10, 11, 18, 27], "googl": [5, 28], "govern": [17, 18, 24, 25], "gpe": [5, 26], "gpt": [3, 6, 9, 11, 17, 18, 19, 23, 26, 27], "gpt2": [21, 22], "gpt2lmheadmodel": [21, 22], "gpt2token": [21, 22], "gpt3_complet": 10, "gpu": 11, "grade": 3, "grain": 17, "gram": 9, "grammar": [1, 2, 9], "grammat": [9, 14], "grant": 10, "graph": 26, "grasp": [9, 10, 16], "grassroot": 7, "great": [4, 9, 10, 17, 18, 23, 26], "greater": 27, "green": 18, "grew": 9, "grid": 11, "grid_carbon_intens": 11, "gross": 18, "groundbreak": 17, "group": [9, 11, 13, 14, 22], "groupbi": 15, "grow": [1, 8, 19, 25, 27], "growth": 9, "guest": 28, "guid": [1, 14, 22, 23], "guidelin": [1, 4, 11], "h": [5, 6, 7, 28], "ha": [1, 4, 5, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27], "habit": 9, "habitat": [6, 7], "had": [8, 27], "halla": 0, "hallucin": 9, "hammer": 23, "hand": [4, 9, 12, 20], "handl": [1, 2, 15, 17, 18, 19, 21, 23, 25, 26, 27], "hanoi": 5, "har": [4, 8, 9, 11], "hard": 10, "hardwar": [3, 19], "harm": 11, "harri": 5, "harvard": 17, "hasattr": 27, "hate": 9, "have": [1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 19, 20, 23, 24, 25, 26, 27], "haven": 17, "he": [10, 11, 22], "head": [5, 6, 7], "headlin": 26, "health": [7, 18, 21, 25, 27], "healthcar": [17, 18], "heapq": 14, "hear": [5, 6], "heartbroken": 26, "heat": 21, "heavi": 18, "hello": 9, "help": [1, 2, 6, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 27], "her": 11, "here": [4, 9, 10, 11, 13, 14, 17, 18, 19, 21, 22, 23, 25, 26], "hernand": [6, 7], "hesit": 8, "hi": 11, "hidden": [9, 15, 20, 24, 26], "hidden_layer_s": 27, "hidden_s": 10, "hierarch": [9, 15], "hierarchi": 15, "high": [2, 4, 6, 7, 9, 11, 19, 20, 23, 28], "higher": [15, 28], "highli": [9, 23], "highlight": 21, "hill": 9, "him": 11, "hint": 5, "hist": 5, "histor": [4, 6, 7, 10, 11, 14, 15, 23, 25], "histori": 17, "hoax": 26, "hold": [5, 6, 9], "home": [5, 6, 7], "hop": 18, "host": 6, "hour": 11, "household": [6, 7], "hovi": 28, "how": [4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 28], "howev": [4, 9, 10, 12, 13, 16, 17, 18, 21, 22, 23, 27], "html": [5, 6, 7, 15, 26, 27], "html_text": 13, "http": [5, 6, 9, 13, 26], "hug": [19, 21], "human": [4, 9, 11, 14, 15, 16, 18, 19, 23], "human_evalu": 23, "hundr": [5, 10], "hybrid": 19, "hyfi": [5, 6, 7], "hyperbol": 23, "hypothes": [1, 9, 10, 20, 21, 25], "hypothesi": [10, 21], "i": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "ian": [5, 6], "ianbrickeysierraclub": 5, "ich": 27, "id": 25, "id2word": [7, 14, 15, 25], "idea": [1, 10, 17, 20, 23], "ident": 11, "identifi": [1, 7, 9, 10, 11, 14, 15, 17, 18, 23, 24, 25, 26], "idf": [2, 5, 7, 9, 14, 26], "idiom": 20, "idiomat": 10, "idx": [7, 14, 15, 25], "ignor": [2, 7], "ignorecas": 26, "illustr": [10, 12, 21], "iloc": 5, "imag": [1, 2, 9, 10, 26, 27], "image_classifi": 27, "image_cont": 27, "image_path": 27, "image_result": 27, "image_scor": 27, "imagin": 25, "imbalanc": 19, "imblearn": 19, "immedi": 6, "impact": [4, 8, 10, 13, 14, 18, 19, 21, 22, 23, 24, 26, 27], "imperson": 26, "implement": [2, 3, 6, 7, 10, 11, 12, 14, 18, 21, 22, 23, 24, 25, 28], "impli": 9, "implic": [1, 3, 6, 7, 8, 9, 10, 20, 21, 22, 23, 24, 26], "import": [5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "impos": 18, "imposs": 10, "impost": 26, "impract": 10, "impress": 23, "improv": [1, 3, 7, 9, 13, 15, 18, 20, 23, 27], "inaccess": 25, "inadvert": 11, "inc": [14, 18, 19], "includ": [1, 3, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27], "inclus": 27, "inconsist": [18, 26], "incorpor": [11, 15, 18, 21], "incorrect": [10, 11], "increas": [5, 6, 7, 9, 10, 11, 18, 27], "increasingli": [9, 25, 26, 27], "incredibli": 21, "independ": [14, 21], "index": 6, "indic": [15, 22, 26], "individu": [9, 11, 22, 23, 26], "industri": [5, 9, 10, 17, 18], "ineffici": 1, "inequ": 11, "infeas": [9, 13], "infer": [4, 15, 19, 20, 28], "influenc": [6, 9, 11, 17, 23, 27], "info": [5, 6, 7, 13], "inform": [1, 2, 4, 5, 6, 7, 13, 14, 16, 20, 21, 22, 24, 26, 27], "inher": 9, "initi": [3, 5, 6, 7, 10, 25], "innov": [18, 24], "input": [1, 2, 9, 10, 11, 18, 21, 22, 23, 25, 26], "input_data": 19, "input_id": [10, 22, 25], "input_text": 9, "inputcol": 25, "insight": [7, 8, 9, 10, 12, 14, 15, 20, 23, 24, 25, 28], "instal": 3, "instanc": 9, "instant": [18, 27], "instead": 3, "institut": [9, 11], "instruct": [3, 17], "int64": [5, 6], "integr": [1, 9, 20, 27], "intellig": [0, 9, 10, 14], "intens": [10, 11, 21], "inter": 14, "interact": [9, 14, 18, 23, 26, 27], "interdisciplinari": [1, 9, 24, 26], "interest": [0, 8, 16], "interfer": 13, "intermedi": 3, "intern": [1, 10, 11], "internet": 23, "interpret": [1, 8, 9, 12, 17, 20, 22], "interpret_internet_slang": 23, "intersect": [4, 8], "intersection": 10, "interview": [1, 9, 10, 21], "introduc": [9, 11, 13, 28], "introduct": 4, "introductori": 8, "intuit": 15, "invers": [1, 2, 9], "invest": [10, 18], "investig": [7, 11, 24], "involv": [9, 10, 13, 14, 19, 20, 22, 26, 27], "io": 6, "iphon": 18, "iprogress": 6, "ipywidget": 6, "iron": 23, "ironi": [9, 14], "irrelev": [9, 13], "is_avail": 25, "is_colab": [5, 6, 7], "isalpha": [7, 9, 14, 25], "isn": 8, "isol": 27, "issu": [1, 3, 8, 9, 10, 14, 17, 22, 24, 25, 26, 27], "issue_count": 6, "issues_df": 7, "item": [5, 7, 9, 10, 18, 22, 25, 26], "iter": [3, 7, 10], "its": [4, 6, 7, 8, 14, 17, 18, 21, 23, 24, 25, 26, 27, 28], "j": [9, 27, 28], "jamal": 22, "jane": [17, 18], "japanes": 23, "jeff": 19, "jeju": 0, "job": [9, 17, 21], "joblib": [5, 6, 7], "john": [11, 18], "johndo": 11, "johnson": [18, 21], "joi": 17, "join": [5, 6, 7, 9, 10, 11, 13, 14, 17, 18, 19, 21, 26], "journal": 17, "journei": [4, 8], "jpg": 27, "jpmorgan": 6, "json": [5, 6, 19], "jsonl": [5, 6], "ju": 7, "judg": 6, "judgment": 23, "judici": 21, "jump": [13, 14], "jupyt": [6, 28], "jurafski": 28, "just": [6, 8, 13, 23], "justic": [6, 7], "k": [14, 15, 18, 21, 25], "kb": [5, 6], "keep": [4, 23], "keepdim": 10, "kei": [3, 5, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 25, 26, 27, 28], "key_issu": [6, 7], "key_pap": 21, "keyword": 7, "kg": 11, "kick": 23, "kim": 5, "kimpettysi": 5, "kind": [6, 7, 15], "king": [9, 27], "kmean": 14, "knowledg": [1, 4, 9, 14, 17, 18, 24], "known": 10, "korea": [0, 5], "kr": 0, "kwh": 11, "l": 21, "la": 7, "label": [3, 5, 6, 9, 10, 14, 17, 18, 19, 25, 26, 27], "label_": [5, 14, 19, 25, 26], "labels_": 14, "lack": 26, "lack_of_sourc": 26, "lakisha": 22, "lambda": [5, 6, 7, 15, 19], "land": 7, "landscap": 9, "lang": [11, 25, 26], "lang_count": 11, "langid": 11, "languag": [0, 1, 2, 4, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28], "larg": [1, 2, 3, 4, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28], "large_dataset": 25, "larger": 20, "largescaletextprocess": 25, "last": [17, 18], "last_hidden_st": 22, "late": [17, 18], "latent": [4, 7, 9, 12, 25, 28], "later": 12, "latest": [10, 22], "law": [5, 18, 19], "lazi": [13, 14], "lda": [4, 12, 25, 28], "lda_model": [7, 14, 15, 25], "lda_result": 15, "lda_visu": [7, 15], "ldamodel": [7, 14, 15], "ldamulticor": 25, "lead": [1, 9, 11, 13, 17, 18, 24, 25], "leap": 10, "learn": [1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 15, 16, 20, 24, 27, 28], "lectur": 28, "led": 10, "lee": [5, 6, 21], "leezieschesierraclub": 5, "legal": [11, 14], "legend": 7, "legisl": 6, "lemmat": [2, 5, 9, 15, 26], "lemmatize_token": 5, "lemmatize_word": 13, "lemmatized_text": 13, "lemmatized_token": 9, "len": [6, 7, 11, 15, 22, 25, 26], "length": 2, "less": [2, 11, 14, 18], "let": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24, 25, 26], "level": [1, 9, 18, 25], "leverag": [3, 4, 8, 10, 12, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28], "lexic": [7, 9], "lexicon": 7, "li": [14, 25], "lib": 6, "librari": [3, 4, 6, 7, 11, 12, 14, 15, 21, 25, 28], "lieb": 27, "life": [11, 17, 21, 23, 27], "lifetim": 11, "lightblu": 26, "like": [1, 2, 3, 9, 11, 12, 13, 14, 15, 18, 21, 22, 23, 24, 25, 26, 27], "lime": [11, 19, 27], "lime_text": [11, 19, 27], "limetextexplain": [11, 19, 27], "limit": [1, 4, 8, 9, 11, 16, 18, 19, 24, 27, 28], "linalg": 22, "line": [9, 15], "linear": 10, "linear_model": [7, 19], "linesent": 9, "lingual": [9, 15], "linguist": [9, 13, 14, 26], "link": 23, "list": [17, 18, 25, 26], "listen": 27, "liter": [9, 23], "literatur": [1, 9, 10, 20, 21, 27], "literature_review_synthesi": 21, "live": [21, 26, 27], "ll": [4, 5, 6, 8, 10, 12, 13, 14, 15, 16], "llm": [4, 7, 8, 12, 20, 25, 27], "llm_bleu": 19, "llm_entiti": 19, "llm_explan": 19, "llm_gener": 19, "llm_ner": 19, "llm_perform": 19, "llm_predict": 19, "llm_relat": 19, "llm_relation_extract": 19, "llm_sent": 19, "llm_sentiment": 19, "llm_sentiment_analysi": 10, "llm_time": 19, "load": [3, 9, 10, 13, 14, 19, 21, 25, 26, 27], "load_dataset": [5, 6], "local": [3, 6, 9, 14, 18], "localhost": 9, "locat": [14, 18, 26], "logging_level": [5, 6, 7], "logist": [7, 9, 19], "logisticregress": [7, 19], "logit": [9, 10, 22, 26], "lone": 5, "long": [9, 10, 12, 14, 17, 18, 21], "long_text": 17, "longer": 14, "look": [1, 6, 9, 10, 17, 21, 24, 25], "lose": [1, 2], "loss": [1, 10, 13, 25], "lotteri": 17, "love": [9, 10, 13, 14, 17, 19, 27], "low": [14, 18, 23, 27], "lower": [2, 5, 7, 9, 10, 11, 13, 14, 15, 25, 26], "lowercas": [2, 9, 15, 26], "lowercased_text": 13, "loyal": 14, "lr": 10, "lr_classifi": 7, "lr_predict": 7, "lstm": 9, "lyndon": 18, "m": [5, 9, 10, 15, 19], "machin": [1, 2, 7, 9, 13, 14, 15, 17, 18], "macro": 7, "made": [1, 3, 4, 8, 13], "mai": [1, 2, 3, 5, 10, 11, 13, 14, 15, 18, 19, 23, 25, 27], "mail": 0, "main": [5, 6, 7, 12, 15, 16, 17, 21, 24], "maintain": [9, 10, 11, 20, 24], "major": [6, 17, 18], "make": [1, 6, 9, 10, 13, 14, 16, 17, 18, 19, 26, 27], "make_pipelin": [11, 27], "makedir": 6, "male": [22, 27], "male_assoc": 22, "male_associ": 22, "male_prob": 22, "male_prompt": 22, "male_sim": 27, "male_term": 22, "male_vec": 27, "man": [9, 22, 27], "manag": 13, "mani": [1, 9, 10, 12, 13, 14, 16, 19, 23, 26], "manifest": 22, "manin": 5, "manipul": [10, 26], "mankind": 11, "manual": [3, 9, 13, 14, 15], "map": [1, 25], "marilyn": 6, "mark": [14, 17], "market": [9, 14, 17, 18, 19], "markov": 9, "martin": 28, "maryland": 6, "mask": 10, "massiv": [9, 17, 24], "master": [12, 13, 14, 24], "mat": [9, 14, 15], "match": [7, 9, 18, 19], "materi": 11, "matplotlib": [5, 6, 7, 26], "matrix": 14, "max": 15, "max_featur": [5, 7], "max_it": [7, 27], "max_length": [6, 9, 10, 19, 21, 22, 25, 26], "max_token": [9, 10, 11, 17, 18, 19, 23, 26, 27], "max_word": [17, 18], "me": [0, 5, 6, 9], "mean": [5, 9, 10, 13, 14, 15, 19, 22, 23, 27], "meaning": [1, 12, 13, 15, 20, 24, 25], "meaningless": 23, "measur": [7, 11, 14, 18, 26], "measure_inference_tim": 19, "mechan": [1, 9], "media": [4, 5, 6, 9, 10, 11, 13, 14, 15, 18, 19, 20, 21, 24, 25, 26, 27], "medic": [14, 19, 25], "meet": [5, 6, 23], "megan": 5, "meganwittmansierra": 5, "meme": 23, "memor": 11, "memori": [5, 6, 9], "men": 10, "mental": [18, 21, 27], "mention": [5, 6, 7], "merg": 7, "merged_df": 7, "messag": 6, "messi": 13, "metaphor": 20, "methan": 7, "method": [1, 2, 3, 4, 5, 9, 11, 12, 13, 14, 15, 16, 19, 21, 22, 26, 28], "methodologi": [4, 8, 9, 17, 24, 27], "metric": [7, 9, 14, 15, 21, 22, 26, 27], "microchip": 26, "midterm": 28, "might": [6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 21, 23], "million": [5, 25], "min": [6, 27], "min_count": 9, "mind": [4, 11], "mine": [6, 7, 9], "minim": [1, 2, 10, 18, 21], "misinform": [4, 18, 24, 27, 28], "misinformation_top": 26, "mislead": [11, 26], "mismatch": 26, "misrepres": 11, "miss": 2, "misus": [1, 10], "mitig": [9, 20, 27], "mix": 18, "mixtur": 15, "ml": [2, 18, 25, 26], "mlop": 0, "mlpclassifi": 27, "modal": 27, "model": [1, 2, 3, 4, 6, 8, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28], "model_nam": [9, 10, 11, 13, 22, 25, 26], "model_output": 23, "model_select": [7, 9, 14, 19, 26], "modern": [4, 8, 28], "modul": 10, "moham": 22, "monei": 5, "monitor": 27, "montana": 6, "month": [6, 10, 14, 17, 19], "more": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 26, 27], "moreov": 14, "most": [5, 6, 9, 13, 15, 17, 18], "most_common": [6, 11], "most_similar": 9, "mother": 22, "mount_google_dr": [5, 6, 7], "move": [4, 13], "movi": [9, 11, 13, 27], "mp": 25, "mse": 19, "mtld": 7, "much": [8, 13], "multi": [5, 17, 18, 25], "multidisciplinari": 26, "multilingu": [9, 26], "multilingual_senti": 27, "multimod": [0, 1, 2, 9, 10, 26], "multinomi": 15, "multinomialnb": [7, 9, 11, 14, 27], "multipl": [9, 10, 11, 14, 15, 20, 25, 27], "multiprocess": 25, "musk": 19, "must": [1, 5, 9, 10, 11, 22, 26], "mutual": 14, "my": [6, 9, 10, 17], "mydriv": [5, 6, 7], "mystream": 27, "mystreamlisten": 27, "mywot": 26, "n": [5, 6, 7, 9, 10, 11, 14, 15, 17, 18, 19, 23, 26, 27], "n_cluster": 14, "n_estim": 26, "n_run": 19, "n_sampl": 19, "n_test": 18, "nada": [5, 6], "nail": 23, "naiv": [7, 9, 14], "naive_bay": [7, 9, 11, 14, 27], "nall": 11, "name": [6, 7, 9, 10, 13, 22, 26], "name_senti": 22, "name_sentiment_analysi": 22, "nanswer": 18, "nation": 18, "natur": [0, 2, 4, 8, 10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28], "navig": [1, 11], "nb_classifi": 7, "nb_predict": 7, "ncategori": [9, 17, 18, 19], "ncontact": [5, 6, 7], "ncourtnei": [6, 7], "nearbi": 1, "necessari": [5, 6, 7, 12, 14], "need": [1, 3, 5, 9, 10, 13, 15, 17, 18, 25, 27], "neg": [6, 7, 9, 10, 11, 14, 17, 18, 19, 21, 27], "nentiti": 18, "ner": 25, "ner_pipelin": 19, "network": [9, 10, 21, 27], "networkx": 26, "neural": [9, 10, 15, 27], "neural_network": 27, "neuro_symbolic_analysi": 27, "neutral": [6, 7, 9, 10, 11, 14, 17, 18, 19, 22, 27], "never": 17, "new": [3, 4, 6, 7, 8, 10, 11, 14, 15, 16, 17, 18, 19, 21, 24, 25, 27, 28], "newer": 10, "next": [6, 9, 10, 14, 19], "next_word": 19, "next_word_vec": 19, "ngabbi": [6, 7], "ngener": 11, "ngram_rang": 7, "nhead": 10, "nian": [5, 6], "nice": 19, "nkim": [5, 6], "nking": 9, "nlargest": 14, "nlee": [5, 6], "nllm": 10, "nlp": [3, 4, 13, 19, 23, 24, 25, 26], "nlp4ss": [5, 6, 7], "nlptown": [9, 27], "nltk": [5, 7, 9, 12, 13, 15, 19, 25, 26, 28], "nltk_data": 5, "nmegan": [5, 6], "nn": [9, 10, 26], "nnote": 11, "no_grad": [9, 10], "no_repeat_ngram_s": 21, "noam": 9, "node_color": 26, "node_s": 26, "nois": [7, 9, 13], "non": [5, 6, 9, 14, 23, 25], "none": [5, 6, 7, 9, 10, 11, 17, 18, 19, 23, 26, 27], "nonstandard": 14, "norm": [22, 24], "normal": [4, 5, 12, 25, 28], "north": [17, 18], "notabl": [6, 11], "notat": 15, "note": [9, 21], "notebook": [3, 5, 28], "notebook_tqdm": 6, "noth": 9, "notic": 9, "noun": [6, 14], "novel": [9, 17, 18], "now": [5, 6, 7, 8, 9, 10, 17, 24], "np": [7, 9, 10, 19, 22, 27], "nquestion": 18, "nrespons": 11, "nsampl": [5, 6], "nsentiment": [18, 19], "nshiloh": [6, 7], "nsimilar": 14, "nsummari": 18, "ntext": [9, 17, 18, 19], "ntopic": 15, "nuanc": [1, 2, 9, 10, 13, 14, 20, 23], "null": [5, 6], "num": 13, "num_clust": 14, "num_featur": [11, 19, 27], "num_label": [9, 10, 25, 26], "num_permut": 22, "num_process": 25, "num_quest": 10, "num_return_sequ": [21, 22], "num_run": 11, "num_sent": 14, "num_top": [7, 14, 15, 25], "number": [2, 7, 10, 11, 15, 18, 19], "numer": [1, 2, 9, 13], "numpi": [3, 7, 10, 19, 22, 27], "nurs": [11, 22, 27], "nwarn": 11, "nx": 26, "o": 6, "oauthhandl": [25, 26, 27], "object": [1, 5, 25], "obscur": 13, "observ": [3, 7, 15, 22], "observed_scor": 22, "obviou": 11, "occ": 27, "occup": [22, 27], "occur": [9, 14, 15, 22], "occurr": 2, "octob": [6, 7], "off": 19, "offens": 23, "offer": [1, 2, 3, 4, 9, 10, 11, 12, 16, 17, 19, 20, 21, 23, 24, 25], "offic": 23, "often": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 23, 26], "oh": 23, "oil": [6, 7], "okai": 9, "old": 21, "omiss": 11, "on_error": 27, "on_statu": 27, "onc": 9, "one": [2, 6, 9, 10, 11, 13, 15, 17, 18, 19, 23, 25], "ongo": [6, 10, 11, 15], "onli": [3, 4, 6, 9, 10, 11, 18, 24, 25], "onlin": [9, 14, 25, 26, 27, 28], "open": [3, 4, 9, 10, 14, 16, 17, 19, 21, 27], "openai": [3, 6, 9, 10, 11, 17, 18, 19, 23, 26, 27], "openai_api_kei": 6, "oper": [2, 3], "opinion": [9, 11, 14, 24, 26], "opportun": [4, 8, 25], "optim": [10, 15, 16, 25], "option": [3, 23], "order": [1, 2, 7], "oregon": [5, 6], "org": [5, 6, 26], "organ": [6, 7, 14, 15, 17, 18, 26], "origin": [6, 9, 18, 22], "other": [1, 2, 11, 14, 17, 18, 20, 21], "our": [4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 20, 24, 25, 26, 27], "out": [1, 2, 13, 23], "outcom": [22, 24], "outdat": 11, "outperform": [18, 23], "output": [1, 2, 9, 10, 13, 17, 18, 19, 20, 21, 22, 23, 25, 26], "output_fil": 6, "outputcol": 25, "over": [5, 6, 11, 13, 14, 15, 18, 21, 24], "over_sampl": 19, "overal": [10, 19, 23], "overall_scor": 23, "overload": 24, "overpr": 18, "oversight": [1, 11], "oversimplifi": 6, "overst": [2, 13], "overview": [8, 28], "overwhelm": 10, "own": [8, 9, 16, 27], "ownership": 11, "p": [13, 21, 22], "p_valu": 22, "packag": [3, 5, 6, 7], "pad": [9, 10, 25, 26], "page": [5, 6], "page_url": [5, 6], "pair": 1, "pairwis": [14, 27], "panda": [5, 6, 7, 15, 25], "pandem": [9, 21], "paper": [1, 10, 17, 20, 21, 28], "paradigm": [17, 18, 19], "paragraph": 10, "parallel": 10, "parallel_preprocess": 25, "paramet": [10, 15, 18, 27], "paramount": 11, "paraphras": [1, 21], "parent": [6, 21], "park": 23, "pars": [9, 25], "parser": [9, 26], "part": [9, 17, 27], "partial": 10, "particip": [10, 11], "particular": [10, 11, 14, 18], "particularli": [1, 4, 8, 9, 10, 11, 13, 14, 15, 17, 18, 21, 23, 26], "pass": 7, "passion": 21, "past": 7, "pattern": [1, 6, 7, 9, 10, 11, 13, 14, 15, 18, 19, 23, 24, 25, 26], "pd": [6, 7, 15, 25], "penalti": 18, "peopl": [13, 14, 26], "per": [3, 9, 14, 15, 18, 19], "percent": 5, "perform": [1, 4, 5, 6, 7, 9, 10, 13, 14, 15, 16, 17, 18, 23, 28], "perform_n": 14, "period": 18, "perm_scor": 22, "perm_target1": 22, "perm_target2": 22, "permut": 22, "permutation_scor": 22, "perpetu": [1, 10, 11, 23], "perplex": 19, "persist": 10, "person": [5, 9, 14, 17, 18, 19], "personif": 23, "perspect": 11, "pet": 14, "petti": [5, 6], "phase": 10, "phd": 5, "phenomena": [4, 9, 10, 18, 20, 22, 23, 24, 25], "phenomenon": 26, "phone": 11, "phone_pattern": 11, "phrase": [6, 11, 23], "pie": 6, "piec": 14, "pii": 11, "pil": 27, "pip": [5, 6, 7], "pipe": 25, "pipelin": [4, 7, 11, 13, 19, 25, 27], "place": [13, 18, 27], "placehold": 13, "plai": [13, 14, 23], "plan": [14, 19], "planet": [14, 18], "plate": 15, "platform": [23, 25, 26], "plausibl": [10, 11], "pleas": [4, 6, 7], "plot": [5, 6, 7, 9, 15, 19], "plt": [5, 6, 7, 19, 26], "po": [9, 26], "point": [1, 6, 7, 8, 10, 13, 16, 17], "polar": [5, 7, 10, 15, 19, 21, 27], "polarity_scor": 14, "poli": 6, "policeman": 11, "polici": [5, 6, 9, 10, 11, 14, 15, 17, 18, 19, 21], "polit": [9, 10, 14, 15, 17, 18, 19, 21, 24, 26, 27], "politifact": 26, "pollut": 7, "pomilio": [6, 7], "pool": 25, "poorli": [14, 15], "popul": [1, 11, 25], "popular": [1, 2, 12, 14, 15], "porterstemm": [5, 9, 13], "pos_tag": [9, 14], "pos_tag_text": 14, "pose": [8, 26], "posit": [6, 7, 9, 10, 11, 14, 15, 17, 18, 19, 22, 24, 27], "possibl": [4, 10, 11, 12, 16, 17, 23, 24, 25], "possibli": 25, "post": [4, 9, 10, 11, 13, 14, 24], "potenti": [1, 4, 6, 7, 9, 13, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28], "power": [1, 2, 4, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 27], "power_usage_effect": 11, "pp": 9, "practic": [1, 4, 10, 11, 12, 18, 22, 25], "pragmat": 9, "prais": 21, "pre": [8, 9, 15, 17, 18, 19, 21, 25, 26, 27], "precis": [7, 19], "precision_recall_fscore_support": 19, "predefin": [14, 17], "predict": [7, 9, 10, 11, 14, 17, 18, 19, 26, 27], "predict_proba": [11, 19, 27], "predicted_class": [9, 10, 26], "prefer": 19, "prefix": 22, "prejud": 22, "prepar": [3, 7, 10, 13, 14, 16], "preprocess": [1, 2, 3, 4, 7, 14, 15], "preprocess_chunk": 25, "preprocess_text": [5, 7, 9, 15, 25, 26], "preprocessed_data": 25, "presenc": 15, "present": [1, 10, 11, 20, 22, 23, 25], "preserv": [1, 14, 27], "presid": [18, 19, 26], "press": [5, 6, 7, 17, 24, 28], "pretty_print": 9, "preval": 15, "prevent": [6, 11], "previou": [7, 18], "previous": [9, 10, 24, 25], "price": 18, "primari": [0, 6, 9, 10, 17], "primarili": [9, 11], "principl": [1, 8, 17], "print": [5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "print_top": [7, 14, 15, 25], "prior": 15, "privaci": [1, 8, 9, 10, 18, 22, 24, 27], "pro": 7, "prob": 15, "probabilist": [9, 15], "probabl": [9, 15, 22, 26], "probe": [9, 11], "probe_model_bia": 9, "problem": [9, 10, 15], "problemat": 1, "process": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 24, 26, 28], "process_batch": 25, "processed_chunk": 25, "processed_cont": 5, "processed_doc": [14, 15, 25], "processed_text": [7, 13, 15, 26], "processeddf": 25, "produc": [10, 11, 13, 18], "product": [10, 18, 19, 21, 27], "produit": 27, "produkt": 27, "profess": [10, 11, 22], "professor": 0, "profound": 19, "program": [1, 9, 14, 27, 28], "progress": [8, 9, 16, 21, 22, 24], "prohibit": 18, "project": [3, 4, 5, 6, 7, 10, 13, 16, 24, 28], "project_dir": 5, "project_nam": [5, 6, 7], "project_root": [5, 6, 7], "project_workspace_dir": 5, "prolifer": 25, "promis": [19, 26], "prompt": [1, 4, 6, 9, 10, 11, 16, 19, 22, 23, 26, 27, 28], "prompt_vari": 18, "pronoun": 11, "propag": 26, "proper": 12, "properli": [3, 11], "proport": 15, "propos": [9, 18, 28], "protect": [6, 7, 17], "protocol": [11, 23], "provid": [1, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 25, 26, 27], "psychotherapist": 9, "pt": [9, 10, 21, 22, 25, 26], "public": [6, 7, 9, 11, 14, 17, 18, 21, 24, 25, 26], "publish": 17, "punkt": [5, 9, 14, 15, 25], "purpos": [1, 11, 14, 21], "push": [2, 12, 24], "py": 6, "pyldavi": [7, 15], "pyplot": [5, 6, 7, 26], "pyspark": 25, "python": [4, 5, 6, 9, 10, 12, 28], "python3": 6, "pytorch": [10, 28], "q": [25, 26], "qualit": [9, 11, 14, 15, 20], "qualiti": [4, 6, 7, 15, 18, 20, 28], "quantit": 15, "queen": 27, "queri": [10, 26], "question": [1, 2, 4, 5, 6, 8, 9, 11, 13, 14, 15, 19, 20, 21, 24, 25, 28], "quick": [13, 14], "quickli": [3, 9, 13, 14, 16, 17, 18], "quit": [9, 19], "quot": [6, 7], "r": [5, 9, 11, 13, 15, 19, 26], "race": [9, 18, 22], "racial": 11, "raimondo": 5, "rain": 23, "rais": [11, 18], "ralli": [9, 17], "randint": 10, "randn": 10, "random": [9, 10, 15, 18, 19, 22, 26], "random_st": [6, 7, 9, 14, 15, 19, 26], "randomforestclassifi": [19, 26], "rang": [8, 9, 10, 11, 14, 15, 17, 18, 19, 22, 25], "rangeindex": [5, 6], "rapid": [9, 17, 18, 27], "rapidli": [10, 19, 22, 23, 24, 27], "rate": [5, 6, 23, 26], "ratio": 7, "raw": [2, 3, 5, 6, 9, 13, 19], "raw_data_fil": [5, 6], "raw_pars": 9, "raw_text": 26, "rdata": [5, 6], "rdata_df": 5, "re": [3, 4, 5, 8, 9, 12, 13, 15, 19, 24, 26], "reach": [11, 19], "reaction": 21, "read": 18, "read_csv": [7, 15], "readabl": 2, "readi": 24, "readthedoc": 6, "real": [4, 9, 17, 22, 26], "realist": 21, "realli": [9, 11, 27], "reason": [9, 12, 14, 19, 27], "recal": [7, 19], "recap": 13, "receiv": 10, "recent": [4, 6, 8, 12, 21, 26, 27], "recino": [5, 6], "recogn": 22, "recognit": [7, 10, 13, 26], "recommend": 9, "record": [3, 25], "recurr": 9, "reddit": [25, 26], "redefin": 27, "reduc": [3, 6, 9, 10, 13, 17, 18, 27], "reduct": [6, 7], "refer": [10, 14, 18, 19, 21, 22, 23, 25, 26], "referenc": 11, "reference_explan": 23, "refin": 3, "reflect": [11, 22, 23], "reform": 18, "regardless": [12, 22], "region": 11, "regress": [7, 9, 19], "regul": [5, 6], "regular": [11, 13], "reinforc": [11, 22], "rel": [1, 22], "relat": [5, 18, 21, 26, 27], "relationship": [2, 9, 13, 15, 17, 19, 21], "releas": [4, 5, 6, 7, 19], "relev": [2, 4, 9, 10, 12, 13, 15, 18, 19, 20, 21, 24, 28], "reli": [9, 26], "reliabl": [1, 10], "religion": 18, "remain": [1, 2, 11, 12, 14, 23], "remark": [9, 23], "rememb": [8, 12, 13, 14, 15, 16, 24], "remot": [21, 27], "remov": [2, 5, 9, 15, 25, 26], "remove_stopword": [5, 13], "remove_urls_email": 13, "renew": [6, 7, 17, 18], "renov": 26, "repeat": 15, "rephras": [9, 10], "replac": [14, 26, 27], "replace_emoji": 13, "report": [6, 7, 25], "repres": [1, 2, 9, 10, 11, 13, 15, 18, 24], "represent": [1, 4, 9, 10, 11, 12, 14, 28], "reproduc": [1, 24], "request": [6, 26], "requir": [1, 2, 3, 6, 7, 8, 9, 13, 15, 16, 18, 23, 26], "rescu": 11, "research": [0, 4, 6, 7, 8, 12, 13, 14, 16, 18, 19, 20, 22, 23, 25], "reshap": 27, "resourc": [2, 14, 18, 25, 27], "resp": 11, "respect": 20, "respond": [3, 6, 21], "respons": [1, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 26], "responsibli": [4, 9, 16], "restart": 3, "result": [1, 3, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 19, 22, 23, 25, 26, 27], "retriev": 1, "return": [5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "return_tensor": [9, 10, 21, 22, 25, 26], "retweeted_statu": 27, "reveal": [9, 13, 14], "revers": [5, 7, 15], "review": [1, 3, 10, 11, 20, 21, 27], "revolut": [17, 18], "revolution": [9, 10, 16, 18, 21, 27], "revolutionari": [1, 4, 8], "rewrit": 10, "rewrite_prompt": 10, "rf_model": 19, "rf_perform": 19, "rf_predict": 19, "rich": 23, "richer": 2, "ride": 23, "right": [5, 6, 17, 18], "rigor": 11, "rio": 7, "rise": [1, 14, 27], "river": 9, "rnn": 9, "roberta": 10, "robot": 0, "robust": 11, "role": [1, 6, 11, 19, 23, 27], "roller": 23, "room": [10, 22], "root": [9, 13], "root_dir": 5, "rotat": [5, 6, 7], "roug": [19, 21], "row": 7, "rstrip": 9, "rule": [3, 6, 7, 8, 9, 27], "rule_result": 27, "run": [3, 5, 6, 7, 9, 10, 11, 13], "runner": 13, "sad": 17, "safeti": 5, "sai": [9, 26], "same": [11, 18], "sampl": [3, 5, 6, 7, 9, 13, 14, 15, 19, 21], "sample_comparison": 7, "sample_s": [6, 19], "sample_text": [5, 13, 21], "samsung": 5, "sar": 21, "sarcasm": [9, 14], "sarcast": 23, "sat": [9, 14, 15], "satisfact": 21, "save": [3, 6, 7, 9, 15, 26], "save_html": [7, 15], "save_to_fil": 27, "saw": [9, 14, 17], "sc": 26, "scalabl": 9, "scale": [1, 3, 4, 8, 9, 13, 15, 24, 27, 28], "scari": 23, "scatter": 7, "scenario": [10, 14, 17, 18, 19, 21], "scheme": 9, "scienc": [4, 6, 7, 12, 13, 14, 16, 18, 19, 22, 23, 25, 26], "scientist": [4, 8, 14, 15, 16, 20, 22, 23, 25, 26, 27, 28], "scikit": [9, 12, 14, 19], "scipi": 22, "scope": 11, "score": [5, 7, 9, 10, 14, 15, 19, 21, 22, 23, 27], "scorecard": 26, "scrape": [11, 13], "scratch": 8, "scrutini": 10, "seaborn": [6, 7], "search": 26, "search_tweet": [25, 26], "second": [13, 19, 25], "secreta": 5, "section": [10, 15], "sector": 17, "secur": 11, "see": [4, 6, 9], "seek": 4, "seen": [1, 9, 14, 17], "select": [1, 14, 18, 19, 25], "self": [9, 25, 27], "self_attent": 10, "semant": [1, 2, 13, 17, 26], "semicolon": 6, "senat": 18, "sens": [10, 23], "sensation": 26, "sensational_titl": 26, "sensit": [11, 18, 20, 23], "sensitive_term": 11, "sent": 3, "sent_token": [5, 13, 14], "sentenc": [6, 9, 10, 11, 14, 23], "sentence_bleu": 19, "sentence_scor": 14, "sentiment": [1, 3, 9, 13, 15, 20, 21, 22, 23, 27], "sentiment_analyz": 25, "sentiment_by_top": 15, "sentiment_df": 7, "sentiment_scor": [9, 27], "sentimentintensityanalyz": 14, "separ": [1, 6, 9, 17, 18], "sequenc": [1, 9, 10], "sequence_length": 10, "sequenti": 9, "seri": 14, "serv": 2, "server": 11, "server_power_kw": 11, "servic": [18, 19], "session": [3, 4, 25], "set": [1, 2, 5, 7, 9, 11, 13, 14, 15, 16, 25, 26], "set_access_token": [25, 26, 27], "setup": 28, "sever": [1, 9, 10, 11, 12, 19, 21, 22, 23], "sex": 18, "shap": 11, "shape": [1, 10], "share": [19, 26], "she": [10, 11, 22], "shift": 8, "shock": 26, "shop": 9, "short": [9, 15], "shot": [1, 3, 4, 7, 16, 19, 26, 27, 28], "should": [1, 2, 6, 9, 11, 14, 17, 18, 19, 21, 22, 23], "show": [5, 6, 7, 14, 15, 18, 19, 23, 25, 26], "shown": [22, 23, 26], "shuffl": [10, 22, 25], "sia": 14, "side": 21, "sierra": [5, 6, 7], "sierra_club_key_issu": [6, 7], "sierra_club_senti": [6, 7], "sierra_club_summari": 6, "sierra_club_top": [6, 7], "sierraclub": [5, 6], "sign": [18, 19], "signific": [1, 2, 9, 10, 11, 14, 16, 17, 22, 26], "significantli": [2, 6, 9, 13, 18, 19, 20, 23, 25], "simil": 23, "similar": [1, 9, 13, 22, 23, 27], "similar_word": 9, "similarity_matrix": 14, "simpl": [1, 9, 10, 11, 14, 18, 19, 21, 23, 26, 27], "simple_preprocess": 25, "simple_senti": 10, "simplemaskedlanguagemodel": 10, "simplest": 2, "simplifi": [2, 10, 11, 21, 25, 27], "simul": [9, 10, 21], "sinc": 9, "singl": [1, 10, 11, 18], "sister": 22, "site": 6, "size": [1, 7, 13, 15, 19, 27], "skew": 11, "skill": [4, 12, 18, 24, 27, 28], "skip_special_token": [21, 22], "sklearn": [5, 7, 9, 11, 13, 14, 19, 26, 27], "slang": [14, 23], "small": [3, 14, 15, 18, 19], "smaller": [3, 12, 13, 25], "smiling_face_with_heart_ey": 13, "smith": [17, 18, 21], "smote": 19, "sn": [6, 7], "snippet": 12, "snope": 26, "so": [4, 14, 22], "social": [4, 6, 7, 12, 13, 14, 16, 18, 19, 25, 26], "social_media_data": 15, "societ": [4, 9, 22, 24, 27], "societi": [9, 11, 19, 26, 27], "socioeconom": [9, 22], "sociologi": 13, "softmax": [9, 10, 22, 26], "solar": 14, "sole": 17, "solid": [12, 16, 20], "solut": [1, 3], "solv": 9, "some": [1, 3, 5, 10, 13, 14, 15, 17, 18, 21, 26], "sometim": 23, "son": 22, "sophist": [9, 10, 15, 17, 21, 22, 24, 25, 26], "sorri": 9, "sort": [5, 7], "sound": [10, 11], "soup": 26, "sourc": [1, 3, 10, 20, 23, 24], "source_languag": 23, "south": 5, "space": [1, 2, 9, 25], "spacex": 19, "spaci": [5, 19, 25, 26, 28], "spam": 14, "spanish": 23, "spark": [21, 25], "sparksess": 25, "spars": 1, "sparsiti": 1, "speak": 23, "speaker": [6, 9], "special": [1, 2, 5, 6, 9, 10, 14, 15, 26, 27], "specif": [1, 2, 3, 6, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 27, 28], "speech": [9, 23, 28], "speed": 19, "sphere": 26, "spill": 6, "split": [6, 7, 9, 14, 17, 18, 19, 26], "spoken": 14, "sport": [9, 10, 14, 17, 18, 19], "spread": [17, 18, 21, 24, 27], "spring_layout": 26, "sql": 25, "sqrt": 10, "squar": 19, "ssn": 11, "ssn_pattern": 11, "stabl": 6, "stack": 7, "stage": 9, "stai": [10, 22, 24, 27], "stand": 18, "standard": [9, 13], "standardize_numb": 13, "stanford": 9, "star": 5, "start": [3, 6, 18, 22, 27], "start_tim": 19, "stat": 22, "state": 4, "statement": [5, 6, 23], "statist": [11, 14, 15, 22, 28], "statu": [9, 22, 27], "status_cod": 27, "stem": [2, 5, 9, 15, 26], "stem_token": 5, "stem_word": 13, "stemmed_text": 13, "stemmed_token": 9, "stemmer": [5, 9], "step": [2, 3, 5, 9, 10, 12, 13, 19, 21, 25], "stereotyp": [11, 22], "stewardess": 11, "stick": 23, "still": [1, 10, 19], "stock": [9, 14, 17, 18, 19], "stop": [2, 9, 10, 11, 14, 17, 18, 19, 23, 25, 26, 27], "stop_word": [5, 7, 9, 13, 14, 15, 25, 26], "stopword": [5, 7, 9, 13, 14, 15, 25, 26], "stopwordsremov": 25, "store": [9, 14, 19], "strategi": [1, 6, 7, 9, 10, 24], "stream": 27, "streamlisten": 27, "street": 10, "strength": [7, 9, 16, 19], "strip": [6, 7, 9, 10, 11, 17, 18, 19, 23, 26, 27], "strive": 11, "strong": [11, 12, 21, 24], "structur": [9, 14, 15, 21, 25, 26], "struggl": [9, 11, 23], "stuck": 11, "student": 28, "studi": [1, 6, 9, 10, 11, 14, 17, 18, 21, 24, 25, 26, 27, 28], "sub": [5, 13, 15, 26], "subfield": 14, "subject": 23, "sublist": 25, "submit": [5, 6, 7], "subset": 3, "substitut": 9, "subtl": [1, 25], "subword": 9, "success": [9, 18], "suggest": [20, 23], "suitabl": [13, 14], "sum": [7, 10, 22], "sum_word": 7, "summar": [1, 6, 9, 20, 25, 27], "summari": [4, 11, 14, 17, 18, 21, 25], "summarize_text": 14, "summary_sent": 14, "super": 10, "superior": 19, "supervis": [3, 4, 16, 18, 28], "support": [7, 9, 14, 18], "sure": [6, 9], "surpris": 17, "surround": 10, "survei": [9, 13, 14, 15, 17, 20, 21], "survey_respons": 17, "sustain": 0, "sven": 22, "svm": [9, 19], "syllabu": 4, "syntact": 9, "synthes": [20, 21], "synthesi": 21, "synthet": [10, 21], "system": [3, 6, 8, 9, 10, 14, 17, 18, 19, 26, 27], "systemat": 22, "t": [6, 8, 10, 11, 13, 15, 17, 22, 26, 27], "t5": 10, "tackl": [9, 13, 20, 23, 24], "tactic": 26, "tag": [5, 9], "tagged_text": 14, "tailor": [1, 2, 21], "takeawai": [9, 23, 25, 26], "target": 26, "target_languag": 23, "target_nam": 9, "target_set1": 22, "target_set2": 22, "task": [1, 2, 3, 4, 6, 7, 8, 11, 12, 13, 16, 18, 23, 25, 27, 28], "taylor": 5, "teach": [0, 4], "teacher": [22, 27], "team": [14, 18, 19], "tech": [9, 17], "technic": [13, 22], "techniqu": [1, 3, 4, 5, 6, 8, 9, 10, 14, 16, 20, 21, 24], "technolog": 27, "technologi": [1, 2, 4, 9, 10, 14, 17, 18, 19, 21, 23, 24, 25, 27], "telescop": 9, "tell": 6, "temperatur": [6, 9, 10, 11, 17, 18, 19, 21, 23, 26, 27], "tend": 18, "tendenc": 11, "tension": 14, "tensor": [10, 25], "tensordataset": 10, "tensorflow": 28, "term": [1, 2, 5, 9, 11, 15, 18, 21, 22], "terribl": [9, 10, 14, 19], "tesla": 19, "test": [3, 9, 18, 19], "test_result": 18, "test_siz": [7, 9, 14, 19, 26], "texa": 5, "text": [3, 4, 6, 8, 15, 20, 22, 23, 24, 26, 27], "text_classifi": 27, "text_low": 11, "text_result": 27, "text_scor": 27, "text_senti": 27, "text_to_classifi": 18, "text_to_explain": [11, 27], "text_to_summar": 18, "textblob": [5, 7, 15, 19, 27], "textblob_senti": 7, "textblob_sentiment_categori": 7, "textdataset": 25, "textual": [1, 2, 4, 8, 9, 10, 13, 14, 16, 17, 20, 24, 28], "tf": [2, 5, 7, 9, 14, 26], "tfidf": 7, "tfidf_keyword": 7, "tfidf_matrix": [5, 9, 13, 14], "tfidf_represent": 13, "tfidf_sort": 7, "tfidf_vector": [5, 7], "tfidfvector": [5, 7, 9, 11, 13, 14, 19, 26, 27], "tfw": 23, "th": 15, "than": [5, 6, 9, 14, 17, 18], "thei": [1, 3, 6, 8, 9, 10, 13, 14, 16, 17, 18, 21, 22, 23, 24], "them": [9, 10, 13, 14, 16, 17, 18, 20, 23], "theme": [5, 7, 9, 14, 15, 17], "themselv": [14, 22], "theori": [9, 26], "therefor": 13, "thermal": [6, 7], "thi": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28], "thing": 23, "think": [4, 8, 16, 17, 27], "third": [5, 6, 13, 25], "thorough": 12, "those": [4, 8], "though": 3, "thoughtfulli": 15, "thousand": 9, "three": [1, 4, 5, 6, 8, 12, 16, 20, 24], "thrill": [6, 10, 18, 23], "through": [1, 4, 6, 9, 11, 13, 15, 16, 17, 22, 24, 26], "throughout": [4, 8, 12, 16, 18, 20, 24], "thumbs_up": 13, "tight_layout": [5, 6, 7], "tiktok": 26, "tim": [14, 19], "time": [5, 6, 9, 14, 15, 16, 18, 19, 24, 25], "timestamp": [5, 6], "titl": [5, 6, 7, 19, 26], "to_csv": 6, "to_lowercas": 13, "to_panda": [5, 6], "toarrai": [5, 7, 13], "todai": [9, 14, 17, 19, 27], "togeth": [7, 14], "toi": 13, "token": [2, 3, 5, 7, 9, 10, 14, 15, 21, 22, 25, 26], "tokenize_sent": 13, "tokenize_text": 5, "tokenize_word": 13, "toll": 7, "tone": [14, 15], "too": [7, 10], "took": 13, "tool": [4, 8, 9, 10, 12, 14, 15, 16, 20, 21, 23, 24, 25], "toolkit": 9, "top": [5, 6, 7, 14, 21], "top_bigram": 7, "top_k": 21, "top_p": 21, "top_term": 5, "topic": [4, 10, 11, 12, 16, 21, 26, 27, 28], "topic_trend": 15, "topics_df": 7, "topn": 9, "torch": [9, 10, 21, 25, 26], "total": [5, 6], "toward": [11, 21, 22], "tower": 26, "tqdm": 6, "tqdmwarn": 6, "track": [13, 14, 26, 27], "trad_explan": 19, "trad_rel": 19, "trad_sent": 19, "trad_tim": 19, "trade": [5, 19], "tradit": [1, 3, 4, 8, 11, 16, 18, 21, 23], "tradition": [8, 16], "traditional_bleu": 19, "traditional_ent": 19, "traditional_gener": 19, "traditional_n": 19, "traditional_perform": 19, "traditional_predict": 19, "traditional_relation_extract": 19, "traditional_senti": 19, "train": [1, 2, 3, 5, 6, 7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27], "train_label": [11, 27], "train_test_split": [7, 9, 14, 19, 26], "train_text": [11, 27], "transcript": [1, 10], "transfer": [10, 17], "transform": [4, 5, 7, 8, 13, 14, 18, 19, 21, 22, 24, 25, 26, 27, 28], "transformerencoderlay": 10, "transit": 9, "translat": [9, 17, 19, 23], "transpar": [8, 20, 24, 27], "treati": 18, "treatment": 22, "tree": [9, 11, 14], "trend": [1, 4, 9, 10, 13, 15, 18, 24, 25, 28], "trend_descript": 27, "trigram": 1, "trillion": 27, "true": [5, 6, 7, 9, 21, 22, 25, 26], "truli": [10, 25], "truncat": [9, 10, 25, 26], "trust": 11, "truth": 21, "try": [5, 26], "tune": [1, 2, 9, 11, 17, 19, 21], "turn": 17, "tutori": 28, "tweepi": [25, 26, 27], "tweet": [9, 15, 25, 26, 27], "twitter": [23, 25, 26, 27], "two": [14, 15, 21, 23], "txt": 9, "type": [1, 2, 7, 16, 17, 22, 23, 25, 26], "typic": [3, 9, 10, 11, 13, 15, 18, 25], "u": [5, 6, 8, 11, 13, 22], "ultim": [12, 22], "un": 11, "una": 11, "unbeliev": 26, "uncas": [9, 10, 22, 25, 26, 27], "uncov": [9, 15, 20, 24, 25], "under": 4, "undergon": [1, 4, 8], "underli": 8, "understand": [1, 2, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 28], "unfair": [11, 22], "unfamiliar": 9, "unhelp": 18, "unigram": 1, "unimagin": 24, "unintend": 11, "unintent": 11, "unit": [5, 13], "univers": [0, 17, 18, 28], "unlik": [10, 23], "unlock": 9, "unord": 2, "unpreced": [4, 9, 10, 20, 24], "unpredict": 23, "unproduct": 23, "unseen": [17, 19], "unstack": 15, "unstructur": [13, 14], "unsupervis": [10, 15], "unzip": 5, "up": [3, 4, 5, 7, 9, 14, 16, 23], "upda": 6, "updat": [6, 7], "upon": 12, "urg": [5, 6], "url": [5, 6, 9, 26], "us": [1, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28], "usag": [5, 6, 7, 9, 10, 11, 14, 15, 17, 18, 19, 22, 23, 25, 26, 27], "usage_descript": 11, "used_pronoun": 11, "user": [5, 6, 26], "user_input": 9, "user_instal": 6, "usual": 13, "util": [5, 8, 10, 11, 22, 25], "uuid": [5, 6], "v": [7, 14, 25], "vaccin": 26, "vader": 14, "vadersenti": 14, "valenc": 14, "valid": [1, 8, 9, 10, 17, 18, 19, 22, 25], "valu": [10, 18, 22, 23], "valuabl": [1, 10, 14, 15, 18, 21], "value_count": [6, 25], "vari": [11, 19], "variabl": [6, 13, 21], "variant": 9, "variat": [15, 18], "varieti": 9, "variou": [1, 5, 6, 9, 14, 16, 18, 19, 20, 21, 22, 23, 25, 26], "vast": [1, 4, 9, 10, 17, 18, 20, 24, 25], "vbd": 9, "ve": [4, 5, 6, 9, 24], "vec": 7, "vector": [1, 2, 5, 7, 9, 11, 13, 14, 15, 19, 26, 27], "vector_s": 9, "venv": 6, "verb": 14, "verbos": [5, 6, 7], "veri": [1, 10, 11, 15, 18, 19, 25, 27], "verifi": 21, "versail": 18, "version": [3, 10], "versu": 16, "vi": 7, "victori": 6, "video": [26, 27], "vietnam": 5, "view": 9, "virtual": 3, "viru": [21, 26], "vis_data": 15, "visibl": 25, "visual": [6, 7, 10, 11, 15, 26, 27], "vivid": 23, "vocab_s": 10, "vocabulari": [1, 2, 9, 13], "vocabulary_": 7, "volum": [1, 10, 14, 18, 20, 23], "vp": 9, "vulner": 11, "w": [11, 15, 19], "wa": [9, 10, 11, 14, 15, 18, 26, 27], "wage": 10, "wai": [4, 10, 12, 19, 20, 22], "waiter": 18, "walk": [10, 22], "want": [15, 23], "war": [9, 18, 23], "warn": [6, 7, 11], "washington": 5, "wasn": 17, "wast": 9, "watch": 9, "water": [6, 7], "wd": 15, "we": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27], "weak": 7, "weat_scor": 22, "weat_signific": 22, "weat_test": 22, "weather": [14, 18, 19], "web": [11, 13], "websit": [10, 13, 26], "week": [18, 28], "weekli": 28, "wei": 22, "weigh": [1, 10], "weight": [7, 9, 10, 19], "welcom": [4, 8, 12, 16, 20, 24], "well": [12, 13, 14], "were": [9, 10, 17, 25], "western": [11, 18], "what": [4, 5, 6, 7, 10, 11, 12, 13, 17, 18, 23, 24, 26], "when": [1, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26], "where": [1, 2, 15, 17, 18, 20], "which": [1, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 25], "while": [1, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19, 21, 22, 23], "who": [4, 11, 18], "whole": 18, "why": [9, 10, 11, 21], "wide": [8, 9, 10, 14, 15, 17, 18], "wiki": [13, 27], "wildlif": [6, 7], "win": 19, "window": 9, "with_label": 26, "within": [2, 14, 15, 23], "without": [1, 3, 6, 9, 10, 16, 17, 18, 22], "wittman": [5, 6], "woman": [9, 22, 27], "women": 10, "won": [14, 17, 18, 26], "word": [6, 10, 14, 15, 17, 18, 19, 23, 25, 26, 27], "word2vec": [1, 2, 9], "word_freq": [5, 14], "word_pair": 27, "word_token": [5, 7, 9, 13, 14, 15, 25, 26], "wordnet": [5, 9, 15], "wordnetlemmat": [5, 9, 13, 15, 26], "words_freq": 7, "wordsdf": 25, "work": [1, 3, 4, 6, 8, 10, 11, 12, 15, 16, 21, 25, 27], "work_of_art": 5, "worker": [5, 9, 25], "workflow": [14, 20], "workforc": 10, "workspac": [5, 6, 7], "workspace_dir": [5, 6, 7], "world": [4, 9, 10, 18, 22], "worst": 9, "would": [13, 25], "write": [6, 7, 9], "written": [0, 6, 7], "wv": 9, "www": [5, 6, 13, 26], "x": [5, 6, 7, 10, 15, 19, 27], "x_subset": 19, "x_test": [7, 9, 14, 19, 26], "x_test_tfidf": [7, 9, 26], "x_test_vec": [9, 19], "x_test_vector": 14, "x_train": [7, 9, 14, 19, 26], "x_train_balanc": 19, "x_train_tfidf": [7, 9, 26], "x_train_vec": [9, 19], "x_train_vector": 14, "xlabel": [5, 6, 7, 19], "xtick": [5, 6, 7], "y": [7, 19, 27], "y_pred": [9, 14, 19, 26], "y_subset": 19, "y_test": [7, 9, 14, 19, 26], "y_train": [7, 9, 14, 19, 26], "y_train_balanc": 19, "y_true": 19, "yard": 14, "ye": 23, "year": [4, 5, 8, 12, 21], "yesterdai": 18, "yield": 18, "yj": [0, 5, 6], "ylabel": [5, 6, 7, 19], "york": [14, 19, 26], "you": [4, 5, 6, 7, 8, 9, 12, 13, 14, 16, 18, 20, 21, 24, 25, 26], "young": 10, "younger": 27, "your": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27], "your_access_token": [25, 27], "your_access_token_secret": [25, 27], "your_api_kei": 6, "your_consumer_kei": [25, 27], "your_consumer_secret": [25, 27], "youtub": 26, "z": [5, 11, 15, 26], "z0": [11, 13], "za": [5, 11, 13, 15, 26], "zd": 15, "zero": [1, 4, 7, 16, 18, 19, 26, 27, 28], "zero_grad": [10, 25], "zero_shot_classif": [6, 9, 10, 17], "zero_shot_emotion_detect": 17, "zero_shot_multi_label_classif": 17, "zero_shot_n": 17, "zero_shot_qa": 17, "zero_shot_sentiment_analysi": 17, "zero_shot_summar": 17, "zero_shot_top": [6, 7], "zhang": 22, "ziesch": [5, 6], "zip": [5, 6, 7, 22, 27], "\u03b1": 15, "\u03b2": 15, "\u03b8": 15, "\u03b8d": 15, "\u03c6": 15, "\u03c6k": 15, "\u03c6zd": 15, "\u6211\u559c\u6b22\u8fd9\u4e2a\u4ea7\u54c1": 27, "\u8fd9\u662f\u4e00\u4e2a\u4e2d\u6587\u53e5\u5b50": 11}, "titles": ["Who made this book?", "Extra 1: The Evolution and Impact of LLMs in Social Science Research", "Extra 2: Text Representation and NLP Pipeline", "Extra 3: Practical Considerations for Using LLMs in Social Science Research", "Home", "Lab Session 1: Introduction to NLP for Social Science", "Lab Session 2: LLMs for Data Annotation and Classification", "Lab Session 3: Applying Traditional NLP Techniques", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Course Syllabus"], "titleterms": {"0": 5, "1": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28], "10": [9, 14, 15, 17, 18, 19, 21, 23, 26], "11": [15, 18, 19, 23], "12": [15, 18, 19], "13": 15, "1950": 9, "1980": 9, "2": [1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28], "2000": 9, "2010": 9, "3": [1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28], "4": [1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28], "5": [1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28], "6": [1, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "7": [1, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "8": [1, 3, 5, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27], "9": [9, 10, 14, 15, 17, 18, 19, 21, 22, 23, 26, 27], "A": 1, "In": 18, "Its": 28, "The": [1, 2], "Their": 9, "abil": 10, "about": 4, "academ": 11, "access": [6, 11], "accuraci": [10, 11], "adapt": [10, 19], "addit": 28, "address": 13, "advanc": [10, 15, 24, 27, 28], "advantag": [2, 10], "ai": [11, 27], "algorithm": 15, "alloc": [14, 15], "altern": 3, "ambigu": 9, "analysi": [5, 6, 7, 10, 14, 17, 18, 19, 22, 23, 25, 26, 27], "analyz": [9, 22, 25], "annot": [6, 16, 28], "answer": [10, 17, 18], "api": 3, "appli": 7, "applic": [15, 17, 20, 24, 28], "approach": [2, 3, 9, 19, 26], "architectur": 10, "aspect": 21, "assess": [26, 28], "associ": 22, "attent": 10, "attribut": 11, "augment": 21, "autom": 1, "bag": [1, 2, 13], "balanc": [1, 2, 11], "base": [2, 6, 14, 21, 26], "basic": [5, 9, 14], "bert": 10, "bia": [11, 22], "bias": 10, "book": 0, "bow": [1, 2, 13], "capabl": [1, 9, 10, 17, 18, 19], "categor": 25, "challeng": [1, 9, 10, 11, 14, 15, 22, 23], "chang": 1, "changelog": 4, "charact": 13, "characterist": 26, "choos": 2, "class": 14, "classif": [6, 7, 14, 16, 17, 18, 19, 25, 28], "clean": 13, "cluster": 14, "co": 7, "collabor": 27, "collect": [25, 26], "combin": 15, "commerci": 3, "compar": [7, 19], "comparison": [7, 19], "complet": 10, "complex": [9, 10], "complianc": 11, "compon": 10, "comput": [9, 10, 11, 19], "concept": [9, 10], "concern": 11, "conclus": [5, 9, 11, 13, 14, 18, 19, 21, 22, 23, 25, 26, 27], "consider": [1, 2, 3, 6, 10, 11, 20, 22, 24], "consist": 11, "content": [4, 11, 21, 26], "context": [9, 10, 18, 23], "contribut": 4, "control": 21, "convers": 13, "copyright": 11, "core": 10, "corpora": 10, "cost": 3, "cours": [4, 28], "creation": 21, "credibl": 26, "cross": [10, 11, 27], "crucial": 1, "cultur": [11, 23, 27], "current": 9, "data": [3, 5, 6, 7, 9, 10, 11, 15, 16, 21, 25, 26, 28], "dataset": [9, 10, 25], "date": 13, "deal": [9, 13], "decis": 11, "deep": [9, 26], "definit": [9, 10], "deploy": 10, "descript": 28, "design": [1, 18], "detect": [10, 11, 17, 22, 23, 26], "develop": 9, "direct": [2, 9, 10, 15, 27], "dirichlet": [14, 15], "discours": 23, "dispar": 11, "distinct": 10, "divers": 11, "document": [13, 14], "domain": 10, "earli": 9, "effici": [10, 19], "email": 13, "embed": [1, 2, 9, 13, 22], "emerg": [9, 27], "emoji": 13, "emot": [10, 17, 21], "emoticon": 13, "engin": [3, 17, 18, 21], "enhanc": 10, "ensur": 11, "entiti": [5, 14, 17, 18, 19, 25], "environment": [6, 11], "equiti": 11, "ethic": [6, 10, 11, 20, 22, 24, 27], "ethnic": 22, "evalu": [7, 9, 14, 15, 19, 21, 23], "evolut": [1, 2, 9], "exampl": [9, 10, 14], "exercis": [5, 6, 7], "explain": [11, 19, 27], "explan": [20, 21, 23, 28], "explor": [20, 24], "exposur": 11, "extra": [1, 2, 3, 4], "extract": [7, 9, 14, 17, 18, 19, 25], "factual": [10, 11], "fake": 26, "featur": 9, "few": [6, 9, 10, 18], "figur": 23, "fine": 10, "foundat": [15, 17], "frequenc": [5, 13], "from": [9, 10], "fundament": [9, 14, 15, 18, 21], "futur": [1, 2, 9, 10, 15, 24, 27], "gender": 22, "gener": [6, 9, 10, 11, 17, 18, 19, 20, 21, 28], "gensim": 14, "global": 11, "gpt": 10, "gram": 1, "hallucin": 11, "handl": [3, 9, 10, 13], "high": 21, "histor": 9, "home": 4, "html": 13, "human": [1, 10, 27], "hybrid": 3, "identif": 11, "idf": [1, 13], "idiom": 23, "impact": [1, 9, 11], "implement": 15, "implic": 11, "import": [1, 2, 9, 11], "improv": [10, 11], "infer": 22, "inform": [10, 11, 17, 18, 19], "insight": 1, "instal": [5, 6, 7], "instructor": 0, "integr": [10, 11], "intellectu": 11, "interpret": [2, 6, 7, 10, 11, 14, 15, 19, 23, 27], "introduct": [5, 8, 9, 10, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28], "invers": 13, "ironi": 23, "issu": [6, 7, 11], "its": [9, 10], "joon": 0, "kei": [1, 6, 7, 10, 20, 24], "knowledg": 10, "lab": [4, 5, 6, 7], "lack": 10, "languag": [9, 10, 23, 27], "larg": [9, 10, 11, 25, 27], "larger": 9, "latent": [14, 15], "lda": [7, 14, 15], "learn": [6, 9, 10, 17, 18, 19, 26], "lectur": 4, "lee": 0, "lemmat": 13, "lexicon": 14, "librari": 5, "licens": 4, "like": 10, "limit": [2, 10, 14, 15, 23], "lingual": 10, "ll": [20, 24], "llm": [1, 2, 3, 6, 9, 10, 11, 16, 17, 18, 19, 21, 22, 23, 24, 26, 28], "load": [5, 6, 7], "lowercas": 13, "machin": 26, "made": 0, "manag": 3, "massiv": 10, "materi": 28, "mathemat": 15, "matter": [2, 4, 20, 24], "mechan": 10, "media": 23, "metaphor": 23, "method": 7, "methodologi": 19, "metric": [19, 23], "mine": [18, 19], "misinform": [21, 26], "mitig": [10, 11, 22], "modal": 10, "model": [7, 9, 10, 11, 13, 14, 15, 25, 27], "modern": [2, 9], "multi": [10, 14], "multilingu": 27, "multimod": 27, "n": 1, "name": [5, 14, 17, 18, 19, 25], "natur": [1, 9], "need": 11, "ner": [14, 17, 18, 19], "network": 26, "neuro": 27, "new": [9, 26], "nlp": [1, 2, 5, 7, 8, 9, 10, 11, 12, 14, 15, 22, 27, 28], "nltk": 14, "normal": 13, "notabl": 10, "note": 4, "number": [1, 13], "object": [4, 6, 7, 28], "occurr": 7, "ongo": 9, "opinion": [18, 19], "opportun": 9, "optim": 18, "other": [10, 15], "outcom": 11, "output": [3, 11], "overview": [4, 10], "paradigm": [1, 9], "paramet": 21, "paraphras": 10, "part": 14, "perform": 19, "person": 11, "perspect": 9, "pipelin": [2, 9], "plagiar": 11, "po": 14, "polit": 23, "pose": 11, "possibl": 9, "potenti": [10, 11], "practic": [2, 3, 20, 24], "pre": 10, "prepar": [15, 24], "preprocess": [5, 9, 12, 13, 25, 26, 28], "prerequisit": 28, "present": 9, "privaci": 11, "process": [9, 10, 23, 25, 27], "progress": 10, "promin": 10, "prompt": [3, 17, 18, 21], "proper": 11, "properti": 11, "protect": 11, "proverb": 23, "purpos": 9, "qualiti": 21, "quantifi": 22, "question": [10, 17, 18], "racial": 22, "re": 11, "real": 27, "reason": 10, "recap": 19, "recent": 10, "recognit": [5, 14, 17, 18, 19, 25], "recommend": 28, "regul": 11, "relat": [19, 25], "relev": 1, "reliabl": 11, "remov": 13, "replac": 13, "represent": [2, 5, 13], "reproduc": [3, 11], "requir": [5, 10, 11, 19, 28], "research": [1, 2, 3, 9, 10, 11, 15, 17, 21, 24, 26, 27, 28], "resourc": [10, 11, 19, 28], "respons": 27, "result": [11, 15], "retriev": 10, "revolut": 9, "right": 2, "rise": 9, "risk": 11, "sarcasm": 23, "scalabl": [19, 25], "scale": [10, 11, 25], "schedul": 28, "scienc": [1, 2, 3, 5, 8, 9, 10, 11, 15, 17, 20, 21, 24, 27, 28], "scientif": 11, "scientist": 9, "self": 10, "semant": 9, "sentenc": 13, "sentiment": [5, 6, 7, 10, 14, 17, 18, 19, 25], "seri": 10, "session": [5, 6, 7, 8, 12, 16, 20, 24, 28], "set": 6, "setup": [3, 5, 6, 7], "shift": [1, 9], "shot": [6, 9, 10, 17, 18], "similar": 14, "size": 10, "skill": 1, "social": [1, 2, 3, 5, 8, 9, 10, 11, 15, 17, 20, 21, 22, 23, 24, 27, 28], "societ": 11, "socioeconom": 11, "sophist": 2, "sourc": [11, 22, 25, 26], "spaci": 14, "special": 13, "specif": [9, 10], "speech": 14, "spread": 26, "state": 9, "statist": 9, "stem": 13, "step": 1, "stop": 13, "strategi": [11, 18], "structur": [4, 28], "student": 0, "summar": [10, 14, 17, 18, 21], "summari": [6, 20, 28], "supervis": 19, "sustain": 11, "syllabu": 28, "symbol": 27, "tabl": 4, "tag": [13, 14], "task": [5, 9, 10, 14, 17, 19, 21], "technic": 3, "techniqu": [2, 7, 11, 12, 13, 15, 18, 22, 25, 26, 28], "technologi": 11, "term": 13, "test": 22, "text": [1, 2, 5, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 21, 25, 28], "textbook": 28, "textual": 25, "tf": [1, 13], "theoret": 17, "thi": [0, 4], "time": 27, "token": 13, "topic": [6, 7, 14, 15, 20, 24, 25], "toward": 9, "tradit": [2, 7, 9, 10, 12, 19, 26, 28], "train": [9, 10, 11], "transform": [1, 9, 10], "translat": 10, "transpar": [10, 11], "trend": 27, "true": 10, "tune": 10, "type": [11, 14, 18, 21], "understand": [10, 23], "uniqu": 11, "unstructur": 9, "up": [6, 10], "url": 13, "us": [3, 11, 14, 21, 22], "v": 2, "valid": [3, 11], "variant": 10, "variou": 10, "we": [20, 24], "weat": 22, "who": 0, "why": [2, 4, 20, 24], "wisdom": 23, "word": [1, 2, 5, 7, 9, 13, 22], "young": 0, "zero": [6, 9, 10, 17]}})