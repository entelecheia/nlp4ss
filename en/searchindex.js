Search.setIndex({"alltitles": {"0. Installation": [[2, "installation"]], "1. Introduction": [[2, "introduction"], [14, "introduction"]], "1. Introduction to Emerging Trends in NLP for Social Science": [[22, "introduction-to-emerging-trends-in-nlp-for-social-science"]], "1. Introduction to Ethics in AI and NLP Research": [[6, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Few-shot Learning": [[13, "introduction-to-few-shot-learning"]], "1. Introduction to Figurative Language": [[18, "introduction-to-figurative-language"]], "1. Introduction to Fundamental NLP Tasks": [[9, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[5, "introduction-to-generative-llms"]], "1. Introduction to Large-Scale Text Analysis": [[20, "introduction-to-large-scale-text-analysis"]], "1. Introduction to Misinformation and Fake News": [[21, "introduction-to-misinformation-and-fake-news"]], "1. Introduction to Natural Language Processing (NLP)": [[4, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Social Bias in NLP": [[17, "introduction-to-social-bias-in-nlp"]], "1. Introduction to Text Generation with LLMs": [[16, "introduction-to-text-generation-with-llms"]], "1. Introduction to Text Preprocessing": [[8, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[10, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[12, "introduction-to-zero-shot-learning"]], "1.1 Definition of NLP": [[4, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[4, "fundamentals-of-nlp-and-its-evolution"]], "1.2 Basic Concepts": [[4, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[5, "overview-of-generative-llms"]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[6, "ethical-considerations-and-challenges-in-using-llms-for-research"]], "1.3 Importance in Social Science Research": [[4, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[10, "applications-in-social-science-research"], [12, "applications-in-social-science-research"]], "10. Computational Efficiency and Resource Requirements": [[14, "computational-efficiency-and-resource-requirements"]], "10. Current State and Future Directions": [[4, "current-state-and-future-directions"]], "10. Evaluation Metrics for Figurative Language Processing": [[18, "evaluation-metrics-for-figurative-language-processing"]], "10. Evaluation and Interpretation": [[9, "evaluation-and-interpretation"]], "10. Evaluation of Generated Text": [[16, "evaluation-of-generated-text"]], "10. Few-shot Text Generation and Summarization": [[13, "few-shot-text-generation-and-summarization"]], "10. Network Analysis in Misinformation Spread": [[21, "network-analysis-in-misinformation-spread"]], "10.1 Ongoing Developments in LLMs": [[4, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[4, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations": [[18, "challenges-and-limitations"]], "11. Challenges and Limitations of LDA": [[10, "challenges-and-limitations-of-lda"]], "11. Few-shot Question Answering and Information Extraction": [[13, "few-shot-question-answering-and-information-extraction"]], "11. Scalability and Adaptability": [[14, "scalability-and-adaptability"]], "12. Combining Topic Modeling with Other NLP Techniques": [[10, "combining-topic-modeling-with-other-nlp-techniques"]], "12. Interpretability and Explainability": [[14, "interpretability-and-explainability"]], "12. Prompt Optimization Techniques": [[13, "prompt-optimization-techniques"]], "13. Future Directions in Topic Modeling": [[10, "future-directions-in-topic-modeling"]], "2. Advancements in Large Language Models": [[22, "advancements-in-large-language-models"]], "2. Bias in LLMs": [[6, "bias-in-llms"]], "2. Characteristics of Misinformation and Fake News": [[21, "characteristics-of-misinformation-and-fake-news"]], "2. Cultural Context in Figurative Language": [[18, "cultural-context-in-figurative-language"]], "2. Data Sources for Large-Scale Text Analysis": [[20, "data-sources-for-large-scale-text-analysis"]], "2. Few-shot Learning Capabilities of LLMs": [[13, "few-shot-learning-capabilities-of-llms"]], "2. Fundamentals of LLM-based Text Generation": [[16, "fundamentals-of-llm-based-text-generation"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[10, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Historical Perspective of NLP": [[4, "historical-perspective-of-nlp"]], "2. Key Components of LLMs": [[5, "key-components-of-llms"]], "2. Recap of Traditional Supervised Learning": [[14, "recap-of-traditional-supervised-learning"]], "2. Setup and Data Loading": [[2, "setup-and-data-loading"]], "2. Sources of Bias in LLMs": [[17, "sources-of-bias-in-llms"]], "2. Text Classification": [[9, "text-classification"]], "2. Text Cleaning": [[8, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[12, "theoretical-foundations-of-zero-shot-learning"]], "2.1 Early Approaches (1950s-1980s)": [[4, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[8, "text-cleaning-normalization-and-representation"]], "2.2 Basic NLP Tasks": [[9, "basic-nlp-tasks"]], "2.2 Statistical Revolution (1980s-2000s)": [[4, "statistical-revolution-1980s-2000s"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[10, "topic-modeling-and-latent-dirichlet-allocation-lda"]], "3. Data Collection and Preprocessing for Large Datasets": [[20, "data-collection-and-preprocessing-for-large-datasets"]], "3. Data Sources for Misinformation Research": [[21, "data-sources-for-misinformation-research"]], "3. LLM Approaches in Comparison": [[14, "llm-approaches-in-comparison"]], "3. LLMs and Figurative Language Understanding": [[18, "llms-and-figurative-language-understanding"]], "3. Lowercase Conversion": [[8, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[10, "mathematical-foundation-of-lda"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[4, "modern-nlp-and-deep-learning-2010s-present"]], "3. Multimodal Analysis": [[22, "multimodal-analysis"]], "3. Notable Examples of LLMs": [[5, "notable-examples-of-llms"]], "3. Privacy Concerns": [[6, "privacy-concerns"]], "3. Required Libraries": [[2, "required-libraries"]], "3. Sentiment Analysis": [[9, "sentiment-analysis"]], "3. Techniques for Detecting Bias in LLMs": [[17, "techniques-for-detecting-bias-in-llms"]], "3. Types of Few-shot Learning": [[13, "types-of-few-shot-learning"]], "3. Types of Text Generation Tasks": [[16, "types-of-text-generation-tasks"]], "3. Zero-shot Capabilities of LLMs": [[12, "zero-shot-capabilities-of-llms"]], "3.1 Zero-shot Learning with LLMs": [[12, "zero-shot-learning-with-llms"]], "3.2 Few-shot Learning and Prompt Engineering": [[13, "few-shot-learning-and-prompt-engineering"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[14, "comparing-llm-performance-with-traditional-supervised-learning"]], "4. Capabilities of LLMs in Social Science Contexts": [[5, "capabilities-of-llms-in-social-science-contexts"]], "4. Data Collection and Preprocessing": [[21, "data-collection-and-preprocessing"]], "4. Evaluation Metrics and Methodologies": [[14, "evaluation-metrics-and-methodologies"]], "4. Explainable AI and Interpretable NLP": [[22, "explainable-ai-and-interpretable-nlp"]], "4. Fundamentals of Prompt Engineering": [[13, "fundamentals-of-prompt-engineering"]], "4. LDA Algorithm": [[10, "lda-algorithm"]], "4. Metaphor Detection and Interpretation": [[18, "metaphor-detection-and-interpretation"]], "4. Named Entity Recognition (NER)": [[9, "named-entity-recognition-ner"]], "4. Prompt Engineering for Text Generation": [[16, "prompt-engineering-for-text-generation"]], "4. Prompt Engineering for Zero-shot Tasks": [[12, "prompt-engineering-for-zero-shot-tasks"]], "4. Quantifying Bias in LLMs": [[17, "quantifying-bias-in-llms"]], "4. Scalable Text Processing Techniques": [[20, "scalable-text-processing-techniques"]], "4. Text Preprocessing": [[2, "text-preprocessing"]], "4. Tokenization": [[8, "tokenization"]], "4. Traditional NLP Pipeline": [[4, "traditional-nlp-pipeline"]], "4. Transparency and Interpretability": [[6, "transparency-and-interpretability"]], "4.1 Text Preprocessing": [[4, "text-preprocessing"]], "4.1 Using LLMs for High-Quality Text Generation": [[16, "using-llms-for-high-quality-text-generation"]], "4.2 Feature Extraction": [[4, "feature-extraction"]], "4.2 Social Bias Inference and Analysis": [[17, "social-bias-inference-and-analysis"]], "4.3 Figurative Language Explanation and Cultural Context": [[18, "figurative-language-explanation-and-cultural-context"]], "4.3 Model Training and Evaluation": [[4, "model-training-and-evaluation"]], "5. Basic NLP Tasks": [[2, "basic-nlp-tasks"]], "5. Challenges in Traditional NLP": [[4, "challenges-in-traditional-nlp"]], "5. Controlling Generation Parameters": [[16, "controlling-generation-parameters"]], "5. Ethical AI and Responsible NLP": [[22, "ethical-ai-and-responsible-nlp"]], "5. Idiom Processing with LLMs": [[18, "idiom-processing-with-llms"]], "5. Part-of-Speech (POS) Tagging": [[9, "part-of-speech-pos-tagging"]], "5. Performance Comparison in Classification Tasks": [[14, "performance-comparison-in-classification-tasks"]], "5. Preparing Data for LDA": [[10, "preparing-data-for-lda"]], "5. Prompt Design Strategies": [[13, "prompt-design-strategies"]], "5. Reliability and Reproducibility": [[6, "reliability-and-reproducibility"]], "5. Social Bias Inference Using LLMs": [[17, "social-bias-inference-using-llms"]], "5. Stop Word Removal": [[8, "stop-word-removal"]], "5. Topic Modeling at Scale": [[20, "topic-modeling-at-scale"]], "5. Traditional Machine Learning Approaches": [[21, "traditional-machine-learning-approaches"]], "5. Training Process of LLMs": [[5, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[12, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[20, "analyzing-large-scale-textual-data"]], "5.1 Handling Language Ambiguity": [[4, "handling-language-ambiguity"]], "5.1 Word Frequency Analysis": [[2, "word-frequency-analysis"]], "5.2 Dealing with Context and Semantics": [[4, "dealing-with-context-and-semantics"]], "5.2 Misinformation and Fake News Detection": [[21, "misinformation-and-fake-news-detection"]], "5.2 Named Entity Recognition": [[2, "named-entity-recognition"]], "5.3 Computational Complexity": [[4, "computational-complexity"]], "5.3 Future Directions and Emerging Trends": [[22, "future-directions-and-emerging-trends"]], "5.3 Sentiment Analysis": [[2, "sentiment-analysis"]], "6. Advantages of LLMs in Social Science Research": [[5, "advantages-of-llms-in-social-science-research"]], "6. Analyzing Gender Bias": [[17, "analyzing-gender-bias"]], "6. Aspect-based Emotion Summarization": [[16, "aspect-based-emotion-summarization"]], "6. Comparing Text Generation Capabilities": [[14, "comparing-text-generation-capabilities"]], "6. Deep Learning Techniques": [[21, "deep-learning-techniques"]], "6. Evolution Towards Modern NLP": [[4, "evolution-towards-modern-nlp"]], "6. Implementing LDA": [[10, "implementing-lda"]], "6. In-context Learning": [[13, "in-context-learning"]], "6. Intellectual Property and Attribution": [[6, "intellectual-property-and-attribution"]], "6. Large-Scale Sentiment Analysis": [[20, "large-scale-sentiment-analysis"]], "6. Multilingual and Cross-cultural NLP": [[22, "multilingual-and-cross-cultural-nlp"]], "6. Sarcasm and Irony Detection": [[18, "sarcasm-and-irony-detection"]], "6. Stemming": [[8, "stemming"]], "6. Text Representation": [[2, "text-representation"]], "6. Text Summarization": [[9, "text-summarization"]], "6. Zero-shot Named Entity Recognition (NER)": [[12, "zero-shot-named-entity-recognition-ner"]], "6.1 Introduction of Word Embeddings": [[4, "introduction-of-word-embeddings"]], "6.2 Rise of Deep Learning in NLP": [[4, "rise-of-deep-learning-in-nlp"]], "6.3 Emergence of Transformer Models": [[4, "emergence-of-transformer-models"]], "7. Conclusion": [[2, "conclusion"]], "7. Environmental and Resource Considerations": [[6, "environmental-and-resource-considerations"]], "7. Few-shot Classification Techniques": [[13, "few-shot-classification-techniques"]], "7. Figurative Language in Social Media Analysis": [[18, "figurative-language-in-social-media-analysis"]], "7. Interpreting LDA Results": [[10, "interpreting-lda-results"]], "7. LLM-based Approaches to Misinformation Detection": [[21, "llm-based-approaches-to-misinformation-detection"]], "7. Large Language Models (LLMs)": [[4, "large-language-models-llms"]], "7. Lemmatization": [[8, "lemmatization"]], "7. Limitations and Challenges": [[5, "limitations-and-challenges"]], "7. Misinformation Explanation Generation": [[16, "misinformation-explanation-generation"]], "7. Named Entity Recognition (NER) Performance": [[14, "named-entity-recognition-ner-performance"]], "7. Named Entity Recognition and Relation Extraction": [[20, "named-entity-recognition-and-relation-extraction"]], "7. Racial and Ethnic Bias Analysis": [[17, "racial-and-ethnic-bias-analysis"]], "7. Real-time Language Processing and Analysis": [[22, "real-time-language-processing-and-analysis"]], "7. Text Similarity and Clustering": [[9, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[12, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[4, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[4, "examples-and-their-impact"]], "8. Content-based Analysis": [[21, "content-based-analysis"]], "8. Evaluating Topic Models": [[10, "evaluating-topic-models"]], "8. Exercise": [[2, "exercise"]], "8. Few-shot Named Entity Recognition (NER)": [[13, "few-shot-named-entity-recognition-ner"]], "8. High-Quality Content Creation": [[16, "high-quality-content-creation"]], "8. Mitigating Bias in LLMs": [[17, "mitigating-bias-in-llms"]], "8. Neuro-symbolic AI in NLP": [[22, "neuro-symbolic-ai-in-nlp"]], "8. Paradigm Shift in NLP Tasks": [[4, "paradigm-shift-in-nlp-tasks"]], "8. Proverbs and Cultural Wisdom": [[18, "proverbs-and-cultural-wisdom"]], "8. Recent Advancements": [[5, "recent-advancements"]], "8. Sentiment Analysis and Opinion Mining": [[14, "sentiment-analysis-and-opinion-mining"]], "8. Socioeconomic Implications": [[6, "socioeconomic-implications"]], "8. Text Classification and Categorization": [[20, "text-classification-and-categorization"]], "8. Text Representation Techniques": [[8, "text-representation-techniques"]], "8. Topic Modeling": [[9, "topic-modeling"]], "8. Zero-shot Text Summarization and Generation": [[12, "zero-shot-text-summarization-and-generation"]], "8.1 From Task-Specific to General-Purpose Models": [[4, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[4, "few-shot-and-zero-shot-learning"]], "9. Advanced Topic Modeling Techniques": [[10, "advanced-topic-modeling-techniques"]], "9. Challenges and Limitations": [[9, "challenges-and-limitations"]], "9. Data Augmentation for Social Science Research": [[16, "data-augmentation-for-social-science-research"]], "9. Ethical Considerations and Challenges": [[17, "ethical-considerations-and-challenges"]], "9. Few-shot Sentiment Analysis and Opinion Mining": [[13, "few-shot-sentiment-analysis-and-opinion-mining"]], "9. Figurative Language in Political Discourse": [[18, "figurative-language-in-political-discourse"]], "9. Future Directions": [[5, "future-directions"]], "9. Human-AI Collaboration in Research": [[22, "human-ai-collaboration-in-research"]], "9. Impact on Social Science Research": [[4, "impact-on-social-science-research"]], "9. Information Extraction and Relation Classification": [[14, "information-extraction-and-relation-classification"]], "9. Source Credibility Assessment": [[21, "source-credibility-assessment"]], "9. Zero-shot Question Answering and Information Extraction": [[12, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[4, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[4, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[5, "ability-to-generate-human-like-text"]], "About": [[1, null]], "Access disparities to LLM technologies": [[6, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[5, "adaptability-to-various-domains-and-tasks"]], "Additional Resources": [[23, "additional-resources"]], "Assessment": [[23, "assessment"]], "BERT and its variants": [[5, "bert-and-its-variants"]], "Bag-of-Words (BoW) model": [[8, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[6, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[6, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[6, "challenges-in-explaining-model-decisions"]], "Changelog": [[1, "changelog"]], "Computational resources required": [[5, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[6, "computational-resources-required-for-training-and-using-llms"]], "Conclusion": [[4, "conclusion"], [6, "conclusion"], [8, "conclusion"], [9, "conclusion"], [13, "conclusion"], [14, "conclusion"], [16, "conclusion"], [17, "conclusion"], [18, "conclusion"], [20, "conclusion"], [21, "conclusion"], [22, "conclusion"]], "Considerations for global and cross-cultural research": [[6, "considerations-for-global-and-cross-cultural-research"]], "Contributing": [[1, "contributing"]], "Copyright issues with training data and generated content": [[6, "copyright-issues-with-training-data-and-generated-content"]], "Course Description": [[23, "course-description"]], "Course Objectives": [[1, "course-objectives"], [23, "course-objectives"]], "Course Overview": [[1, "course-overview"]], "Course Structure": [[1, "course-structure"], [23, "course-structure"]], "Course Syllabus": [[23, "course-syllabus"]], "Data protection and compliance with privacy regulations": [[6, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[8, "dealing-with-numbers-and-dates"]], "Definition and core concept": [[5, "definition-and-core-concept"]], "Distinction from traditional NLP models": [[5, "distinction-from-traditional-nlp-models"]], "Enhanced multi-modal capabilities": [[5, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[6, "environmental-impact-of-large-scale-ai-models"]], "Ethical Considerations": [[15, "ethical-considerations"]], "Ethical considerations in deployment": [[5, "ethical-considerations-in-deployment"]], "Example: Document Similarity and Clustering": [[9, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[9, "example-extractive-summarization"]], "Example: Latent Dirichlet Allocation (LDA) with Gensim": [[9, "example-latent-dirichlet-allocation-lda-with-gensim"]], "Example: Lexicon-based Sentiment Analysis": [[9, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[9, "example-multi-class-classification"]], "Example: NER using spaCy": [[9, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[9, "example-pos-tagging-with-nltk"]], "Few-shot and zero-shot learning capabilities": [[5, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[5, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[5, "gpt-generative-pre-trained-transformer-series"]], "Handling URLs and email addresses": [[8, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[5, "handling-complex-language-understanding-tasks"]], "Home": [[1, "home"]], "Impact on research outcomes and societal implications": [[6, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[6, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[6, "importance-of-interpretability-in-scientific-research"]], "Improved interpretability and transparency": [[5, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[5, "improvements-in-model-size-and-efficiency"]], "Integration with domain-specific knowledge": [[5, "integration-with-domain-specific-knowledge"]], "Issues with hallucination and factual accuracy": [[6, "issues-with-hallucination-and-factual-accuracy"]], "Key Topics We\u2019ll Explore": [[15, "key-topics-we-ll-explore"], [19, "key-topics-we-ll-explore"]], "Lab Session 1: Introduction to NLP for Social Science": [[2, "lab-session-1-introduction-to-nlp-for-social-science"]], "Labs": [[1, null]], "Lack of true understanding or reasoning": [[5, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[1, null]], "License": [[1, "license"]], "Other prominent models": [[5, "other-prominent-models"]], "Plagiarism concerns and academic integrity": [[6, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[5, "potential-biases-in-training-data"]], "Potential for personal information exposure in training data": [[6, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[6, "potential-impact-on-research-equity-and-diversity"]], "Practical Applications": [[15, "practical-applications"]], "Practical Applications and Ethical Considerations": [[19, "practical-applications-and-ethical-considerations"]], "Pre-training on large corpora": [[5, "pre-training-on-large-corpora"]], "Preparing for the Future of Social Science Research": [[19, "preparing-for-the-future-of-social-science-research"]], "Prerequisites": [[23, "prerequisites"]], "Progress in mitigating biases and improving factual accuracy": [[5, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Proper attribution of AI-generated text in research": [[6, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[5, "question-answering-and-information-retrieval"]], "Recommended Textbooks": [[23, "recommended-textbooks"]], "Removing HTML tags and special characters": [[8, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[8, "removing-or-replacing-emojis-and-emoticons"]], "Required Materials": [[23, "required-materials"]], "Risks of re-identification in generated text": [[6, "risks-of-re-identification-in-generated-text"]], "Scaled-up training on massive datasets": [[5, "scaled-up-training-on-massive-datasets"]], "Schedule": [[23, "schedule"]], "Self-attention mechanism": [[5, "self-attention-mechanism"]], "Sentence tokenization": [[8, "sentence-tokenization"]], "Sentiment analysis and emotion detection": [[5, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[3, "session-1-introduction-to-nlp-for-social-science"]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[23, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[7, "session-2-traditional-nlp-techniques-and-text-preprocessing"], [23, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[11, "session-3-llms-for-data-annotation-and-classification"], [23, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[15, "session-4-generative-explanations-and-summaries-in-social-science"], [23, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[19, "session-5-advanced-applications-of-llms-in-social-science-research"], [23, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Sources of bias": [[6, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[6, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[6, "strategies-for-validating-llm-generated-results"]], "Summarization and paraphrasing": [[5, "summarization-and-paraphrasing"]], "Table of Contents": [[1, "table-of-contents"]], "Techniques for improving model transparency": [[6, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[8, "term-frequency-inverse-document-frequency-tf-idf"]], "Text generation and completion": [[5, "text-generation-and-completion"]], "Transformer architecture": [[5, "transformer-architecture"]], "Translation and cross-lingual tasks": [[5, "translation-and-cross-lingual-tasks"]], "Types of bias": [[6, "types-of-bias"]], "Types of classification:": [[9, "types-of-classification"]], "Unique challenges posed by LLMs": [[6, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, "who-made-this-book"]], "Why Advanced Applications Matter in Social Science Research": [[19, "why-advanced-applications-matter-in-social-science-research"]], "Why Generative Explanations and Summaries Matter in Social Science": [[15, "why-generative-explanations-and-summaries-matter-in-social-science"]], "Why This Course Matters": [[1, "why-this-course-matters"]], "Word Embedding Association Test (WEAT)": [[17, "word-embedding-association-test-weat"]], "Word Embeddings": [[8, "word-embeddings"]], "Word tokenization": [[8, "word-tokenization"]]}, "docnames": ["about/index", "index", "labs/nlp4ss-lab-1", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "labs/nlp4ss-lab-1.ipynb", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "0": [1, 4, 5, 6, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "002": [4, 5, 6, 12, 13, 14, 18, 21, 22], "04": 8, "05": 9, "0x16fea3020": 2, "1": [1, 7, 11, 15, 19], "10": [2, 5, 8, 20], "100": [2, 4, 5, 6, 8, 12, 13, 14, 16, 18, 21, 22], "1000": [2, 14, 17, 20, 22], "10000": [5, 14], "12": 2, "123": 6, "128": 20, "12952396179718417": 2, "13363707315372284": 2, "14915865499620834": 2, "15": [2, 8], "150": [5, 14, 22], "1500": 8, "15154887003653952": 2, "1538819754578188": 2, "15a5": 2, "175": 5, "1752966664790094": 2, "18951266c182": 2, "18th": [12, 13], "19": [16, 21], "1919": 13, "1964": 13, "1966": 4, "19th": 13, "2": [1, 3, 11, 15, 19], "20": [2, 14], "200": [4, 18, 22], "2009832958865476": 2, "2017": 4, "2019": 16, "2020": [16, 22, 23], "2021": 16, "2022": 23, "2023": [2, 8, 22], "2024": 2, "2030": 13, "208b731ebb2b": 2, "21455232095761398": 2, "2288625126017953": 2, "25": 23, "256": 5, "27622023052939987": 2, "2e": 5, "2f": [6, 22], "3": [1, 3, 7, 15, 19], "30": [10, 13], "300": 5, "3101051886326014": 2, "319a": 2, "32": 20, "32a0": 2, "347": 2, "35": [16, 23], "3ebc6ab6": 2, "3f": 17, "3rd": 23, "4": 1, "40": [2, 23], "4087": 2, "42": [4, 9, 10, 14, 21], "420": 22, "45": [2, 6], "456": 6, "4607": 2, "4617": 2, "46c8": 2, "4ccc": 2, "4f": [4, 14, 22], "5": 1, "50": [4, 5, 6, 12, 13, 14, 16, 17], "500": [6, 21], "512": [4, 5, 21], "56bdd61fd9e5": 2, "58": 6, "586d": 2, "593965ae0ad8": 2, "5g": [16, 21], "60": 10, "6353": 2, "6354": 2, "6789": 6, "7": 23, "7890": 6, "9": [6, 8], "9000": 4, "924abe2c": 2, "94d2": 2, "95": 16, "953b": 2, "9622": 2, "9c0e": 2, "9ee69b6c": 2, "A": [5, 6, 7, 9, 10, 13, 14, 17, 18, 21], "And": [8, 20], "As": [1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "BY": 1, "Be": [6, 9, 12], "By": [1, 4, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 23], "For": [4, 7, 8, 9, 10, 14, 16, 20], "IN": 4, "If": [16, 18], "In": [1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 14, 15, 17, 19, 20], "It": [3, 4, 8, 9, 10, 12, 13, 14, 15, 18], "NOT": 21, "No": [6, 14, 18], "One": [13, 17], "The": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "There": 4, "These": [1, 2, 4, 5, 7, 8, 9, 11, 13, 15], "To": [6, 8, 10, 14, 16, 17], "_": [6, 13, 14, 17], "___": 4, "____": 4, "_______": 4, "________________________": 4, "__getitem__": 20, "__init__": [5, 20], "__len__": 20, "_wra": 2, "ab_test_prompt": 13, "abbrevi": 9, "abil": [4, 6, 7, 9, 12, 13, 15, 16, 20], "abl": [11, 23], "about": [2, 3, 4, 5, 6, 8, 10, 11, 13, 14, 16, 17, 20, 21], "abov": 17, "absolut": [4, 12], "abstract": [3, 9, 10, 12], "academ": [4, 5], "acc": 14, "access": [3, 5, 15], "access_token": [20, 21, 22], "access_token_secret": [20, 21, 22], "accord": [4, 6, 9, 14, 21], "account": 6, "accur": [7, 9, 13, 17, 18], "accuraci": [4, 9, 13, 14, 15, 16, 18, 21], "accuracy_scor": 14, "achiev": [4, 5, 7, 12], "acknowledg": 17, "across": [4, 5, 10, 15, 18, 20], "act": [2, 4, 13], "actual": 13, "ada": 2, "adamw": 5, "adapt": [3, 4, 11, 13, 16, 19, 22], "add": [10, 13, 20], "add_edg": 21, "addit": [2, 18], "addition": 17, "address": [4, 6, 10, 17, 19, 21, 22, 23], "adher": [6, 22], "adjac": 4, "adject": 9, "adjust": 16, "adopt": [4, 22], "ador": 22, "adult": 5, "advanc": [1, 2, 3, 4, 6, 7, 8, 9, 13, 16, 18, 20], "advantag": [13, 16], "advent": [1, 11], "advisori": 2, "affect": [6, 13, 16], "after": [5, 8, 13], "ag": [4, 17], "against": 6, "agenc": 6, "agreement": [2, 9], "ahead": 5, "ai": [4, 13, 14, 15, 16, 19, 21, 23], "ai_research_assist": 22, "aim": [1, 4, 5, 12, 13], "al": 16, "albert": 5, "algorithm": [4, 6, 8, 13, 14, 17], "alik": 9, "all": [2, 3, 4, 5, 6, 12, 13, 17], "all_ent": 20, "all_target": 17, "all_text": 2, "alloc": [1, 6, 7, 20, 23], "allow": [4, 5, 6, 8, 10, 11, 12, 13, 15, 17, 20], "almost": 12, "alon": 10, "alphabet": [4, 20], "alreadi": 2, "also": [1, 3, 4, 5, 6, 8, 11, 12, 13, 15, 18, 19], "alter": 13, "altern": 6, "alwai": [1, 9, 10, 16], "am": 4, "amaz": [14, 21, 22], "amazon": 14, "america": [2, 12, 13], "among": [5, 16, 22], "amount": [1, 4, 5, 9, 13, 15, 19, 20], "amp": 8, "amplif": [6, 15], "amplifi": [5, 6], "amus": 18, "an": [1, 2, 4, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23], "analys": [2, 4, 8, 9, 18], "analysi": [1, 3, 4, 6, 7, 8, 10, 11, 15, 16, 23], "analyt": [4, 8], "analyz": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 22, 23], "analyze_cont": 21, "analyze_emot": 5, "analyze_language_divers": 6, "analyze_occupation_bia": 17, "analyze_political_metaphor": 18, "analyze_proverb": 18, "analyze_senti": [4, 9], "analyze_sentiment_multilingu": 4, "analyze_social_concept": 5, "analyze_social_media_post": 22, "analyze_social_trend": 22, "analyze_spread_network": 21, "anger": 12, "angri": 21, "ani": [4, 6, 7, 17, 18], "anim": [5, 9], "annot": [1, 3, 9, 12], "announc": [9, 13, 14, 21], "anonym": 6, "anoth": [6, 8, 18], "answer": [2, 3, 4], "answer_quest": 5, "anticip": 19, "apach": 20, "api": [4, 5, 6, 8, 12, 13, 14, 18, 20, 21, 22], "api_kei": [4, 5, 6, 12, 13, 14, 18, 21, 22], "apolog": 4, "append": [6, 12, 14, 17, 20, 21, 22], "appl": [9, 13, 14], "appli": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 23], "applic": [1, 4, 5, 7, 8, 9, 13, 14, 16, 22], "apply_rul": 22, "appnam": 20, "approach": [1, 3, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20, 22, 23], "appropri": [4, 5, 6, 9, 13, 14], "april": 2, "ar": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21], "architectur": [4, 6, 16, 17], "archiv": 20, "area": [3, 5, 7, 15, 17, 18], "aren": 6, "argmax": [4, 5, 21], "argument": 16, "aris": 17, "arithmet": 4, "around": 4, "arrai": 22, "art": [1, 4], "articl": [2, 5, 9, 10, 19, 21], "artifact": 5, "artifici": [4, 5, 9], "artist": [17, 22], "as_list": [6, 14, 22], "as_posix": 2, "ask": 3, "aspect": [12, 13, 18, 23], "assess": 10, "assign": [4, 9, 13, 23], "assist": [6, 16, 18, 19, 22], "associ": [6, 10], "association_1": 17, "association_2": 17, "assum": [4, 6, 10, 14, 20, 21, 22], "assumpt": [6, 8, 10], "assura": 2, "attend": 8, "attent": [4, 6, 13], "attention_mask": [5, 20], "attention_output": 5, "attribut": [10, 17, 18], "attribute_set1": 17, "attribute_set2": 17, "attun": 9, "audienc": [15, 18], "audio": [4, 22], "audit": 6, "augment": 9, "ausgezeichnet": 4, "austin": 2, "auth": [20, 21, 22], "authent": [20, 21], "author": 6, "authorit": 6, "autom": [4, 11, 14, 21], "automat": [4, 9, 10], "automodel": 17, "automodelforsequenceclassif": [4, 20], "autoregress": 16, "autotim": 2, "autotoken": [4, 17, 20], "avail": [4, 14, 21], "averag": [2, 6, 10, 14], "averaged_perceptron_tagg": [4, 9], "avoid": [15, 17], "awai": 3, "awar": [4, 5, 6, 8, 9, 12, 13, 18], "axi": 5, "b": [6, 8, 13, 17, 21], "b4f2": 2, "backbon": 7, "background": 17, "backgrounddespit": 2, "backward": [5, 20], "bad": [6, 22], "bag": [4, 9], "balanc": [14, 16, 21], "bank": 4, "bar": 2, "barrier": 5, "base": [1, 2, 3, 4, 5, 6, 10, 12, 13, 14, 17, 20, 22, 23], "basi": 7, "basic": [1, 7, 16, 23], "batch": [5, 20], "batch_ent": 20, "batch_result": 20, "batch_siz": [5, 20], "batcher": 2, "bay": [4, 9], "beach": 22, "beach_selfi": 22, "beat": 14, "beautifulsoup": 21, "becaus": [3, 5, 8, 21], "becom": [4, 6, 9, 20, 21, 22], "been": [6, 11, 12, 13, 14], "befor": [2, 4, 10], "began": [12, 13], "begin": [1, 2, 7, 11, 15], "behavior": [1, 4, 21, 22], "behind": [9, 10, 12], "being": 7, "believ": [5, 12, 21], "benchmark": 4, "benefici": [6, 8], "benefit": [1, 6], "bert": [4, 14, 17, 20, 21, 22], "bertforsequenceclassif": [4, 5, 21], "berttoken": [4, 5, 21], "best": [3, 5, 9, 12, 13, 17], "better": [5, 6, 10, 12, 13, 22], "between": [1, 3, 4, 5, 9, 10, 12, 13, 14, 16, 17, 18, 21, 22], "betweenness_c": 21, "betweenness_centr": 21, "beyond": [4, 5], "bezo": 14, "bia": [1, 3, 4, 5, 15, 18, 20, 22, 23], "bias": [1, 4, 6, 8, 9, 12, 13, 15, 17, 18, 19, 21, 22], "bias_analysi": 4, "bias_check": 5, "biased_prompt": 17, "biden": 2, "bidirect": [4, 5], "big": 20, "bill": [13, 14], "billion": [2, 5], "bin": 2, "binari": 9, "biodivers": 9, "bit": [5, 13], "black": [4, 6, 22], "bleu": 14, "bleu_scor": 14, "blockchain": 22, "board": 6, "boem": 2, "boi": [17, 22], "bold": 21, "book": [1, 5], "bool": 21, "both": [1, 3, 4, 5, 10, 14, 16, 20, 21], "boundari": [7, 19], "bow_matrix": 8, "bow_represent": 8, "box": [4, 6, 22], "brad": 17, "break": [4, 8, 13], "breakthrough": 4, "brickei": 2, "bridg": [1, 3, 4, 13, 19], "brief": [4, 5, 21], "bring": 6, "britain": [12, 13], "broader": 6, "brother": 17, "brought": 4, "brown": [8, 9], "bs4": 21, "bucket": 18, "buffer": [12, 13], "bui": 4, "build": [3, 7], "builder": 20, "built": [5, 7, 19], "busi": [4, 13, 20], "c": 21, "c0486029": 2, "c_v": 10, "calcul": [6, 9, 10, 17, 21, 22], "call": 6, "cambridg": 23, "can": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21], "cannot": 8, "capabl": [1, 3, 6, 9, 11, 15, 16, 18, 19, 22], "capit": 6, "captur": [2, 4, 5, 8, 12], "car": 6, "carbon": [6, 12, 13], "carbon_footprint_kg": 6, "cardin": 2, "care": [4, 5, 8, 9, 16, 17, 20], "carefulli": [5, 6, 8, 10, 14, 17, 21], "caregiv": 17, "carri": 8, "case": [8, 14], "cat": [4, 6, 9, 10, 18], "categor": [4, 9], "categori": [4, 5, 9, 12, 13, 14], "caus": [13, 16, 21], "caution": 17, "cc": 1, "cd7a": 2, "ce": 22, "ceci": 6, "cell": 2, "central": 21, "centuri": [12, 13], "ceo": [9, 14, 17], "certain": [6, 8, 21], "cett": 4, "chairman": 6, "challeng": [1, 3, 11, 13, 20, 21, 22, 23], "chamber": 22, "championship": [9, 13, 14], "chang": [2, 4, 5, 9, 10, 12, 13, 14, 16, 18, 20, 21, 22], "changer": 15, "chapter": 2, "charact": [2, 4, 10, 21], "character": [4, 10], "characterist": [8, 14, 18], "chase": [4, 9, 10], "chatbot": 4, "cheap": 13, "check": [5, 6, 8, 21, 22], "check_consist": 6, "check_domain_cred": 21, "check_for_pii": 6, "check_gender_bia": 5, "check_misinformation_ind": 21, "check_profession_gender_bia": 6, "child": 8, "children": [8, 16], "chines": 22, "chip": 2, "choic": [4, 5, 6, 8, 9, 12, 13, 14, 18, 21, 22], "chomski": 4, "choos": [9, 12, 14], "chunk": 20, "chunk_siz": 20, "citat": 21, "citi": [9, 14], "citizen": [6, 16], "civil": 13, "claim": 16, "clariti": 18, "class": [2, 4, 5, 12, 13, 14, 20, 22], "class_": 21, "class_nam": [6, 14, 22], "classif": [1, 4, 5, 21, 22], "classifi": [4, 5, 6, 9, 11, 12, 13, 14, 21, 22], "classification_report": [4, 9, 14, 21], "classify_text": [5, 21], "clean": [1, 2, 4, 7, 10, 23], "clean_html": 8, "clean_text": [2, 8], "cleaned_text": 8, "clear": [6, 12, 13], "clearer": 7, "clf": [4, 9, 21, 22], "climat": [9, 10, 12, 13, 20, 21, 22], "climb": 9, "close": [4, 13, 21], "closer": 22, "cloudi": 9, "club": 2, "cluster_docu": 9, "cnn": 4, "co2e": 6, "coaster": 18, "code": [2, 4, 5, 7, 12, 15, 17, 20, 23], "code_interview_respons": 4, "code_survey_respons": 12, "coded_data": 12, "coded_respons": 12, "coded_them": 12, "coding_schem": 4, "coher": [4, 5, 9, 10, 16], "coherence_model": 10, "coherence_scor": 10, "coherencemodel": 10, "colab": [2, 23], "cold": 18, "collabor": [4, 19, 21], "collect": [4, 6, 9, 10], "collect_tweet": 21, "collected_tweet": 21, "color": 13, "column": [2, 10], "com": [6, 8, 21], "combat": [19, 21], "combin": [4, 6, 9, 13, 14, 21, 22], "come": [1, 4, 7, 9, 11], "comfort": 9, "comma": [12, 13], "commerc": 2, "commissio": 2, "commit": [2, 13], "common": [2, 4, 8, 9, 10, 12, 17, 18, 21], "commun": [2, 4, 9, 13, 14, 15, 18], "commut": 22, "compani": [14, 17], "compar": [1, 8, 11, 17, 18, 23], "comparison": 18, "complet": [4, 6, 12, 13, 14, 17, 18, 20, 21, 22], "complex": [3, 6, 7, 8, 9, 13, 15, 17, 18, 19, 20, 21, 22, 23], "compon": [13, 20], "composit": 18, "compound": 9, "comprehens": [5, 9, 11, 13, 19, 21, 22], "comput": [9, 17, 20], "computation": 5, "compute_hour": 6, "compute_tim": 6, "conc": 2, "concept": [7, 12, 14, 15, 23], "concern": [3, 4, 9, 13, 16, 21], "concis": [9, 22], "conclus": [5, 10, 12], "condens": 5, "conduct": [17, 19], "confid": 6, "config": 2, "congress": 13, "conll03": 14, "connect": 13, "consciou": 4, "consent": [5, 17, 19], "consequ": [6, 9], "consid": [3, 4, 5, 6, 8, 10, 11, 13, 14, 16, 17, 18, 19, 21], "consider": [1, 3, 4, 8, 11, 20, 21, 22, 23], "consist": [4, 8, 12, 13, 23], "conspiraci": 21, "constantli": 1, "constrain": 16, "consum": [9, 11], "consumer_kei": [20, 21, 22], "consumer_secret": [20, 21, 22], "consumpt": 6, "contact": [2, 6], "contain": [1, 5, 6, 9, 18, 21, 22], "contemporari": [5, 6], "content": [2, 4, 5, 8, 9, 15, 22], "context": [1, 3, 6, 8, 9, 11, 12, 15, 16, 17, 21, 22, 23], "contextu": [4, 5, 9, 16, 18, 21], "continu": [4, 5, 6, 12, 13, 14, 16, 18, 20, 21, 22], "contradict": 16, "contribut": [5, 6, 8, 17, 19, 22], "controversi": 5, "convei": 18, "convert": [4, 8, 10, 21], "convolut": 4, "cook": [9, 14], "core": [2, 12], "corenlp": 4, "corenlppars": 4, "corpora": [2, 4, 9, 10, 12, 13, 20], "corpu": [2, 4, 8, 9, 10, 20, 21], "correct": [8, 16, 18], "correl": [10, 16], "correspond": 9, "cosin": 9, "cosine_similar": [9, 17, 22], "cost": [4, 6], "could": [4, 5, 6, 8, 11, 13], "couldn": 5, "count": [2, 6, 13, 20, 21], "counter": [6, 19, 20], "counti": 2, "countri": 5, "countvector": [2, 4, 8], "cours": [2, 3, 7, 11, 15, 19], "cov": 16, "cover": [3, 7, 11, 19, 23], "coverag": 13, "covid": [16, 21], "cpu": 20, "cpu_count": 20, "craft": [4, 17], "creat": [0, 2, 4, 5, 6, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "createdatafram": 20, "creativ": 16, "creator": 21, "credenti": [20, 21, 22], "crise": 19, "criteria": 18, "criterion": 18, "critic": [1, 3, 4, 6, 13, 17, 19, 21, 22, 23], "cross": [4, 10, 12, 18, 21], "crucial": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "cryptocurr": 22, "csv": 10, "cuda": 20, "cultur": [1, 9, 12, 13, 15, 17, 19, 21, 23], "cultural_context": 18, "curat": 6, "current": [5, 16, 19], "cursor": [20, 21], "curtain": 18, "custom": [9, 13], "cut": [1, 3, 19, 22, 23], "d": [6, 8, 10, 21, 23], "d_model": 5, "dai": [6, 12], "daili": [12, 16], "dall": 5, "danger": 21, "data": [1, 3, 8, 9, 12, 13, 14, 15, 17, 18, 19, 22], "data_fil": 2, "databas": 21, "datafram": [2, 10, 20], "dataload": [5, 20], "dataset": [1, 2, 6, 7, 8, 9, 12, 13, 14, 15, 16, 19, 23], "date": [2, 10, 12], "daughter": 17, "davinci": [4, 5, 6, 12, 13, 14, 18, 21, 22], "dbmdz": 14, "dc": 2, "deal": [6, 13, 15, 18, 20], "debat": [5, 10, 16], "debias": 17, "debiased_gener": 17, "debiased_prompt": 17, "debiased_result": 17, "debiasing_prefix": 17, "decad": 5, "decid": 8, "decis": [4, 5, 9, 11, 14], "decod": [16, 17], "deduc": 18, "deed5268": 2, "deep": [3, 10, 16], "deepen": 1, "deeper": [4, 5, 18, 19, 20], "def": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "degre": 21, "degree_c": 21, "degree_centr": 21, "delici": 13, "delv": [5, 7, 15, 19], "demograph": [4, 16, 22], "demographic_group": 4, "demoj": 8, "demonstr": [4, 5, 6, 9, 10, 12, 13, 23], "dens": [4, 8], "depart": 2, "depend": [4, 5, 8, 16, 18, 21], "deploy": 17, "depth": 15, "depu": 2, "deputi": 2, "describ": [4, 6, 13], "descript": [5, 6, 12, 13], "design": [1, 3, 5, 6, 12, 19, 23], "desir": 13, "despit": [4, 5], "detach": 17, "detail": [6, 8, 13, 16], "detect": [1, 2, 10, 15, 19, 20, 23], "detect_and_explain_metaphor": 18, "detect_bia": 6, "detect_misinform": 21, "detect_sarcasm": 18, "detected_term": 6, "determin": [9, 10, 13, 18], "develop": [1, 5, 6, 10, 13, 17, 19, 21, 22], "devic": 20, "df": [10, 20], "diagnosi": 14, "diagnost": 13, "diagram": 10, "dialogu": [6, 16], "dict": 2, "dictionari": [9, 10, 20], "did": 13, "didn": 5, "dies": 22, "dieser": 4, "differ": [5, 6, 8, 9, 10, 12, 14, 15, 17], "difficult": [9, 10, 13, 18], "difficulti": 13, "digit": [2, 4, 20, 21], "dim": [4, 5, 17, 21], "dimens": [6, 8], "dimension": 4, "direct": [1, 14, 18, 19, 23], "dirichlet": [1, 7, 20, 23], "disadvantag": 6, "disappoint": [5, 14], "disclaim": 6, "disclos": 6, "discours": [4, 10, 16, 19, 22], "discov": [1, 9, 10, 21], "discoveri": [20, 21, 23], "discrimin": 13, "discriminatori": 6, "discuss": [3, 10, 11, 15, 19], "displai": 2, "distant": 9, "distort": 21, "distribut": [2, 6, 10, 20], "div": 21, "dive": [1, 19], "divers": [5, 8, 13, 15, 16, 18, 19, 20, 22], "do": [1, 4, 17, 20], "do_sampl": 17, "doc": [2, 4, 9, 10, 14, 20, 21], "doc2bow": [9, 10, 20], "doc_ent": 20, "doc_lda": 10, "doctor": [5, 17, 22], "document": [1, 2, 4, 10, 19, 20, 23], "doe": [2, 6, 13], "dog": [4, 8, 9, 10, 18], "dollar": 2, "domain": [4, 9, 10, 12, 13, 16, 21, 22], "domest": 13, "domin": [4, 10], "dominant_top": 10, "don": [3, 5, 8, 22], "dot": [5, 10, 17], "down": 18, "download": [2, 4, 8, 9, 10, 20, 22], "downstream": 8, "dr": 12, "draft": 23, "dramat": 4, "draw": [10, 21], "drawback": 8, "drive": 2, "driven": [4, 19, 23], "drug": 13, "dt": 4, "dtype": 2, "due": [4, 6, 13, 18, 20, 21, 22], "dure": [5, 8, 12, 13, 19], "dynam": [1, 6, 10, 19], "d\u00e9cision": 4, "e": [4, 5, 6, 8, 9, 10, 13, 14, 16, 21], "e4f565b189f7": 2, "each": [1, 4, 5, 8, 10, 13, 14, 23], "earli": [13, 20], "earn": 5, "earth": 21, "easier": 8, "easili": [8, 10, 13], "echo": 22, "econom": [4, 5, 10, 12, 13, 14], "economi": [12, 14], "ecstat": 21, "ed": 23, "edg": [1, 3, 19, 22, 23], "educ": 12, "effect": [1, 4, 5, 6, 7, 8, 11, 12, 13, 15, 16, 18, 20, 21, 22], "effici": [4, 7, 9, 11, 15, 20], "effort": 11, "eiffel": 21, "either": 21, "elabor": 4, "element": [8, 10], "elicit": 13, "elif": [6, 9, 22], "elimin": [4, 17], "eliza": 4, "eliza_respons": 4, "elon": 14, "els": [2, 4, 5, 6, 9, 18, 20, 21, 22], "email": 6, "email_pattern": 6, "embark": [1, 3, 19], "embed": [5, 10, 12, 22], "embed_s": 5, "embedding_dim": 5, "emerg": [1, 13, 19, 23], "emili": 17, "emiss": 12, "emot": [9, 10, 15, 18, 21], "emotion_analysi": 5, "emotion_summari": 16, "emotional_languag": 21, "emphas": [1, 3, 4, 18, 22], "emphasi": [18, 22], "emploi": [6, 17], "employe": 16, "empow": 13, "en": [6, 20, 21], "en_core_web_sm": [2, 9, 14, 20, 21], "enabl": [4, 5, 8, 15, 18, 22], "encapsul": 18, "encod": [4, 5, 12, 16, 17, 20], "encoded_data": 5, "encompass": [4, 9], "encount": 4, "encourag": [3, 11], "end": [1, 4, 7, 9, 11, 12, 13, 15, 16, 19, 23], "end_tim": 14, "energi": [2, 6, 12, 13], "energy_consumption_kwh": 6, "engag": [3, 22], "engin": [1, 4, 5, 6, 11, 14, 17, 18, 21, 22, 23], "english": [2, 4, 6, 8, 9, 10, 14, 18, 20, 21, 22], "enhanc": [4, 7, 10, 11, 12, 13, 15, 19, 20, 22], "enjoi": 4, "enorm": 5, "ensembl": [14, 21], "ensur": [3, 8, 11, 15, 17, 19, 22], "ent": [2, 9, 14, 20, 21], "ent1": 21, "ent2": 21, "entir": [6, 13, 15], "entiti": [5, 8, 21], "entity_count": 20, "entity_typ": [12, 13], "entitytyp": [12, 13], "entri": 2, "enumer": [4, 6, 9], "environ": [2, 12, 18], "environment": [4, 12, 14, 22], "epoch": [5, 20], "equal": [6, 7, 17], "equip": [1, 8, 15, 19], "equit": 17, "equival": [6, 18], "era": [4, 18, 19], "error": [6, 14, 21], "espa\u00f1ol": 6, "especi": [6, 7, 8, 15], "essenti": [7, 18, 20], "est": [4, 6], "estim": 6, "estimate_carbon_footprint": 6, "esto": 6, "et": 16, "ethic": [1, 3, 4, 11, 16, 20, 21, 23], "eu": 6, "europ": [12, 13], "evalu": [1, 19, 20, 21, 23], "evaluate_generated_text": 16, "evaluate_perform": 14, "evaluate_scal": 14, "even": [3, 5, 6, 7, 12, 15, 16, 18], "event": [6, 8], "ever": 4, "everi": 12, "evolut": [1, 3, 19, 23], "evolv": [4, 5, 6, 10, 12, 13, 14, 17, 18, 19, 21, 22], "ex_answ": 13, "ex_context": 13, "ex_quest": 13, "exacerb": 6, "exagger": 18, "examin": [15, 17, 20, 21], "exampl": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22], "excel": [13, 15], "except": 21, "excit": [1, 3, 6, 18, 19, 22], "exclus": 9, "exercis": [15, 23], "exhibit": [4, 10, 21], "exist": [5, 6], "exp": [5, 6, 14, 22], "expand": 5, "expect": [12, 13, 16, 17, 18], "experi": [1, 4, 5, 7, 8, 10, 18], "experiment": 10, "expert": [4, 13, 14, 23], "expertis": [4, 10, 18], "explain": [5, 15, 16, 18], "explain_figurative_languag": 18, "explain_idiom": 18, "explain_inst": [6, 14, 22], "explain_llm_predict": 14, "explain_misinform": 16, "explain_traditional_predict": 14, "explan": [1, 4, 5, 6, 14, 20, 21, 22], "explanatori": 6, "explicit": 17, "explicitli": [4, 12, 18], "explor": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 23], "exploratori": 12, "express": [5, 8, 9, 12, 15, 16, 18, 21], "extend": [13, 20], "extens": [2, 5], "extract": [2, 15, 19, 23], "extract_ent": 2, "f": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "f1": [9, 14, 16], "fabric": [6, 21], "face": [4, 14, 16, 18], "facebook": [20, 21], "facil": 2, "facilit": 5, "fact": 21, "factor": [4, 5, 14], "factual": [4, 15, 16, 21], "fail": 4, "fair": [4, 17, 22], "fake": [1, 19, 23], "fals": [16, 19, 20, 21, 22], "familiar": 23, "fantast": 4, "far": 6, "fascin": 1, "faster": 13, "father": 17, "favor": 6, "fc": 5, "fear": [12, 18], "featur": [2, 6, 9, 14, 20, 21, 22], "feature_extract": [2, 4, 6, 8, 9, 14, 21, 22], "feature_nam": [2, 4, 8], "feder": 2, "feedback": 9, "femal": [17, 22], "female_assoc": 17, "female_associ": 17, "female_prob": 17, "female_prompt": 17, "female_sim": 22, "female_term": 17, "female_vec": 22, "few": [1, 11, 12, 14, 21, 22, 23], "few_shot_aspect_senti": 13, "few_shot_classif": [13, 14], "few_shot_multi_label_classif": 13, "few_shot_n": 13, "few_shot_qa": 13, "few_shot_summar": 13, "fewer": 5, "field": [1, 3, 4, 5, 6, 12, 13, 14, 16, 17, 19, 21, 22], "figsiz": 2, "figur": [1, 2, 15, 23], "file": [2, 4, 10], "film": 4, "filter": [20, 22], "filtered_text": 8, "final": [1, 5, 7, 13, 19, 23], "financ": 9, "financi": [2, 4, 20], "find": [2, 4, 6, 8, 15, 16, 21, 22], "findal": [6, 14, 21], "fine": [4, 6, 12, 14, 16], "finetun": 14, "fireman": 6, "first": [2, 5, 8, 10, 20], "first_doc_vector": 2, "fit": [4, 6, 9, 14, 21, 22], "fit_resampl": 14, "fit_transform": [2, 4, 8, 9, 14, 21], "five": [1, 23], "flat": 21, "flatten": 20, "flaw": 6, "flexibl": [4, 16, 22], "float": 18, "flood": 16, "floor": 9, "flower": 9, "focu": [2, 4, 5, 10, 12, 15, 19, 22, 23], "focus": [4, 5, 7, 8, 16], "follow": [2, 4, 5, 12, 13, 14, 16, 18, 21, 22], "font_siz": 21, "font_weight": 21, "food": 13, "footprint": 6, "forefront": [4, 19, 22], "foreign": 5, "forest": [4, 14, 21], "form": [4, 7, 8, 9, 18], "formal": [4, 13], "format": [4, 8, 12, 13, 14, 16, 18], "formul": 5, "forward": [5, 8], "foster": 6, "found": [2, 16], "foundat": [2, 7, 9, 19, 20], "founder": 14, "fox": [8, 9], "frame": [2, 3, 5, 21], "framework": [20, 22], "franc": [6, 21], "fran\u00e7ai": 6, "frase": 6, "free": 4, "freedom": 21, "french": [4, 22], "freq": 2, "frequenc": [4, 9, 16], "frequent": [2, 18], "friendli": 4, "from": [1, 2, 3, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "from_pretrain": [4, 5, 16, 17, 20, 21], "full": [4, 9, 14, 19, 22], "fulli": 22, "function": [2, 4, 6, 10, 17, 18, 21], "fundament": [1, 2, 3, 7, 8, 11, 23], "furiou": 21, "further": [5, 6, 8, 12, 13], "futur": [1, 2, 14, 23], "fzqarj": 21, "g": [4, 5, 6, 8, 9, 10, 13, 14, 16, 21], "gain": [1, 3, 4, 9, 10, 12, 18, 19], "game": [9, 15], "gap": [1, 3, 4, 5, 13, 16], "garcia": 16, "gaug": [4, 9], "gdp": 13, "gdpr": 6, "gender": [4, 5, 6, 22], "gender_association_test": 17, "gender_bias_check": 22, "gendered_pronoun": 6, "gener": [1, 3, 9, 10, 17, 18, 20, 21], "generate_complet": 17, "generate_llm_disclaim": 6, "generate_research_hypothesi": [5, 16], "generate_research_quest": 5, "generate_survey_respons": 16, "generate_text": [4, 16], "generate_text_llm": 14, "generate_text_tradit": 14, "generate_text_with_param": 16, "generated_text": [4, 14, 16], "gensim": [4, 7, 8, 10, 20, 22, 23], "genuin": 21, "german": [4, 22], "germani": 13, "get": [2, 4, 5, 9, 10, 18, 21], "get_coher": 10, "get_dominant_top": 10, "get_embed": 17, "get_feature_names_out": [2, 4, 8], "get_scor": 16, "get_senti": [2, 10], "get_word_embed": 8, "get_word_freq": 2, "getorcr": 20, "gf": 18, "gibb": 10, "gigaword": [8, 22], "girl": [17, 22], "given": [6, 9, 10, 13], "global": [4, 13, 19], "glove": [4, 8, 22], "go": [5, 9], "goal": [3, 4, 8, 9], "good": [5, 6, 13, 22], "googl": [2, 23], "govern": [12, 13, 19, 20], "gpe": [2, 21], "gpt": [4, 6, 12, 13, 14, 18, 21, 22], "gpt2": [16, 17], "gpt2lmheadmodel": [16, 17], "gpt2token": [16, 17], "gpt3_complet": 5, "gpu": 6, "grain": 12, "gram": 4, "grammar": 4, "grammat": [4, 9], "grant": 5, "graph": 21, "grasp": [4, 5, 11], "great": [1, 4, 5, 12, 13, 18, 21], "greater": 22, "green": 13, "grew": 4, "grid": 6, "grid_carbon_intens": 6, "gross": 13, "groundbreak": 12, "group": [4, 6, 8, 9, 17], "groupbi": 10, "grow": [3, 14, 20, 22], "growth": 4, "guest": 23, "guid": [9, 17, 18], "guidelin": [1, 6], "h": [2, 23], "ha": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22], "habit": 4, "had": [3, 22], "hallucin": 4, "hammer": 18, "hand": [1, 4, 7, 15], "handl": [10, 12, 13, 14, 16, 18, 20, 21, 22], "hanoi": 2, "har": [1, 3, 4, 6], "hard": 5, "hardwar": 14, "harm": 6, "harri": 2, "harvard": 12, "hasattr": 22, "hate": 4, "have": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 18, 19, 20, 21, 22], "haven": 12, "he": [5, 6, 17], "head": 2, "headlin": 21, "health": [13, 16, 20, 22], "healthcar": [12, 13], "heapq": 9, "hear": 2, "heartbroken": 21, "heat": 16, "heavi": 13, "hello": 4, "help": [4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 22], "her": 6, "here": [1, 4, 5, 6, 8, 9, 12, 13, 14, 16, 17, 18, 20, 21], "hesit": 3, "hi": 6, "hidden": [4, 10, 15, 19, 21], "hidden_layer_s": 22, "hidden_s": 5, "hierarch": [4, 10], "hierarchi": 10, "high": [1, 4, 6, 14, 15, 18, 23], "higher": [10, 23], "highli": [4, 18], "highlight": 16, "hill": 4, "him": 6, "hint": 2, "hist": 2, "histor": [1, 5, 6, 9, 10, 18, 20], "histori": 12, "hoax": 21, "hold": [2, 4], "home": 2, "hop": 13, "hour": 6, "hovi": 23, "how": [1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 23], "howev": [1, 4, 5, 7, 8, 11, 12, 13, 16, 17, 18, 22], "html": [2, 10, 21, 22], "html_text": 8, "http": [2, 4, 8, 21], "hug": [14, 16], "human": [1, 4, 6, 9, 10, 11, 13, 14, 18], "human_evalu": 18, "hundr": [2, 5], "hybrid": 14, "hyfi": 2, "hyperbol": 18, "hypothes": [4, 5, 15, 16, 20], "hypothesi": [5, 16], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "ian": 2, "ianbrickeysierraclub": 2, "ich": 22, "id": 20, "id2word": [9, 10, 20], "idea": [5, 12, 15, 18], "ident": 6, "identifi": [4, 5, 6, 9, 10, 12, 13, 18, 19, 20, 21], "idf": [2, 4, 9, 21], "idiom": 15, "idiomat": 5, "idx": [9, 10, 20], "ignorecas": 21, "illustr": [5, 7, 16], "iloc": 2, "imag": [4, 5, 21, 22], "image_classifi": 22, "image_cont": 22, "image_path": 22, "image_result": 22, "image_scor": 22, "imagin": 20, "imbalanc": 14, "imblearn": 14, "impact": [3, 5, 8, 9, 13, 14, 16, 17, 18, 19, 21, 22], "imperson": 21, "implement": [5, 6, 7, 9, 13, 16, 17, 18, 19, 20, 23], "impli": 4, "implic": [3, 4, 5, 15, 16, 17, 18, 19, 21], "import": [2, 3, 5, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "impos": 13, "imposs": 5, "impost": 21, "impract": 5, "impress": 18, "improv": [4, 8, 10, 13, 15, 18, 22], "inaccess": 20, "inadvert": 6, "inc": [9, 13, 14], "includ": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22], "inclus": 22, "inconsist": [13, 21], "incorpor": [6, 10, 13, 16], "incorrect": [5, 6], "increas": [2, 4, 5, 6, 13, 22], "increasingli": [4, 20, 21, 22], "incredibli": 16, "independ": [9, 16], "indic": [10, 17, 21], "individu": [4, 6, 17, 18, 21], "industri": [2, 4, 5, 12, 13], "inequ": 6, "infeas": [4, 8], "infer": [1, 10, 14, 15, 23], "influenc": [4, 6, 12, 18, 22], "info": [2, 8], "inform": [1, 2, 8, 9, 11, 15, 16, 17, 19, 21, 22], "inher": 4, "initi": [2, 5, 20], "innov": [13, 19], "input": [4, 5, 6, 13, 16, 17, 18, 20, 21], "input_data": 14, "input_id": [5, 17, 20], "input_text": 4, "inputcol": 20, "insight": [3, 4, 5, 7, 9, 10, 15, 18, 19, 20, 23], "instanc": 4, "instant": [13, 22], "institut": [4, 6], "instruct": 12, "int64": 2, "integr": [4, 15, 22], "intellig": [4, 5, 9], "intens": [5, 6, 16], "inter": 9, "interact": [4, 9, 13, 18, 21, 22], "interdisciplinari": [4, 19, 21], "interest": [3, 11], "interfer": 8, "intern": [5, 6], "internet": 18, "interpret": [3, 4, 7, 12, 15, 17], "interpret_internet_slang": 18, "intersect": [1, 3], "intersection": 5, "interview": [4, 5, 16], "introduc": [4, 6, 8, 23], "introduct": 1, "introductori": 3, "intuit": 10, "invers": 4, "invest": [5, 13], "investig": [6, 19], "involv": [4, 5, 8, 9, 14, 15, 17, 21, 22], "iphon": 13, "iron": 18, "ironi": [4, 9], "irrelev": [4, 8], "is_avail": 20, "is_colab": 2, "isalpha": [4, 9, 20], "isn": 3, "isol": 22, "issu": [3, 4, 5, 9, 12, 17, 19, 20, 21, 22], "item": [2, 4, 5, 13, 17, 20, 21], "iter": 5, "its": [1, 3, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23], "j": [4, 22, 23], "jamal": 17, "jane": [12, 13], "japanes": 18, "jeff": 14, "job": [4, 12, 16], "joblib": 2, "john": [6, 13], "johndo": 6, "johnson": [13, 16], "joi": 12, "join": [2, 4, 5, 6, 8, 9, 12, 13, 14, 16, 21], "journal": 12, "journei": [1, 3], "jpg": 22, "json": [2, 14], "jsonl": 2, "judgment": 18, "judici": 16, "jump": [8, 9], "jupyt": 23, "jurafski": 23, "just": [3, 8, 18], "k": [9, 10, 13, 16, 20], "kb": 2, "keep": [1, 18], "keepdim": 5, "kei": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23], "key_pap": 16, "kg": 6, "kick": 18, "kim": 2, "kimpettysi": 2, "kind": 10, "king": [4, 22], "kmean": 9, "knowledg": [1, 4, 9, 12, 13, 19], "known": 5, "korea": 2, "kwh": 6, "l": 16, "label": [2, 4, 5, 9, 12, 13, 14, 20, 21, 22], "label_": [2, 9, 14, 20, 21], "labels_": 9, "lack": 21, "lack_of_sourc": 21, "lakisha": 17, "lambda": [2, 10, 14], "landscap": 4, "lang": [6, 20, 21], "lang_count": 6, "langid": 6, "languag": [1, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23], "larg": [1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23], "large_dataset": 20, "larger": 15, "largescaletextprocess": 20, "last": [12, 13], "last_hidden_st": 17, "late": [12, 13], "latent": [1, 4, 7, 20, 23], "later": 7, "latest": [5, 17], "law": [2, 13, 14], "lazi": [8, 9], "lda": [1, 7, 20, 23], "lda_model": [9, 10, 20], "lda_result": 10, "lda_visu": 10, "ldamodel": [9, 10], "ldamulticor": 20, "lead": [4, 6, 8, 12, 13, 19, 20], "leap": 5, "learn": [1, 2, 3, 7, 8, 9, 10, 11, 15, 19, 22, 23], "lectur": 23, "led": 5, "lee": [2, 16], "leezieschesierraclub": 2, "legal": [6, 9], "lemmat": [2, 4, 10, 21], "lemmatize_token": 2, "lemmatize_word": 8, "lemmatized_text": 8, "lemmatized_token": 4, "len": [6, 10, 17, 20, 21], "less": [6, 9, 13], "let": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 20, 21], "level": [4, 13, 20], "leverag": [1, 3, 5, 7, 11, 12, 13, 15, 16, 18, 19, 20, 22, 23], "lexic": 4, "li": [9, 20], "librari": [1, 6, 7, 9, 10, 16, 20, 23], "lieb": 22, "life": [6, 12, 16, 18, 22], "lifetim": 6, "lightblu": 21, "like": [4, 6, 7, 8, 9, 10, 13, 16, 17, 18, 19, 20, 21, 22], "lime": [6, 14, 22], "lime_text": [6, 14, 22], "limetextexplain": [6, 14, 22], "limit": [1, 3, 4, 6, 11, 13, 14, 19, 22, 23], "linalg": 17, "line": [4, 10], "linear": 5, "linear_model": 14, "linesent": 4, "lingual": [4, 10], "linguist": [4, 8, 9, 21], "link": 18, "list": [12, 13, 20, 21], "listen": 22, "liter": [4, 18], "literatur": [4, 5, 15, 16, 22], "literature_review_synthesi": 16, "live": [16, 21, 22], "ll": [1, 2, 3, 5, 7, 8, 9, 10, 11], "llm": [1, 3, 7, 15, 20, 22], "llm_bleu": 14, "llm_entiti": 14, "llm_explan": 14, "llm_gener": 14, "llm_ner": 14, "llm_perform": 14, "llm_predict": 14, "llm_relat": 14, "llm_relation_extract": 14, "llm_sent": 14, "llm_sentiment": 14, "llm_sentiment_analysi": 5, "llm_time": 14, "load": [4, 5, 8, 9, 14, 16, 20, 21, 22], "load_dataset": 2, "local": [4, 9, 13], "localhost": 4, "locat": [9, 13, 21], "logging_level": 2, "logist": [4, 14], "logisticregress": 14, "logit": [4, 5, 17, 21], "lone": 2, "long": [4, 5, 7, 9, 12, 13, 16], "long_text": 12, "longer": 9, "look": [4, 5, 12, 16, 19, 20], "loss": [5, 8, 20], "lotteri": 12, "love": [4, 5, 8, 9, 12, 14, 22], "low": [9, 13, 18, 22], "lower": [2, 4, 5, 6, 8, 9, 10, 20, 21], "lowercas": [4, 10, 21], "lowercased_text": 8, "loyal": 9, "lr": 5, "lstm": 4, "lyndon": 13, "m": [2, 4, 5, 10, 14], "machin": [4, 8, 9, 10, 12, 13], "made": [1, 3, 8], "mai": [2, 5, 6, 8, 9, 10, 13, 14, 18, 20, 22], "main": [2, 7, 10, 11, 12, 16, 19], "maintain": [4, 5, 6, 15, 19], "major": [12, 13], "make": [4, 5, 8, 9, 11, 12, 13, 14, 21, 22], "make_pipelin": [6, 22], "male": [17, 22], "male_assoc": 17, "male_associ": 17, "male_prob": 17, "male_prompt": 17, "male_sim": 22, "male_term": 17, "male_vec": 22, "man": [4, 17, 22], "manag": 8, "mani": [4, 5, 7, 8, 9, 11, 14, 18, 21], "manifest": 17, "manin": 2, "manipul": [5, 21], "mankind": 6, "manual": [4, 8, 9, 10], "map": 20, "mark": [9, 12], "market": [4, 9, 12, 13, 14], "markov": 4, "martin": 23, "mask": 5, "massiv": [4, 12, 19], "master": [7, 8, 9, 19], "mat": [4, 9, 10], "match": [4, 13, 14], "materi": 6, "matplotlib": [2, 21], "matrix": 9, "max": 10, "max_featur": 2, "max_it": 22, "max_length": [4, 5, 14, 16, 17, 20, 21], "max_token": [4, 5, 6, 12, 13, 14, 18, 21, 22], "max_word": [12, 13], "me": [2, 4], "mean": [2, 4, 5, 8, 9, 10, 14, 17, 18, 22], "meaning": [7, 8, 10, 15, 19, 20], "meaningless": 18, "measur": [6, 9, 13, 21], "measure_inference_tim": 14, "mechan": 4, "media": [1, 2, 4, 5, 6, 8, 9, 10, 13, 14, 15, 16, 19, 20, 21, 22], "medic": [9, 14, 20], "meet": [2, 18], "megan": 2, "meganwittmansierra": 2, "meme": 18, "memor": 6, "memori": [2, 4], "men": 5, "mental": [13, 16, 22], "mention": 2, "messi": 8, "metaphor": 15, "method": [1, 2, 4, 6, 7, 8, 9, 10, 11, 14, 16, 17, 21, 23], "methodologi": [1, 3, 4, 12, 19, 22], "metric": [4, 9, 10, 16, 17, 21, 22], "microchip": 21, "midterm": 23, "might": [3, 4, 5, 6, 8, 9, 10, 11, 13, 16, 18], "million": [2, 20], "min": 22, "min_count": 4, "mind": [1, 6], "mine": 4, "minim": [5, 13, 16], "misinform": [1, 13, 19, 22, 23], "misinformation_top": 21, "mislead": [6, 21], "mismatch": 21, "misrepres": 6, "misus": 5, "mitig": [4, 15, 22], "mix": 13, "mixtur": 10, "ml": [13, 20, 21], "mlpclassifi": 22, "modal": 22, "model": [1, 3, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23], "model_nam": [4, 5, 6, 8, 17, 20, 21], "model_output": 18, "model_select": [4, 9, 14, 21], "modern": [1, 3, 23], "modul": 5, "moham": 17, "monei": 2, "monitor": 22, "month": [5, 9, 12, 14], "more": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 20, 21, 22], "moreov": 9, "most": [2, 4, 8, 10, 12, 13], "most_common": 6, "most_similar": 4, "mother": 17, "mount_google_dr": 2, "move": [1, 8], "movi": [4, 6, 8, 22], "mp": 20, "mse": 14, "much": [3, 8], "multi": [2, 12, 13, 20], "multidisciplinari": 21, "multilingu": [4, 21], "multilingual_senti": 22, "multimod": [4, 5, 21], "multinomi": 10, "multinomialnb": [4, 6, 9, 22], "multipl": [4, 5, 6, 9, 10, 15, 20, 22], "multiprocess": 20, "musk": 14, "must": [2, 4, 5, 6, 17, 21], "mutual": 9, "my": [4, 5, 12], "mydriv": 2, "mystream": 22, "mystreamlisten": 22, "mywot": 21, "n": [2, 4, 5, 6, 9, 10, 12, 13, 14, 18, 21, 22], "n_cluster": 9, "n_estim": 21, "n_run": 14, "n_sampl": 14, "n_test": 13, "nada": 2, "nail": 18, "naiv": [4, 9], "naive_bay": [4, 6, 9, 22], "nall": 6, "name": [4, 5, 8, 17, 21], "name_senti": 17, "name_sentiment_analysi": 17, "nanswer": 13, "nation": 13, "natur": [1, 3, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23], "navig": 6, "ncategori": [4, 12, 13, 14], "ncontact": 2, "necessari": [2, 7, 9], "need": [2, 4, 5, 8, 10, 12, 13, 20, 22], "neg": [4, 5, 6, 9, 12, 13, 14, 16, 22], "nentiti": 13, "ner": 20, "ner_pipelin": 14, "network": [4, 5, 16, 22], "networkx": 21, "neural": [4, 5, 10, 22], "neural_network": 22, "neuro_symbolic_analysi": 22, "neutral": [4, 5, 6, 9, 12, 13, 14, 17, 22], "never": 12, "new": [1, 3, 5, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 22, 23], "newer": 5, "next": [4, 5, 9, 14], "next_word": 14, "next_word_vec": 14, "ngener": 6, "nhead": 5, "nian": 2, "nice": 14, "nkim": 2, "nking": 4, "nlargest": 9, "nlee": 2, "nllm": 5, "nlp": [1, 8, 14, 18, 19, 20, 21], "nlp4ss": 2, "nlptown": [4, 22], "nltk": [2, 4, 7, 8, 10, 14, 20, 21, 23], "nltk_data": 2, "nmegan": 2, "nn": [4, 5, 21], "nnote": 6, "no_grad": [4, 5], "no_repeat_ngram_s": 16, "noam": 4, "node_color": 21, "node_s": 21, "nois": [4, 8], "non": [2, 4, 9, 18, 20], "none": [2, 4, 5, 6, 12, 13, 14, 18, 21, 22], "nonstandard": 9, "norm": [17, 19], "normal": [1, 2, 7, 20, 23], "north": [12, 13], "notabl": 6, "notat": 10, "note": [4, 16], "notebook": [2, 23], "noth": 4, "notic": 4, "noun": 9, "novel": [4, 12, 13], "now": [2, 3, 4, 5, 12, 19], "np": [4, 5, 14, 17, 22], "nquestion": 13, "nrespons": 6, "nsampl": 2, "nsentiment": [13, 14], "nsimilar": 9, "nsummari": 13, "ntext": [4, 12, 13, 14], "ntopic": 10, "nuanc": [4, 5, 8, 9, 15, 18], "null": 2, "num": 8, "num_clust": 9, "num_featur": [6, 14, 22], "num_label": [4, 5, 20, 21], "num_permut": 17, "num_process": 20, "num_quest": 5, "num_return_sequ": [16, 17], "num_run": 6, "num_sent": 9, "num_top": [9, 10, 20], "number": [5, 6, 10, 13, 14], "numer": [4, 8], "numpi": [5, 14, 17, 22], "nurs": [6, 17, 22], "nwarn": 6, "nx": 21, "oauthhandl": [20, 21, 22], "object": [2, 20], "obscur": 8, "observ": [10, 17], "observed_scor": 17, "obviou": 6, "occ": 22, "occup": [17, 22], "occur": [4, 9, 10, 17], "off": 14, "offens": 18, "offer": [1, 4, 5, 6, 7, 11, 12, 14, 15, 16, 18, 19, 20], "offic": 18, "often": [4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 18, 21], "oh": 18, "okai": 4, "old": 16, "omiss": 6, "on_error": 22, "on_statu": 22, "onc": 4, "one": [4, 5, 6, 8, 10, 12, 13, 14, 18, 20], "ongo": [5, 6, 10], "onli": [1, 4, 5, 6, 13, 19, 20], "onlin": [4, 9, 20, 21, 22, 23], "open": [1, 4, 5, 9, 11, 12, 14, 16, 22], "openai": [4, 5, 6, 12, 13, 14, 18, 21, 22], "opinion": [4, 6, 9, 19, 21], "opportun": [1, 3, 20], "optim": [5, 10, 11, 20], "option": 18, "oregon": 2, "org": [2, 21], "organ": [9, 10, 12, 13, 21], "origin": [4, 13, 17], "other": [6, 9, 12, 13, 15, 16], "our": [1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 15, 19, 20, 21, 22], "out": [8, 18], "outcom": [17, 19], "outdat": 6, "outperform": [13, 18], "output": [4, 5, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21], "outputcol": 20, "over": [2, 6, 8, 9, 10, 13, 16, 19], "over_sampl": 14, "overal": [5, 14, 18], "overall_scor": 18, "overload": 19, "overpr": 13, "oversight": 6, "overst": 8, "overview": [3, 23], "overwhelm": 5, "own": [3, 4, 11, 22], "ownership": 6, "p": [8, 16, 17], "p_valu": 17, "packag": 2, "pad": [4, 5, 20, 21], "page": 2, "page_url": 2, "pairwis": [9, 22], "panda": [2, 10, 20], "pandem": [4, 16], "paper": [5, 12, 15, 16, 23], "paradigm": [12, 13, 14], "paragraph": 5, "parallel": 5, "parallel_preprocess": 20, "paramet": [5, 10, 13, 22], "paramount": 6, "paraphras": 16, "parent": 16, "park": 18, "pars": [4, 20], "parser": [4, 21], "part": [4, 12, 22], "partial": 5, "particip": [5, 6], "particular": [5, 6, 9, 13], "particularli": [1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 16, 18, 21], "passion": 16, "pattern": [4, 5, 6, 8, 9, 10, 13, 14, 18, 19, 20, 21], "pd": [10, 20], "penalti": 13, "peopl": [8, 9, 21], "per": [4, 9, 10, 13, 14], "percent": 2, "perform": [1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 18, 23], "perform_n": 9, "period": 13, "perm_scor": 17, "perm_target1": 17, "perm_target2": 17, "permut": 17, "permutation_scor": 17, "perpetu": [5, 6, 18], "perplex": 14, "persist": 5, "person": [2, 4, 9, 12, 13, 14], "personif": 18, "perspect": 6, "pet": 9, "petti": 2, "phase": 5, "phd": 2, "phenomena": [1, 4, 5, 13, 15, 17, 18, 19, 20], "phenomenon": 21, "phone": 6, "phone_pattern": 6, "phrase": [6, 18], "piec": 9, "pii": 6, "pil": 22, "pip": 2, "pipe": 20, "pipelin": [6, 8, 14, 20, 22], "place": [8, 13, 22], "placehold": 8, "plai": [8, 9, 18], "plan": [9, 14], "planet": [9, 13], "plate": 10, "platform": [18, 20, 21], "plausibl": [5, 6], "pleas": 1, "plot": [2, 4, 10, 14], "plt": [2, 14, 21], "po": [4, 21], "point": [3, 5, 8, 11, 12], "polar": [2, 5, 10, 14, 16, 22], "polarity_scor": 9, "policeman": 6, "polici": [2, 4, 5, 6, 9, 10, 12, 13, 14, 16], "polit": [4, 5, 9, 10, 12, 13, 14, 16, 19, 21, 22], "politifact": 21, "pool": 20, "poorli": [9, 10], "popul": [6, 20], "popular": [7, 9, 10], "porterstemm": [2, 4, 8], "pos_tag": [4, 9], "pos_tag_text": 9, "pose": [3, 21], "posit": [4, 5, 6, 9, 10, 12, 13, 14, 17, 19, 22], "possibl": [1, 5, 6, 7, 11, 12, 18, 19, 20], "possibli": 20, "post": [1, 4, 5, 6, 8, 9, 19], "potenti": [1, 4, 8, 9, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23], "power": [1, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 22], "power_usage_effect": 6, "pp": 4, "practic": [1, 5, 6, 7, 13, 17, 20], "pragmat": 4, "prais": 16, "pre": [3, 4, 10, 12, 13, 14, 16, 20, 21, 22], "precis": 14, "precision_recall_fscore_support": 14, "predefin": [9, 12], "predict": [4, 5, 6, 9, 12, 13, 14, 21, 22], "predict_proba": [6, 14, 22], "predicted_class": [4, 5, 21], "prefer": 14, "prefix": 17, "prejud": 17, "prepar": [5, 8, 9, 11], "preprocess": [1, 9, 10], "preprocess_chunk": 20, "preprocess_text": [2, 4, 10, 20, 21], "preprocessed_data": 20, "presenc": 10, "present": [5, 6, 15, 17, 18, 20], "preserv": [9, 22], "presid": [13, 14, 21], "press": [2, 12, 19, 23], "pretty_print": 4, "preval": 10, "prevent": 6, "previou": 13, "previous": [4, 5, 19, 20], "price": 13, "primari": [4, 5, 12], "primarili": [4, 6], "principl": [3, 12], "print": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "print_top": [9, 10, 20], "prior": 10, "privaci": [3, 4, 5, 13, 17, 19, 22], "prob": 10, "probabilist": [4, 10], "probabl": [4, 10, 17, 21], "probe": [4, 6], "probe_model_bia": 4, "problem": [4, 5, 10], "process": [1, 2, 3, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 19, 21, 23], "process_batch": 20, "processed_chunk": 20, "processed_cont": 2, "processed_doc": [9, 10, 20], "processed_text": [8, 10, 21], "processeddf": 20, "produc": [5, 6, 8, 13], "product": [5, 13, 14, 16, 22], "produit": 22, "produkt": 22, "profess": [5, 6, 17], "profound": 14, "program": [4, 9, 22, 23], "progress": [3, 4, 11, 16, 17, 19], "prohibit": 13, "project": [1, 2, 5, 8, 11, 19, 23], "project_dir": 2, "project_nam": 2, "project_root": 2, "project_workspace_dir": 2, "prolifer": 20, "promis": [14, 21], "prompt": [1, 4, 5, 6, 11, 14, 17, 18, 21, 22, 23], "prompt_vari": 13, "pronoun": 6, "propag": 21, "proper": 7, "properli": 6, "proport": 10, "propos": [4, 13, 23], "protect": 12, "protocol": [6, 18], "provid": [2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 18, 20, 21, 22], "psychotherapist": 4, "pt": [4, 5, 16, 17, 20, 21], "public": [4, 6, 9, 12, 13, 16, 19, 20, 21], "publish": 12, "punkt": [2, 4, 9, 10, 20], "purpos": [6, 9, 16], "push": [7, 19], "pyldavi": 10, "pyplot": [2, 21], "pyspark": 20, "python": [1, 2, 4, 5, 7, 23], "pytorch": [5, 23], "q": [20, 21], "qualit": [4, 6, 9, 10, 15], "qualiti": [1, 10, 13, 15, 23], "quantit": 10, "queen": 22, "queri": [5, 21], "question": [1, 2, 3, 4, 6, 8, 9, 10, 14, 15, 16, 19, 20, 23], "quick": [8, 9], "quickli": [4, 8, 9, 11, 12, 13], "quit": [4, 14], "r": [2, 4, 6, 8, 10, 14, 21], "race": [4, 13, 17], "racial": 6, "raimondo": 2, "rain": 18, "rais": [6, 13], "ralli": [4, 12], "randint": 5, "randn": 5, "random": [4, 5, 10, 13, 14, 17, 21], "random_st": [4, 9, 10, 14, 21], "randomforestclassifi": [14, 21], "rang": [3, 4, 5, 6, 9, 10, 12, 13, 14, 17, 20], "rangeindex": 2, "rapid": [4, 12, 13, 22], "rapidli": [5, 14, 17, 18, 19, 22], "rate": [2, 18, 21], "raw": [2, 4, 8, 14], "raw_data_fil": 2, "raw_pars": 4, "raw_text": 21, "rdata": 2, "rdata_df": 2, "re": [1, 2, 3, 4, 7, 8, 10, 14, 19, 21], "reach": [6, 14], "reaction": 16, "read": 13, "read_csv": 10, "readi": 19, "real": [1, 4, 12, 17, 21], "realist": 16, "realli": [4, 6, 22], "reason": [4, 7, 9, 14, 22], "recal": 14, "recap": 8, "receiv": 5, "recent": [1, 3, 7, 16, 21, 22], "recino": 2, "recogn": 17, "recognit": [5, 8, 21], "recommend": 4, "record": 20, "recurr": 4, "reddit": [20, 21], "redefin": 22, "reduc": [4, 5, 8, 12, 13, 22], "refer": [5, 9, 13, 14, 16, 17, 18, 20, 21], "referenc": 6, "reference_explan": 18, "reflect": [6, 17, 18], "reform": 13, "regardless": [7, 17], "region": 6, "regress": [4, 14], "regul": 2, "regular": [6, 8], "reinforc": [6, 17], "rel": 17, "relat": [2, 13, 16, 21, 22], "relationship": [4, 8, 10, 12, 14, 16], "releas": [1, 2, 14], "relev": [1, 4, 5, 7, 8, 10, 13, 14, 15, 16, 19, 23], "reli": [4, 21], "reliabl": 5, "religion": 13, "remain": [6, 7, 9, 18], "remark": [4, 18], "rememb": [3, 7, 8, 9, 10, 11, 19], "remot": [16, 22], "remov": [2, 4, 10, 20, 21], "remove_stopword": [2, 8], "remove_urls_email": 8, "renew": [12, 13], "renov": 21, "repeat": 10, "rephras": [4, 5], "replac": [9, 21, 22], "replace_emoji": 8, "report": 20, "repres": [4, 5, 6, 8, 10, 13, 19], "represent": [1, 4, 5, 6, 7, 9, 23], "reproduc": 19, "request": 21, "requir": [3, 4, 8, 10, 11, 13, 18, 21], "rescu": 6, "research": [1, 3, 7, 8, 9, 11, 13, 14, 15, 17, 18, 20], "reshap": 22, "resourc": [9, 13, 20, 22], "resp": 6, "respect": 15, "respond": 16, "respons": [1, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 21], "responsibli": [1, 4, 11], "result": [3, 4, 5, 7, 8, 9, 12, 13, 14, 17, 18, 20, 21, 22], "return": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "return_tensor": [4, 5, 16, 17, 20, 21], "retweeted_statu": 22, "reveal": [4, 8, 9], "revers": [2, 10], "review": [5, 6, 15, 16, 22], "revolut": [12, 13], "revolution": [4, 5, 11, 13, 16, 22], "revolutionari": [1, 3], "rewrit": 5, "rewrite_prompt": 5, "rf_model": 14, "rf_perform": 14, "rf_predict": 14, "rich": 18, "ride": 18, "right": [2, 12, 13], "rigor": 6, "rise": [9, 22], "river": 4, "rnn": 4, "roberta": 5, "robust": 6, "role": [6, 14, 18, 22], "roller": 18, "room": [5, 17], "root": [4, 8], "root_dir": 2, "rotat": 2, "roug": [14, 16], "rstrip": 4, "rule": [3, 4, 22], "rule_result": 22, "run": [2, 4, 5, 6, 8], "runner": 8, "sad": 12, "safeti": 2, "sai": [4, 21], "same": [6, 13], "sampl": [2, 4, 8, 9, 10, 14, 16], "sample_s": 14, "sample_text": [2, 8, 16], "samsung": 2, "sar": 16, "sarcasm": [4, 9], "sarcast": 18, "sat": [4, 9, 10], "satisfact": 16, "save": [4, 10, 21], "save_html": 10, "save_to_fil": 22, "saw": [4, 9, 12], "sc": 21, "scalabl": 4, "scale": [1, 3, 4, 8, 10, 19, 22, 23], "scari": 18, "scenario": [5, 9, 12, 13, 14, 16], "scheme": 4, "scienc": [1, 7, 8, 9, 11, 13, 14, 17, 18, 20, 21], "scientist": [1, 3, 9, 10, 11, 15, 17, 18, 20, 21, 22, 23], "scikit": [2, 4, 7, 9, 14], "scipi": 17, "scope": 6, "score": [2, 4, 5, 9, 10, 14, 16, 17, 18, 22], "scorecard": 21, "scrape": [6, 8], "scratch": 3, "scrutini": 5, "search": 21, "search_tweet": [20, 21], "second": [8, 14, 20], "secreta": 2, "section": [5, 10], "sector": 12, "secur": 6, "see": [1, 4], "seek": 1, "seen": [4, 9, 12], "select": [9, 13, 14, 20], "self": [4, 20, 22], "self_attent": 5, "semant": [8, 12, 21], "senat": 13, "sens": [5, 18], "sensation": 21, "sensational_titl": 21, "sensit": [6, 13, 15, 18], "sensitive_term": 6, "sent_token": [2, 8, 9], "sentenc": [4, 5, 6, 9, 18], "sentence_bleu": 14, "sentence_scor": 9, "sentiment": [4, 8, 10, 15, 16, 17, 18, 22], "sentiment_analyz": 20, "sentiment_by_top": 10, "sentiment_scor": [4, 22], "sentimentintensityanalyz": 9, "separ": [4, 12, 13], "sequenc": [4, 5], "sequence_length": 5, "sequenti": 4, "seri": 9, "server": 6, "server_power_kw": 6, "servic": [13, 14], "session": [1, 20], "set": [2, 4, 6, 8, 9, 10, 11, 20, 21], "set_access_token": [20, 21, 22], "setup": 23, "sever": [4, 5, 6, 7, 14, 16, 17, 18], "sex": 13, "shap": 6, "shape": 5, "share": [14, 21], "she": [5, 6, 17], "shift": 3, "shock": 21, "shop": 4, "short": [4, 10], "shot": [1, 11, 14, 21, 22, 23], "should": [4, 6, 9, 12, 13, 14, 16, 17, 18], "show": [2, 9, 10, 13, 14, 18, 20, 21], "shown": [17, 18, 21], "shuffl": [5, 17, 20], "sia": 9, "side": 16, "sierra": 2, "sierraclub": 2, "sign": [13, 14], "signific": [4, 5, 6, 9, 11, 12, 17, 21], "significantli": [4, 8, 13, 14, 15, 18, 20], "simil": 18, "similar": [4, 8, 17, 18, 22], "similar_word": 4, "similarity_matrix": 9, "simpl": [4, 5, 6, 9, 13, 14, 16, 18, 21, 22], "simple_preprocess": 20, "simple_senti": 5, "simplemaskedlanguagemodel": 5, "simplifi": [5, 6, 16, 20, 22], "simul": [4, 5, 16], "sinc": 4, "singl": [5, 6, 13], "sister": 17, "size": [8, 10, 14, 22], "skew": 6, "skill": [1, 7, 13, 19, 22, 23], "skip_special_token": [16, 17], "sklearn": [2, 4, 6, 8, 9, 14, 21, 22], "slang": [9, 18], "small": [9, 10, 13, 14], "smaller": [7, 8, 20], "smiling_face_with_heart_ey": 8, "smith": [12, 13, 16], "smote": 14, "snippet": 7, "snope": 21, "so": [1, 9, 17], "social": [1, 7, 8, 9, 11, 13, 14, 20, 21], "social_media_data": 10, "societ": [1, 4, 17, 19, 22], "societi": [4, 6, 14, 21, 22], "socioeconom": [4, 17], "sociologi": 8, "softmax": [4, 5, 17, 21], "solar": 9, "sole": 12, "solid": [7, 11, 15], "solv": 4, "some": [2, 5, 8, 9, 10, 12, 13, 16, 21], "sometim": 18, "son": 17, "sophist": [4, 5, 10, 12, 16, 17, 19, 20, 21], "sorri": 4, "sort": 2, "sound": [5, 6], "soup": 21, "sourc": [5, 15, 18, 19], "source_languag": 18, "south": 2, "space": [4, 20], "spacex": 14, "spaci": [2, 14, 20, 21, 23], "spam": 9, "spanish": 18, "spark": [16, 20], "sparksess": 20, "speak": 18, "speaker": 4, "special": [2, 4, 5, 9, 10, 21, 22], "specif": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23], "speech": [4, 18, 23], "speed": 14, "sphere": 21, "split": [4, 9, 12, 13, 14, 21], "spoken": 9, "sport": [4, 5, 9, 12, 13, 14], "spread": [12, 13, 16, 19, 22], "spring_layout": 21, "sql": 20, "sqrt": 5, "squar": 14, "ssn": 6, "ssn_pattern": 6, "stage": 4, "stai": [5, 17, 19, 22], "stand": 13, "standard": [4, 8], "standardize_numb": 8, "stanford": 4, "star": 2, "start": [13, 17, 22], "start_tim": 14, "stat": 17, "state": 1, "statement": [2, 18], "statist": [6, 9, 10, 17, 23], "statu": [4, 17, 22], "status_cod": 22, "stem": [2, 4, 10, 21], "stem_token": 2, "stem_word": 8, "stemmed_text": 8, "stemmed_token": 4, "stemmer": [2, 4], "step": [2, 4, 5, 7, 8, 14, 16, 20], "stereotyp": [6, 17], "stewardess": 6, "stick": 18, "still": [5, 14], "stock": [4, 9, 12, 13, 14], "stop": [4, 5, 6, 9, 12, 13, 14, 18, 20, 21, 22], "stop_word": [2, 4, 8, 9, 10, 20, 21], "stopword": [2, 4, 8, 9, 10, 20, 21], "stopwordsremov": 20, "store": [4, 9, 14], "strategi": [4, 5, 19], "stream": 22, "streamlisten": 22, "street": 5, "strength": [4, 11, 14], "strip": [4, 5, 6, 12, 13, 14, 18, 21, 22], "strive": 6, "strong": [6, 7, 16, 19], "structur": [4, 9, 10, 16, 20, 21], "struggl": [4, 6, 18], "stuck": 6, "student": 23, "studi": [4, 5, 6, 9, 12, 13, 16, 19, 20, 21, 22, 23], "sub": [2, 8, 10, 21], "subfield": 9, "subject": 18, "sublist": 20, "submit": 2, "substitut": 4, "subtl": 20, "subword": 4, "success": [4, 13], "suggest": [15, 18], "suitabl": [8, 9], "sum": [5, 17], "summar": [4, 15, 20, 22], "summari": [1, 6, 9, 12, 13, 16, 20], "summarize_text": 9, "summary_sent": 9, "super": 5, "superior": 14, "supervis": [1, 11, 13, 23], "support": [4, 9, 13], "sure": 4, "surpris": 12, "surround": 5, "survei": [4, 8, 9, 10, 12, 15, 16], "survey_respons": 12, "sven": 17, "svm": [4, 14], "syllabu": 1, "syntact": 4, "synthes": [15, 16], "synthesi": 16, "synthet": [5, 16], "system": [3, 4, 5, 9, 12, 13, 14, 21, 22], "systemat": 17, "t": [3, 5, 6, 8, 10, 12, 17, 21, 22], "t5": 5, "tackl": [4, 8, 15, 18, 19], "tactic": 21, "tag": [2, 4], "tagged_text": 9, "tailor": 16, "takeawai": [4, 18, 20, 21], "target": 21, "target_languag": 18, "target_nam": 4, "target_set1": 17, "target_set2": 17, "task": [1, 3, 6, 7, 8, 11, 13, 18, 20, 22, 23], "taylor": 2, "teach": 1, "teacher": [17, 22], "team": [9, 13, 14], "tech": [4, 12], "technic": [8, 17], "techniqu": [1, 2, 3, 4, 5, 9, 11, 15, 16, 19], "technolog": 22, "technologi": [1, 4, 5, 9, 12, 13, 14, 16, 18, 19, 20, 22], "telescop": 4, "temperatur": [4, 5, 6, 12, 13, 14, 16, 18, 21, 22], "tend": 13, "tendenc": 6, "tension": 9, "tensor": [5, 20], "tensordataset": 5, "tensorflow": 23, "term": [2, 4, 6, 10, 13, 16, 17], "terribl": [4, 5, 9, 14], "tesla": 14, "test": [4, 13, 14], "test_result": 13, "test_siz": [4, 9, 14, 21], "texa": 2, "text": [1, 3, 10, 15, 17, 18, 19, 21, 22], "text_classifi": 22, "text_low": 6, "text_result": 22, "text_scor": 22, "text_senti": 22, "text_to_classifi": 13, "text_to_explain": [6, 22], "text_to_summar": 13, "textblob": [2, 10, 14, 22], "textdataset": 20, "textual": [1, 3, 4, 5, 8, 9, 11, 12, 15, 19, 23], "tf": [2, 4, 9, 21], "tfidf_matrix": [2, 4, 8, 9], "tfidf_represent": 8, "tfidf_vector": 2, "tfidfvector": [2, 4, 6, 8, 9, 14, 21, 22], "tfw": 18, "th": 10, "than": [2, 4, 9, 12, 13], "thei": [3, 4, 5, 8, 9, 11, 12, 13, 16, 17, 18, 19], "them": [4, 5, 8, 9, 11, 12, 13, 15, 18], "theme": [2, 4, 9, 10, 12], "themselv": [9, 17], "theori": [4, 21], "therefor": 8, "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23], "thing": 18, "think": [1, 3, 11, 12, 22], "third": [2, 8, 20], "thorough": 7, "those": [1, 3], "thoughtfulli": 10, "thousand": 4, "three": [1, 2, 3, 7, 11, 15, 19], "thrill": [5, 13, 18], "through": [1, 4, 6, 8, 10, 11, 12, 17, 19, 21], "throughout": [1, 3, 7, 11, 13, 15, 19], "thumbs_up": 8, "tight_layout": 2, "tiktok": 21, "tim": [9, 14], "time": [2, 4, 9, 10, 11, 13, 14, 19, 20], "timestamp": 2, "titl": [2, 14, 21], "to_lowercas": 8, "to_panda": 2, "toarrai": [2, 8], "todai": [4, 9, 12, 14, 22], "togeth": 9, "toi": 8, "token": [2, 4, 5, 9, 10, 16, 17, 20, 21], "tokenize_sent": 8, "tokenize_text": 2, "tokenize_word": 8, "tone": [9, 10], "too": 5, "took": 8, "tool": [1, 3, 4, 5, 7, 9, 10, 11, 15, 16, 18, 19, 20], "toolkit": 4, "top": [2, 9, 16], "top_k": 16, "top_p": 16, "top_term": 2, "topic": [1, 5, 6, 7, 11, 16, 21, 22, 23], "topic_trend": 10, "topn": 4, "torch": [4, 5, 16, 20, 21], "total": 2, "toward": [6, 16, 17], "tower": 21, "track": [8, 9, 21, 22], "trad_explan": 14, "trad_rel": 14, "trad_sent": 14, "trad_tim": 14, "trade": [2, 14], "tradit": [1, 3, 6, 11, 13, 16, 18], "tradition": [3, 11], "traditional_bleu": 14, "traditional_ent": 14, "traditional_gener": 14, "traditional_n": 14, "traditional_perform": 14, "traditional_predict": 14, "traditional_relation_extract": 14, "traditional_senti": 14, "train": [2, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22], "train_label": [6, 22], "train_test_split": [4, 9, 14, 21], "train_text": [6, 22], "transcript": 5, "transfer": [5, 12], "transform": [1, 2, 3, 8, 9, 13, 14, 16, 17, 19, 20, 21, 22, 23], "transformerencoderlay": 5, "transit": 4, "translat": [4, 12, 14, 18], "transpar": [3, 15, 19, 22], "treati": 13, "treatment": 17, "tree": [4, 6, 9], "trend": [1, 4, 5, 8, 10, 13, 19, 20, 23], "trend_descript": 22, "trillion": 22, "true": [2, 4, 16, 17, 20, 21], "truli": [5, 20], "truncat": [4, 5, 20, 21], "trust": 6, "truth": 16, "try": [2, 21], "tune": [4, 6, 12, 14, 16], "turn": 12, "tutori": 23, "tweepi": [20, 21, 22], "tweet": [4, 10, 20, 21, 22], "twitter": [18, 20, 21, 22], "two": [9, 10, 16, 18], "txt": 4, "type": [11, 12, 17, 18, 20, 21], "typic": [4, 5, 6, 8, 10, 13, 20], "u": [2, 3, 6, 8, 17], "ultim": [7, 17], "un": 6, "una": 6, "unbeliev": 21, "uncas": [4, 5, 17, 20, 21, 22], "uncov": [4, 10, 15, 19, 20], "under": 1, "undergon": [1, 3], "underli": 3, "understand": [1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 22, 23], "unfair": [6, 17], "unfamiliar": 4, "unhelp": 13, "unimagin": 19, "unintend": 6, "unintent": 6, "unit": [2, 8], "univers": [12, 13, 23], "unlik": [5, 18], "unlock": 4, "unpreced": [1, 4, 5, 15, 19], "unpredict": 18, "unproduct": 18, "unseen": [12, 14], "unstack": 10, "unstructur": [8, 9], "unsupervis": [5, 10], "unzip": 2, "up": [1, 2, 4, 9, 11, 18], "upon": 7, "urg": 2, "url": [2, 4, 21], "us": [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23], "usag": [2, 4, 5, 6, 9, 10, 12, 13, 14, 17, 18, 20, 21, 22], "usage_descript": 6, "used_pronoun": 6, "user": [2, 21], "user_input": 4, "usual": 8, "util": [2, 3, 5, 6, 17, 20], "uuid": 2, "v": [9, 20], "vaccin": 21, "vader": 9, "vadersenti": 9, "valenc": 9, "valid": [3, 4, 5, 12, 13, 14, 17, 20], "valu": [5, 13, 17, 18], "valuabl": [5, 9, 10, 13, 16], "value_count": 20, "vari": [6, 14], "variabl": [8, 16], "variant": 4, "variat": [10, 13], "varieti": 4, "variou": [2, 4, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21], "vast": [1, 4, 5, 12, 13, 15, 19, 20], "vbd": 4, "ve": [1, 2, 4, 19], "vector": [2, 4, 6, 8, 9, 10, 14, 21, 22], "vector_s": 4, "verb": 9, "verbos": 2, "veri": [5, 6, 10, 13, 14, 20, 22], "verifi": 16, "versail": 13, "version": 5, "versu": 11, "video": [21, 22], "vietnam": 2, "view": 4, "viru": [16, 21], "vis_data": 10, "visibl": 20, "visual": [5, 6, 10, 21, 22], "vivid": 18, "vocab_s": 5, "vocabulari": [4, 8], "volum": [5, 9, 13, 15, 18], "vp": 4, "vulner": 6, "w": [6, 10, 14], "wa": [0, 4, 5, 6, 9, 10, 13, 21, 22], "wage": 5, "wai": [1, 5, 7, 14, 15, 17], "waiter": 13, "walk": [5, 17], "want": [10, 18], "war": [4, 13, 18], "warn": 6, "washington": 2, "wasn": 12, "wast": 4, "watch": 4, "wd": 10, "we": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22], "weat_scor": 17, "weat_signific": 17, "weat_test": 17, "weather": [9, 13, 14], "web": [6, 8], "websit": [5, 8, 21], "week": [13, 23], "weekli": 23, "wei": 17, "weigh": 5, "weight": [4, 5, 14], "welcom": [1, 3, 7, 11, 15, 19], "well": [7, 8, 9], "were": [4, 5, 12, 20], "western": [6, 13], "what": [1, 2, 5, 6, 7, 8, 12, 13, 18, 19, 21], "when": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21], "where": [10, 12, 13, 15], "which": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 20], "while": [3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 16, 17, 18], "who": [1, 6, 13], "whole": 13, "why": [4, 5, 6, 16], "wide": [3, 4, 5, 9, 10, 12, 13], "wiki": [8, 22], "win": 14, "window": 4, "with_label": 21, "within": [9, 10, 18], "without": [4, 5, 11, 12, 13, 17], "wittman": 2, "woman": [4, 17, 22], "women": 5, "won": [9, 12, 13, 21], "word": [5, 9, 10, 12, 13, 14, 18, 20, 21, 22], "word2vec": 4, "word_freq": [2, 9], "word_pair": 22, "word_token": [2, 4, 8, 9, 10, 20, 21], "wordnet": [2, 4, 10], "wordnetlemmat": [2, 4, 8, 10, 21], "wordsdf": 20, "work": [1, 3, 5, 6, 7, 10, 11, 16, 20, 22], "work_of_art": 2, "worker": [2, 4, 20], "workflow": [9, 15], "workforc": 5, "workspac": 2, "workspace_dir": 2, "world": [1, 4, 5, 13, 17], "worst": 4, "would": [8, 20], "write": 4, "wv": 4, "www": [2, 8, 21], "x": [2, 5, 10, 14, 22], "x_subset": 14, "x_test": [4, 9, 14, 21], "x_test_tfidf": [4, 21], "x_test_vec": [4, 14], "x_test_vector": 9, "x_train": [4, 9, 14, 21], "x_train_balanc": 14, "x_train_tfidf": [4, 21], "x_train_vec": [4, 14], "x_train_vector": 9, "xlabel": [2, 14], "xtick": 2, "y": [14, 22], "y_pred": [4, 9, 14, 21], "y_subset": 14, "y_test": [4, 9, 14, 21], "y_train": [4, 9, 14, 21], "y_train_balanc": 14, "y_true": 14, "yard": 9, "ye": 18, "year": [1, 2, 3, 7, 16], "yesterdai": 13, "yield": 13, "yj": 2, "ylabel": [2, 14], "york": [9, 14, 21], "you": [1, 2, 3, 4, 7, 8, 9, 11, 13, 15, 16, 19, 20, 21], "young": 5, "younger": 22, "your": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22], "your_access_token": [20, 22], "your_access_token_secret": [20, 22], "your_consumer_kei": [20, 22], "your_consumer_secret": [20, 22], "youtub": 21, "z": [2, 6, 10, 21], "z0": [6, 8], "za": [2, 6, 8, 10, 21], "zd": 10, "zero": [1, 11, 13, 14, 21, 22, 23], "zero_grad": [5, 20], "zero_shot_classif": [4, 5, 12], "zero_shot_emotion_detect": 12, "zero_shot_multi_label_classif": 12, "zero_shot_n": 12, "zero_shot_qa": 12, "zero_shot_sentiment_analysi": 12, "zero_shot_summar": 12, "zhang": 17, "ziesch": 2, "zip": [2, 17, 22], "\u03b1": 10, "\u03b2": 10, "\u03b8": 10, "\u03b8d": 10, "\u03c6": 10, "\u03c6k": 10, "\u03c6zd": 10, "\u6211\u559c\u6b22\u8fd9\u4e2a\u4ea7\u54c1": 22, "\u8fd9\u662f\u4e00\u4e2a\u4e2d\u6587\u53e5\u5b50": 6}, "titles": ["Who made this book?", "Home", "Lab Session 1: Introduction to NLP for Social Science", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Course Syllabus"], "titleterms": {"0": 2, "1": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23], "10": [4, 9, 10, 12, 13, 14, 16, 18, 21], "11": [10, 13, 14, 18], "12": [10, 13, 14], "13": 10, "1950": 4, "1980": 4, "2": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23], "2000": 4, "2010": 4, "3": [2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23], "4": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23], "5": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23], "6": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "7": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "8": [2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22], "9": [4, 5, 9, 10, 12, 13, 14, 16, 17, 18, 21, 22], "In": 13, "Its": 23, "Their": 4, "abil": 5, "about": 1, "academ": 6, "access": 6, "accuraci": [5, 6], "adapt": [5, 14], "addit": 23, "address": 8, "advanc": [5, 10, 19, 22, 23], "advantag": 5, "ai": [6, 22], "algorithm": 10, "alloc": [9, 10], "ambigu": 4, "analysi": [2, 5, 9, 12, 13, 14, 17, 18, 20, 21, 22], "analyz": [4, 17, 20], "annot": [11, 23], "answer": [5, 12, 13], "applic": [10, 12, 15, 19, 23], "approach": [4, 14, 21], "architectur": 5, "aspect": 16, "assess": [21, 23], "associ": 17, "attent": 5, "attribut": 6, "augment": 16, "bag": 8, "balanc": 6, "base": [9, 16, 21], "basic": [2, 4, 9], "bert": 5, "bia": [6, 17], "bias": 5, "book": 0, "bow": 8, "capabl": [4, 5, 12, 13, 14], "categor": 20, "challeng": [4, 5, 6, 9, 10, 17, 18], "changelog": 1, "charact": 8, "characterist": 21, "class": 9, "classif": [9, 11, 12, 13, 14, 20, 23], "clean": 8, "cluster": 9, "collabor": 22, "collect": [20, 21], "combin": 10, "compar": 14, "comparison": 14, "complet": 5, "complex": [4, 5], "complianc": 6, "compon": 5, "comput": [4, 5, 6, 14], "concept": [4, 5], "concern": 6, "conclus": [2, 4, 6, 8, 9, 13, 14, 16, 17, 18, 20, 21, 22], "consider": [5, 6, 15, 17, 19], "consist": 6, "content": [1, 6, 16, 21], "context": [4, 5, 13, 18], "contribut": 1, "control": 16, "convers": 8, "copyright": 6, "core": 5, "corpora": 5, "cours": [1, 23], "creation": 16, "credibl": 21, "cross": [5, 6, 22], "cultur": [6, 18, 22], "current": 4, "data": [2, 4, 5, 6, 10, 11, 16, 20, 21, 23], "dataset": [4, 5, 20], "date": 8, "deal": [4, 8], "decis": 6, "deep": [4, 21], "definit": [4, 5], "deploy": 5, "descript": 23, "design": 13, "detect": [5, 6, 12, 17, 18, 21], "develop": 4, "direct": [4, 5, 10, 22], "dirichlet": [9, 10], "discours": 18, "dispar": 6, "distinct": 5, "divers": 6, "document": [8, 9], "domain": 5, "earli": 4, "effici": [5, 14], "email": 8, "embed": [4, 8, 17], "emerg": [4, 22], "emoji": 8, "emot": [5, 12, 16], "emoticon": 8, "engin": [12, 13, 16], "enhanc": 5, "ensur": 6, "entiti": [2, 9, 12, 13, 14, 20], "environment": 6, "equiti": 6, "ethic": [5, 6, 15, 17, 19, 22], "ethnic": 17, "evalu": [4, 9, 10, 14, 16, 18], "evolut": 4, "exampl": [4, 5, 9], "exercis": 2, "explain": [6, 14, 22], "explan": [15, 16, 18, 23], "explor": [15, 19], "exposur": 6, "extract": [4, 9, 12, 13, 14, 20], "factual": [5, 6], "fake": 21, "featur": 4, "few": [4, 5, 13], "figur": 18, "fine": 5, "foundat": [10, 12], "frequenc": [2, 8], "from": [4, 5], "fundament": [4, 9, 10, 13, 16], "futur": [4, 5, 10, 19, 22], "gender": 17, "gener": [4, 5, 6, 12, 13, 14, 15, 16, 23], "gensim": 9, "global": 6, "gpt": 5, "hallucin": 6, "handl": [4, 5, 8], "high": 16, "histor": 4, "home": 1, "html": 8, "human": [5, 22], "identif": 6, "idf": 8, "idiom": 18, "impact": [4, 6], "implement": 10, "implic": 6, "import": [4, 6], "improv": [5, 6], "infer": 17, "inform": [5, 6, 12, 13, 14], "instal": 2, "integr": [5, 6], "intellectu": 6, "interpret": [5, 6, 9, 10, 14, 18, 22], "introduct": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23], "invers": 8, "ironi": 18, "issu": 6, "its": [4, 5], "kei": [5, 15, 19], "knowledg": 5, "lab": [1, 2], "lack": 5, "languag": [4, 5, 18, 22], "larg": [4, 5, 6, 20, 22], "larger": 4, "latent": [9, 10], "lda": [9, 10], "learn": [4, 5, 12, 13, 14, 21], "lectur": 1, "lemmat": 8, "lexicon": 9, "librari": 2, "licens": 1, "like": 5, "limit": [5, 9, 10, 18], "lingual": 5, "ll": [15, 19], "llm": [4, 5, 6, 11, 12, 13, 14, 16, 17, 18, 19, 21, 23], "load": 2, "lowercas": 8, "machin": 21, "made": 0, "massiv": 5, "materi": 23, "mathemat": 10, "matter": [1, 15, 19], "mechan": 5, "media": 18, "metaphor": 18, "methodologi": 14, "metric": [14, 18], "mine": [13, 14], "misinform": [16, 21], "mitig": [5, 6, 17], "modal": 5, "model": [4, 5, 6, 8, 9, 10, 20, 22], "modern": 4, "multi": [5, 9], "multilingu": 22, "multimod": 22, "name": [2, 9, 12, 13, 14, 20], "natur": 4, "need": 6, "ner": [9, 12, 13, 14], "network": 21, "neuro": 22, "new": [4, 21], "nlp": [2, 3, 4, 5, 6, 7, 9, 10, 17, 22, 23], "nltk": 9, "normal": 8, "notabl": 5, "note": 1, "number": 8, "object": [1, 23], "ongo": 4, "opinion": [13, 14], "opportun": 4, "optim": 13, "other": [5, 10], "outcom": 6, "output": 6, "overview": [1, 5], "paradigm": 4, "paramet": 16, "paraphras": 5, "part": 9, "perform": 14, "person": 6, "perspect": 4, "pipelin": 4, "plagiar": 6, "po": 9, "polit": 18, "pose": 6, "possibl": 4, "potenti": [5, 6], "practic": [15, 19], "pre": 5, "prepar": [10, 19], "preprocess": [2, 4, 7, 8, 20, 21, 23], "prerequisit": 23, "present": 4, "privaci": 6, "process": [4, 5, 18, 20, 22], "progress": 5, "promin": 5, "prompt": [12, 13, 16], "proper": 6, "properti": 6, "protect": 6, "proverb": 18, "purpos": 4, "qualiti": 16, "quantifi": 17, "question": [5, 12, 13], "racial": 17, "re": 6, "real": 22, "reason": 5, "recap": 14, "recent": 5, "recognit": [2, 9, 12, 13, 14, 20], "recommend": 23, "regul": 6, "relat": [14, 20], "reliabl": 6, "remov": 8, "replac": 8, "represent": [2, 8], "reproduc": 6, "requir": [2, 5, 6, 14, 23], "research": [4, 5, 6, 10, 12, 16, 19, 21, 22, 23], "resourc": [5, 6, 14, 23], "respons": 22, "result": [6, 10], "retriev": 5, "revolut": 4, "rise": 4, "risk": 6, "sarcasm": 18, "scalabl": [14, 20], "scale": [5, 6, 20], "schedul": 23, "scienc": [2, 3, 4, 5, 6, 10, 12, 15, 16, 19, 22, 23], "scientif": 6, "scientist": 4, "self": 5, "semant": 4, "sentenc": 8, "sentiment": [2, 5, 9, 12, 13, 14, 20], "seri": 5, "session": [2, 3, 7, 11, 15, 19, 23], "setup": 2, "shift": 4, "shot": [4, 5, 12, 13], "similar": 9, "size": 5, "social": [2, 3, 4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 22, 23], "societ": 6, "socioeconom": 6, "sourc": [6, 17, 20, 21], "spaci": 9, "special": 8, "specif": [4, 5], "speech": 9, "spread": 21, "state": 4, "statist": 4, "stem": 8, "stop": 8, "strategi": [6, 13], "structur": [1, 23], "summar": [5, 9, 12, 13, 16], "summari": [15, 23], "supervis": 14, "sustain": 6, "syllabu": 23, "symbol": 22, "tabl": 1, "tag": [8, 9], "task": [2, 4, 5, 9, 12, 14, 16], "techniqu": [6, 7, 8, 10, 13, 17, 20, 21, 23], "technologi": 6, "term": 8, "test": 17, "text": [2, 4, 5, 6, 7, 8, 9, 12, 13, 14, 16, 20, 23], "textbook": 23, "textual": 20, "tf": 8, "theoret": 12, "thi": [0, 1], "time": 22, "token": 8, "topic": [9, 10, 15, 19, 20], "toward": 4, "tradit": [4, 5, 7, 14, 21, 23], "train": [4, 5, 6], "transform": [4, 5], "translat": 5, "transpar": [5, 6], "trend": 22, "true": 5, "tune": 5, "type": [6, 9, 13, 16], "understand": [5, 18], "uniqu": 6, "unstructur": 4, "up": 5, "url": 8, "us": [6, 9, 16, 17], "valid": 6, "variant": 5, "variou": 5, "we": [15, 19], "weat": 17, "who": 0, "why": [1, 15, 19], "wisdom": 18, "word": [2, 4, 8, 17], "zero": [4, 5, 12]}})