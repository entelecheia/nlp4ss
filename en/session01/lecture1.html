
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.1 Fundamentals of NLP and its Evolution &#8212; NLP for Social Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'session01/lecture1';</script>
    <script src="../_static/language_switcher.js?v=ff97be19"></script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.2 Overview of Generative LLMs" href="lecture2.html" />
    <link rel="prev" title="Session 1 - Introduction to NLP for Social Science" href="index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          English <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">NLP for Social Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Session 1 - Introduction to NLP for Social Science</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.1 Fundamentals of NLP and its Evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture2.html">1.2 Overview of Generative LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture3.html">1.3 Ethical Considerations and Challenges in Using LLMs for Research</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session02/index.html">Session 2: Traditional NLP Techniques and Text Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture1.html">2.1 Text Cleaning, Normalization, and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture2.html">2.2 Basic NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture3.html">2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session03/index.html">Session 3: LLMs for Data Annotation and Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture1.html">3.1 Zero-shot Learning with LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture2.html">3.2 Few-shot Learning and Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture3.html">3.3 Comparing LLM Performance with Traditional Supervised Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session04/index.html">Session 4: Generative Explanations and Summaries in Social Science</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture1.html">4.1 Using LLMs for High-Quality Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture2.html">4.2 Social Bias Inference and Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture3.html">4.3 Figurative Language Explanation and Cultural Context</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session05/index.html">Session 5: Advanced Applications of LLMs in Social Science Research</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture1.html">5.1 Analyzing Large-Scale Textual Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture2.html">5.2 Misinformation and Fake News Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture3.html">5.3 Future Directions and Emerging Trends</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">Course Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/edit/main/book/session01/lecture1.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/issues/new?title=Issue%20on%20page%20%2Fsession01/lecture1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/session01/lecture1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>1.1 Fundamentals of NLP and its Evolution</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-natural-language-processing-nlp">1. Introduction to Natural Language Processing (NLP)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-nlp">1.1 Definition of NLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">1.2 Basic Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-in-social-science-research">1.3 Importance in Social Science Research</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#historical-perspective-of-nlp">2. Historical Perspective of NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#early-approaches-1950s-1980s">2.1 Early Approaches (1950s-1980s)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-revolution-1980s-2000s">2.2 Statistical Revolution (1980s-2000s)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#traditional-nlp-pipeline">3. Traditional NLP Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-preprocessing">3.1 Text Preprocessing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">3.2 Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-training-and-evaluation">3.3 Model Training and Evaluation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-in-traditional-nlp">4. Challenges in Traditional NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-language-ambiguity">4.1 Handling Language Ambiguity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-context-and-semantics">4.2 Dealing with Context and Semantics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-complexity">4.3 Computational Complexity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution-towards-modern-nlp">5. Evolution Towards Modern NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-of-word-embeddings">5.1 Introduction of Word Embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rise-of-deep-learning-in-nlp">5.2 Rise of Deep Learning in NLP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergence-of-transformer-models">6. Emergence of Transformer Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">6.1 Key Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#breakthrough-models">6.2 Breakthrough Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-llms">7. Large Language Models (LLMs)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-capabilities">7.1 Definition and Capabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-and-their-impact">7.2 Examples and Their Impact</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#paradigm-shift-in-nlp-tasks">8. Paradigm Shift in NLP Tasks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-task-specific-to-general-purpose-models">8.1 From Task-Specific to General-Purpose Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-and-zero-shot-learning">8.2 Few-Shot and Zero-Shot Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#impact-on-social-science-research">9. Impact on Social Science Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-possibilities-for-analyzing-unstructured-text-data">9.1 New Possibilities for Analyzing Unstructured Text Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-larger-datasets-and-complex-language-tasks">9.2 Handling Larger Datasets and Complex Language Tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#current-state-and-future-directions">10. Current State and Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ongoing-developments-in-llms">10.1 Ongoing Developments in LLMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#emerging-challenges-and-opportunities-for-social-scientists">10.2 Emerging Challenges and Opportunities for Social Scientists</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="fundamentals-of-nlp-and-its-evolution">
<h1>1.1 Fundamentals of NLP and its Evolution<a class="headerlink" href="#fundamentals-of-nlp-and-its-evolution" title="Link to this heading">#</a></h1>
<section id="introduction-to-natural-language-processing-nlp">
<h2>1. Introduction to Natural Language Processing (NLP)<a class="headerlink" href="#introduction-to-natural-language-processing-nlp" title="Link to this heading">#</a></h2>
<p>Natural Language Processing (NLP) is an interdisciplinary field that combines linguistics, computer science, and artificial intelligence to enable computers to understand, interpret, and generate human language. The primary goal of NLP is to bridge the gap between human communication and computer understanding.</p>
<section id="definition-of-nlp">
<h3>1.1 Definition of NLP<a class="headerlink" href="#definition-of-nlp" title="Link to this heading">#</a></h3>
<p>NLP encompasses a wide range of computational techniques for analyzing and representing naturally occurring text at one or more levels of linguistic analysis. These techniques aim to achieve human-like language processing for a variety of tasks or applications.</p>
</section>
<section id="basic-concepts">
<h3>1.2 Basic Concepts<a class="headerlink" href="#basic-concepts" title="Link to this heading">#</a></h3>
<p>Key concepts in NLP include:</p>
<ul class="simple">
<li><p>Tokenization: Breaking text into individual words or subwords</p></li>
<li><p>Parsing: Analyzing the grammatical structure of sentences</p></li>
<li><p>Semantic analysis: Interpreting the meaning of words and sentences</p></li>
</ul>
<p>For example, given the sentence “The cat sat on the mat,” NLP processes might involve:</p>
<ul class="simple">
<li><p>Tokenization: [The, cat, sat, on, the, mat]</p></li>
<li><p>Parsing: Identifying “The cat” as the subject and “sat on the mat” as the predicate</p></li>
<li><p>Semantic analysis: Understanding that this sentence describes the location of a cat</p></li>
</ul>
</section>
<section id="importance-in-social-science-research">
<h3>1.3 Importance in Social Science Research<a class="headerlink" href="#importance-in-social-science-research" title="Link to this heading">#</a></h3>
<p>NLP has become increasingly important in social science research due to its ability to:</p>
<ul class="simple">
<li><p>Analyze large-scale textual data, such as social media posts, historical documents, or survey responses</p></li>
<li><p>Extract insights from unstructured text, revealing patterns and trends in human communication</p></li>
<li><p>Automate content analysis and coding, saving time and reducing human bias in qualitative research</p></li>
</ul>
<p>For instance, researchers might use NLP to analyze thousands of tweets to gauge public opinion on a political issue or to automatically categorize open-ended survey responses into themes.</p>
</section>
</section>
<section id="historical-perspective-of-nlp">
<h2>2. Historical Perspective of NLP<a class="headerlink" href="#historical-perspective-of-nlp" title="Link to this heading">#</a></h2>
<section id="early-approaches-1950s-1980s">
<h3>2.1 Early Approaches (1950s-1980s)<a class="headerlink" href="#early-approaches-1950s-1980s" title="Link to this heading">#</a></h3>
<p>Early NLP systems were primarily rule-based, relying on hand-crafted rules and expert knowledge. These approaches were influenced by Noam Chomsky’s formal language theory, which proposed that language could be described by a set of grammatical rules.</p>
<p>Example: The ELIZA chatbot (1966) used pattern matching and substitution rules to simulate a psychotherapist’s responses.</p>
<p>Limitations: These systems struggled with the complexity and ambiguity of natural language, often failing when encountering unfamiliar patterns or contexts.</p>
</section>
<section id="statistical-revolution-1980s-2000s">
<h3>2.2 Statistical Revolution (1980s-2000s)<a class="headerlink" href="#statistical-revolution-1980s-2000s" title="Link to this heading">#</a></h3>
<p>The 1980s saw a shift towards statistical methods in NLP, driven by:</p>
<ul class="simple">
<li><p>Increased availability of digital text corpora</p></li>
<li><p>Growth in computational power</p></li>
<li><p>Development of machine learning techniques</p></li>
</ul>
<p>Examples of statistical NLP techniques:</p>
<ul class="simple">
<li><p>Hidden Markov Models for part-of-speech tagging</p></li>
<li><p>Probabilistic context-free grammars for parsing</p></li>
<li><p>Naive Bayes classifiers for text categorization</p></li>
</ul>
<p>This era also saw the emergence of corpus linguistics, which emphasized the study of language through large collections of real-world text data.</p>
</section>
</section>
<section id="traditional-nlp-pipeline">
<h2>3. Traditional NLP Pipeline<a class="headerlink" href="#traditional-nlp-pipeline" title="Link to this heading">#</a></h2>
<p>The traditional NLP pipeline typically consists of several stages:</p>
<section id="text-preprocessing">
<h3>3.1 Text Preprocessing<a class="headerlink" href="#text-preprocessing" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Tokenization: Breaking text into words or subwords</p></li>
<li><p>Lowercasing: Converting all text to lowercase to reduce dimensionality</p></li>
<li><p>Noise removal: Eliminating irrelevant characters or formatting</p></li>
<li><p>Stemming and lemmatization: Reducing words to their root form</p></li>
</ul>
<p>Example:</p>
<ul class="simple">
<li><p>Original: “The cats are running quickly.”</p></li>
<li><p>Preprocessed: [“the”, “cat”, “are”, “run”, “quick”]</p></li>
</ul>
</section>
<section id="feature-extraction">
<h3>3.2 Feature Extraction<a class="headerlink" href="#feature-extraction" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Bag-of-words model: Representing text as a vector of word frequencies</p></li>
<li><p>TF-IDF (Term Frequency-Inverse Document Frequency): Weighting terms based on their importance in a document and corpus</p></li>
<li><p>N-grams: Capturing sequences of N adjacent words</p></li>
</ul>
<p>Example:</p>
<ul class="simple">
<li><p>Sentence: “The cat sat on the mat”</p></li>
<li><p>Bag-of-words: {“the”: 2, “cat”: 1, “sat”: 1, “on”: 1, “mat”: 1}</p></li>
</ul>
</section>
<section id="model-training-and-evaluation">
<h3>3.3 Model Training and Evaluation<a class="headerlink" href="#model-training-and-evaluation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Supervised learning algorithms: Training models on labeled data (e.g., Naive Bayes, Support Vector Machines)</p></li>
<li><p>Evaluation metrics: Assessing model performance using metrics like accuracy, precision, recall, and F1-score</p></li>
</ul>
<p>Example:</p>
<ul class="simple">
<li><p>Task: Sentiment analysis of movie reviews</p></li>
<li><p>Training: Use a dataset of labeled reviews (positive/negative) to train a classifier</p></li>
<li><p>Evaluation: Test the model on a held-out set and calculate accuracy</p></li>
</ul>
</section>
</section>
<section id="challenges-in-traditional-nlp">
<h2>4. Challenges in Traditional NLP<a class="headerlink" href="#challenges-in-traditional-nlp" title="Link to this heading">#</a></h2>
<section id="handling-language-ambiguity">
<h3>4.1 Handling Language Ambiguity<a class="headerlink" href="#handling-language-ambiguity" title="Link to this heading">#</a></h3>
<p>Natural language is inherently ambiguous, presenting challenges such as:</p>
<ul class="simple">
<li><p>Lexical ambiguity: Words with multiple meanings (e.g., “bank” as a financial institution or river bank)</p></li>
<li><p>Syntactic ambiguity: Sentences with multiple grammatical interpretations</p></li>
</ul>
<p>Example: “I saw a man on a hill with a telescope”</p>
<ul class="simple">
<li><p>Is the man holding the telescope?</p></li>
<li><p>Is the speaker using the telescope to see the man?</p></li>
<li><p>Is the telescope on the hill?</p></li>
</ul>
</section>
<section id="dealing-with-context-and-semantics">
<h3>4.2 Dealing with Context and Semantics<a class="headerlink" href="#dealing-with-context-and-semantics" title="Link to this heading">#</a></h3>
<p>Traditional NLP models often struggled to capture:</p>
<ul class="simple">
<li><p>Long-range dependencies in text</p></li>
<li><p>Contextual nuances and implied meaning</p></li>
<li><p>Pragmatics and discourse-level understanding</p></li>
</ul>
<p>Example: Understanding sarcasm or irony in text requires grasping context beyond literal word meanings.</p>
</section>
<section id="computational-complexity">
<h3>4.3 Computational Complexity<a class="headerlink" href="#computational-complexity" title="Link to this heading">#</a></h3>
<p>As vocabularies and datasets grew, traditional NLP methods faced scalability issues:</p>
<ul class="simple">
<li><p>High-dimensional feature spaces in bag-of-words models</p></li>
<li><p>Computational costs of parsing complex sentences</p></li>
<li><p>Memory requirements for storing large language models</p></li>
</ul>
</section>
</section>
<section id="evolution-towards-modern-nlp">
<h2>5. Evolution Towards Modern NLP<a class="headerlink" href="#evolution-towards-modern-nlp" title="Link to this heading">#</a></h2>
<section id="introduction-of-word-embeddings">
<h3>5.1 Introduction of Word Embeddings<a class="headerlink" href="#introduction-of-word-embeddings" title="Link to this heading">#</a></h3>
<p>Word embeddings revolutionized NLP by representing words as dense vectors in a continuous space, capturing semantic relationships.</p>
<p>Example: word2vec model</p>
<ul class="simple">
<li><p>Words with similar meanings cluster together in the vector space</p></li>
<li><p>Semantic relationships can be captured through vector arithmetic:
king - man + woman ≈ queen</p></li>
</ul>
</section>
<section id="rise-of-deep-learning-in-nlp">
<h3>5.2 Rise of Deep Learning in NLP<a class="headerlink" href="#rise-of-deep-learning-in-nlp" title="Link to this heading">#</a></h3>
<p>Deep learning models, particularly neural networks, brought significant advancements:</p>
<ul class="simple">
<li><p>Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks for sequential data</p></li>
<li><p>Convolutional Neural Networks (CNNs) for text classification tasks</p></li>
</ul>
<p>These models could automatically learn hierarchical features from data, reducing the need for manual feature engineering.</p>
</section>
</section>
<section id="emergence-of-transformer-models">
<h2>6. Emergence of Transformer Models<a class="headerlink" href="#emergence-of-transformer-models" title="Link to this heading">#</a></h2>
<section id="key-concepts">
<h3>6.1 Key Concepts<a class="headerlink" href="#key-concepts" title="Link to this heading">#</a></h3>
<p>The transformer architecture, introduced in 2017, brought a paradigm shift in NLP:</p>
<ul class="simple">
<li><p>Attention mechanism: Allowing models to focus on relevant parts of the input</p></li>
<li><p>Self-attention: Enabling the model to consider the full context of each word</p></li>
</ul>
</section>
<section id="breakthrough-models">
<h3>6.2 Breakthrough Models<a class="headerlink" href="#breakthrough-models" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>BERT (Bidirectional Encoder Representations from Transformers): Pre-trained on massive amounts of text, allowing fine-tuning for specific tasks</p></li>
<li><p>GPT (Generative Pre-trained Transformer) series: Capable of generating human-like text and performing a wide range of language tasks</p></li>
</ul>
<p>These models achieved state-of-the-art results across numerous NLP benchmarks.</p>
</section>
</section>
<section id="large-language-models-llms">
<h2>7. Large Language Models (LLMs)<a class="headerlink" href="#large-language-models-llms" title="Link to this heading">#</a></h2>
<section id="definition-and-capabilities">
<h3>7.1 Definition and Capabilities<a class="headerlink" href="#definition-and-capabilities" title="Link to this heading">#</a></h3>
<p>LLMs are massive neural networks trained on vast amounts of text data, capable of:</p>
<ul class="simple">
<li><p>Understanding and generating human-like text</p></li>
<li><p>Performing a wide range of language tasks without task-specific training</p></li>
<li><p>Exhibiting emergent abilities not explicitly programmed</p></li>
</ul>
</section>
<section id="examples-and-their-impact">
<h3>7.2 Examples and Their Impact<a class="headerlink" href="#examples-and-their-impact" title="Link to this heading">#</a></h3>
<p>Models like GPT-3 and GPT-4 have demonstrated remarkable capabilities:</p>
<ul class="simple">
<li><p>Generating coherent and contextually appropriate text</p></li>
<li><p>Answering questions and providing explanations</p></li>
<li><p>Translating between languages</p></li>
<li><p>Summarizing long documents</p></li>
<li><p>Writing code and solving analytical problems</p></li>
</ul>
<p>These models have significantly impacted various fields, including social science research, by enabling more sophisticated text analysis and generation.</p>
</section>
</section>
<section id="paradigm-shift-in-nlp-tasks">
<h2>8. Paradigm Shift in NLP Tasks<a class="headerlink" href="#paradigm-shift-in-nlp-tasks" title="Link to this heading">#</a></h2>
<section id="from-task-specific-to-general-purpose-models">
<h3>8.1 From Task-Specific to General-Purpose Models<a class="headerlink" href="#from-task-specific-to-general-purpose-models" title="Link to this heading">#</a></h3>
<p>Modern NLP has shifted from developing separate models for each task to using general-purpose models that can be adapted to various tasks through fine-tuning or prompting.</p>
</section>
<section id="few-shot-and-zero-shot-learning">
<h3>8.2 Few-Shot and Zero-Shot Learning<a class="headerlink" href="#few-shot-and-zero-shot-learning" title="Link to this heading">#</a></h3>
<p>LLMs have introduced new learning paradigms:</p>
<ul class="simple">
<li><p>Few-shot learning: Performing tasks with only a few examples</p></li>
<li><p>Zero-shot learning: Completing tasks without any specific training examples</p></li>
</ul>
<p>Example: A model might classify news articles into categories it has never been explicitly trained on, based on its general understanding of language and concepts.</p>
</section>
</section>
<section id="impact-on-social-science-research">
<h2>9. Impact on Social Science Research<a class="headerlink" href="#impact-on-social-science-research" title="Link to this heading">#</a></h2>
<section id="new-possibilities-for-analyzing-unstructured-text-data">
<h3>9.1 New Possibilities for Analyzing Unstructured Text Data<a class="headerlink" href="#new-possibilities-for-analyzing-unstructured-text-data" title="Link to this heading">#</a></h3>
<p>LLMs offer social scientists powerful tools for:</p>
<ul class="simple">
<li><p>Automated coding of qualitative data</p></li>
<li><p>Sentiment analysis and opinion mining at scale</p></li>
<li><p>Identifying themes and patterns in large text corpora</p></li>
</ul>
</section>
<section id="handling-larger-datasets-and-complex-language-tasks">
<h3>9.2 Handling Larger Datasets and Complex Language Tasks<a class="headerlink" href="#handling-larger-datasets-and-complex-language-tasks" title="Link to this heading">#</a></h3>
<p>Researchers can now tackle previously infeasible tasks:</p>
<ul class="simple">
<li><p>Cross-lingual analysis of global social media discourse</p></li>
<li><p>Summarization of vast collections of academic literature</p></li>
<li><p>Generating hypotheses from unstructured data</p></li>
</ul>
</section>
</section>
<section id="current-state-and-future-directions">
<h2>10. Current State and Future Directions<a class="headerlink" href="#current-state-and-future-directions" title="Link to this heading">#</a></h2>
<section id="ongoing-developments-in-llms">
<h3>10.1 Ongoing Developments in LLMs<a class="headerlink" href="#ongoing-developments-in-llms" title="Link to this heading">#</a></h3>
<p>Current research focuses on:</p>
<ul class="simple">
<li><p>Improving factual accuracy and reducing hallucinations</p></li>
<li><p>Enhancing reasoning capabilities</p></li>
<li><p>Developing more efficient and environmentally friendly models</p></li>
<li><p>Creating multimodal models that can process text, images, and audio</p></li>
</ul>
</section>
<section id="emerging-challenges-and-opportunities-for-social-scientists">
<h3>10.2 Emerging Challenges and Opportunities for Social Scientists<a class="headerlink" href="#emerging-challenges-and-opportunities-for-social-scientists" title="Link to this heading">#</a></h3>
<p>As NLP continues to evolve, social scientists face new challenges and opportunities:</p>
<ul class="simple">
<li><p>Addressing ethical concerns around bias, privacy, and the interpretability of AI-generated insights</p></li>
<li><p>Developing methodologies to validate and interpret results from LLM-based analyses</p></li>
<li><p>Integrating domain-specific knowledge with the capabilities of advanced NLP models</p></li>
<li><p>Exploring novel research questions enabled by these powerful tools</p></li>
</ul>
<p>The rapid evolution of NLP, from rule-based systems to sophisticated LLMs, has transformed the landscape of text analysis in social science research. While offering unprecedented opportunities, these advancements also require careful consideration of their limitations and ethical implications. As the field continues to progress, close collaboration between NLP researchers and social scientists will be crucial in harnessing the full potential of these technologies for advancing our understanding of human behavior and society.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/nlp4ss",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./session01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Session 1 - Introduction to NLP for Social Science</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture2.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">1.2 Overview of Generative LLMs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-natural-language-processing-nlp">1. Introduction to Natural Language Processing (NLP)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-of-nlp">1.1 Definition of NLP</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts">1.2 Basic Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#importance-in-social-science-research">1.3 Importance in Social Science Research</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#historical-perspective-of-nlp">2. Historical Perspective of NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#early-approaches-1950s-1980s">2.1 Early Approaches (1950s-1980s)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-revolution-1980s-2000s">2.2 Statistical Revolution (1980s-2000s)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#traditional-nlp-pipeline">3. Traditional NLP Pipeline</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-preprocessing">3.1 Text Preprocessing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">3.2 Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-training-and-evaluation">3.3 Model Training and Evaluation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-in-traditional-nlp">4. Challenges in Traditional NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-language-ambiguity">4.1 Handling Language Ambiguity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-context-and-semantics">4.2 Dealing with Context and Semantics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-complexity">4.3 Computational Complexity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evolution-towards-modern-nlp">5. Evolution Towards Modern NLP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-of-word-embeddings">5.1 Introduction of Word Embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rise-of-deep-learning-in-nlp">5.2 Rise of Deep Learning in NLP</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#emergence-of-transformer-models">6. Emergence of Transformer Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-concepts">6.1 Key Concepts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#breakthrough-models">6.2 Breakthrough Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-llms">7. Large Language Models (LLMs)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-capabilities">7.1 Definition and Capabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#examples-and-their-impact">7.2 Examples and Their Impact</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#paradigm-shift-in-nlp-tasks">8. Paradigm Shift in NLP Tasks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-task-specific-to-general-purpose-models">8.1 From Task-Specific to General-Purpose Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-and-zero-shot-learning">8.2 Few-Shot and Zero-Shot Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#impact-on-social-science-research">9. Impact on Social Science Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-possibilities-for-analyzing-unstructured-text-data">9.1 New Possibilities for Analyzing Unstructured Text Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-larger-datasets-and-complex-language-tasks">9.2 Handling Larger Datasets and Complex Language Tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#current-state-and-future-directions">10. Current State and Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ongoing-developments-in-llms">10.1 Ongoing Developments in LLMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#emerging-challenges-and-opportunities-for-social-scientists">10.2 Emerging Challenges and Opportunities for Social Scientists</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
