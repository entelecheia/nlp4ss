
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1.2 Overview of Generative LLMs &#8212; NLP for Social Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=4c969af8" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-examples.css?v=e236af4b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/language_selector.css?v=6a8ebae4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/tabs.js?v=3ee01567"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-BQJE5V9RK2"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-BQJE5V9RK2');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'session01/lecture2';</script>
    <script src="../_static/language_switcher.js?v=ff97be19"></script>
    <script src="../_static/chat.js?v=f0de43d7"></script>
    <link rel="icon" href="https://assets.entelecheia.ai/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.3 Ethical Considerations and Challenges in Using LLMs for Research" href="lecture3.html" />
    <link rel="prev" title="1.1 Fundamentals of NLP and its Evolution" href="lecture1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <script src="/_static/language_switcher.js"></script>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-lang-select">  <nav class="menu">    <ul class="clearfix">      <li class="current-item">        <a href="#" class="clicker">          English <span class="arrow">&#9660;</span>        </a>        <ul class="sub-menu">                    <li><a href="#" onclick="switchLanguage('en'); return false;">English</a></li>        </ul>      </li>    </ul>  </nav></div>
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">NLP for Social Science</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture Notes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Session 1 - Introduction to NLP for Social Science</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="lecture1.html">1.1 Fundamentals of NLP and its Evolution</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">1.2 Overview of Generative LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="lecture3.html">1.3 Ethical Considerations and Challenges in Using LLMs for Research</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session02/index.html">Session 2: Traditional NLP Techniques and Text Preprocessing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture1.html">2.1 Text Cleaning, Normalization, and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture2.html">2.2 Basic NLP Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session02/lecture3.html">2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session03/index.html">Session 3: LLMs for Data Annotation and Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture1.html">3.1 Zero-shot Learning with LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture2.html">3.2 Few-shot Learning and Prompt Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session03/lecture3.html">3.3 Comparing LLM Performance with Traditional Supervised Learning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session04/index.html">Session 4: Generative Explanations and Summaries in Social Science</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture1.html">4.1 Using LLMs for High-Quality Text Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture2.html">4.2 Social Bias Inference and Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session04/lecture3.html">4.3 Figurative Language Explanation and Cultural Context</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../session05/index.html">Session 5: Advanced Applications of LLMs in Social Science Research</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture1.html">5.1 Analyzing Large-Scale Textual Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture2.html">5.2 Misinformation and Fake News Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../session05/lecture3.html">5.3 Future Directions and Emerging Trends</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../extras/extra01.html">Extra 1: The Evolution and Impact of LLMs in Social Science Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extras/extra02.html">Extra 2: Text Representation and NLP Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extras/extra03.html">Extra 3: Practical Considerations for Using LLMs in Social Science Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extras/extra04.html">Extra 4: Advanced Considerations for LLMs in Social Science Research</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../labs/nlp4ss-lab-1.html">Lab Session 1: Introduction to NLP for Social Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/nlp4ss-lab-2.html">Lab Session 2: LLMs for Data Annotation and Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../labs/nlp4ss-lab-3.html">Lab Session 3: Applying Traditional NLP Techniques</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../projects/nlp4ss-project-1.html">NLP Analysis of Sierra Club Press Releases</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus/index.html">Course Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about/index.html">Who made this book?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/edit/main/book/en/session01/lecture2.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/nlp4ss/issues/new?title=Issue%20on%20page%20%2Fsession01/lecture2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/session01/lecture2.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>1.2 Overview of Generative LLMs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-generative-llms">1. Introduction to Generative LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-core-concept">Definition and core concept</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distinction-from-traditional-nlp-models">Distinction from traditional NLP models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components-of-llms">2. Key Components of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformer-architecture">Transformer architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-attention-mechanism">Self-attention mechanism</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-up-training-on-massive-datasets">Scaled-up training on massive datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notable-examples-of-llms">3. Notable Examples of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-generative-pre-trained-transformer-series">GPT (Generative Pre-trained Transformer) series</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-and-its-variants">BERT and its variants</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-prominent-models">Other prominent models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities-of-llms-in-social-science-contexts">4. Capabilities of LLMs in Social Science Contexts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-and-completion">Text generation and completion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering-and-information-retrieval">Question answering and information retrieval</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summarization-and-paraphrasing">Summarization and paraphrasing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#translation-and-cross-lingual-tasks">Translation and cross-lingual tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis-and-emotion-detection">Sentiment analysis and emotion detection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-process-of-llms">5. Training Process of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-on-large-corpora">Pre-training on large corpora</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-for-specific-tasks">Fine-tuning for specific tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-and-zero-shot-learning-capabilities">Few-shot and zero-shot learning capabilities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-llms-in-social-science-research">6. Advantages of LLMs in Social Science Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-complex-language-understanding-tasks">Handling complex language understanding tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ability-to-generate-human-like-text">Ability to generate human-like text</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptability-to-various-domains-and-tasks">Adaptability to various domains and tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-challenges">7. Limitations and Challenges</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#potential-biases-in-training-data">Potential biases in training data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lack-of-true-understanding-or-reasoning">Lack of true understanding or reasoning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-resources-required">Computational resources required</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ethical-considerations-in-deployment">Ethical considerations in deployment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recent-advancements">8. Recent Advancements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improvements-in-model-size-and-efficiency">Improvements in model size and efficiency</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#enhanced-multi-modal-capabilities">Enhanced multi-modal capabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#progress-in-mitigating-biases-and-improving-factual-accuracy">Progress in mitigating biases and improving factual accuracy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#future-directions">9. Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-domain-specific-knowledge">Integration with domain-specific knowledge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improved-interpretability-and-transparency">Improved interpretability and transparency</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="overview-of-generative-llms">
<h1>1.2 Overview of Generative LLMs<a class="headerlink" href="#overview-of-generative-llms" title="Link to this heading">#</a></h1>
<section id="introduction-to-generative-llms">
<h2>1. Introduction to Generative LLMs<a class="headerlink" href="#introduction-to-generative-llms" title="Link to this heading">#</a></h2>
<p>Generative Large Language Models (LLMs) represent a significant leap forward in natural language processing (NLP) technology. These advanced artificial intelligence systems are designed to understand and generate human-like text, offering unprecedented capabilities in language tasks.</p>
<div align="center" class="mermaid align-center">
            graph TD
    A[Generative LLMs] --&gt; B[Text Understanding]
    A --&gt; C[Text Generation]
    B --&gt; D[Context Comprehension]
    B --&gt; E[Semantic Analysis]
    C --&gt; F[Coherent Text Production]
    C --&gt; G[Style Adaptation]
    A --&gt; H[Few-shot Learning]
    A --&gt; I[Zero-shot Learning]
        </div>
        <section id="definition-and-core-concept">
<h3>Definition and core concept<a class="headerlink" href="#definition-and-core-concept" title="Link to this heading">#</a></h3>
<p>Generative LLMs are neural networks trained on vast amounts of text data to predict the next word in a sequence, allowing them to generate coherent and contextually appropriate text. They use this predictive capability to understand and produce language.</p>
</section>
<section id="distinction-from-traditional-nlp-models">
<h3>Distinction from traditional NLP models<a class="headerlink" href="#distinction-from-traditional-nlp-models" title="Link to this heading">#</a></h3>
<p>Unlike traditional NLP models that focus on specific tasks (e.g., sentiment analysis or named entity recognition), generative LLMs can perform a wide range of language tasks without task-specific training.</p>
<p>Example: While a traditional sentiment analysis model might only classify text as positive or negative, a generative LLM could analyze sentiment, explain the reasoning, and even rewrite the text to change its sentiment.</p>
<p>Let’s demonstrate this with a code example using the OpenAI GPT-3 API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">openai</span>

<span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="s1">&#39;your-api-key-here&#39;</span>

<span class="k">def</span> <span class="nf">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">Completion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;text-davinci-002&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
        <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">stop</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="c1"># Traditional sentiment analysis</span>
<span class="k">def</span> <span class="nf">simple_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="s2">&quot;positive&quot;</span> <span class="k">if</span> <span class="s2">&quot;good&quot;</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;great&quot;</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;negative&quot;</span>

<span class="c1"># LLM-based analysis</span>
<span class="k">def</span> <span class="nf">llm_sentiment_analysis</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Analyze the sentiment of the following text. Provide the sentiment (positive/negative/neutral) and a brief explanation.</span>

<span class="s2">    Text: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="s2">    Sentiment analysis:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;The new policy has some good points, but overall it&#39;s disappointing.&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Traditional sentiment:&quot;</span><span class="p">,</span> <span class="n">simple_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">LLM sentiment analysis:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">llm_sentiment_analysis</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">LLM text rewriting (changing sentiment):&quot;</span><span class="p">)</span>
<span class="n">rewrite_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Rewrite the following text to make it more positive: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">&quot;&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gpt3_completion</span><span class="p">(</span><span class="n">rewrite_prompt</span><span class="p">))</span>
</pre></div>
</div>
<p>This example illustrates how a generative LLM can provide more nuanced analysis and even manipulate the text, tasks that are beyond the capabilities of traditional models.</p>
</section>
</section>
<section id="key-components-of-llms">
<h2>2. Key Components of LLMs<a class="headerlink" href="#key-components-of-llms" title="Link to this heading">#</a></h2>
<section id="transformer-architecture">
<h3>Transformer architecture<a class="headerlink" href="#transformer-architecture" title="Link to this heading">#</a></h3>
<p>LLMs are built on the transformer architecture, which uses self-attention mechanisms to process input sequences in parallel, allowing for more efficient training on large datasets.</p>
<div align="center" class="mermaid align-center">
            graph TD
    A[Transformer Architecture] --&gt; B[Self-Attention Mechanism]
    A --&gt; C[Feed-Forward Networks]
    A --&gt; D[Positional Encoding]
    B --&gt; E[Multi-Head Attention]
    C --&gt; F[Non-linear Transformations]
    D --&gt; G[Sequence Order Information]
        </div>
        </section>
<section id="self-attention-mechanism">
<h3>Self-attention mechanism<a class="headerlink" href="#self-attention-mechanism" title="Link to this heading">#</a></h3>
<p>Self-attention allows the model to weigh the importance of different words in a sentence when processing each word, capturing long-range dependencies in text.</p>
<p>Example: In the sentence “The animal didn’t cross the street because it was too wide,” self-attention helps the model understand that “it” refers to “the street” and not “the animal.”</p>
<p>Here’s a simplified implementation of self-attention in Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">self_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="c1"># Compute attention scores</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Apply softmax to get attention weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Compute weighted sum of values</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span>

<span class="c1"># Example usage</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">query</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

<span class="n">attention_output</span> <span class="o">=</span> <span class="n">self_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Self-attention output shape:&quot;</span><span class="p">,</span> <span class="n">attention_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Self-attention output:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">attention_output</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="scaled-up-training-on-massive-datasets">
<h3>Scaled-up training on massive datasets<a class="headerlink" href="#scaled-up-training-on-massive-datasets" title="Link to this heading">#</a></h3>
<p>LLMs are trained on enormous text corpora, often containing hundreds of billions of words from diverse sources like websites, books, and articles. This extensive training allows them to capture a wide range of language patterns and world knowledge.</p>
</section>
</section>
<section id="notable-examples-of-llms">
<h2>3. Notable Examples of LLMs<a class="headerlink" href="#notable-examples-of-llms" title="Link to this heading">#</a></h2>
<section id="gpt-generative-pre-trained-transformer-series">
<h3>GPT (Generative Pre-trained Transformer) series<a class="headerlink" href="#gpt-generative-pre-trained-transformer-series" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>GPT-3: 175 billion parameters, capable of generating human-like text across various domains</p></li>
<li><p>GPT-4: Latest iteration with multimodal capabilities (text and image input)</p></li>
</ul>
</section>
<section id="bert-and-its-variants">
<h3>BERT and its variants<a class="headerlink" href="#bert-and-its-variants" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>BERT (Bidirectional Encoder Representations from Transformers): Focuses on understanding context from both directions in a sentence</p></li>
<li><p>RoBERTa, ALBERT: Improved versions of BERT with different training strategies</p></li>
</ul>
</section>
<section id="other-prominent-models">
<h3>Other prominent models<a class="headerlink" href="#other-prominent-models" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>T5 (Text-to-Text Transfer Transformer): Frames all NLP tasks as text-to-text problems</p></li>
<li><p>DALL-E: Generates images from text descriptions</p></li>
</ul>
<p>Let’s demonstrate the use of a pre-trained BERT model for a simple classification task:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Load pre-trained model and tokenizer</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-uncased&#39;</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">classify_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Tokenize and encode the text</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

    <span class="c1"># Make prediction</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
        <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="s2">&quot;Positive&quot;</span> <span class="k">if</span> <span class="n">predicted_class</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;Negative&quot;</span>

<span class="c1"># Example usage</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;This new technology has the potential to revolutionize the industry.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classification: </span><span class="si">{</span><span class="n">classify_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="capabilities-of-llms-in-social-science-contexts">
<h2>4. Capabilities of LLMs in Social Science Contexts<a class="headerlink" href="#capabilities-of-llms-in-social-science-contexts" title="Link to this heading">#</a></h2>
<p>LLMs offer a wide range of capabilities that are particularly relevant to social science research:</p>
<div align="center" class="mermaid align-center">
            graph TD
    A[LLM Capabilities] --&gt; B[Text Generation]
    A --&gt; C[Text Completion]
    A --&gt; D[Question Answering]
    A --&gt; E[Summarization]
    A --&gt; F[Translation]
    A --&gt; G[Sentiment Analysis]
    A --&gt; H[Topic Modeling]
        </div>
        <section id="text-generation-and-completion">
<h3>Text generation and completion<a class="headerlink" href="#text-generation-and-completion" title="Link to this heading">#</a></h3>
<p>LLMs can generate coherent paragraphs or complete partial text, useful for creating research hypotheses or expanding on ideas.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_research_hypothesis</span><span class="p">(</span><span class="n">topic</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Generate a research hypothesis about the following topic: </span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">topic</span> <span class="o">=</span> <span class="s2">&quot;The impact of social media on political polarization&quot;</span>
<span class="n">hypothesis</span> <span class="o">=</span> <span class="n">generate_research_hypothesis</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated hypothesis: </span><span class="si">{</span><span class="n">hypothesis</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="question-answering-and-information-retrieval">
<h3>Question answering and information retrieval<a class="headerlink" href="#question-answering-and-information-retrieval" title="Link to this heading">#</a></h3>
<p>LLMs can understand and answer complex questions, making them valuable for literature reviews or data exploration.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">answer_question</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">question</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Context: </span><span class="si">{</span><span class="n">context</span><span class="si">}</span>

<span class="s2">    Question: </span><span class="si">{</span><span class="n">question</span><span class="si">}</span>

<span class="s2">    Answer:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="s2">&quot;The gender wage gap refers to the difference in earnings between men and women in the workforce. Despite progress in recent decades, a significant gap still exists in many countries.&quot;</span>
<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;What are some factors contributing to the persistence of the gender wage gap?&quot;</span>

<span class="n">answer</span> <span class="o">=</span> <span class="n">answer_question</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">question</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Answer: </span><span class="si">{</span><span class="n">answer</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="summarization-and-paraphrasing">
<h3>Summarization and paraphrasing<a class="headerlink" href="#summarization-and-paraphrasing" title="Link to this heading">#</a></h3>
<p>LLMs can condense long texts or rephrase content, useful for processing large volumes of research papers or interview transcripts.</p>
</section>
<section id="translation-and-cross-lingual-tasks">
<h3>Translation and cross-lingual tasks<a class="headerlink" href="#translation-and-cross-lingual-tasks" title="Link to this heading">#</a></h3>
<p>These models can translate between languages and perform analysis across multiple languages, facilitating international research.</p>
</section>
<section id="sentiment-analysis-and-emotion-detection">
<h3>Sentiment analysis and emotion detection<a class="headerlink" href="#sentiment-analysis-and-emotion-detection" title="Link to this heading">#</a></h3>
<p>LLMs can identify and explain complex emotions and sentiments in text, going beyond simple positive/negative classifications.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">analyze_emotion</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Analyze the emotional content of the following text. Identify the primary emotion and explain why.</span>

<span class="s2">    Text: &quot;</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="s2">    Emotion analysis:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;After months of hard work, I finally received the grant for my research project. I couldn&#39;t believe it at first, but now I&#39;m thrilled and a bit overwhelmed.&quot;</span>
<span class="n">emotion_analysis</span> <span class="o">=</span> <span class="n">analyze_emotion</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">emotion_analysis</span><span class="p">)</span>
</pre></div>
</div>
<p>These capabilities make LLMs powerful tools for social science researchers, enabling them to process and analyze large volumes of textual data, generate insights, and explore complex social phenomena in ways that were previously impractical or impossible.</p>
<p>In the next sections, we’ll delve deeper into how these models are trained, their advantages and limitations, and the ethical considerations surrounding their use in social science research.</p>
</section>
</section>
<section id="training-process-of-llms">
<h2>5. Training Process of LLMs<a class="headerlink" href="#training-process-of-llms" title="Link to this heading">#</a></h2>
<p>The training process of Large Language Models is a complex and computationally intensive task that involves several key steps:</p>
<div align="center" class="mermaid align-center">
            graph TD
    A[LLM Training Process] --&gt; B[Pre-training on large corpora]
    A --&gt; C[Fine-tuning for specific tasks]
    B --&gt; D[Unsupervised learning]
    B --&gt; E[Masked language modeling]
    C --&gt; F[Supervised learning]
    C --&gt; G[Transfer learning]
    A --&gt; H[Few-shot learning]
    A --&gt; I[Zero-shot learning]
        </div>
        <section id="pre-training-on-large-corpora">
<h3>Pre-training on large corpora<a class="headerlink" href="#pre-training-on-large-corpora" title="Link to this heading">#</a></h3>
<p>LLMs are initially trained on diverse text data to learn general language patterns and knowledge. This pre-training phase typically uses unsupervised learning techniques such as masked language modeling or next token prediction.</p>
<p>Example of a simple masked language model using PyTorch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">SimpleMaskedLanguageModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMaskedLanguageModel</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

<span class="c1"># Simulate input (batch_size=2, sequence_length=10)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shape:&quot;</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="fine-tuning-for-specific-tasks">
<h3>Fine-tuning for specific tasks<a class="headerlink" href="#fine-tuning-for-specific-tasks" title="Link to this heading">#</a></h3>
<p>Pre-trained models can be further trained on domain-specific data to adapt to particular research areas or tasks. This process, known as fine-tuning, allows researchers to leverage the general knowledge learned during pre-training while specializing the model for their specific needs.</p>
<p>Example of fine-tuning a pre-trained BERT model for sentiment analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Load pre-trained model and tokenizer</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-base-uncased&#39;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># Prepare your dataset (simplified example)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I love this product&quot;</span><span class="p">,</span> <span class="s2">&quot;This is terrible&quot;</span><span class="p">,</span> <span class="s2">&quot;Great experience&quot;</span><span class="p">,</span> <span class="s2">&quot;Very disappointing&quot;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># 1 for positive, 0 for negative</span>

<span class="c1"># Tokenize and encode the dataset</span>
<span class="n">encoded_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">encoded_data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">encoded_data</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># Create DataLoader</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Fine-tuning</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>  <span class="c1"># Number of epochs</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fine-tuning completed&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="few-shot-and-zero-shot-learning-capabilities">
<h3>Few-shot and zero-shot learning capabilities<a class="headerlink" href="#few-shot-and-zero-shot-learning-capabilities" title="Link to this heading">#</a></h3>
<p>LLMs can perform tasks with minimal (few-shot) or no (zero-shot) specific examples, adapting to new scenarios based on their general language understanding.</p>
<p>Example of zero-shot classification using GPT-3:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">zero_shot_classification</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">categories</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Classify the following text into one of these categories: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">categories</span><span class="p">)</span><span class="si">}</span><span class="s2">.</span>

<span class="s2">    Text: </span><span class="si">{</span><span class="n">text</span><span class="si">}</span>

<span class="s2">    Category:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;The new economic policy has led to a significant increase in foreign investment.&quot;</span>
<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Politics&quot;</span><span class="p">,</span> <span class="s2">&quot;Economics&quot;</span><span class="p">,</span> <span class="s2">&quot;Technology&quot;</span><span class="p">,</span> <span class="s2">&quot;Sports&quot;</span><span class="p">]</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">zero_shot_classification</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">categories</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Classified category: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="advantages-of-llms-in-social-science-research">
<h2>6. Advantages of LLMs in Social Science Research<a class="headerlink" href="#advantages-of-llms-in-social-science-research" title="Link to this heading">#</a></h2>
<p>LLMs offer several key advantages for social science researchers:</p>
<section id="handling-complex-language-understanding-tasks">
<h3>Handling complex language understanding tasks<a class="headerlink" href="#handling-complex-language-understanding-tasks" title="Link to this heading">#</a></h3>
<p>LLMs can grasp nuanced meanings, idiomatic expressions, and context-dependent interpretations, which is crucial for analyzing complex social phenomena.</p>
<p>Example of analyzing a complex social concept:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">analyze_social_concept</span><span class="p">(</span><span class="n">concept</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Provide a comprehensive analysis of the social concept: &quot;</span><span class="si">{</span><span class="n">concept</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="s2">    Include:</span>
<span class="s2">    1. Definition</span>
<span class="s2">    2. Historical context</span>
<span class="s2">    3. Current relevance</span>
<span class="s2">    4. Controversies or debates</span>
<span class="s2">    5. Implications for social research</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="n">concept</span> <span class="o">=</span> <span class="s2">&quot;Intersectionality&quot;</span>
<span class="n">analysis</span> <span class="o">=</span> <span class="n">analyze_social_concept</span><span class="p">(</span><span class="n">concept</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">analysis</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="ability-to-generate-human-like-text">
<h3>Ability to generate human-like text<a class="headerlink" href="#ability-to-generate-human-like-text" title="Link to this heading">#</a></h3>
<p>This capability is useful for creating synthetic data, formulating research questions, or generating interview questions.</p>
<p>Example of generating research questions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_research_questions</span><span class="p">(</span><span class="n">topic</span><span class="p">,</span> <span class="n">num_questions</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Generate </span><span class="si">{</span><span class="n">num_questions</span><span class="si">}</span><span class="s2"> research questions for a study on the following topic:</span>
<span class="s2">    &quot;</span><span class="si">{</span><span class="n">topic</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="s2">    Research questions:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="n">topic</span> <span class="o">=</span> <span class="s2">&quot;The impact of social media on political participation among young adults&quot;</span>
<span class="n">questions</span> <span class="o">=</span> <span class="n">generate_research_questions</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">questions</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="adaptability-to-various-domains-and-tasks">
<h3>Adaptability to various domains and tasks<a class="headerlink" href="#adaptability-to-various-domains-and-tasks" title="Link to this heading">#</a></h3>
<p>A single LLM can be applied to multiple research areas, from analyzing historical texts to coding contemporary social media posts.</p>
</section>
</section>
<section id="limitations-and-challenges">
<h2>7. Limitations and Challenges<a class="headerlink" href="#limitations-and-challenges" title="Link to this heading">#</a></h2>
<p>Despite their power, LLMs also have significant limitations that researchers must be aware of:</p>
<section id="potential-biases-in-training-data">
<h3>Potential biases in training data<a class="headerlink" href="#potential-biases-in-training-data" title="Link to this heading">#</a></h3>
<p>LLMs may perpetuate or amplify biases present in their training data, requiring careful scrutiny in social science applications.</p>
<p>Example of checking for gender bias:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">check_gender_bias</span><span class="p">(</span><span class="n">profession</span><span class="p">):</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    Complete the following sentences:</span>
<span class="s2">    1. The </span><span class="si">{</span><span class="n">profession</span><span class="si">}</span><span class="s2"> walked into the room. He</span>
<span class="s2">    2. The </span><span class="si">{</span><span class="n">profession</span><span class="si">}</span><span class="s2"> walked into the room. She</span>

<span class="s2">    Completions:</span>
<span class="s2">    &quot;&quot;&quot;</span>
    <span class="n">completions</span> <span class="o">=</span> <span class="n">gpt3_completion</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">completions</span>

<span class="n">profession</span> <span class="o">=</span> <span class="s2">&quot;doctor&quot;</span>
<span class="n">bias_check</span> <span class="o">=</span> <span class="n">check_gender_bias</span><span class="p">(</span><span class="n">profession</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bias_check</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lack-of-true-understanding-or-reasoning">
<h3>Lack of true understanding or reasoning<a class="headerlink" href="#lack-of-true-understanding-or-reasoning" title="Link to this heading">#</a></h3>
<p>Despite their sophisticated outputs, LLMs don’t truly “understand” text in a human sense and may produce plausible-sounding but incorrect information.</p>
</section>
<section id="computational-resources-required">
<h3>Computational resources required<a class="headerlink" href="#computational-resources-required" title="Link to this heading">#</a></h3>
<p>Training and running large LLMs require significant computational power, which may be a barrier for some researchers.</p>
</section>
<section id="ethical-considerations-in-deployment">
<h3>Ethical considerations in deployment<a class="headerlink" href="#ethical-considerations-in-deployment" title="Link to this heading">#</a></h3>
<p>Issues of privacy, consent, and the potential for misuse need to be carefully considered when applying LLMs to social science research.</p>
</section>
</section>
<section id="recent-advancements">
<h2>8. Recent Advancements<a class="headerlink" href="#recent-advancements" title="Link to this heading">#</a></h2>
<p>The field of LLMs is rapidly evolving, with several recent advancements:</p>
<section id="improvements-in-model-size-and-efficiency">
<h3>Improvements in model size and efficiency<a class="headerlink" href="#improvements-in-model-size-and-efficiency" title="Link to this heading">#</a></h3>
<p>Newer models achieve better performance with fewer parameters, making them more accessible for research use.</p>
</section>
<section id="enhanced-multi-modal-capabilities">
<h3>Enhanced multi-modal capabilities<a class="headerlink" href="#enhanced-multi-modal-capabilities" title="Link to this heading">#</a></h3>
<p>Some LLMs can now process and generate both text and images, opening new possibilities for analyzing visual social media content or historical artifacts.</p>
</section>
<section id="progress-in-mitigating-biases-and-improving-factual-accuracy">
<h3>Progress in mitigating biases and improving factual accuracy<a class="headerlink" href="#progress-in-mitigating-biases-and-improving-factual-accuracy" title="Link to this heading">#</a></h3>
<p>Ongoing research aims to reduce biases and increase the reliability of LLM outputs, crucial for their use in academic research.</p>
</section>
</section>
<section id="future-directions">
<h2>9. Future Directions<a class="headerlink" href="#future-directions" title="Link to this heading">#</a></h2>
<p>Looking ahead, several trends are likely to shape the future of LLMs in social science research:</p>
<section id="integration-with-domain-specific-knowledge">
<h3>Integration with domain-specific knowledge<a class="headerlink" href="#integration-with-domain-specific-knowledge" title="Link to this heading">#</a></h3>
<p>Future LLMs may better integrate factual knowledge and understanding of specific social science domains, improving their reliability for research applications.</p>
</section>
<section id="improved-interpretability-and-transparency">
<h3>Improved interpretability and transparency<a class="headerlink" href="#improved-interpretability-and-transparency" title="Link to this heading">#</a></h3>
<p>Ongoing research aims to make LLM decision-making processes more transparent, allowing researchers to better understand and validate their outputs.</p>
<p>In conclusion, LLMs represent a powerful tool for social science researchers, offering unprecedented capabilities in text analysis and generation. However, their use also requires careful consideration of their limitations and ethical implications. As the field continues to evolve, researchers must stay informed about the latest developments and best practices to effectively leverage these technologies in their work while maintaining the integrity and responsibility of their research.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "entelecheia/nlp4ss",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./session01"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
    <div class="giscus"></div>
<script src="https://giscus.app/client.js"        data-repo="entelecheia/nlp4ss"        data-repo-id="R_kgDOMTcakg"        data-category="Q&A"        data-category-id="DIC_kwDOMTcaks4Cgwzd"        data-mapping="pathname"        data-strict="1"        data-reactions-enabled="1"        data-emit-metadata="1"        data-input-position="bottom"        data-theme="noborder_light"        data-lang="en"        data-loading="lazy"        crossorigin="anonymous"        async></script>
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="lecture1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">1.1 Fundamentals of NLP and its Evolution</p>
      </div>
    </a>
    <a class="right-next"
       href="lecture3.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">1.3 Ethical Considerations and Challenges in Using LLMs for Research</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-generative-llms">1. Introduction to Generative LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definition-and-core-concept">Definition and core concept</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distinction-from-traditional-nlp-models">Distinction from traditional NLP models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-components-of-llms">2. Key Components of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transformer-architecture">Transformer architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#self-attention-mechanism">Self-attention mechanism</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-up-training-on-massive-datasets">Scaled-up training on massive datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notable-examples-of-llms">3. Notable Examples of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-generative-pre-trained-transformer-series">GPT (Generative Pre-trained Transformer) series</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-and-its-variants">BERT and its variants</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-prominent-models">Other prominent models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities-of-llms-in-social-science-contexts">4. Capabilities of LLMs in Social Science Contexts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-generation-and-completion">Text generation and completion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering-and-information-retrieval">Question answering and information retrieval</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summarization-and-paraphrasing">Summarization and paraphrasing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#translation-and-cross-lingual-tasks">Translation and cross-lingual tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis-and-emotion-detection">Sentiment analysis and emotion detection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-process-of-llms">5. Training Process of LLMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-on-large-corpora">Pre-training on large corpora</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-for-specific-tasks">Fine-tuning for specific tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-and-zero-shot-learning-capabilities">Few-shot and zero-shot learning capabilities</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages-of-llms-in-social-science-research">6. Advantages of LLMs in Social Science Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-complex-language-understanding-tasks">Handling complex language understanding tasks</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ability-to-generate-human-like-text">Ability to generate human-like text</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptability-to-various-domains-and-tasks">Adaptability to various domains and tasks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-and-challenges">7. Limitations and Challenges</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#potential-biases-in-training-data">Potential biases in training data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lack-of-true-understanding-or-reasoning">Lack of true understanding or reasoning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-resources-required">Computational resources required</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ethical-considerations-in-deployment">Ethical considerations in deployment</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recent-advancements">8. Recent Advancements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improvements-in-model-size-and-efficiency">Improvements in model size and efficiency</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#enhanced-multi-modal-capabilities">Enhanced multi-modal capabilities</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#progress-in-mitigating-biases-and-improving-factual-accuracy">Progress in mitigating biases and improving factual accuracy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#future-directions">9. Future Directions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-domain-specific-knowledge">Integration with domain-specific knowledge</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improved-interpretability-and-transparency">Improved interpretability and transparency</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Young Joon Lee
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
