Search.setIndex({"alltitles": {"1. Introduction": [[13, "introduction"]], "1. Introduction to Ethics in AI and NLP Research": [[5, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Few-shot Learning": [[12, "introduction-to-few-shot-learning"]], "1. Introduction to Figurative Language": [[17, "introduction-to-figurative-language"]], "1. Introduction to Fundamental NLP Tasks": [[8, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[4, "introduction-to-generative-llms"]], "1. Introduction to Large-Scale Text Analysis": [[19, "introduction-to-large-scale-text-analysis"]], "1. Introduction to Natural Language Processing (NLP)": [[3, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Social Bias in NLP": [[16, "introduction-to-social-bias-in-nlp"]], "1. Introduction to Text Generation with LLMs": [[15, "introduction-to-text-generation-with-llms"]], "1. Introduction to Text Preprocessing": [[7, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[9, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[11, "introduction-to-zero-shot-learning"]], "1.1 Definition of NLP": [[3, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[3, "fundamentals-of-nlp-and-its-evolution"]], "1.1 Fundamentals of Natural Language Processing and its evolution": [[22, "fundamentals-of-natural-language-processing-and-its-evolution"]], "1.2 Basic Concepts": [[3, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[4, "overview-of-generative-llms"]], "1.2 Overview of Generative Large Language Models (LLMs)": [[22, "overview-of-generative-large-language-models-llms"]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[5, "ethical-considerations-and-challenges-in-using-llms-for-research"], [22, "ethical-considerations-and-challenges-in-using-llms-for-research"]], "1.3 Importance in Social Science Research": [[3, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[9, "applications-in-social-science-research"], [11, "applications-in-social-science-research"]], "10. Computational Efficiency and Resource Requirements": [[13, "computational-efficiency-and-resource-requirements"]], "10. Current State and Future Directions": [[3, "current-state-and-future-directions"]], "10. Evaluation Metrics for Figurative Language Processing": [[17, "evaluation-metrics-for-figurative-language-processing"]], "10. Evaluation of Generated Text": [[15, "evaluation-of-generated-text"]], "10. Few-shot Text Generation and Summarization": [[12, "few-shot-text-generation-and-summarization"]], "10. Future Directions": [[4, "future-directions"]], "10. Responsible Development and Deployment": [[5, "responsible-development-and-deployment"]], "10.1 Ongoing Developments in LLMs": [[3, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[3, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations": [[17, "challenges-and-limitations"]], "11. Challenges and Limitations of LDA": [[9, "challenges-and-limitations-of-lda"]], "11. Few-shot Question Answering and Information Extraction": [[12, "few-shot-question-answering-and-information-extraction"]], "11. Future Challenges and Opportunities": [[5, "future-challenges-and-opportunities"]], "11. Scalability and Adaptability": [[13, "scalability-and-adaptability"]], "12. Combining Topic Modeling with Other NLP Techniques": [[9, "combining-topic-modeling-with-other-nlp-techniques"]], "12. Interpretability and Explainability": [[13, "interpretability-and-explainability"]], "12. Prompt Optimization Techniques": [[12, "prompt-optimization-techniques"]], "13. Future Directions in Topic Modeling": [[9, "future-directions-in-topic-modeling"]], "2. Bias in LLMs": [[5, "bias-in-llms"]], "2. Cultural Context in Figurative Language": [[17, "cultural-context-in-figurative-language"]], "2. Data Sources for Large-Scale Text Analysis": [[19, "data-sources-for-large-scale-text-analysis"]], "2. Few-shot Learning Capabilities of LLMs": [[12, "few-shot-learning-capabilities-of-llms"]], "2. Fundamentals of LLM-based Text Generation": [[15, "fundamentals-of-llm-based-text-generation"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[9, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Historical Perspective of NLP": [[3, "historical-perspective-of-nlp"]], "2. Key Components of LLMs": [[4, "key-components-of-llms"]], "2. Recap of Traditional Supervised Learning": [[13, "recap-of-traditional-supervised-learning"]], "2. Sources of Bias in LLMs": [[16, "sources-of-bias-in-llms"]], "2. Text Classification": [[8, "text-classification"]], "2. Text Cleaning": [[7, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[11, "theoretical-foundations-of-zero-shot-learning"]], "2.1 Early Approaches (1950s-1980s)": [[3, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[7, "text-cleaning-normalization-and-representation"], [22, "text-cleaning-normalization-and-representation"]], "2.2 Basic NLP Tasks": [[8, "basic-nlp-tasks"], [22, "basic-nlp-tasks"]], "2.2 Statistical Revolution (1980s-2000s)": [[3, "statistical-revolution-1980s-2000s"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[9, "topic-modeling-and-latent-dirichlet-allocation-lda"], [22, "topic-modeling-and-latent-dirichlet-allocation-lda"]], "3. Data Collection and Preprocessing for Large Datasets": [[19, "data-collection-and-preprocessing-for-large-datasets"]], "3. LLM Approaches in Comparison": [[13, "llm-approaches-in-comparison"]], "3. LLMs and Figurative Language Understanding": [[17, "llms-and-figurative-language-understanding"]], "3. Lowercase Conversion": [[7, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[9, "mathematical-foundation-of-lda"]], "3. Notable Examples of LLMs": [[4, "notable-examples-of-llms"]], "3. Privacy Concerns": [[5, "privacy-concerns"]], "3. Sentiment Analysis": [[8, "sentiment-analysis"]], "3. Techniques for Detecting Bias in LLMs": [[16, "techniques-for-detecting-bias-in-llms"]], "3. Traditional NLP Pipeline": [[3, "traditional-nlp-pipeline"]], "3. Types of Few-shot Learning": [[12, "types-of-few-shot-learning"]], "3. Types of Text Generation Tasks": [[15, "types-of-text-generation-tasks"]], "3. Zero-shot Capabilities of LLMs": [[11, "zero-shot-capabilities-of-llms"]], "3.1 Text Preprocessing": [[3, "text-preprocessing"]], "3.1 Zero-shot Learning with LLMs": [[11, "zero-shot-learning-with-llms"], [22, "zero-shot-learning-with-llms"]], "3.2 Feature Extraction": [[3, "feature-extraction"]], "3.2 Few-shot Learning and Prompt Engineering": [[12, "few-shot-learning-and-prompt-engineering"], [22, "few-shot-learning-and-prompt-engineering"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[13, "comparing-llm-performance-with-traditional-supervised-learning"], [22, "comparing-llm-performance-with-traditional-supervised-learning"]], "3.3 Model Training and Evaluation": [[3, "model-training-and-evaluation"]], "4. Capabilities of LLMs in Social Science Contexts": [[4, "capabilities-of-llms-in-social-science-contexts"]], "4. Challenges in Traditional NLP": [[3, "challenges-in-traditional-nlp"]], "4. Evaluation Metrics and Methodologies": [[13, "evaluation-metrics-and-methodologies"]], "4. Fundamentals of Prompt Engineering": [[12, "fundamentals-of-prompt-engineering"]], "4. LDA Algorithm": [[9, "lda-algorithm"]], "4. Metaphor Detection and Interpretation": [[17, "metaphor-detection-and-interpretation"]], "4. Named Entity Recognition (NER)": [[8, "named-entity-recognition-ner"]], "4. Prompt Engineering for Text Generation": [[15, "prompt-engineering-for-text-generation"]], "4. Prompt Engineering for Zero-shot Tasks": [[11, "prompt-engineering-for-zero-shot-tasks"]], "4. Quantifying Bias in LLMs": [[16, "quantifying-bias-in-llms"]], "4. Scalable Text Processing Techniques": [[19, "scalable-text-processing-techniques"]], "4. Tokenization": [[7, "tokenization"]], "4. Transparency and Interpretability": [[5, "transparency-and-interpretability"]], "4.1 Handling Language Ambiguity": [[3, "handling-language-ambiguity"]], "4.1 Using LLMs for High-Quality Text Generation": [[15, "using-llms-for-high-quality-text-generation"], [22, "using-llms-for-high-quality-text-generation"]], "4.2 Dealing with Context and Semantics": [[3, "dealing-with-context-and-semantics"]], "4.2 Social Bias Inference and Analysis": [[16, "social-bias-inference-and-analysis"], [22, "social-bias-inference-and-analysis"]], "4.3 Computational Complexity": [[3, "computational-complexity"]], "4.3 Figurative Language Explanation and Cultural Context": [[17, "figurative-language-explanation-and-cultural-context"], [22, "figurative-language-explanation-and-cultural-context"]], "5. Controlling Generation Parameters": [[15, "controlling-generation-parameters"]], "5. Evolution Towards Modern NLP": [[3, "evolution-towards-modern-nlp"]], "5. Idiom Processing with LLMs": [[17, "idiom-processing-with-llms"]], "5. Part-of-Speech (POS) Tagging": [[8, "part-of-speech-pos-tagging"]], "5. Performance Comparison in Classification Tasks": [[13, "performance-comparison-in-classification-tasks"]], "5. Preparing Data for LDA": [[9, "preparing-data-for-lda"]], "5. Prompt Design Strategies": [[12, "prompt-design-strategies"]], "5. Reliability and Reproducibility": [[5, "reliability-and-reproducibility"]], "5. Social Bias Inference Using LLMs": [[16, "social-bias-inference-using-llms"]], "5. Stop Word Removal": [[7, "stop-word-removal"]], "5. Topic Modeling at Scale": [[19, "topic-modeling-at-scale"]], "5. Training Process of LLMs": [[4, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[11, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[19, "analyzing-large-scale-textual-data"], [22, "analyzing-large-scale-textual-data"]], "5.1 Introduction of Word Embeddings": [[3, "introduction-of-word-embeddings"]], "5.2 Misinformation and Fake News Detection": [[20, "misinformation-and-fake-news-detection"], [22, "misinformation-and-fake-news-detection"]], "5.2 Rise of Deep Learning in NLP": [[3, "rise-of-deep-learning-in-nlp"]], "5.3 Future Directions and Emerging Trends": [[21, "future-directions-and-emerging-trends"], [22, "future-directions-and-emerging-trends"]], "6. Advantages of LLMs in Social Science Research": [[4, "advantages-of-llms-in-social-science-research"]], "6. Analyzing Gender Bias": [[16, "analyzing-gender-bias"]], "6. Aspect-based Emotion Summarization": [[15, "aspect-based-emotion-summarization"]], "6. Comparing Text Generation Capabilities": [[13, "comparing-text-generation-capabilities"]], "6. Emergence of Transformer Models": [[3, "emergence-of-transformer-models"]], "6. Implementing LDA": [[9, "implementing-lda"]], "6. In-context Learning": [[12, "in-context-learning"]], "6. Intellectual Property and Attribution": [[5, "intellectual-property-and-attribution"]], "6. Large-Scale Sentiment Analysis": [[19, "large-scale-sentiment-analysis"]], "6. Sarcasm and Irony Detection": [[17, "sarcasm-and-irony-detection"]], "6. Stemming": [[7, "stemming"]], "6. Text Summarization": [[8, "text-summarization"]], "6. Zero-shot Named Entity Recognition (NER)": [[11, "zero-shot-named-entity-recognition-ner"]], "6.1 Key Concepts": [[3, "key-concepts"]], "6.2 Breakthrough Models": [[3, "breakthrough-models"]], "7. Environmental and Resource Considerations": [[5, "environmental-and-resource-considerations"]], "7. Few-shot Classification Techniques": [[12, "few-shot-classification-techniques"]], "7. Figurative Language in Social Media Analysis": [[17, "figurative-language-in-social-media-analysis"]], "7. Interpreting LDA Results": [[9, "interpreting-lda-results"]], "7. Large Language Models (LLMs)": [[3, "large-language-models-llms"]], "7. Lemmatization": [[7, "lemmatization"]], "7. Limitations and Challenges": [[4, "limitations-and-challenges"]], "7. Misinformation Explanation Generation": [[15, "misinformation-explanation-generation"]], "7. Named Entity Recognition (NER) Performance": [[13, "named-entity-recognition-ner-performance"]], "7. Named Entity Recognition and Relation Extraction": [[19, "named-entity-recognition-and-relation-extraction"]], "7. Racial and Ethnic Bias Analysis": [[16, "racial-and-ethnic-bias-analysis"]], "7. Text Similarity and Clustering": [[8, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[11, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[3, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[3, "examples-and-their-impact"]], "8. Challenges and Limitations": [[8, "challenges-and-limitations"]], "8. Evaluating Topic Models": [[9, "evaluating-topic-models"]], "8. Few-shot Named Entity Recognition (NER)": [[12, "few-shot-named-entity-recognition-ner"]], "8. High-Quality Content Creation": [[15, "high-quality-content-creation"]], "8. Mitigating Bias in LLMs": [[16, "mitigating-bias-in-llms"]], "8. Paradigm Shift in NLP Tasks": [[3, "paradigm-shift-in-nlp-tasks"]], "8. Proverbs and Cultural Wisdom": [[17, "proverbs-and-cultural-wisdom"]], "8. Recent Advancements": [[4, "recent-advancements"]], "8. Sentiment Analysis and Opinion Mining": [[13, "sentiment-analysis-and-opinion-mining"]], "8. Socioeconomic Implications": [[5, "socioeconomic-implications"]], "8. Text Classification and Categorization": [[19, "text-classification-and-categorization"]], "8. Text Representation Techniques": [[7, "text-representation-techniques"]], "8. Zero-shot Text Summarization and Generation": [[11, "zero-shot-text-summarization-and-generation"]], "8.1 From Task-Specific to General-Purpose Models": [[3, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[3, "few-shot-and-zero-shot-learning"]], "9. Advanced Topic Modeling Techniques": [[9, "advanced-topic-modeling-techniques"]], "9. Applications in Social Science": [[4, "applications-in-social-science"]], "9. Data Augmentation for Social Science Research": [[15, "data-augmentation-for-social-science-research"]], "9. Ethical Considerations and Challenges": [[16, "ethical-considerations-and-challenges"]], "9. Evaluation and Interpretation": [[8, "evaluation-and-interpretation"]], "9. Few-shot Sentiment Analysis and Opinion Mining": [[12, "few-shot-sentiment-analysis-and-opinion-mining"]], "9. Figurative Language in Political Discourse": [[17, "figurative-language-in-political-discourse"]], "9. Impact on Social Science Research": [[3, "impact-on-social-science-research"]], "9. Information Extraction and Relation Classification": [[13, "information-extraction-and-relation-classification"]], "9. Informed Consent and Participant Rights": [[5, "informed-consent-and-participant-rights"]], "9. Zero-shot Question Answering and Information Extraction": [[11, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[3, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[3, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[4, "ability-to-generate-human-like-text"]], "About": [[1, null]], "Access disparities to LLM technologies": [[5, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[4, "adaptability-to-various-domains-and-tasks"]], "Analyzing large-scale textual data": [[4, "analyzing-large-scale-textual-data"]], "BERT and its variants": [[4, "bert-and-its-variants"]], "Bag-of-Words (BoW) model": [[7, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[5, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[5, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[5, "challenges-in-explaining-model-decisions"]], "Changelog": [[1, "changelog"]], "Computational resources required": [[4, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[5, "computational-resources-required-for-training-and-using-llms"]], "Conclusion": [[12, "conclusion"], [13, "conclusion"], [15, "conclusion"], [16, "conclusion"], [17, "conclusion"], [19, "conclusion"]], "Considerations for global and cross-cultural research": [[5, "considerations-for-global-and-cross-cultural-research"]], "Continuous monitoring and evaluation of ethical implications": [[5, "continuous-monitoring-and-evaluation-of-ethical-implications"]], "Contributing": [[1, "contributing"]], "Copyright issues with training data and generated content": [[5, "copyright-issues-with-training-data-and-generated-content"]], "Course Objectives": [[1, "course-objectives"]], "Course Overview": [[1, "course-overview"]], "Course Structure": [[1, "course-structure"]], "Data annotation and classification": [[4, "data-annotation-and-classification"]], "Data protection and compliance with privacy regulations": [[5, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[7, "dealing-with-numbers-and-dates"]], "Definition and core concept": [[4, "definition-and-core-concept"]], "Disclosure of AI involvement in research studies": [[5, "disclosure-of-ai-involvement-in-research-studies"]], "Distinction from traditional NLP models": [[4, "distinction-from-traditional-nlp-models"]], "Emerging ethical issues with advancing LLM capabilities": [[5, "emerging-ethical-issues-with-advancing-llm-capabilities"]], "Enhanced multi-modal capabilities": [[4, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[5, "environmental-impact-of-large-scale-ai-models"]], "Ethical Considerations": [[14, "ethical-considerations"]], "Ethical considerations in deployment": [[4, "ethical-considerations-in-deployment"]], "Ethical considerations in model development and fine-tuning": [[5, "ethical-considerations-in-model-development-and-fine-tuning"]], "Ethical considerations when using LLMs in human subjects research": [[5, "ethical-considerations-when-using-llms-in-human-subjects-research"]], "Example: Document Similarity and Clustering": [[8, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[8, "example-extractive-summarization"]], "Example: Lexicon-based Sentiment Analysis": [[8, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[8, "example-multi-class-classification"]], "Example: NER using spaCy": [[8, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[8, "example-pos-tagging-with-nltk"]], "Few-shot and zero-shot learning capabilities": [[4, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[4, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[4, "gpt-generative-pre-trained-transformer-series"]], "Generating explanations and summaries": [[4, "generating-explanations-and-summaries"]], "Handling URLs and email addresses": [[7, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[4, "handling-complex-language-understanding-tasks"]], "Home": [[1, "home"]], "Impact on research outcomes and societal implications": [[5, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[5, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[5, "importance-of-interpretability-in-scientific-research"]], "Importance of reproducibility in scientific research": [[5, "importance-of-reproducibility-in-scientific-research"]], "Improved interpretability and transparency": [[4, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[4, "improvements-in-model-size-and-efficiency"]], "Inferring social patterns and trends": [[4, "inferring-social-patterns-and-trends"]], "Integration with world knowledge and physical world understanding": [[4, "integration-with-world-knowledge-and-physical-world-understanding"]], "Interdisciplinary collaboration in addressing ethical challenges": [[5, "interdisciplinary-collaboration-in-addressing-ethical-challenges"]], "Issues with hallucination and factual accuracy": [[5, "issues-with-hallucination-and-factual-accuracy"]], "Key Topics We\u2019ll Explore": [[14, "key-topics-we-ll-explore"]], "Lack of true understanding or reasoning": [[4, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[1, null]], "License": [[1, "license"]], "Other prominent models": [[4, "other-prominent-models"]], "Participant rights and data usage in LLM-based research": [[5, "participant-rights-and-data-usage-in-llm-based-research"]], "Plagiarism concerns and academic integrity": [[5, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[4, "potential-biases-in-training-data"]], "Potential for LLMs in promoting ethical research practices": [[5, "potential-for-llms-in-promoting-ethical-research-practices"]], "Potential for personal information exposure in training data": [[5, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[5, "potential-impact-on-research-equity-and-diversity"]], "Practical Applications": [[14, "practical-applications"]], "Pre-training on large corpora": [[4, "pre-training-on-large-corpora"]], "Progress in mitigating biases and improving factual accuracy": [[4, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Proper attribution of AI-generated text in research": [[5, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[4, "question-answering-and-information-retrieval"]], "Removing HTML tags and special characters": [[7, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[7, "removing-or-replacing-emojis-and-emoticons"]], "Responsible use of LLMs in different research contexts": [[5, "responsible-use-of-llms-in-different-research-contexts"]], "Risks of re-identification in generated text": [[5, "risks-of-re-identification-in-generated-text"]], "Scaled-up training on massive datasets": [[4, "scaled-up-training-on-massive-datasets"]], "Self-attention mechanism": [[4, "self-attention-mechanism"]], "Sentence tokenization": [[7, "sentence-tokenization"]], "Sentiment analysis and emotion detection": [[4, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[2, "session-1-introduction-to-nlp-for-social-science"]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[22, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[6, "session-2-traditional-nlp-techniques-and-text-preprocessing"], [22, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[10, "session-3-llms-for-data-annotation-and-classification"], [22, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[14, "session-4-generative-explanations-and-summaries-in-social-science"], [22, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[18, "session-5-advanced-applications-of-llms-in-social-science-research"], [22, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Sources of bias": [[5, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[5, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[5, "strategies-for-validating-llm-generated-results"]], "Summarization and paraphrasing": [[4, "summarization-and-paraphrasing"]], "Syllabus": [[22, "syllabus"]], "Table of Contents": [[1, "table-of-contents"]], "Techniques for improving model transparency": [[5, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[7, "term-frequency-inverse-document-frequency-tf-idf"]], "Text generation and completion": [[4, "text-generation-and-completion"]], "The \u201cblack box\u201d nature of LLMs": [[5, "the-black-box-nature-of-llms"]], "Transformer architecture": [[4, "transformer-architecture"]], "Translation and cross-lingual tasks": [[4, "translation-and-cross-lingual-tasks"]], "Types of bias": [[5, "types-of-bias"]], "Types of classification:": [[8, "types-of-classification"]], "Unique challenges posed by LLMs": [[5, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, "who-made-this-book"]], "Why Generative Explanations and Summaries Matter in Social Science": [[14, "why-generative-explanations-and-summaries-matter-in-social-science"]], "Why This Course Matters": [[1, "why-this-course-matters"]], "Word Embedding Association Test (WEAT)": [[16, "word-embedding-association-test-weat"]], "Word Embeddings": [[7, "word-embeddings"]], "Word tokenization": [[7, "word-tokenization"]]}, "docnames": ["about/index", "index", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19], "0": [1, 8, 9, 11, 12, 13, 15, 16, 17, 19], "002": [11, 12, 13, 17], "04": 7, "05": 8, "1": [1, 6, 10, 14, 18], "10": [7, 19], "100": [7, 11, 12, 13, 15, 17], "1000": [13, 16, 19], "10000": 13, "128": 19, "15": 7, "150": 13, "1500": 7, "175": 4, "18th": [11, 12], "19": 15, "1919": 12, "1964": 12, "1966": 3, "19th": 12, "2": [1, 2, 10, 14, 18], "20": 13, "200": 17, "2017": 3, "2019": 15, "2020": 15, "2021": 15, "2023": 7, "2030": 12, "3": [1, 2, 6, 14, 18], "30": [9, 12], "32": 19, "35": 15, "3f": 16, "4": 1, "42": [8, 9, 13], "4f": 13, "5": 1, "50": [11, 12, 13, 15, 16], "5g": 15, "60": 9, "9": 7, "95": 15, "A": [3, 4, 6, 8, 9, 12, 13, 16, 17], "And": [7, 19], "As": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 19], "BY": 1, "Be": [8, 11], "By": [1, 5, 6, 9, 10, 14, 15, 16, 17, 19], "For": [3, 6, 7, 8, 9, 13, 15, 19], "If": [15, 17], "In": [1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 19], "It": [2, 7, 8, 9, 11, 12, 13, 14, 17], "No": [13, 17], "One": [12, 16], "The": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22], "These": [1, 3, 4, 6, 8, 10, 12, 14], "To": [9, 13, 15, 16], "_": [12, 13, 16], "__getitem__": 19, "__init__": 19, "__len__": 19, "ab_test_prompt": 12, "abbrevi": 8, "abil": [3, 5, 6, 8, 11, 12, 14, 15, 19], "abl": 10, "about": [2, 5, 7, 9, 10, 12, 13, 15, 16, 19], "abov": 16, "absolut": 11, "abstract": [2, 9, 11], "academ": [3, 4], "acc": 13, "access": [2, 4, 14], "access_token": 19, "access_token_secret": 19, "accord": [8, 13], "account": 5, "accur": [6, 8, 12, 16, 17], "accuraci": [3, 8, 12, 13, 14, 15, 17, 20], "accuracy_scor": 13, "achiev": [3, 4, 6, 11], "acknowledg": 16, "across": [3, 4, 9, 14, 17, 19, 20], "act": 12, "actual": 12, "adapt": [2, 3, 5, 10, 12, 15, 21], "add": [9, 12, 19], "addit": 17, "addition": 16, "address": [3, 9, 16, 20], "adjac": 3, "adject": 8, "adjust": 15, "advanc": [1, 2, 3, 6, 12, 15, 17, 19, 20, 21], "advantag": [12, 15], "advent": [1, 10], "affect": [5, 12, 15], "after": [7, 12], "ag": 16, "against": 5, "agenc": 5, "agreement": 8, "ai": [3, 12, 13, 14, 15, 20, 21], "aim": [1, 3, 4, 11, 12], "al": 15, "albert": 4, "alert": 20, "algorithm": [3, 5, 7, 12, 13, 16, 20], "alik": 8, "all": [2, 3, 4, 11, 12, 16], "all_ent": 19, "all_target": 16, "alloc": [1, 5, 6, 19], "allow": [3, 4, 5, 6, 9, 10, 11, 12, 14, 16, 19], "almost": 11, "alon": 9, "alongsid": 5, "alphabet": 19, "also": [1, 2, 3, 4, 6, 10, 11, 12, 14, 17], "alter": 12, "alwai": [1, 9, 15], "amaz": 13, "amazon": 13, "america": [11, 12], "among": 15, "amount": [1, 3, 4, 8, 12, 14, 19], "amp": 7, "amplif": [5, 14], "amplifi": [4, 5], "amus": 17, "an": [1, 3, 4, 5, 9, 11, 12, 13, 15, 16, 17, 19, 21], "analys": [3, 6, 17], "analysi": [1, 2, 3, 5, 6, 7, 9, 10, 14, 15, 20, 21], "analyt": 3, "analyz": [1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20], "analyze_occupation_bia": 16, "analyze_political_metaphor": 17, "analyze_proverb": 17, "analyze_senti": 8, "anger": 11, "ani": [3, 6, 16, 17], "anim": 4, "annot": [1, 2, 8, 11], "announc": [8, 12, 13], "anonym": 5, "anoth": [7, 17], "answer": [2, 3], "anticip": 21, "apach": 19, "api": [7, 11, 12, 13, 17, 19, 20], "api_kei": [11, 12, 13, 17], "append": [11, 13, 16, 19], "appl": [8, 12, 13], "appli": [1, 2, 4, 8, 9, 10, 11, 12, 16, 22], "applic": [1, 3, 6, 7, 8, 12, 13, 15, 21], "appnam": 19, "approach": [1, 2, 4, 5, 8, 9, 10, 12, 15, 16, 17, 19, 20, 22], "appropri": [3, 4, 5, 8, 12, 13], "ar": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19], "architectur": [3, 5, 15, 16, 22], "archiv": 19, "area": [2, 4, 6, 14, 16, 17], "aren": 5, "argument": 15, "aris": [5, 16], "arithmet": 3, "around": 3, "arriv": 5, "art": [1, 3, 21], "articl": [3, 4, 8, 9, 20], "artifact": 4, "artifici": [3, 4, 8], "artist": 16, "as_list": 13, "ask": [2, 4], "aspect": [4, 5, 11, 12, 17, 20, 22], "assess": [3, 5, 9, 20, 21], "assign": [8, 12], "assist": [4, 5, 15, 17, 21], "associ": [5, 9], "association_1": 16, "association_2": 16, "assum": [9, 13, 19], "assumpt": 9, "attend": 7, "attent": [3, 5, 12], "attention_mask": 19, "attitud": [4, 22], "attribut": [9, 16, 17], "attribute_set1": 16, "attribute_set2": 16, "attun": 8, "audienc": [14, 17], "audio": [3, 20, 21], "audit": 5, "augment": [8, 21], "auth": 19, "authent": 19, "author": 20, "authorit": 5, "autom": [3, 10, 13, 20, 21], "automat": [3, 4, 9], "automodel": 16, "automodelforsequenceclassif": 19, "autoregress": 15, "autotoken": [16, 19], "avail": [3, 13], "averag": [9, 13], "averaged_perceptron_tagg": 8, "avoid": [14, 16, 20], "awai": 2, "awar": [5, 8, 11, 12, 17, 21], "b": [7, 12, 16], "backbon": 6, "background": 16, "backward": 19, "bag": [3, 6, 22], "balanc": [13, 15, 20, 21], "bank": 3, "barrier": 4, "base": [1, 2, 3, 4, 9, 11, 12, 13, 16, 19, 20, 21, 22], "basi": 6, "basic": [1, 6, 15], "batch": 19, "batch_ent": 19, "batch_result": 19, "batch_siz": 19, "bay": [3, 8], "beat": 13, "becaus": [2, 4], "becom": [3, 5, 19], "been": [3, 4, 10, 11, 12, 13], "befor": 9, "began": [11, 12], "begin": [1, 6, 10, 14], "behavior": [1, 3, 20, 21], "behind": [4, 8, 9, 11], "being": 6, "believ": 11, "benchmark": [3, 20], "benefit": [1, 5, 22], "bert": [3, 13, 16, 19, 20], "best": [2, 8, 11, 12, 16], "better": [4, 5, 9, 11, 12], "between": [1, 2, 3, 4, 5, 8, 9, 11, 12, 13, 15, 16, 17, 22], "beyond": [3, 4], "bezo": 13, "bia": [1, 2, 3, 14, 17, 19, 20, 21], "bias": [1, 5, 8, 11, 12, 14, 16, 17, 22], "biased_prompt": 16, "bidirect": [3, 4], "big": 19, "bill": [12, 13], "billion": 4, "binari": 8, "biodivers": 8, "bit": 12, "bleu": 13, "bleu_scor": 13, "block": 6, "boi": 16, "book": [1, 4], "bot": 20, "both": [1, 2, 4, 9, 13, 15, 19], "boundari": 6, "bow_matrix": 7, "bow_represent": 7, "brad": 16, "break": [3, 7, 12], "bridg": [1, 2, 3, 12, 21], "bring": 5, "britain": [11, 12], "broader": 5, "brother": 16, "brought": 3, "brown": [7, 8], "bucket": 17, "buffer": [11, 12], "build": [2, 6, 20], "builder": 19, "built": [4, 6], "busi": [12, 19], "c_v": 9, "calcul": [3, 8, 9, 16], "campaign": 20, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19], "cannot": 7, "capabl": [1, 2, 8, 10, 14, 15, 17, 21, 22], "captur": [3, 4, 7, 11], "car": 5, "carbon": [5, 11, 12], "care": [3, 4, 8, 15, 16, 19], "carefulli": [4, 5, 9, 13, 16], "caregiv": 16, "carri": 7, "case": [7, 13, 20, 22], "cat": [3, 8, 9, 17], "categor": [3, 4, 8], "categori": [3, 4, 8, 11, 12, 13], "caus": [12, 15], "causal": 21, "caution": 16, "cc": 1, "centuri": [11, 12], "ceo": [8, 13, 16], "certain": 5, "challeng": [1, 2, 10, 12, 19, 20, 21], "championship": [8, 12, 13], "chang": [4, 8, 9, 11, 12, 13, 15, 17, 19, 21], "changer": 14, "charact": [3, 9], "character": 9, "characterist": [13, 17, 20], "chase": 9, "chatbot": 3, "cheap": 12, "check": [7, 20], "child": 7, "children": [7, 15], "choic": [11, 12, 13, 17], "chomski": 3, "choos": [8, 11, 13], "chunk": 19, "chunk_siz": 19, "citi": [8, 13], "citizen": [5, 15], "civil": 12, "claim": [15, 20], "clariti": 17, "class": [11, 12, 13, 19], "class_nam": 13, "classif": [1, 3, 6, 20], "classifi": [3, 4, 8, 10, 11, 12, 13], "classification_report": [8, 13], "clean": [1, 6, 9], "clean_html": 7, "clean_text": 7, "cleaned_text": 7, "clear": [5, 11, 12], "clearer": 6, "clf": 8, "climat": [4, 8, 9, 11, 12, 19, 21], "close": [3, 12], "cloudi": 8, "cluster": 3, "cluster_docu": 8, "cnn": [3, 20], "coaster": 17, "code": [3, 4, 6, 11, 14, 16, 19], "code_survey_respons": 11, "coded_data": 11, "coded_respons": 11, "coded_them": 11, "cognit": 21, "coher": [3, 4, 8, 9, 15], "coherence_model": 9, "coherence_scor": 9, "coherencemodel": 9, "cold": 17, "collabor": [3, 21, 22], "collect": [3, 6, 9, 20], "color": 12, "column": 9, "com": 7, "combin": [3, 5, 8, 12, 13], "come": [1, 5, 6, 8, 10], "comma": [11, 12], "commit": [5, 12], "common": [7, 8, 9, 11, 16, 17], "commun": [3, 8, 12, 13, 14, 17, 22], "compani": [13, 16], "compar": [1, 10, 16, 17, 20], "comparison": 17, "complet": [3, 11, 12, 13, 16, 17, 19], "complex": [2, 5, 6, 8, 12, 14, 16, 17, 19, 21], "compon": [12, 19], "composit": 17, "compound": 8, "comprehens": [4, 8, 10, 12], "comput": [8, 16, 19], "concept": [6, 11, 13, 14, 22], "concern": [2, 3, 8, 12, 15, 20], "concis": 8, "conclus": [5, 9, 11], "condens": 4, "conduct": 16, "confid": 5, "congress": 12, "conll03": 13, "connect": 12, "consent": [4, 16], "consequ": [8, 21], "consid": [2, 3, 4, 5, 7, 9, 10, 12, 13, 15, 16, 17], "consider": [1, 2, 3, 10, 19, 20, 21], "consist": [3, 4, 7, 11, 12, 20], "constantli": 1, "constrain": 15, "constraint": 4, "consum": [8, 10], "consumer_kei": 19, "consumer_secret": 19, "consumpt": 5, "contain": [1, 4, 8, 17], "contemporari": [4, 5], "content": [3, 4, 7, 8, 14, 20, 21], "context": [1, 2, 8, 10, 11, 14, 15, 16, 20, 21], "contextu": [3, 4, 8, 15, 17, 20, 21], "continu": [3, 4, 11, 12, 13, 15, 17, 19], "contradict": 15, "contribut": [7, 16], "control": [5, 20], "convei": 17, "convert": [3, 7, 9], "convolut": 3, "cook": [8, 13], "coordin": 20, "core": 11, "cornerston": 5, "corpora": [3, 6, 9, 11, 12, 19], "corpu": [3, 7, 8, 9, 19], "correct": [7, 15, 17], "correl": [9, 15], "correspond": 8, "cosin": 8, "cosine_similar": [8, 16], "cost": [3, 5], "could": [3, 4, 5, 10, 12], "count": [12, 19], "counter": [19, 20], "countermeasur": 20, "countvector": 7, "cours": [2, 6, 10, 14, 22], "cov": 15, "cover": [2, 6, 10], "coverag": 12, "covid": 15, "cpu": 19, "cpu_count": 19, "craft": [3, 16], "creat": [0, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20], "createdatafram": 19, "creativ": 15, "credenti": 19, "credibl": 20, "crisi": 21, "criteria": 17, "criterion": 17, "critic": [1, 2, 4, 12, 16, 21, 22], "cross": [3, 9, 11, 17, 20, 21, 22], "crucial": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19], "csv": 9, "cuda": 19, "cultur": [1, 4, 8, 11, 12, 14, 16, 20, 21], "cultural_context": 17, "curat": 5, "current": [15, 21], "cursor": 19, "curtain": 17, "custom": [8, 12], "cut": [1, 2], "d": [7, 9], "dai": 11, "daili": [11, 15], "dall": 4, "data": [1, 2, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 20, 21], "databas": 20, "datafram": [9, 19], "dataload": 19, "dataset": [1, 5, 6, 8, 11, 12, 13, 14, 15, 20, 22], "date": [9, 11], "daughter": 16, "davinci": [11, 12, 13, 17], "dbmdz": 13, "deal": [5, 12, 14, 17, 19, 20], "debat": [9, 15], "debias": 16, "debiased_gener": 16, "debiased_prompt": 16, "debiased_result": 16, "debiasing_prefix": 16, "decept": [5, 20], "decis": [4, 8, 10, 13, 20], "decod": [15, 16], "deduc": 17, "deep": [2, 9, 15, 20], "deepen": 1, "deeper": [17, 19], "deepfak": 20, "def": [7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "definit": 20, "delici": 12, "delv": [6, 14], "demograph": 15, "demoj": 7, "demonstr": [3, 8, 9, 11, 12], "dens": [3, 7], "depend": [3, 4, 5, 7, 15, 17, 20], "deploy": 16, "depth": 14, "describ": [3, 12], "descript": [4, 11, 12], "design": [1, 2, 4, 5, 11, 22], "desir": 12, "despit": 4, "detach": 16, "detail": [4, 5, 7, 12, 15], "detect": [1, 9, 14, 18, 19, 21], "detect_and_explain_metaphor": 17, "detect_sarcasm": 17, "determin": [8, 9, 12, 17], "develop": [1, 4, 9, 12, 16, 20, 21, 22], "devic": 19, "df": [9, 19], "diagnosi": 13, "diagnost": 12, "diagram": 9, "dialogu": [5, 15], "dictionari": [8, 9, 19], "did": 12, "didn": 4, "differ": [4, 8, 9, 11, 13, 14, 16], "difficult": [8, 9, 12, 17], "difficulti": 12, "diffus": 20, "digit": [3, 19], "dim": 16, "dimens": [5, 7], "dimension": 3, "direct": [1, 13, 17, 18, 20], "dirichlet": [1, 6, 19], "disadvantag": 5, "disappoint": 13, "discours": [3, 9, 15, 21], "discov": [1, 8, 9], "discoveri": 19, "discrimin": 12, "discuss": [2, 4, 6, 9, 10, 14], "distant": 8, "distribut": [9, 19], "dive": [1, 6], "divers": [4, 12, 14, 15, 17, 19], "do": [1, 16, 19], "do_sampl": 16, "doc": [8, 9, 13, 19], "doc2bow": [9, 19], "doc_ent": 19, "doc_lda": 9, "doctor": 16, "document": [1, 3, 4, 6, 9, 19, 22], "doe": 12, "dog": [7, 8, 9, 17], "domain": [3, 8, 9, 11, 12, 15, 20], "domest": 12, "domin": 9, "dominant_top": 9, "don": [2, 4, 7], "dot": [9, 16], "down": 17, "download": [7, 8, 9, 19], "downstream": 7, "dr": 11, "draw": 9, "driven": [3, 21], "drug": 12, "due": [3, 12, 17, 19], "dure": [11, 12, 20], "dynam": [1, 9, 20], "e": [3, 4, 5, 7, 8, 9, 12, 13, 15, 20], "each": [1, 3, 4, 7, 9, 12, 13, 22], "earli": [12, 19, 20], "easier": 7, "easili": [7, 9, 12], "econom": [9, 11, 12, 13], "economi": [11, 13], "edg": [1, 2], "educ": [11, 20], "effect": [1, 5, 6, 10, 11, 12, 14, 15, 17, 19, 20, 22], "effici": [3, 6, 8, 10, 14, 19, 21], "effort": 10, "elect": 20, "element": [7, 9], "elicit": 12, "elif": 8, "elimin": [3, 16], "eliza": 3, "elon": 13, "els": [8, 17, 19], "embark": [1, 2], "embed": [9, 11, 22], "emerg": [1, 4, 12, 18, 20], "emili": 16, "emiss": 11, "emot": [8, 9, 14, 17, 22], "emotion_summari": 15, "emphas": [1, 2, 3, 17], "emphasi": 17, "emploi": [5, 16], "employe": 15, "empow": 12, "en": 19, "en_core_web_sm": [8, 13, 19], "enabl": [3, 14, 17], "encapsul": 17, "encod": [3, 4, 11, 15, 16, 19], "encompass": [3, 8], "encount": 3, "encourag": [2, 10, 22], "end": [1, 3, 4, 6, 8, 10, 11, 12, 14, 15], "end_tim": 13, "energi": [5, 11, 12, 21], "engag": [2, 20], "engin": [1, 3, 10, 13, 16, 17, 20], "english": [5, 7, 8, 9, 13, 17, 19], "enhanc": [3, 6, 9, 10, 11, 12, 14, 19, 21], "enorm": 4, "ensembl": [13, 20], "ensur": [2, 4, 10, 14, 16], "ent": [8, 13, 19], "enthusiasm": 4, "entir": [5, 12, 14], "entiti": [4, 6, 7, 22], "entity_count": 19, "entity_typ": [11, 12], "entitytyp": [11, 12], "enumer": 8, "environ": [11, 17, 21], "environment": [3, 11, 13, 21], "epoch": 19, "equal": [5, 6, 16], "equip": [1, 14], "equit": 16, "equival": [5, 17], "era": [3, 17], "error": 13, "especi": [6, 7, 14], "essenti": [6, 17, 19], "et": 15, "etc": 20, "ethic": [1, 2, 3, 10, 15, 19, 20, 21], "ethicist": 5, "eu": 5, "europ": [11, 12], "evalu": [1, 19, 20, 22], "evaluate_generated_text": 15, "evaluate_perform": 13, "evaluate_scal": 13, "even": [2, 4, 6, 11, 14, 15, 17], "event": [5, 7, 21], "everi": 11, "evid": 21, "evolut": [1, 2, 20], "evolv": [3, 4, 5, 9, 11, 12, 13, 16, 17, 20, 21], "ex_answ": 12, "ex_context": 12, "ex_quest": 12, "exacerb": 5, "exactli": 5, "exagger": 17, "examin": [14, 16, 19], "exampl": [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22], "excel": [4, 12, 14], "excit": [1, 2, 4, 17], "exclus": 8, "exercis": [14, 22], "exhibit": [3, 9], "exist": 5, "exp": 13, "expand": 4, "expect": [11, 12, 15, 16, 17], "experi": [1, 6, 9, 17], "experiment": 9, "expert": [3, 12, 13], "expertis": [9, 17, 20], "explain": [4, 14, 15, 17, 20, 21, 22], "explain_figurative_languag": 17, "explain_idiom": 17, "explain_inst": 13, "explain_llm_predict": 13, "explain_misinform": 15, "explain_traditional_predict": 13, "explan": [1, 3, 5, 13, 19, 20], "explanatori": 5, "explicit": 16, "explicitli": [3, 4, 11, 17], "explor": [1, 2, 3, 4, 6, 7, 9, 10, 12, 15], "exploratori": 11, "express": [4, 7, 8, 11, 14, 15, 17], "extend": [12, 19], "extern": 20, "extract": [4, 14], "f": [7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "f1": [3, 8, 13, 15], "fabric": 5, "face": [3, 13, 15, 17], "facebook": 19, "facilit": 4, "fact": 20, "factor": 13, "factual": [3, 14, 15], "fail": 3, "fair": [16, 21], "fake": [1, 18], "fallaci": 20, "fals": [15, 19, 22], "fascin": 1, "faster": 12, "father": 16, "favor": 5, "fear": [11, 17], "featur": [8, 13, 19, 20], "feature_extract": [7, 8, 13], "feature_nam": 7, "feedback": 8, "femal": 16, "female_assoc": 16, "female_associ": 16, "female_prob": 16, "female_prompt": 16, "female_term": 16, "few": [1, 10, 11, 13, 20, 21], "few_shot_aspect_senti": 12, "few_shot_classif": [12, 13], "few_shot_multi_label_classif": 12, "few_shot_n": 12, "few_shot_qa": 12, "few_shot_summar": 12, "fewer": 4, "field": [1, 2, 3, 11, 12, 13, 15, 16], "figur": [1, 14], "file": 9, "filter": 19, "filtered_text": 7, "final": [1, 6, 12], "financ": 8, "financi": [3, 19, 22], "find": [4, 5, 14, 15], "findal": 13, "fine": [3, 11, 13, 15], "finetun": 13, "first": [7, 9, 19], "fit": [8, 13], "fit_resampl": 13, "fit_transform": [7, 8, 13], "five": 1, "flatten": 19, "flaw": 5, "flexibl": 15, "float": 17, "flood": 15, "floor": 8, "flower": 8, "focu": [3, 4, 6, 9, 11, 14, 22], "focus": [3, 4, 6, 15], "follow": [11, 12, 13, 15, 17], "food": 12, "footprint": 5, "forest": [13, 20], "form": [3, 6, 7, 17], "formal": [3, 12], "format": [3, 7, 11, 12, 13, 15, 17], "formul": [4, 21], "forward": 4, "foster": [5, 21], "found": 15, "foundat": [6, 19], "founder": 13, "fox": [7, 8], "frame": [2, 4], "framework": [19, 21], "free": [3, 20], "frequenc": [3, 8, 15], "frequent": 17, "friendli": 3, "from": [1, 2, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19], "from_pretrain": [15, 16, 19], "full": [3, 8, 13], "function": [9, 16, 17], "fundament": [1, 2, 6, 7, 10], "further": [4, 11, 12], "futur": [1, 13, 18, 20], "g": [3, 4, 5, 7, 8, 9, 12, 13, 15, 20], "gain": [1, 2, 8, 9, 11, 17], "game": [8, 14], "gap": [1, 2, 3, 4, 12, 15], "garcia": 15, "gather": 20, "gaug": 3, "gdp": 12, "gdpr": 5, "gender": [4, 5], "gender_association_test": 16, "gener": [1, 2, 8, 9, 16, 17, 19, 20, 21], "generate_complet": 16, "generate_research_hypothesi": 15, "generate_survey_respons": 15, "generate_text": 15, "generate_text_llm": 13, "generate_text_tradit": 13, "generate_text_with_param": 15, "generated_text": [13, 15], "gensim": [6, 7, 9, 19], "germani": 12, "get": [8, 9, 17], "get_coher": 9, "get_dominant_top": 9, "get_embed": 16, "get_feature_names_out": 7, "get_scor": 15, "get_senti": 9, "get_word_embed": 7, "getorcr": 19, "gf": 17, "gibb": 9, "gigaword": 7, "girl": 16, "given": [3, 4, 8, 9, 12], "global": [3, 12], "glove": 7, "go": [4, 8], "goal": [2, 3, 8], "good": 12, "govern": [11, 12, 19], "gpt": [3, 11, 12, 13, 17, 22], "gpt2": [15, 16], "gpt2lmheadmodel": [15, 16], "gpt2token": [15, 16], "grain": 11, "gram": 3, "grammar": 3, "grammat": [3, 8], "graph": 20, "grasp": [3, 4, 10], "great": [1, 11, 12, 17], "green": [12, 21], "grew": 3, "gross": 12, "groundbreak": 11, "group": [5, 7, 8, 16], "groupbi": 9, "grow": [2, 13, 19], "growth": 3, "guid": [16, 17], "guidelin": 1, "ha": [1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 15, 17, 19], "had": 2, "hallucin": 3, "hammer": 17, "hand": [1, 3, 6, 14, 22], "handl": [9, 11, 12, 13, 15, 17, 19, 20], "har": [1, 2, 3, 4, 5], "hardwar": 13, "harm": 5, "harvard": 11, "hasn": 4, "have": [1, 2, 3, 5, 6, 8, 9, 10, 13, 14, 17, 19], "haven": 11, "he": 16, "health": [12, 15, 19, 20], "healthcar": [11, 12], "heapq": 8, "heat": 15, "heavi": 12, "held": 3, "help": [4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 19], "here": [1, 7, 8, 11, 12, 13, 15, 16, 17, 19], "hesit": 2, "hidden": [3, 9, 14], "hierarch": [3, 9], "hierarchi": 9, "high": [1, 3, 5, 13, 14, 17], "higher": 9, "highli": 17, "highlight": 15, "hill": 3, "histor": [1, 4, 5, 8, 9, 17, 19, 20], "histori": 11, "hold": 3, "hop": 12, "how": [1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17], "howev": [1, 4, 6, 7, 10, 11, 12, 15, 16, 17], "html": 9, "html_text": 7, "http": 7, "hug": [13, 15], "human": [1, 3, 8, 9, 10, 12, 13, 17, 20, 21], "human_evalu": 17, "hundr": 4, "hybrid": 13, "hyperbol": 17, "hypothes": [3, 4, 14, 15, 19], "hypothesi": [15, 21], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19], "id": 19, "id2word": [9, 19], "idea": [4, 11, 14, 17], "identif": 20, "identifi": [3, 4, 5, 8, 9, 11, 12, 17, 19, 20, 22], "idf": [3, 6, 8, 22], "idiom": [14, 22], "idiomat": 4, "idx": [9, 19], "illustr": [6, 15], "imag": [3, 4, 20, 21], "imagin": [19, 21], "imbalanc": 13, "imblearn": 13, "immers": 21, "impact": [2, 4, 8, 12, 13, 15, 16, 17, 20, 21, 22], "implement": [6, 8, 12, 15, 16, 17, 19], "impli": 3, "implic": [2, 3, 4, 14, 15, 16, 17, 21], "import": [2, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21], "impos": 12, "impress": 17, "improv": [3, 7, 9, 12, 14, 17, 20, 21], "inaccess": 19, "inadvert": 5, "inauthent": 20, "inc": [8, 12, 13], "includ": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 22], "inconsist": [5, 12, 20], "incorpor": [9, 12, 15, 20], "incorrect": [4, 5], "increas": [3, 4, 12], "increasingli": [3, 19], "incredibli": 15, "independ": 15, "indic": [9, 16], "individu": [3, 5, 16, 17, 21], "industri": [11, 12], "inequ": 5, "infeas": 3, "infer": [1, 9, 13, 14, 21], "influenc": [3, 11, 17], "info": 7, "inform": [1, 7, 8, 10, 14, 15, 16, 20, 22], "inher": 3, "initi": [4, 19], "innov": 12, "input": [3, 4, 5, 12, 15, 16, 17, 19], "input_data": 13, "input_id": [16, 19], "inputcol": 19, "insight": [2, 3, 4, 6, 8, 9, 14, 17, 19], "inspir": 21, "instanc": 3, "instant": 12, "institut": [3, 5], "instruct": 11, "integr": [3, 14, 20, 21, 22], "intellig": [3, 4, 8, 21], "intens": 15, "inter": 8, "interact": [8, 12, 17, 21, 22], "interdisciplinari": [3, 20], "interest": [2, 10, 22], "interfer": 7, "intern": [4, 5], "internet": 17, "interpret": [2, 3, 6, 11, 14, 16, 20, 21, 22], "interpret_internet_slang": 17, "intersect": [1, 2, 22], "intervent": 20, "interview": [4, 15], "introduc": [3, 5, 6], "introduct": [1, 20, 21], "introductori": 2, "intuit": 9, "invers": 3, "invest": 12, "investig": 20, "involv": [3, 7, 8, 13, 14, 16], "iphon": 12, "iron": 17, "ironi": [3, 8], "irrelev": [3, 7], "is_avail": 19, "isalpha": 19, "isn": 2, "issu": [2, 3, 4, 8, 11, 16, 19, 22], "item": [12, 16, 19], "iter": 4, "its": [1, 2, 5, 8, 11, 12, 15, 17, 19], "jamal": 16, "jane": [11, 12], "japanes": 17, "jeff": 13, "job": [11, 15], "john": 12, "johnson": [12, 15], "joi": 11, "join": [7, 8, 11, 12, 13, 15], "journal": 11, "journei": [1, 2], "json": 13, "judgment": [17, 20], "judici": 15, "jump": [7, 8], "just": [2, 4, 17], "k": [8, 9, 12, 15, 19], "keen": 5, "keep": [1, 17], "kei": [2, 6, 8, 9, 10, 11, 12, 13, 15, 17, 19], "key_pap": 15, "kick": 17, "kind": 9, "king": 3, "kmean": 8, "knowledg": [1, 3, 11, 12, 20, 21], "l": 15, "label": [3, 8, 11, 12, 13, 19], "label_": [8, 13, 19], "labels_": 8, "lakisha": 16, "lambda": [9, 13], "landscap": 3, "lang": 19, "languag": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21], "larg": [1, 2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21], "large_dataset": 19, "larger": 14, "largescaletextprocess": 19, "last": [11, 12], "last_hidden_st": 16, "late": [11, 12], "latent": [1, 6, 19], "later": 6, "latest": [4, 16], "law": [12, 13], "lazi": [7, 8], "lda": [1, 6, 19], "lda_model": [9, 19], "lda_result": 9, "lda_visu": 9, "ldamodel": 9, "ldamulticor": 19, "lead": [5, 11, 12, 19], "leap": 4, "learn": [1, 2, 6, 7, 8, 9, 10, 14, 20, 21], "lectur": 22, "lee": 15, "legal": [5, 8], "lemmat": [3, 6, 9, 22], "lemmatize_word": 7, "lemmatized_text": 7, "len": [9, 16, 19], "less": [5, 8, 12], "let": [1, 2, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19], "level": [3, 12, 19, 21], "leverag": [1, 2, 6, 10, 11, 12, 14, 15, 17, 19, 20], "lexic": 3, "li": [8, 19], "librari": [1, 6, 8, 9, 15, 19, 22], "life": [11, 15, 17], "lifecycl": 20, "lifetim": 5, "like": [3, 5, 6, 8, 9, 12, 15, 16, 17, 19], "lime": [5, 13], "lime_text": 13, "limetextexplain": 13, "limit": [1, 2, 3, 5, 10, 12, 13, 20, 22], "linalg": 16, "line": 9, "linear_model": 13, "lingual": [3, 9, 20, 21], "linguist": [3, 7, 8, 20], "link": [17, 20], "list": [11, 12, 19], "liter": [3, 17], "literaci": 20, "literatur": [3, 4, 14, 15], "literature_review_synthesi": 15, "live": 15, "ll": [1, 2, 6, 8, 9, 10], "llm": [1, 2, 6, 14, 19, 20, 21], "llm_bleu": 13, "llm_entiti": 13, "llm_explan": 13, "llm_gener": 13, "llm_ner": 13, "llm_perform": 13, "llm_predict": 13, "llm_relat": 13, "llm_relation_extract": 13, "llm_sent": 13, "llm_sentiment": 13, "llm_time": 13, "load": [7, 8, 13, 15, 19], "local": [8, 12], "locat": [3, 8, 12], "logic": 20, "logist": 13, "logisticregress": 13, "logit": 16, "long": [3, 4, 6, 11, 12, 15, 21], "long_text": 11, "longer": 8, "look": [11, 15, 19], "loss": 19, "lotteri": 11, "love": [7, 8, 11, 13], "low": [8, 12, 17, 20, 21], "lower": [7, 8, 9, 19], "lowercas": [3, 9], "lowercased_text": 7, "lstm": 3, "lyndon": 12, "m": [9, 13], "machin": [3, 7, 8, 9, 11, 12, 20], "made": [1, 2], "mai": [4, 5, 7, 8, 9, 12, 13, 17, 19], "main": [4, 6, 9, 10, 11, 15], "maintain": [5, 14], "major": [11, 12], "make": [4, 5, 7, 8, 10, 11, 12, 13], "male": 16, "male_assoc": 16, "male_associ": 16, "male_prob": 16, "male_prompt": 16, "male_term": 16, "man": [3, 16], "manag": 21, "mani": [6, 7, 8, 10, 13, 17], "manifest": 16, "manipul": [5, 20], "manual": [3, 8, 9], "map": 19, "mark": [8, 11], "market": [8, 11, 12, 13], "markov": 3, "massiv": [3, 11], "master": 6, "mat": [3, 8, 9], "match": [3, 12, 13], "materi": 5, "matrix": 8, "max": 9, "max_length": [13, 15, 16, 19], "max_token": [11, 12, 13, 17], "max_word": [11, 12], "mean": [3, 4, 7, 8, 9, 13, 16, 17], "meaning": [6, 9, 14, 19], "meaningless": 17, "measur": [8, 12], "measure_inference_tim": 13, "mechan": 3, "media": [1, 3, 4, 5, 7, 8, 9, 12, 13, 14, 15, 19, 20, 21, 22], "medic": [8, 13, 19, 22], "meet": 17, "meme": 17, "memor": 5, "memori": 3, "mental": [12, 15], "metaphor": [14, 22], "method": [1, 3, 5, 6, 8, 9, 10, 13, 15, 16, 20], "methodologi": [1, 2, 3, 4, 5, 11, 21, 22], "metric": [3, 8, 9, 15, 16, 20], "might": [2, 3, 4, 5, 7, 8, 9, 10, 12, 15, 17], "million": 19, "mind": 1, "mine": 3, "minim": [4, 12, 15], "misinform": [1, 12, 18], "mislead": 5, "misrepres": 5, "misus": 4, "mitig": [14, 20, 21], "mix": 12, "mixtur": 9, "ml": [12, 19], "modal": 21, "model": [1, 2, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21], "model_nam": [7, 16, 19], "model_output": 17, "model_select": [8, 13], "modern": [1, 2, 22], "moham": 16, "monitor": 21, "month": [8, 11, 13], "more": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 19], "most": [9, 11, 12], "mother": 16, "move": 1, "movi": [3, 7], "mp": 19, "mse": 13, "much": [2, 7], "multi": [11, 12, 19], "multilingu": [20, 21], "multimod": [3, 4, 20, 21], "multinomi": 9, "multinomialnb": 8, "multipl": [3, 4, 5, 8, 9, 14, 19], "multiprocess": 19, "musk": 13, "must": [4, 5, 16], "mutual": 8, "my": 11, "n": [3, 8, 9, 11, 12, 13, 17], "n_cluster": 8, "n_run": 13, "n_sampl": 13, "n_test": 12, "nail": 17, "naiv": [3, 8], "naive_bay": 8, "name": [4, 6, 7, 16, 22], "name_senti": 16, "name_sentiment_analysi": 16, "nanswer": 12, "narr": 20, "nation": 12, "natur": [1, 2, 4, 6, 7, 8, 10, 11, 14, 15, 16, 17, 19], "navig": 5, "ncategori": [11, 12, 13], "necessari": [5, 6], "need": [3, 4, 7, 9, 11, 12, 19], "neg": [3, 4, 8, 11, 12, 13, 15], "nentiti": 12, "ner": 19, "ner_pipelin": 13, "network": [3, 4, 15, 20, 21], "neural": [3, 4, 9, 21], "neuro": 21, "neutral": [8, 11, 12, 13, 16], "never": [3, 11], "new": [1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 15, 18, 19], "newer": 4, "next": [4, 8, 13], "next_word": 13, "next_word_vec": 13, "nice": 13, "nlargest": 8, "nlp": [1, 7, 13, 17, 19, 21], "nltk": [6, 7, 9, 13, 19], "no_repeat_ngram_s": 15, "noam": 3, "nois": [3, 7], "non": [8, 17, 19], "none": [11, 12, 13, 17], "nonstandard": 8, "norm": 16, "normal": [1, 6, 19], "north": [11, 12], "notabl": 5, "notat": 9, "note": 15, "noun": 8, "novel": [3, 11, 12], "now": [2, 3, 4, 11], "np": [13, 16], "nquestion": 12, "nsentiment": [12, 13], "nsimilar": 8, "nsummari": 12, "ntext": [11, 12, 13], "ntopic": 9, "nuanc": [3, 4, 8, 14, 17], "num": 7, "num_clust": 8, "num_featur": 13, "num_label": 19, "num_permut": 16, "num_process": 19, "num_return_sequ": [15, 16], "num_sent": 8, "num_top": [9, 19], "number": [9, 12, 13], "numer": [3, 6], "numpi": [13, 16], "nurs": 16, "oauthhandl": 19, "object": 19, "observ": [9, 16], "observed_scor": 16, "occup": 16, "occur": [3, 9, 16], "off": 13, "offens": 17, "offer": [1, 3, 4, 5, 6, 10, 11, 13, 14, 15, 17, 19], "offic": 17, "often": [3, 4, 5, 6, 8, 9, 10, 13, 14, 17], "oh": 17, "old": 15, "one": [3, 7, 9, 11, 12, 13, 17, 19], "ongo": [4, 5, 9], "onli": [1, 3, 4, 12, 19], "onlin": [8, 19, 21], "open": [1, 3, 4, 8, 10, 11, 13, 15], "openai": [11, 12, 13, 17], "opinion": [3, 4, 8, 20, 21, 22], "opportun": [1, 2, 19], "optim": [9, 10, 19], "option": 17, "organ": [8, 9, 11, 12], "origin": [3, 12, 16], "other": [5, 8, 11, 12, 14, 15, 20], "our": [1, 2, 3, 6, 7, 9, 10, 12, 14, 19], "out": [3, 7, 17], "outcom": 16, "outdat": 5, "outperform": [12, 17], "output": [4, 7, 11, 12, 13, 14, 15, 16, 17, 19], "outputcol": 19, "over": [5, 7, 8, 9, 12, 15], "over_sampl": 13, "overal": [13, 17], "overall_scor": 17, "overpr": 12, "overst": 7, "overview": [2, 21], "own": [2, 10, 22], "ownership": 5, "p": [7, 15, 16], "p_valu": 16, "pad": 19, "pairwis": 8, "panda": [9, 19], "pandem": [15, 20], "paper": [4, 11, 14, 15], "paradigm": [11, 12, 13, 21], "paragraph": 4, "parallel": 4, "parallel_preprocess": 19, "paramet": [4, 9, 12], "paramount": 5, "paraphras": 15, "parent": 15, "park": 17, "pars": [3, 19], "part": [3, 11], "partial": 4, "particular": [4, 5, 8, 12], "particularli": [1, 2, 3, 5, 7, 8, 9, 11, 12, 15, 17], "passion": 15, "pattern": [3, 8, 9, 12, 13, 17, 19, 20, 22], "pd": [9, 19], "penalti": 12, "peopl": [7, 8], "per": [8, 9, 12, 13], "perform": [1, 3, 4, 7, 8, 9, 10, 11, 12, 17, 20], "perform_n": 8, "period": 12, "perm_scor": 16, "perm_target1": 16, "perm_target2": 16, "permut": 16, "permutation_scor": 16, "perpetu": [4, 5, 17], "perplex": 13, "person": [8, 11, 12, 13, 21], "personif": 17, "perspect": 5, "phenomena": [1, 4, 12, 14, 16, 17, 19], "phrase": 17, "piec": 8, "pipe": 19, "pipelin": [7, 13, 19], "place": [7, 12], "placehold": 7, "plai": [7, 8, 17], "plan": [8, 13], "planet": [8, 12], "plate": 9, "platform": [17, 19, 20], "plausibl": [4, 5], "pleas": 1, "plot": [9, 13], "plt": 13, "point": [2, 4, 10, 11], "polar": [4, 9, 13, 15], "polarity_scor": 8, "polici": [8, 9, 11, 12, 13, 15, 20, 21], "policymak": [5, 21], "polit": [3, 4, 8, 9, 11, 12, 13, 15], "pool": 19, "poorli": [8, 9], "popul": [5, 19], "popular": [6, 8, 9], "porterstemm": 7, "pos_tag": 8, "pos_tag_text": 8, "pose": 2, "posit": [3, 4, 8, 9, 11, 12, 13, 16, 22], "possibl": [1, 4, 6, 10, 11, 17, 19], "possibli": 19, "post": [1, 3, 4, 5, 8, 22], "potenti": [1, 3, 8, 10, 11, 12, 15, 16, 17, 19, 20, 21], "power": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 14, 15, 17, 19], "practic": [1, 6, 12, 16, 19, 21, 22], "pragmat": 3, "prais": 15, "pre": [2, 3, 9, 11, 12, 13, 15, 19], "precis": [3, 13], "precision_recall_fscore_support": 13, "predefin": [8, 11], "predic": 3, "predict": [4, 8, 11, 12, 13], "predict_proba": 13, "prefer": 13, "prefix": 16, "prejud": 16, "prepar": [6, 10, 21], "preprocess": [1, 9, 20], "preprocess_chunk": 19, "preprocess_text": [9, 19], "preprocessed_data": 19, "presenc": 9, "present": [3, 4, 5, 14, 16, 17, 19], "preserv": [8, 21], "presid": [12, 13], "press": 11, "preval": 9, "prevent": 5, "previou": 12, "previous": [3, 19], "price": 12, "primari": [3, 11], "primarili": [3, 5], "principl": [2, 5, 11, 22], "print": [7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "print_top": [9, 19], "prior": 9, "privaci": [2, 3, 4, 12, 16, 20, 21, 22], "prob": 9, "probabilist": [3, 9], "probabl": [9, 16], "probe": 5, "problem": [3, 4, 9], "process": [1, 2, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 20, 21], "process_batch": 19, "processed_chunk": 19, "processed_doc": [9, 19], "processed_text": [7, 9], "processeddf": 19, "produc": [4, 5, 7, 12], "product": [12, 13, 15], "profess": [5, 16], "profil": 20, "profound": 13, "program": [3, 8], "progress": [2, 3, 10, 15, 16, 21], "prohibit": 12, "project": [1, 10], "prolifer": 19, "promis": 13, "prompt": [1, 3, 4, 10, 13, 16, 17, 20], "prompt_vari": 12, "propag": 20, "proper": 6, "proport": 9, "propos": [3, 12], "protect": 11, "protocol": 17, "provid": [3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19], "psycholinguist": 21, "psychotherapist": 3, "pt": [15, 16, 19], "public": [3, 4, 8, 11, 12, 15, 19, 20, 21, 22], "publish": 11, "punkt": [8, 9, 19], "purpos": [5, 8, 15], "push": 6, "pyldavi": 9, "pyspark": 19, "python": [1, 6, 22], "q": 19, "qualit": [3, 4, 6, 8, 9, 14], "qualiti": [1, 9, 12, 14], "quantit": 9, "queen": 3, "question": [1, 2, 3, 5, 7, 8, 9, 13, 14, 15, 19], "quick": [3, 7, 8], "quickli": [3, 7, 8, 10, 11, 12], "quit": 13, "r": [7, 9, 13], "race": [12, 16], "racial": 5, "rain": 17, "rais": [5, 12], "ralli": 11, "random": [9, 12, 13, 16, 20], "random_st": [8, 9, 13], "randomforestclassifi": 13, "rang": [2, 3, 4, 8, 9, 11, 12, 13, 16, 19], "rapid": [3, 11, 12, 20], "rapidli": [13, 16, 17], "rate": 17, "raw": [6, 7, 13], "re": [1, 2, 6, 7, 9, 13], "reach": 13, "reaction": 15, "read": 12, "read_csv": 9, "real": [1, 3, 11, 16, 20, 21], "realist": 15, "realiti": 21, "reason": [3, 6, 8, 13, 21], "recal": [3, 13], "receiv": 4, "recent": [1, 2, 6, 15], "recogn": 16, "recognit": [4, 6, 7, 22], "record": [19, 22], "recurr": 3, "reddit": 19, "redefin": 21, "reduc": [3, 4, 7, 11, 12], "refer": [4, 8, 12, 13, 15, 16, 17, 19], "referenc": 5, "reference_explan": 17, "reflect": [5, 16, 17], "reform": 12, "refram": 22, "regardless": [6, 16], "region": 5, "regress": 13, "regular": [5, 7], "reinforc": [5, 16], "rel": 16, "relat": [12, 15, 20], "relationship": [3, 7, 9, 11, 13, 15], "releas": [1, 13], "relev": [1, 3, 6, 7, 9, 12, 13, 14, 15, 22], "reli": 3, "reliabl": [4, 20], "religion": 12, "remain": [6, 8, 17], "remark": [3, 17], "rememb": [2, 6, 8, 9, 10], "remot": 15, "remov": [3, 9, 19], "remove_stopword": 7, "remove_urls_email": 7, "renew": [11, 12], "repeat": 9, "rephras": 4, "replac": 8, "replace_emoji": 7, "report": 19, "repres": [3, 4, 5, 6, 7, 9, 12], "represent": [1, 3, 4, 5, 6], "requir": [2, 3, 9, 10, 12, 17], "researc": 20, "research": [1, 2, 6, 8, 10, 12, 13, 14, 16, 17, 19, 20, 21], "resourc": [8, 12, 19, 20, 21], "respect": 14, "respond": 15, "respons": [1, 2, 3, 4, 8, 9, 11, 12, 13, 14, 15, 17, 21, 22], "responsibli": [1, 10], "result": [2, 3, 6, 8, 11, 12, 13, 16, 17, 19, 22], "return": [7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "return_tensor": [15, 16, 19], "reveal": [3, 8], "revers": 9, "review": [3, 4, 14, 15], "revolut": [11, 12], "revolution": [3, 10, 12, 15], "revolutionari": [1, 2], "rewrit": 4, "rf_model": 13, "rf_perform": 13, "rf_predict": 13, "rich": 17, "ride": 17, "right": [11, 12], "rigor": 5, "rise": 8, "river": 3, "rnn": [3, 20], "roberta": 4, "role": [5, 13, 17, 21], "roller": 17, "room": 16, "root": [3, 7], "roug": [13, 15], "rule": [2, 3], "run": [3, 4, 5, 7], "runner": 7, "sad": 11, "same": [5, 12], "sampl": [7, 8, 9, 13, 15], "sample_s": 13, "sample_text": [7, 15], "sar": 15, "sarcasm": [3, 8], "sarcast": 17, "sat": [3, 8, 9], "satisfact": 15, "save": [3, 9], "save_html": 9, "saw": [3, 8, 11], "scalabl": 3, "scale": [1, 2, 3, 9, 18, 21], "scari": 17, "scenario": [4, 8, 11, 12, 13, 15, 21], "scienc": [1, 6, 7, 8, 10, 12, 13, 16, 17, 19, 20, 21], "scientist": [1, 2, 4, 5, 8, 9, 10, 14, 16, 17, 19, 21, 22], "scikit": [6, 8, 13], "scipi": 16, "score": [3, 8, 9, 13, 15, 16, 17], "scrape": [5, 7, 20], "scratch": 2, "scrutini": 4, "search_tweet": 19, "second": [7, 13, 19], "section": 9, "sector": 11, "see": [1, 3], "seek": 1, "seen": [8, 11], "select": [8, 12, 13, 19], "self": [3, 19], "semant": [7, 11, 20], "senat": 12, "sens": [4, 17], "sensit": [5, 12, 14, 17, 20], "sent_token": [7, 8], "sentenc": [3, 4, 8, 17], "sentence_bleu": 13, "sentence_scor": 8, "sentiment": [3, 6, 7, 9, 14, 15, 16, 17, 22], "sentiment_analyz": 19, "sentiment_by_top": 9, "sentimentintensityanalyz": 8, "separ": [3, 11, 12], "sequenc": [3, 4], "sequenti": 3, "seri": [3, 8, 20], "servic": [12, 13], "session": [1, 19], "set": [3, 7, 8, 9, 10, 19], "set_access_token": 19, "sever": [3, 5, 6, 13, 15, 16, 17], "sex": 12, "shap": 5, "share": 13, "she": 16, "shift": [2, 4, 21], "short": [3, 9], "shot": [1, 10, 13, 20, 21], "should": [5, 8, 11, 12, 13, 15, 16, 17], "show": [8, 9, 12, 13, 17, 19], "shown": [16, 17], "shuffl": [16, 19], "sia": 8, "side": 15, "sign": [12, 13], "signal": 20, "signific": [3, 4, 5, 8, 10, 11, 16], "significantli": [3, 7, 12, 13, 14, 17, 19], "simil": 17, "similar": [3, 7, 16, 17], "similarity_matrix": 8, "simpl": [4, 8, 12, 13, 15, 17], "simple_preprocess": 19, "simplifi": [15, 19], "simul": [3, 15, 21], "singl": [4, 5, 12], "sister": 16, "size": [7, 9, 13], "skew": 5, "skill": [1, 6, 12, 21], "skip_special_token": [15, 16], "sklearn": [7, 8, 13], "slang": [8, 17], "small": [9, 12, 13], "smaller": [6, 7, 19], "smiling_face_with_heart_ey": 7, "smith": [11, 12, 15], "smote": 13, "snippet": 6, "so": [1, 8, 16], "social": [1, 6, 7, 8, 10, 12, 13, 19, 20, 21], "social_media_data": 9, "societ": [1, 16, 21], "societi": [3, 5, 13, 20, 21], "socioeconom": 16, "sociologi": 7, "softmax": 16, "solar": 8, "sole": 11, "solid": [6, 10, 14], "solv": 3, "some": [4, 8, 9, 11, 12, 15], "sometim": 17, "son": 16, "sophist": [3, 4, 5, 9, 11, 15, 16, 19], "sound": [4, 5], "sourc": [4, 14, 17, 20], "source_languag": 17, "space": [3, 19, 21], "spacex": 13, "spaci": [13, 19], "spam": 8, "spanish": 17, "spark": [15, 19], "sparksess": 19, "speak": 17, "speaker": 3, "special": [8, 9, 20, 21], "specif": [2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "specul": 21, "speech": [3, 17, 20], "speed": [13, 20], "split": [8, 11, 12, 13], "spoken": 8, "sport": [8, 11, 12, 13], "spread": [11, 12, 15, 20, 22], "spreader": 20, "sql": 19, "squar": 13, "stage": 3, "stai": 16, "stanc": 20, "stand": 12, "standard": 7, "standardize_numb": 7, "start": [12, 16], "start_tim": 13, "stat": 16, "state": [1, 21], "statement": 17, "statist": [5, 9, 16], "statu": 16, "stem": [3, 6, 9, 22], "stem_word": 7, "stemmed_text": 7, "step": [6, 7, 13, 15, 19], "stereotyp": [5, 16], "stick": 17, "still": 13, "stock": [8, 11, 12, 13], "stop": [8, 11, 12, 13, 17, 19], "stop_word": [7, 8, 9, 19], "stopword": [7, 8, 9, 19], "stopwordsremov": 19, "store": [3, 8, 13], "stori": 20, "strategi": [4, 20], "stream": 21, "street": 4, "strength": [10, 13], "strip": [11, 12, 13, 17], "strong": [6, 15], "structur": [3, 8, 9, 15, 19, 20, 21], "struggl": [3, 5, 17], "student": 22, "studi": [3, 4, 8, 11, 12, 15, 19, 20, 21, 22], "sub": [7, 9], "subfield": 8, "subject": [3, 17, 20], "sublist": 19, "substitut": 3, "subtl": 19, "subword": 3, "success": 12, "suggest": [14, 17], "suitabl": 8, "sum": 16, "summar": [3, 14, 19, 22], "summari": [1, 5, 8, 11, 12, 15, 19], "summarize_text": 8, "summary_sent": 8, "superior": 13, "supervis": [1, 3, 10, 12], "support": [3, 8, 12], "surpris": 11, "survei": [3, 4, 8, 9, 11, 14, 15], "survey_respons": 11, "sustain": 21, "sven": 16, "svm": [13, 20], "syllabu": 1, "symbol": 21, "syntact": 3, "synthes": [14, 15], "synthesi": 15, "synthet": [4, 15], "system": [2, 3, 4, 5, 8, 11, 12, 13, 20], "systemat": 16, "t": [2, 4, 5, 7, 9, 11, 16], "t5": 4, "tackl": [3, 14, 17], "tactic": 20, "tag": 3, "tagged_text": 8, "tailor": 15, "takeawai": [17, 19], "target_languag": 17, "target_set1": 16, "target_set2": 16, "task": [1, 2, 5, 6, 7, 10, 12, 17, 19, 21], "teach": 1, "teacher": 16, "team": [8, 12, 13], "tech": 11, "technic": 16, "techniqu": [1, 2, 3, 8, 10, 14, 15, 20, 21], "technolog": [5, 20], "technologi": [1, 3, 4, 8, 11, 12, 13, 15, 17, 19, 21], "telescop": 3, "temperatur": [11, 12, 13, 15, 17], "tempor": 20, "tend": 12, "tendenc": 5, "tension": 8, "tensor": 19, "term": [3, 9, 12, 15, 16, 21], "terribl": [8, 13], "tesla": 13, "test": [3, 12, 13, 21], "test_result": 12, "test_siz": [8, 13], "text": [1, 2, 9, 14, 16, 17, 20, 21], "text_to_classifi": 12, "text_to_summar": 12, "textblob": [9, 13], "textdataset": 19, "textual": [1, 2, 3, 8, 10, 11, 14, 18], "tf": [3, 6, 8, 22], "tfidf_matrix": [7, 8], "tfidf_represent": 7, "tfidfvector": [7, 8, 13], "tfw": 17, "th": 9, "than": [8, 11, 12], "thei": [2, 4, 5, 8, 10, 11, 12, 15, 16, 17], "them": [4, 7, 8, 10, 11, 12, 14, 17], "theme": [3, 4, 6, 8, 9, 11], "themselv": [8, 16], "theoret": 22, "theori": [3, 4, 21], "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 19], "thing": 17, "think": [1, 2, 10, 11, 21], "third": [7, 19], "thorough": 6, "those": [1, 2], "thoughtfulli": 9, "thousand": 3, "three": [1, 2, 6, 10, 14], "thrill": [12, 17], "through": [1, 3, 7, 9, 10, 11, 16], "throughout": [1, 2, 6, 10, 12, 14, 22], "thumbs_up": 7, "tim": [8, 13], "time": [3, 8, 9, 10, 12, 13, 19, 20, 21], "titl": 13, "to_lowercas": 7, "toarrai": 7, "todai": [8, 11, 13], "togeth": [3, 8], "toi": 7, "token": [3, 6, 8, 9, 15, 16, 19, 22], "tokenize_sent": 7, "tokenize_word": 7, "tone": [8, 9], "too": 4, "took": 7, "tool": [1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 17, 19], "top": [8, 15], "top_k": 15, "top_p": 15, "topic": [1, 4, 5, 6, 8, 10, 15], "topic_trend": 9, "torch": [15, 19], "toward": [4, 15, 16, 20], "track": [4, 7, 8, 20, 21], "trad_explan": 13, "trad_rel": 13, "trad_sent": 13, "trad_tim": 13, "trade": 13, "tradit": [1, 2, 5, 10, 12, 15, 17, 20], "tradition": [2, 10], "traditional_bleu": 13, "traditional_ent": 13, "traditional_gener": 13, "traditional_n": 13, "traditional_perform": 13, "traditional_predict": 13, "traditional_relation_extract": 13, "traditional_senti": 13, "train": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19], "train_test_split": [8, 13], "transcript": 4, "transfer": [4, 11, 20, 21], "transform": [1, 2, 7, 8, 12, 13, 15, 16, 19, 20, 22], "translat": [3, 11, 13, 17], "transpar": [2, 14, 21], "treati": 12, "treatment": 16, "trend": [1, 3, 9, 12, 18, 19, 20], "true": [15, 16, 19], "truli": [4, 19], "truncat": 19, "trust": [5, 20], "truth": 15, "tune": [3, 11, 13, 15], "turn": 11, "tweepi": 19, "tweet": [3, 9, 19], "twitter": [17, 19], "two": [8, 9, 15, 17], "type": [10, 11, 16, 17, 19, 20], "typic": [3, 7, 9, 12, 19], "u": [2, 6, 7, 16], "ultim": [6, 16], "uncas": [16, 19], "uncov": [6, 9, 14, 19], "under": 1, "undergon": [1, 2], "underli": 2, "understand": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 21], "unfair": 16, "unfamiliar": 3, "unhelp": 12, "unintend": 21, "unintent": 5, "unit": 7, "univers": [11, 12], "unlik": [4, 17], "unpreced": [1, 3, 14], "unpredict": 17, "unproduct": 17, "unseen": [11, 13], "unstack": 9, "unstructur": 8, "unsupervis": 9, "up": [1, 8, 10, 17], "uphold": 5, "upon": 6, "us": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 17, 19, 20, 21], "usag": [8, 9, 11, 12, 13, 16, 17, 19, 20], "user": 20, "usual": 7, "util": [2, 16, 19], "v": [8, 19, 22], "vader": 8, "vadersenti": 8, "valenc": 8, "valid": [2, 3, 4, 11, 12, 13, 16, 19, 22], "valu": [12, 16, 17], "valuabl": [4, 6, 8, 9, 12, 15], "value_count": 19, "vari": [5, 13], "variabl": 15, "variat": [9, 12], "varieti": 3, "variou": [3, 6, 8, 10, 12, 13, 14, 15, 16, 17, 19], "vast": [1, 3, 4, 11, 12, 14, 19], "ve": 1, "vector": [3, 7, 8, 9, 13], "verb": 8, "veri": [9, 12, 13, 19], "verif": 20, "verifi": 15, "versail": 12, "version": 4, "versu": 10, "video": [20, 21], "virtual": 21, "viru": 15, "vis_data": 9, "visibl": 19, "visionari": 21, "visual": [4, 5, 9], "vivid": 17, "vocabulari": [3, 7], "volum": [4, 8, 12, 14, 17], "vulner": 5, "w": [9, 13], "wa": [0, 4, 8, 9, 12], "wage": 4, "wai": [1, 6, 13, 14, 16], "waiter": 12, "walk": 16, "want": [9, 17], "war": [12, 17], "warn": 20, "wasn": 11, "wd": 9, "we": [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19], "weat_scor": 16, "weat_signific": 16, "weat_test": 16, "weather": [8, 12, 13], "web": [5, 7, 20], "websit": [4, 7, 20], "week": 12, "wei": 16, "weigh": 4, "weight": [3, 13], "welcom": [1, 2, 6, 10, 14], "well": [6, 8], "were": [3, 11, 19], "western": [5, 12], "what": [1, 4, 6, 7, 11, 12, 17], "when": [3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19], "where": [9, 11, 12, 14], "which": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 19], "while": [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 22], "who": [1, 5, 12], "whole": 12, "why": [5, 15], "wide": [2, 3, 4, 8, 9, 11, 12], "wiki": 7, "win": 13, "within": [8, 9, 17], "without": [3, 4, 10, 11, 12, 16], "woman": [3, 16], "won": [8, 11, 12], "word": [4, 6, 8, 9, 11, 12, 13, 17, 19, 22], "word2vec": 3, "word_freq": 8, "word_token": [7, 8, 9, 19], "wordnet": 9, "wordnetlemmat": [7, 9], "wordsdf": 19, "work": [1, 2, 6, 9, 10, 15, 19], "worker": 19, "workflow": [8, 14], "world": [1, 3, 12, 16, 20, 21], "would": 19, "write": 3, "www": 7, "x": [9, 13], "x_subset": 13, "x_test": [8, 13], "x_test_vec": 13, "x_test_vector": 8, "x_train": [8, 13], "x_train_balanc": 13, "x_train_vec": 13, "x_train_vector": 8, "xlabel": 13, "y": 13, "y_pred": [8, 13], "y_subset": 13, "y_test": [8, 13], "y_train": [8, 13], "y_train_balanc": 13, "y_true": 13, "yard": 8, "ye": 17, "year": [1, 2, 4, 6, 15], "yesterdai": 12, "yield": 12, "ylabel": 13, "york": [8, 13], "you": [1, 2, 6, 10, 12, 14, 15, 19], "your": [2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19], "your_access_token": 19, "your_access_token_secret": 19, "your_consumer_kei": 19, "your_consumer_secret": 19, "z": 9, "z0": 7, "za": [7, 9], "zd": 9, "zero": [1, 10, 12, 13, 20, 21], "zero_grad": 19, "zero_shot_classif": 11, "zero_shot_emotion_detect": 11, "zero_shot_multi_label_classif": 11, "zero_shot_n": 11, "zero_shot_qa": 11, "zero_shot_sentiment_analysi": 11, "zero_shot_summar": 11, "zhang": 16, "zip": 16, "\u03b1": 9, "\u03b2": 9, "\u03b8": 9, "\u03b8d": 9, "\u03c6": 9, "\u03c6k": 9, "\u03c6zd": 9}, "titles": ["Who made this book?", "Home", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Syllabus"], "titleterms": {"1": [2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 22], "10": [3, 4, 5, 9, 11, 12, 13, 15, 17], "11": [5, 9, 12, 13, 17], "12": [9, 12, 13], "13": 9, "1950": 3, "1980": 3, "2": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 22], "2000": 3, "3": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 21, 22], "4": [3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 22], "5": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22], "6": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "7": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "8": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19], "9": [3, 4, 5, 8, 9, 11, 12, 13, 15, 16, 17], "In": 12, "Its": 22, "The": 5, "Their": 3, "abil": 4, "about": 1, "academ": 5, "access": 5, "accuraci": [4, 5], "adapt": [4, 13], "address": [5, 7], "advanc": [4, 5, 9, 18, 22], "advantag": 4, "ai": 5, "algorithm": 9, "alloc": [9, 22], "ambigu": 3, "analysi": [4, 8, 11, 12, 13, 16, 17, 19, 22], "analyz": [3, 4, 16, 19, 22], "annot": [4, 10, 22], "answer": [4, 11, 12], "applic": [4, 9, 11, 14, 18, 22], "approach": [3, 13], "architectur": 4, "aspect": 15, "associ": 16, "attent": 4, "attribut": 5, "augment": 15, "bag": 7, "balanc": 5, "base": [5, 8, 15], "basic": [3, 8, 22], "bert": 4, "bia": [5, 16, 22], "bias": 4, "black": 5, "book": 0, "bow": 7, "box": 5, "breakthrough": 3, "capabl": [3, 4, 5, 11, 12, 13], "categor": 19, "challeng": [3, 4, 5, 8, 9, 16, 17, 22], "changelog": 1, "charact": 7, "class": 8, "classif": [4, 8, 10, 11, 12, 13, 19, 22], "clean": [7, 22], "cluster": 8, "collabor": 5, "collect": 19, "combin": 9, "compar": [13, 22], "comparison": 13, "complet": 4, "complex": [3, 4], "complianc": 5, "compon": 4, "comput": [3, 4, 5, 13], "concept": [3, 4], "concern": 5, "conclus": [12, 13, 15, 16, 17, 19], "consent": 5, "consider": [4, 5, 14, 16, 22], "consist": 5, "content": [1, 5, 15], "context": [3, 4, 5, 12, 17, 22], "continu": 5, "contribut": 1, "control": 15, "convers": 7, "copyright": 5, "core": 4, "corpora": 4, "cours": 1, "creation": 15, "cross": [4, 5], "cultur": [5, 17, 22], "current": 3, "data": [3, 4, 5, 9, 10, 15, 19, 22], "dataset": [3, 4, 19], "date": 7, "deal": [3, 7], "decis": 5, "deep": 3, "definit": [3, 4], "deploy": [4, 5], "design": 12, "detect": [4, 5, 11, 16, 17, 20, 22], "develop": [3, 5], "differ": 5, "direct": [3, 4, 9, 21, 22], "dirichlet": [9, 22], "disclosur": 5, "discours": 17, "dispar": 5, "distinct": 4, "divers": 5, "document": [7, 8], "domain": 4, "earli": 3, "effici": [4, 13], "email": 7, "embed": [3, 7, 16], "emerg": [3, 5, 21, 22], "emoji": 7, "emot": [4, 11, 15], "emoticon": 7, "engin": [11, 12, 15, 22], "enhanc": 4, "ensur": 5, "entiti": [8, 11, 12, 13, 19], "environment": 5, "equiti": 5, "ethic": [4, 5, 14, 16, 22], "ethnic": 16, "evalu": [3, 5, 8, 9, 13, 15, 17], "evolut": [3, 22], "exampl": [3, 4, 8], "explain": [5, 13], "explan": [4, 14, 15, 17, 22], "explor": 14, "exposur": 5, "extract": [3, 8, 11, 12, 13, 19], "factual": [4, 5], "fake": [20, 22], "featur": 3, "few": [3, 4, 12, 22], "figur": [17, 22], "fine": [4, 5], "foundat": [9, 11], "frequenc": 7, "from": [3, 4], "fundament": [3, 8, 9, 12, 15, 22], "futur": [3, 4, 5, 9, 21, 22], "gender": 16, "gener": [3, 4, 5, 11, 12, 13, 14, 15, 22], "global": 5, "gpt": 4, "hallucin": 5, "handl": [3, 4, 7], "high": [15, 22], "histor": 3, "home": 1, "html": 7, "human": [4, 5], "identif": 5, "idf": 7, "idiom": 17, "impact": [3, 5], "implement": 9, "implic": 5, "import": [3, 5], "improv": [4, 5], "infer": [4, 16, 22], "inform": [4, 5, 11, 12, 13], "integr": [4, 5], "intellectu": 5, "interdisciplinari": 5, "interpret": [4, 5, 8, 9, 13, 17], "introduct": [2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 22], "invers": 7, "involv": 5, "ironi": 17, "issu": 5, "its": [3, 4, 22], "kei": [3, 4, 14], "knowledg": 4, "lack": 4, "languag": [3, 4, 17, 22], "larg": [3, 4, 5, 19, 22], "larger": 3, "latent": [9, 22], "lda": [9, 22], "learn": [3, 4, 11, 12, 13, 22], "lectur": 1, "lemmat": 7, "lexicon": 8, "licens": 1, "like": 4, "limit": [4, 8, 9, 17], "lingual": 4, "ll": 14, "llm": [3, 4, 5, 10, 11, 12, 13, 15, 16, 17, 18, 22], "lowercas": 7, "made": 0, "massiv": 4, "mathemat": 9, "matter": [1, 14], "mechan": 4, "media": 17, "metaphor": 17, "methodologi": 13, "metric": [13, 17], "mine": [12, 13], "misinform": [15, 20, 22], "mitig": [4, 5, 16], "modal": 4, "model": [3, 4, 5, 7, 9, 19, 22], "modern": 3, "monitor": 5, "multi": [4, 8], "name": [8, 11, 12, 13, 19], "natur": [3, 5, 22], "need": 5, "ner": [8, 11, 12, 13], "new": [3, 20, 22], "nlp": [2, 3, 4, 5, 6, 8, 9, 16, 22], "nltk": 8, "normal": [7, 22], "notabl": 4, "note": 1, "number": 7, "object": 1, "ongo": 3, "opinion": [12, 13], "opportun": [3, 5], "optim": 12, "other": [4, 9], "outcom": 5, "output": 5, "overview": [1, 4, 22], "paradigm": 3, "paramet": 15, "paraphras": 4, "part": 8, "particip": 5, "pattern": 4, "perform": [13, 22], "person": 5, "perspect": 3, "physic": 4, "pipelin": 3, "plagiar": 5, "po": 8, "polit": 17, "pose": 5, "possibl": 3, "potenti": [4, 5], "practic": [5, 14], "pre": 4, "prepar": 9, "preprocess": [3, 6, 7, 19, 22], "privaci": 5, "process": [3, 4, 17, 19, 22], "progress": 4, "promin": 4, "promot": 5, "prompt": [11, 12, 15, 22], "proper": 5, "properti": 5, "protect": 5, "proverb": 17, "purpos": 3, "qualiti": [15, 22], "quantifi": 16, "question": [4, 11, 12], "racial": 16, "re": 5, "reason": 4, "recap": 13, "recent": 4, "recognit": [8, 11, 12, 13, 19], "regul": 5, "relat": [13, 19], "reliabl": 5, "remov": 7, "replac": 7, "represent": [7, 22], "reproduc": 5, "requir": [4, 5, 13], "research": [3, 4, 5, 9, 11, 15, 18, 22], "resourc": [4, 5, 13], "respons": 5, "result": [5, 9], "retriev": 4, "revolut": 3, "right": 5, "rise": 3, "risk": 5, "sarcasm": 17, "scalabl": [13, 19], "scale": [4, 5, 19, 22], "scienc": [2, 3, 4, 5, 9, 11, 14, 15, 18, 22], "scientif": 5, "scientist": 3, "self": 4, "semant": 3, "sentenc": 7, "sentiment": [4, 8, 11, 12, 13, 19], "seri": 4, "session": [2, 6, 10, 14, 18, 22], "shift": 3, "shot": [3, 4, 11, 12, 22], "similar": 8, "size": 4, "social": [2, 3, 4, 5, 9, 11, 14, 15, 16, 17, 18, 22], "societ": 5, "socioeconom": 5, "sourc": [5, 16, 19], "spaci": 8, "special": 7, "specif": [3, 4], "speech": 8, "state": 3, "statist": 3, "stem": 7, "stop": 7, "strategi": [5, 12], "structur": 1, "studi": 5, "subject": 5, "summar": [4, 8, 11, 12, 15], "summari": [4, 14, 22], "supervis": [13, 22], "sustain": 5, "syllabu": 22, "tabl": 1, "tag": [7, 8], "task": [3, 4, 8, 11, 13, 15, 22], "techniqu": [5, 6, 7, 9, 12, 16, 19, 22], "technologi": 5, "term": 7, "test": 16, "text": [3, 4, 5, 6, 7, 8, 11, 12, 13, 15, 19, 22], "textual": [4, 19, 22], "tf": 7, "theoret": 11, "thi": [0, 1], "token": 7, "topic": [9, 14, 19, 22], "toward": 3, "tradit": [3, 4, 6, 13, 22], "train": [3, 4, 5], "transform": [3, 4], "translat": 4, "transpar": [4, 5], "trend": [4, 21, 22], "true": 4, "tune": [4, 5], "type": [5, 8, 12, 15], "understand": [4, 17], "uniqu": 5, "unstructur": 3, "up": 4, "url": 7, "us": [5, 8, 15, 16, 22], "usag": 5, "valid": 5, "variant": 4, "variou": 4, "we": 14, "weat": 16, "when": 5, "who": 0, "why": [1, 14], "wisdom": 17, "word": [3, 7, 16], "world": 4, "zero": [3, 4, 11, 22]}})