Search.setIndex({"alltitles": {"1. Introduction": [[13, "introduction"]], "1. Introduction to Emerging Trends in NLP for Social Science": [[21, "introduction-to-emerging-trends-in-nlp-for-social-science"]], "1. Introduction to Ethics in AI and NLP Research": [[5, "introduction-to-ethics-in-ai-and-nlp-research"]], "1. Introduction to Few-shot Learning": [[12, "introduction-to-few-shot-learning"]], "1. Introduction to Figurative Language": [[17, "introduction-to-figurative-language"]], "1. Introduction to Fundamental NLP Tasks": [[8, "introduction-to-fundamental-nlp-tasks"]], "1. Introduction to Generative LLMs": [[4, "introduction-to-generative-llms"]], "1. Introduction to Large-Scale Text Analysis": [[19, "introduction-to-large-scale-text-analysis"]], "1. Introduction to Misinformation and Fake News": [[20, "introduction-to-misinformation-and-fake-news"]], "1. Introduction to Natural Language Processing (NLP)": [[3, "introduction-to-natural-language-processing-nlp"]], "1. Introduction to Social Bias in NLP": [[16, "introduction-to-social-bias-in-nlp"]], "1. Introduction to Text Generation with LLMs": [[15, "introduction-to-text-generation-with-llms"]], "1. Introduction to Text Preprocessing": [[7, "introduction-to-text-preprocessing"]], "1. Introduction to Topic Modeling": [[9, "introduction-to-topic-modeling"]], "1. Introduction to Zero-shot Learning": [[11, "introduction-to-zero-shot-learning"]], "1.1 Definition of NLP": [[3, "definition-of-nlp"]], "1.1 Fundamentals of NLP and its Evolution": [[3, "fundamentals-of-nlp-and-its-evolution"]], "1.2 Basic Concepts": [[3, "basic-concepts"]], "1.2 Overview of Generative LLMs": [[4, "overview-of-generative-llms"]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[5, "ethical-considerations-and-challenges-in-using-llms-for-research"]], "1.3 Importance in Social Science Research": [[3, "importance-in-social-science-research"]], "10. Applications in Social Science Research": [[9, "applications-in-social-science-research"], [11, "applications-in-social-science-research"]], "10. Computational Efficiency and Resource Requirements": [[13, "computational-efficiency-and-resource-requirements"]], "10. Current State and Future Directions": [[3, "current-state-and-future-directions"]], "10. Evaluation Metrics for Figurative Language Processing": [[17, "evaluation-metrics-for-figurative-language-processing"]], "10. Evaluation of Generated Text": [[15, "evaluation-of-generated-text"]], "10. Few-shot Text Generation and Summarization": [[12, "few-shot-text-generation-and-summarization"]], "10. Network Analysis in Misinformation Spread": [[20, "network-analysis-in-misinformation-spread"]], "10. Responsible Development and Deployment": [[5, "responsible-development-and-deployment"]], "10.1 Ongoing Developments in LLMs": [[3, "ongoing-developments-in-llms"]], "10.2 Emerging Challenges and Opportunities for Social Scientists": [[3, "emerging-challenges-and-opportunities-for-social-scientists"]], "11. Challenges and Limitations": [[17, "challenges-and-limitations"]], "11. Challenges and Limitations of LDA": [[9, "challenges-and-limitations-of-lda"]], "11. Few-shot Question Answering and Information Extraction": [[12, "few-shot-question-answering-and-information-extraction"]], "11. Future Challenges and Opportunities": [[5, "future-challenges-and-opportunities"]], "11. Scalability and Adaptability": [[13, "scalability-and-adaptability"]], "12. Combining Topic Modeling with Other NLP Techniques": [[9, "combining-topic-modeling-with-other-nlp-techniques"]], "12. Interpretability and Explainability": [[13, "interpretability-and-explainability"]], "12. Prompt Optimization Techniques": [[12, "prompt-optimization-techniques"]], "13. Future Directions in Topic Modeling": [[9, "future-directions-in-topic-modeling"]], "2. Advancements in Large Language Models": [[21, "advancements-in-large-language-models"]], "2. Bias in LLMs": [[5, "bias-in-llms"]], "2. Characteristics of Misinformation and Fake News": [[20, "characteristics-of-misinformation-and-fake-news"]], "2. Cultural Context in Figurative Language": [[17, "cultural-context-in-figurative-language"]], "2. Data Sources for Large-Scale Text Analysis": [[19, "data-sources-for-large-scale-text-analysis"]], "2. Few-shot Learning Capabilities of LLMs": [[12, "few-shot-learning-capabilities-of-llms"]], "2. Fundamentals of LLM-based Text Generation": [[15, "fundamentals-of-llm-based-text-generation"]], "2. Fundamentals of Latent Dirichlet Allocation (LDA)": [[9, "fundamentals-of-latent-dirichlet-allocation-lda"]], "2. Historical Perspective of NLP": [[3, "historical-perspective-of-nlp"]], "2. Key Components of LLMs": [[4, "key-components-of-llms"]], "2. Recap of Traditional Supervised Learning": [[13, "recap-of-traditional-supervised-learning"]], "2. Sources of Bias in LLMs": [[16, "sources-of-bias-in-llms"]], "2. Text Classification": [[8, "text-classification"]], "2. Text Cleaning": [[7, "text-cleaning"]], "2. Theoretical Foundations of Zero-shot Learning": [[11, "theoretical-foundations-of-zero-shot-learning"]], "2.1 Early Approaches (1950s-1980s)": [[3, "early-approaches-1950s-1980s"]], "2.1 Text Cleaning, Normalization, and Representation": [[7, "text-cleaning-normalization-and-representation"]], "2.2 Basic NLP Tasks": [[8, "basic-nlp-tasks"]], "2.2 Statistical Revolution (1980s-2000s)": [[3, "statistical-revolution-1980s-2000s"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[9, "topic-modeling-and-latent-dirichlet-allocation-lda"]], "3. Data Collection and Preprocessing for Large Datasets": [[19, "data-collection-and-preprocessing-for-large-datasets"]], "3. Data Sources for Misinformation Research": [[20, "data-sources-for-misinformation-research"]], "3. LLM Approaches in Comparison": [[13, "llm-approaches-in-comparison"]], "3. LLMs and Figurative Language Understanding": [[17, "llms-and-figurative-language-understanding"]], "3. Lowercase Conversion": [[7, "lowercase-conversion"]], "3. Mathematical Foundation of LDA": [[9, "mathematical-foundation-of-lda"]], "3. Modern NLP and Deep Learning (2010s-Present)": [[3, "modern-nlp-and-deep-learning-2010s-present"]], "3. Multimodal Analysis": [[21, "multimodal-analysis"]], "3. Notable Examples of LLMs": [[4, "notable-examples-of-llms"]], "3. Privacy Concerns": [[5, "privacy-concerns"]], "3. Sentiment Analysis": [[8, "sentiment-analysis"]], "3. Techniques for Detecting Bias in LLMs": [[16, "techniques-for-detecting-bias-in-llms"]], "3. Types of Few-shot Learning": [[12, "types-of-few-shot-learning"]], "3. Types of Text Generation Tasks": [[15, "types-of-text-generation-tasks"]], "3. Zero-shot Capabilities of LLMs": [[11, "zero-shot-capabilities-of-llms"]], "3.1 Zero-shot Learning with LLMs": [[11, "zero-shot-learning-with-llms"]], "3.2 Few-shot Learning and Prompt Engineering": [[12, "few-shot-learning-and-prompt-engineering"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[13, "comparing-llm-performance-with-traditional-supervised-learning"]], "4. Capabilities of LLMs in Social Science Contexts": [[4, "capabilities-of-llms-in-social-science-contexts"]], "4. Data Collection and Preprocessing": [[20, "data-collection-and-preprocessing"]], "4. Evaluation Metrics and Methodologies": [[13, "evaluation-metrics-and-methodologies"]], "4. Explainable AI and Interpretable NLP": [[21, "explainable-ai-and-interpretable-nlp"]], "4. Fundamentals of Prompt Engineering": [[12, "fundamentals-of-prompt-engineering"]], "4. LDA Algorithm": [[9, "lda-algorithm"]], "4. Metaphor Detection and Interpretation": [[17, "metaphor-detection-and-interpretation"]], "4. Named Entity Recognition (NER)": [[8, "named-entity-recognition-ner"]], "4. Prompt Engineering for Text Generation": [[15, "prompt-engineering-for-text-generation"]], "4. Prompt Engineering for Zero-shot Tasks": [[11, "prompt-engineering-for-zero-shot-tasks"]], "4. Quantifying Bias in LLMs": [[16, "quantifying-bias-in-llms"]], "4. Scalable Text Processing Techniques": [[19, "scalable-text-processing-techniques"]], "4. Tokenization": [[7, "tokenization"]], "4. Traditional NLP Pipeline": [[3, "traditional-nlp-pipeline"]], "4. Transparency and Interpretability": [[5, "transparency-and-interpretability"]], "4.1 Text Preprocessing": [[3, "text-preprocessing"]], "4.1 Using LLMs for High-Quality Text Generation": [[15, "using-llms-for-high-quality-text-generation"]], "4.2 Feature Extraction": [[3, "feature-extraction"]], "4.2 Social Bias Inference and Analysis": [[16, "social-bias-inference-and-analysis"]], "4.3 Figurative Language Explanation and Cultural Context": [[17, "figurative-language-explanation-and-cultural-context"]], "4.3 Model Training and Evaluation": [[3, "model-training-and-evaluation"]], "5. Challenges in Traditional NLP": [[3, "challenges-in-traditional-nlp"]], "5. Controlling Generation Parameters": [[15, "controlling-generation-parameters"]], "5. Ethical AI and Responsible NLP": [[21, "ethical-ai-and-responsible-nlp"]], "5. Idiom Processing with LLMs": [[17, "idiom-processing-with-llms"]], "5. Part-of-Speech (POS) Tagging": [[8, "part-of-speech-pos-tagging"]], "5. Performance Comparison in Classification Tasks": [[13, "performance-comparison-in-classification-tasks"]], "5. Preparing Data for LDA": [[9, "preparing-data-for-lda"]], "5. Prompt Design Strategies": [[12, "prompt-design-strategies"]], "5. Reliability and Reproducibility": [[5, "reliability-and-reproducibility"]], "5. Social Bias Inference Using LLMs": [[16, "social-bias-inference-using-llms"]], "5. Stop Word Removal": [[7, "stop-word-removal"]], "5. Topic Modeling at Scale": [[19, "topic-modeling-at-scale"]], "5. Traditional Machine Learning Approaches": [[20, "traditional-machine-learning-approaches"]], "5. Training Process of LLMs": [[4, "training-process-of-llms"]], "5. Zero-shot Classification with LLMs": [[11, "zero-shot-classification-with-llms"]], "5.1 Analyzing Large-Scale Textual Data": [[19, "analyzing-large-scale-textual-data"]], "5.1 Handling Language Ambiguity": [[3, "handling-language-ambiguity"]], "5.2 Dealing with Context and Semantics": [[3, "dealing-with-context-and-semantics"]], "5.2 Misinformation and Fake News Detection": [[20, "misinformation-and-fake-news-detection"]], "5.3 Computational Complexity": [[3, "computational-complexity"]], "5.3 Future Directions and Emerging Trends": [[21, "future-directions-and-emerging-trends"]], "6. Advantages of LLMs in Social Science Research": [[4, "advantages-of-llms-in-social-science-research"]], "6. Analyzing Gender Bias": [[16, "analyzing-gender-bias"]], "6. Aspect-based Emotion Summarization": [[15, "aspect-based-emotion-summarization"]], "6. Comparing Text Generation Capabilities": [[13, "comparing-text-generation-capabilities"]], "6. Deep Learning Techniques": [[20, "deep-learning-techniques"]], "6. Evolution Towards Modern NLP": [[3, "evolution-towards-modern-nlp"]], "6. Implementing LDA": [[9, "implementing-lda"]], "6. In-context Learning": [[12, "in-context-learning"]], "6. Intellectual Property and Attribution": [[5, "intellectual-property-and-attribution"]], "6. Large-Scale Sentiment Analysis": [[19, "large-scale-sentiment-analysis"]], "6. Multilingual and Cross-cultural NLP": [[21, "multilingual-and-cross-cultural-nlp"]], "6. Sarcasm and Irony Detection": [[17, "sarcasm-and-irony-detection"]], "6. Stemming": [[7, "stemming"]], "6. Text Summarization": [[8, "text-summarization"]], "6. Zero-shot Named Entity Recognition (NER)": [[11, "zero-shot-named-entity-recognition-ner"]], "6.1 Introduction of Word Embeddings": [[3, "introduction-of-word-embeddings"]], "6.2 Rise of Deep Learning in NLP": [[3, "rise-of-deep-learning-in-nlp"]], "6.3 Emergence of Transformer Models": [[3, "emergence-of-transformer-models"]], "7. Environmental and Resource Considerations": [[5, "environmental-and-resource-considerations"]], "7. Few-shot Classification Techniques": [[12, "few-shot-classification-techniques"]], "7. Figurative Language in Social Media Analysis": [[17, "figurative-language-in-social-media-analysis"]], "7. Interpreting LDA Results": [[9, "interpreting-lda-results"]], "7. LLM-based Approaches to Misinformation Detection": [[20, "llm-based-approaches-to-misinformation-detection"]], "7. Large Language Models (LLMs)": [[3, "large-language-models-llms"]], "7. Lemmatization": [[7, "lemmatization"]], "7. Limitations and Challenges": [[4, "limitations-and-challenges"]], "7. Misinformation Explanation Generation": [[15, "misinformation-explanation-generation"]], "7. Named Entity Recognition (NER) Performance": [[13, "named-entity-recognition-ner-performance"]], "7. Named Entity Recognition and Relation Extraction": [[19, "named-entity-recognition-and-relation-extraction"]], "7. Racial and Ethnic Bias Analysis": [[16, "racial-and-ethnic-bias-analysis"]], "7. Real-time Language Processing and Analysis": [[21, "real-time-language-processing-and-analysis"]], "7. Text Similarity and Clustering": [[8, "text-similarity-and-clustering"]], "7. Zero-shot Sentiment Analysis and Emotion Detection": [[11, "zero-shot-sentiment-analysis-and-emotion-detection"]], "7.1 Definition and Capabilities": [[3, "definition-and-capabilities"]], "7.2 Examples and Their Impact": [[3, "examples-and-their-impact"]], "8. Challenges and Limitations": [[8, "challenges-and-limitations"]], "8. Content-based Analysis": [[20, "content-based-analysis"]], "8. Evaluating Topic Models": [[9, "evaluating-topic-models"]], "8. Few-shot Named Entity Recognition (NER)": [[12, "few-shot-named-entity-recognition-ner"]], "8. High-Quality Content Creation": [[15, "high-quality-content-creation"]], "8. Mitigating Bias in LLMs": [[16, "mitigating-bias-in-llms"]], "8. Neuro-symbolic AI in NLP": [[21, "neuro-symbolic-ai-in-nlp"]], "8. Paradigm Shift in NLP Tasks": [[3, "paradigm-shift-in-nlp-tasks"]], "8. Proverbs and Cultural Wisdom": [[17, "proverbs-and-cultural-wisdom"]], "8. Recent Advancements": [[4, "recent-advancements"]], "8. Sentiment Analysis and Opinion Mining": [[13, "sentiment-analysis-and-opinion-mining"]], "8. Socioeconomic Implications": [[5, "socioeconomic-implications"]], "8. Text Classification and Categorization": [[19, "text-classification-and-categorization"]], "8. Text Representation Techniques": [[7, "text-representation-techniques"]], "8. Zero-shot Text Summarization and Generation": [[11, "zero-shot-text-summarization-and-generation"]], "8.1 From Task-Specific to General-Purpose Models": [[3, "from-task-specific-to-general-purpose-models"]], "8.2 Few-Shot and Zero-Shot Learning": [[3, "few-shot-and-zero-shot-learning"]], "9. Advanced Topic Modeling Techniques": [[9, "advanced-topic-modeling-techniques"]], "9. Data Augmentation for Social Science Research": [[15, "data-augmentation-for-social-science-research"]], "9. Ethical Considerations and Challenges": [[16, "ethical-considerations-and-challenges"]], "9. Evaluation and Interpretation": [[8, "evaluation-and-interpretation"]], "9. Few-shot Sentiment Analysis and Opinion Mining": [[12, "few-shot-sentiment-analysis-and-opinion-mining"]], "9. Figurative Language in Political Discourse": [[17, "figurative-language-in-political-discourse"]], "9. Future Directions": [[4, "future-directions"]], "9. Human-AI Collaboration in Research": [[21, "human-ai-collaboration-in-research"]], "9. Impact on Social Science Research": [[3, "impact-on-social-science-research"]], "9. Information Extraction and Relation Classification": [[13, "information-extraction-and-relation-classification"]], "9. Informed Consent and Participant Rights": [[5, "informed-consent-and-participant-rights"]], "9. Source Credibility Assessment": [[20, "source-credibility-assessment"]], "9. Zero-shot Question Answering and Information Extraction": [[11, "zero-shot-question-answering-and-information-extraction"]], "9.1 New Possibilities for Analyzing Unstructured Text Data": [[3, "new-possibilities-for-analyzing-unstructured-text-data"]], "9.2 Handling Larger Datasets and Complex Language Tasks": [[3, "handling-larger-datasets-and-complex-language-tasks"]], "Ability to generate human-like text": [[4, "ability-to-generate-human-like-text"]], "About": [[1, null]], "Access disparities to LLM technologies": [[5, "access-disparities-to-llm-technologies"]], "Adaptability to various domains and tasks": [[4, "adaptability-to-various-domains-and-tasks"]], "Additional Resources": [[22, "additional-resources"]], "Assessment": [[22, "assessment"]], "BERT and its variants": [[4, "bert-and-its-variants"]], "Bag-of-Words (BoW) model": [[7, "bag-of-words-bow-model"]], "Balancing research needs with sustainability concerns": [[5, "balancing-research-needs-with-sustainability-concerns"]], "Challenges in ensuring consistent outputs": [[5, "challenges-in-ensuring-consistent-outputs"]], "Challenges in explaining model decisions": [[5, "challenges-in-explaining-model-decisions"]], "Changelog": [[1, "changelog"]], "Computational resources required": [[4, "computational-resources-required"]], "Computational resources required for training and using LLMs": [[5, "computational-resources-required-for-training-and-using-llms"]], "Conclusion": [[3, "conclusion"], [12, "conclusion"], [13, "conclusion"], [15, "conclusion"], [16, "conclusion"], [17, "conclusion"], [19, "conclusion"], [20, "conclusion"], [21, "conclusion"]], "Considerations for global and cross-cultural research": [[5, "considerations-for-global-and-cross-cultural-research"]], "Continuous monitoring and evaluation of ethical implications": [[5, "continuous-monitoring-and-evaluation-of-ethical-implications"]], "Contributing": [[1, "contributing"]], "Copyright issues with training data and generated content": [[5, "copyright-issues-with-training-data-and-generated-content"]], "Course Description": [[22, "course-description"]], "Course Objectives": [[1, "course-objectives"], [22, "course-objectives"]], "Course Overview": [[1, "course-overview"]], "Course Structure": [[1, "course-structure"], [22, "course-structure"]], "Course Syllabus": [[22, "course-syllabus"]], "Data protection and compliance with privacy regulations": [[5, "data-protection-and-compliance-with-privacy-regulations"]], "Dealing with numbers and dates": [[7, "dealing-with-numbers-and-dates"]], "Definition and core concept": [[4, "definition-and-core-concept"]], "Disclosure of AI involvement in research studies": [[5, "disclosure-of-ai-involvement-in-research-studies"]], "Distinction from traditional NLP models": [[4, "distinction-from-traditional-nlp-models"]], "Emerging ethical issues with advancing LLM capabilities": [[5, "emerging-ethical-issues-with-advancing-llm-capabilities"]], "Enhanced multi-modal capabilities": [[4, "enhanced-multi-modal-capabilities"]], "Environmental impact of large-scale AI models": [[5, "environmental-impact-of-large-scale-ai-models"]], "Ethical Considerations": [[14, "ethical-considerations"]], "Ethical considerations in deployment": [[4, "ethical-considerations-in-deployment"]], "Ethical considerations in model development and fine-tuning": [[5, "ethical-considerations-in-model-development-and-fine-tuning"]], "Ethical considerations when using LLMs in human subjects research": [[5, "ethical-considerations-when-using-llms-in-human-subjects-research"]], "Example: Document Similarity and Clustering": [[8, "example-document-similarity-and-clustering"]], "Example: Extractive Summarization": [[8, "example-extractive-summarization"]], "Example: Lexicon-based Sentiment Analysis": [[8, "example-lexicon-based-sentiment-analysis"]], "Example: Multi-class Classification": [[8, "example-multi-class-classification"]], "Example: NER using spaCy": [[8, "example-ner-using-spacy"]], "Example: POS Tagging with NLTK": [[8, "example-pos-tagging-with-nltk"]], "Few-shot and zero-shot learning capabilities": [[4, "few-shot-and-zero-shot-learning-capabilities"]], "Fine-tuning for specific tasks": [[4, "fine-tuning-for-specific-tasks"]], "GPT (Generative Pre-trained Transformer) series": [[4, "gpt-generative-pre-trained-transformer-series"]], "Handling URLs and email addresses": [[7, "handling-urls-and-email-addresses"]], "Handling complex language understanding tasks": [[4, "handling-complex-language-understanding-tasks"]], "Home": [[1, "home"]], "Impact on research outcomes and societal implications": [[5, "impact-on-research-outcomes-and-societal-implications"]], "Importance of ethical considerations in social science": [[5, "importance-of-ethical-considerations-in-social-science"]], "Importance of interpretability in scientific research": [[5, "importance-of-interpretability-in-scientific-research"]], "Importance of reproducibility in scientific research": [[5, "importance-of-reproducibility-in-scientific-research"]], "Improved interpretability and transparency": [[4, "improved-interpretability-and-transparency"]], "Improvements in model size and efficiency": [[4, "improvements-in-model-size-and-efficiency"]], "Integration with domain-specific knowledge": [[4, "integration-with-domain-specific-knowledge"]], "Interdisciplinary collaboration in addressing ethical challenges": [[5, "interdisciplinary-collaboration-in-addressing-ethical-challenges"]], "Issues with hallucination and factual accuracy": [[5, "issues-with-hallucination-and-factual-accuracy"]], "Key Topics We\u2019ll Explore": [[14, "key-topics-we-ll-explore"], [18, "key-topics-we-ll-explore"]], "Lack of true understanding or reasoning": [[4, "lack-of-true-understanding-or-reasoning"]], "Lecture Notes": [[1, null]], "License": [[1, "license"]], "Other prominent models": [[4, "other-prominent-models"]], "Participant rights and data usage in LLM-based research": [[5, "participant-rights-and-data-usage-in-llm-based-research"]], "Plagiarism concerns and academic integrity": [[5, "plagiarism-concerns-and-academic-integrity"]], "Potential biases in training data": [[4, "potential-biases-in-training-data"]], "Potential for LLMs in promoting ethical research practices": [[5, "potential-for-llms-in-promoting-ethical-research-practices"]], "Potential for personal information exposure in training data": [[5, "potential-for-personal-information-exposure-in-training-data"]], "Potential impact on research equity and diversity": [[5, "potential-impact-on-research-equity-and-diversity"]], "Practical Applications": [[14, "practical-applications"]], "Practical Applications and Ethical Considerations": [[18, "practical-applications-and-ethical-considerations"]], "Pre-training on large corpora": [[4, "pre-training-on-large-corpora"]], "Preparing for the Future of Social Science Research": [[18, "preparing-for-the-future-of-social-science-research"]], "Prerequisites": [[22, "prerequisites"]], "Progress in mitigating biases and improving factual accuracy": [[4, "progress-in-mitigating-biases-and-improving-factual-accuracy"]], "Proper attribution of AI-generated text in research": [[5, "proper-attribution-of-ai-generated-text-in-research"]], "Question answering and information retrieval": [[4, "question-answering-and-information-retrieval"]], "Recommended Textbooks": [[22, "recommended-textbooks"]], "Removing HTML tags and special characters": [[7, "removing-html-tags-and-special-characters"]], "Removing or replacing emojis and emoticons": [[7, "removing-or-replacing-emojis-and-emoticons"]], "Required Materials": [[22, "required-materials"]], "Responsible use of LLMs in different research contexts": [[5, "responsible-use-of-llms-in-different-research-contexts"]], "Risks of re-identification in generated text": [[5, "risks-of-re-identification-in-generated-text"]], "Scaled-up training on massive datasets": [[4, "scaled-up-training-on-massive-datasets"]], "Schedule": [[22, "schedule"]], "Self-attention mechanism": [[4, "self-attention-mechanism"]], "Sentence tokenization": [[7, "sentence-tokenization"]], "Sentiment analysis and emotion detection": [[4, "sentiment-analysis-and-emotion-detection"]], "Session 1 - Introduction to NLP for Social Science": [[2, "session-1-introduction-to-nlp-for-social-science"]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[22, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[6, "session-2-traditional-nlp-techniques-and-text-preprocessing"], [22, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[10, "session-3-llms-for-data-annotation-and-classification"], [22, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[14, "session-4-generative-explanations-and-summaries-in-social-science"], [22, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[18, "session-5-advanced-applications-of-llms-in-social-science-research"], [22, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Sources of bias": [[5, "sources-of-bias"]], "Strategies for bias detection and mitigation": [[5, "strategies-for-bias-detection-and-mitigation"]], "Strategies for validating LLM-generated results": [[5, "strategies-for-validating-llm-generated-results"]], "Summarization and paraphrasing": [[4, "summarization-and-paraphrasing"]], "Table of Contents": [[1, "table-of-contents"]], "Techniques for improving model transparency": [[5, "techniques-for-improving-model-transparency"]], "Term Frequency-Inverse Document Frequency (TF-IDF)": [[7, "term-frequency-inverse-document-frequency-tf-idf"]], "Text generation and completion": [[4, "text-generation-and-completion"]], "The \u201cblack box\u201d nature of LLMs": [[5, "the-black-box-nature-of-llms"]], "Transformer architecture": [[4, "transformer-architecture"]], "Translation and cross-lingual tasks": [[4, "translation-and-cross-lingual-tasks"]], "Types of bias": [[5, "types-of-bias"]], "Types of classification:": [[8, "types-of-classification"]], "Unique challenges posed by LLMs": [[5, "unique-challenges-posed-by-llms"]], "Who made this book?": [[0, "who-made-this-book"]], "Why Advanced Applications Matter in Social Science Research": [[18, "why-advanced-applications-matter-in-social-science-research"]], "Why Generative Explanations and Summaries Matter in Social Science": [[14, "why-generative-explanations-and-summaries-matter-in-social-science"]], "Why This Course Matters": [[1, "why-this-course-matters"]], "Word Embedding Association Test (WEAT)": [[16, "word-embedding-association-test-weat"]], "Word Embeddings": [[7, "word-embeddings"]], "Word tokenization": [[7, "word-tokenization"]]}, "docnames": ["about/index", "index", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "0": [1, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "002": [3, 4, 11, 12, 13, 17, 20, 21], "04": 7, "05": 8, "1": [1, 6, 10, 14, 18], "10": [4, 7, 19], "100": [3, 4, 7, 11, 12, 13, 15, 17, 20, 21], "1000": [13, 16, 19, 21], "10000": [4, 13], "128": 19, "15": 7, "150": [4, 13, 21], "1500": 7, "175": 4, "18th": [11, 12], "19": [15, 20], "1919": 12, "1964": 12, "1966": 3, "19th": 12, "2": [1, 2, 10, 14, 18], "20": 13, "200": [3, 17, 21], "2017": 3, "2019": 15, "2020": [15, 21, 22], "2021": 15, "2022": 22, "2023": [7, 21], "2030": 12, "25": 22, "256": 4, "2e": 4, "2f": 21, "3": [1, 2, 6, 14, 18], "30": [9, 12], "300": 4, "32": 19, "35": [15, 22], "3f": 16, "3rd": 22, "4": 1, "40": 22, "42": [3, 8, 9, 13, 20], "420": 21, "4f": [3, 13, 21], "5": 1, "50": [3, 4, 11, 12, 13, 15, 16], "500": 20, "512": [3, 4, 20], "5g": [15, 20], "60": 9, "7": 22, "9": 7, "9000": 3, "95": 15, "A": [4, 6, 8, 9, 12, 13, 16, 17, 20], "And": [7, 19], "As": [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "BY": 1, "Be": [8, 11], "By": [1, 3, 5, 6, 9, 10, 14, 15, 16, 17, 18, 19, 20, 22], "For": [3, 6, 7, 8, 9, 13, 15, 19], "IN": 3, "If": [15, 17], "In": [1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 18, 19], "It": [2, 3, 7, 8, 9, 11, 12, 13, 14, 17], "NOT": 20, "No": [13, 17], "One": [12, 16], "The": [1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "There": 3, "These": [1, 3, 4, 6, 8, 10, 12, 14], "To": [9, 13, 15, 16], "_": [12, 13, 16], "___": 3, "____": 3, "_______": 3, "________________________": 3, "__getitem__": 19, "__init__": [4, 19], "__len__": 19, "ab_test_prompt": 12, "abbrevi": 8, "abil": [3, 5, 6, 8, 11, 12, 14, 15, 19], "abl": [10, 22], "about": [2, 3, 4, 5, 7, 9, 10, 12, 13, 15, 16, 19, 20], "abov": 16, "absolut": [3, 11], "abstract": [2, 9, 11], "academ": [3, 4], "acc": 13, "access": [2, 4, 14], "access_token": [19, 20, 21], "access_token_secret": [19, 20, 21], "accord": [3, 8, 13, 20], "account": 5, "accur": [6, 8, 12, 16, 17], "accuraci": [3, 8, 12, 13, 14, 15, 17, 20], "accuracy_scor": 13, "achiev": [3, 4, 6, 11], "acknowledg": 16, "across": [3, 4, 9, 14, 17, 19], "act": [3, 12], "actual": 12, "adamw": 4, "adapt": [2, 3, 5, 10, 12, 15, 18, 21], "add": [9, 12, 19], "add_edg": 20, "addit": 17, "addition": 16, "address": [3, 9, 16, 18, 20, 21, 22], "adher": 21, "adjac": 3, "adject": 8, "adjust": 15, "adopt": [3, 21], "ador": 21, "adult": 4, "advanc": [1, 2, 3, 6, 12, 15, 17, 19], "advantag": [12, 15], "advent": [1, 10], "affect": [5, 12, 15], "after": [4, 7, 12], "ag": [3, 16], "against": 5, "agenc": 5, "agreement": 8, "ahead": 4, "ai": [3, 12, 13, 14, 15, 18, 20, 22], "ai_research_assist": 21, "aim": [1, 3, 4, 11, 12], "al": 15, "albert": 4, "algorithm": [3, 5, 7, 12, 13, 16], "alik": 8, "all": [2, 3, 4, 11, 12, 16], "all_ent": 19, "all_target": 16, "alloc": [1, 5, 6, 19, 22], "allow": [3, 4, 5, 9, 10, 11, 12, 14, 16, 19], "almost": 11, "alon": 9, "alongsid": 5, "alphabet": [3, 19], "also": [1, 2, 3, 4, 10, 11, 12, 14, 17, 18], "alter": 12, "alwai": [1, 9, 15], "am": 3, "amaz": [13, 20, 21], "amazon": 13, "america": [11, 12], "among": [4, 15, 21], "amount": [1, 3, 4, 8, 12, 14, 18, 19], "amp": 7, "amplif": [5, 14], "amplifi": [4, 5], "amus": 17, "an": [1, 3, 5, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22], "analys": [3, 17], "analysi": [1, 2, 3, 5, 6, 7, 9, 10, 14, 15, 22], "analyt": 3, "analyz": [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22], "analyze_cont": 20, "analyze_emot": 4, "analyze_occupation_bia": 16, "analyze_political_metaphor": 17, "analyze_proverb": 17, "analyze_senti": [3, 8], "analyze_sentiment_multilingu": 3, "analyze_social_concept": 4, "analyze_social_media_post": 21, "analyze_social_trend": 21, "analyze_spread_network": 20, "anger": 11, "angri": 20, "ani": [3, 6, 16, 17], "anim": 4, "annot": [1, 2, 8, 11], "announc": [8, 12, 13, 20], "anonym": 5, "anoth": [7, 17], "answer": [2, 3], "answer_quest": 4, "anticip": 18, "apach": 19, "api": [3, 4, 7, 11, 12, 13, 17, 19, 20, 21], "api_kei": [3, 4, 11, 12, 13, 17, 20, 21], "apolog": 3, "append": [11, 13, 16, 19, 20, 21], "appl": [8, 12, 13], "appli": [1, 2, 3, 4, 8, 9, 10, 11, 12, 16, 22], "applic": [1, 3, 4, 6, 7, 8, 12, 13, 15, 21], "apply_rul": 21, "appnam": 19, "approach": [1, 2, 5, 8, 9, 10, 12, 15, 16, 17, 18, 19, 21, 22], "appropri": [3, 4, 5, 8, 12, 13], "ar": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20], "architectur": [3, 5, 15, 16], "archiv": 19, "area": [2, 4, 6, 14, 16, 17], "aren": 5, "argmax": [3, 4, 20], "argument": 15, "aris": [5, 16], "arithmet": 3, "around": 3, "arrai": 21, "arriv": 5, "art": [1, 3], "articl": [4, 8, 9, 18, 20], "artifact": 4, "artifici": [3, 4, 8], "artist": [16, 21], "as_list": [13, 21], "ask": 2, "aspect": [5, 11, 12, 17, 22], "assess": [5, 9], "assign": [3, 8, 12, 22], "assist": [5, 15, 17, 18, 21], "associ": [5, 9], "association_1": 16, "association_2": 16, "assum": [3, 9, 13, 19, 20, 21], "assumpt": 9, "attend": 7, "attent": [3, 5, 12], "attention_mask": [4, 19], "attention_output": 4, "attribut": [9, 16, 17], "attribute_set1": 16, "attribute_set2": 16, "attun": 8, "audienc": [14, 17], "audio": [3, 21], "audit": 5, "augment": 8, "ausgezeichnet": 3, "auth": [19, 20, 21], "authent": [19, 20], "authorit": 5, "autom": [3, 10, 13, 20], "automat": [3, 9], "automodel": 16, "automodelforsequenceclassif": [3, 19], "autoregress": 15, "autotoken": [3, 16, 19], "avail": [3, 13, 20], "averag": [9, 13], "averaged_perceptron_tagg": [3, 8], "avoid": [14, 16], "awai": 2, "awar": [3, 4, 5, 8, 11, 12, 17], "axi": 4, "b": [7, 12, 16, 20], "backbon": 6, "background": 16, "backward": [4, 19], "bad": 21, "bag": 3, "balanc": [13, 15, 20], "bank": 3, "barrier": 4, "base": [1, 2, 3, 4, 9, 11, 12, 13, 16, 19, 21, 22], "basi": 6, "basic": [1, 6, 15, 22], "batch": [4, 19], "batch_ent": 19, "batch_result": 19, "batch_siz": [4, 19], "bay": [3, 8], "beach": 21, "beach_selfi": 21, "beat": 13, "beautifulsoup": 20, "becaus": [2, 4, 20], "becom": [3, 5, 19, 20, 21], "been": [10, 11, 12, 13], "befor": [3, 9], "began": [11, 12], "begin": [1, 6, 10, 14], "behavior": [1, 3, 20, 21], "behind": [8, 9, 11], "being": 6, "believ": [4, 11, 20], "benchmark": 3, "benefit": [1, 5], "bert": [3, 13, 16, 19, 20, 21], "bertforsequenceclassif": [3, 4, 20], "berttoken": [3, 4, 20], "best": [2, 4, 8, 11, 12, 16], "better": [4, 5, 9, 11, 12, 21], "between": [1, 2, 3, 4, 5, 8, 9, 11, 12, 13, 15, 16, 17, 20, 21], "betweenness_c": 20, "betweenness_centr": 20, "beyond": [3, 4], "bezo": 13, "bia": [1, 2, 3, 4, 14, 17, 19, 21, 22], "bias": [1, 3, 5, 8, 11, 12, 14, 16, 17, 18, 20, 21], "bias_analysi": 3, "bias_check": 4, "biased_prompt": 16, "bidirect": [3, 4], "big": 19, "bill": [12, 13], "billion": 4, "binari": 8, "biodivers": 8, "bit": [4, 12], "black": [3, 21], "bleu": 13, "bleu_scor": 13, "blockchain": 21, "boi": [16, 21], "bold": 20, "book": [1, 4], "bool": 20, "both": [1, 2, 3, 4, 9, 13, 15, 19, 20], "boundari": [6, 18], "bow_matrix": 7, "bow_represent": 7, "box": [3, 21], "brad": 16, "break": [3, 7, 12], "breakthrough": 3, "bridg": [1, 2, 3, 12, 18], "brief": [3, 4, 20], "bring": 5, "britain": [11, 12], "broader": 5, "brother": 16, "brought": 3, "brown": [7, 8], "bs4": 20, "bucket": 17, "buffer": [11, 12], "bui": 3, "build": [2, 6], "builder": 19, "built": [4, 6, 18], "busi": [3, 12, 19], "c": 20, "c_v": 9, "calcul": [8, 9, 16, 20, 21], "cambridg": 22, "can": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20], "cannot": 7, "capabl": [1, 2, 8, 10, 14, 15, 17, 18, 21], "captur": [3, 4, 7, 11], "car": 5, "carbon": [5, 11, 12], "care": [3, 4, 8, 15, 16, 19], "carefulli": [4, 5, 9, 13, 16, 20], "caregiv": 16, "carri": 7, "case": [7, 13], "cat": [3, 8, 9, 17], "categor": [3, 8], "categori": [3, 4, 8, 11, 12, 13], "caus": [12, 15, 20], "caution": 16, "cc": 1, "ce": 21, "central": 20, "centuri": [11, 12], "ceo": [8, 13, 16], "certain": [5, 20], "cett": 3, "challeng": [1, 2, 10, 12, 19, 20, 21, 22], "chamber": 21, "championship": [8, 12, 13], "chang": [3, 4, 8, 9, 11, 12, 13, 15, 17, 19, 20, 21], "changer": 14, "charact": [3, 9, 20], "character": [3, 9], "characterist": [13, 17], "chase": [3, 9], "chatbot": 3, "cheap": 12, "check": [4, 7, 20, 21], "check_domain_cred": 20, "check_gender_bia": 4, "check_misinformation_ind": 20, "child": 7, "children": [7, 15], "chines": 21, "choic": [3, 4, 11, 12, 13, 17, 20, 21], "chomski": 3, "choos": [8, 11, 13], "chunk": 19, "chunk_siz": 19, "citat": 20, "citi": [8, 13], "citizen": [5, 15], "civil": 12, "claim": 15, "clariti": 17, "class": [3, 4, 11, 12, 13, 19, 21], "class_": 20, "class_nam": [13, 21], "classif": [1, 3, 4, 20, 21], "classifi": [3, 4, 8, 10, 11, 12, 13, 20, 21], "classification_report": [3, 8, 13, 20], "classify_text": [4, 20], "clean": [1, 3, 6, 9, 22], "clean_html": 7, "clean_text": 7, "cleaned_text": 7, "clear": [5, 11, 12], "clearer": 6, "clf": [3, 8, 20, 21], "climat": [8, 9, 11, 12, 19, 20, 21], "close": [3, 12, 20], "closer": 21, "cloudi": 8, "cluster_docu": 8, "cnn": 3, "coaster": 17, "code": [3, 4, 6, 11, 14, 16, 19, 22], "code_interview_respons": 3, "code_survey_respons": 11, "coded_data": 11, "coded_respons": 11, "coded_them": 11, "coding_schem": 3, "coher": [3, 4, 8, 9, 15], "coherence_model": 9, "coherence_scor": 9, "coherencemodel": 9, "colab": 22, "cold": 17, "collabor": [3, 18, 20], "collect": [3, 9], "collect_tweet": 20, "collected_tweet": 20, "color": 12, "column": 9, "com": [7, 20], "combat": [18, 20], "combin": [3, 5, 8, 12, 13, 20, 21], "come": [1, 3, 5, 6, 8, 10], "comma": [11, 12], "commit": [5, 12], "common": [3, 7, 8, 9, 11, 16, 17, 20], "commun": [3, 8, 12, 13, 14, 17], "commut": 21, "compani": [13, 16], "compar": [1, 10, 16, 17, 22], "comparison": 17, "complet": [3, 11, 12, 13, 16, 17, 19, 20, 21], "complex": [2, 5, 6, 8, 12, 14, 16, 17, 18, 19, 20, 21, 22], "compon": [12, 19], "composit": 17, "compound": 8, "comprehens": [4, 8, 10, 12, 18, 20, 21], "comput": [8, 16, 19], "computation": 4, "concept": [6, 11, 13, 14, 22], "concern": [2, 3, 8, 12, 15, 20], "concis": [8, 21], "conclus": [4, 5, 9, 11], "condens": 4, "conduct": [16, 18], "confid": 5, "congress": 12, "conll03": 13, "connect": 12, "consciou": 3, "consent": [4, 16, 18], "consequ": 8, "consid": [2, 3, 4, 5, 7, 9, 10, 12, 13, 15, 16, 17, 18, 20], "consider": [1, 2, 3, 10, 19, 20, 21, 22], "consist": [3, 7, 11, 12, 22], "conspiraci": 20, "constantli": 1, "constrain": 15, "consum": [8, 10], "consumer_kei": [19, 20, 21], "consumer_secret": [19, 20, 21], "consumpt": 5, "contain": [1, 4, 8, 17, 20, 21], "contemporari": [4, 5], "content": [3, 4, 7, 8, 14, 21], "context": [1, 2, 8, 10, 11, 14, 15, 16, 20, 21, 22], "contextu": [3, 4, 8, 15, 17, 20], "continu": [3, 4, 11, 12, 13, 15, 17, 19, 20, 21], "contradict": 15, "contribut": [4, 7, 16, 18, 21], "control": 5, "controversi": 4, "convei": 17, "convert": [3, 7, 9, 20], "convolut": 3, "cook": [8, 13], "core": 11, "corenlp": 3, "corenlppars": 3, "cornerston": 5, "corpora": [3, 9, 11, 12, 19], "corpu": [3, 7, 8, 9, 19, 20], "correct": [7, 15, 17], "correl": [9, 15], "correspond": 8, "cosin": 8, "cosine_similar": [8, 16, 21], "cost": [3, 5], "could": [3, 4, 5, 10, 12], "couldn": 4, "count": [12, 19, 20], "counter": [18, 19], "countri": 4, "countvector": [3, 7], "cours": [2, 6, 10, 14, 18], "cov": 15, "cover": [2, 6, 10, 18, 22], "coverag": 12, "covid": [15, 20], "cpu": 19, "cpu_count": 19, "craft": [3, 16], "creat": [0, 3, 4, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "createdatafram": 19, "creativ": 15, "creator": 20, "credenti": [19, 20, 21], "crise": 18, "criteria": 17, "criterion": 17, "critic": [1, 2, 3, 12, 16, 18, 20, 21, 22], "cross": [3, 9, 11, 17, 20], "crucial": [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "cryptocurr": 21, "csv": 9, "cuda": 19, "cultur": [1, 8, 11, 12, 14, 16, 18, 20, 22], "cultural_context": 17, "curat": 5, "current": [4, 15, 18], "cursor": [19, 20], "curtain": 17, "custom": [8, 12], "cut": [1, 2, 18, 21, 22], "d": [7, 9, 20, 22], "d_model": 4, "dai": 11, "daili": [11, 15], "dall": 4, "danger": 20, "data": [1, 2, 7, 8, 11, 12, 13, 14, 16, 17, 18, 21], "databas": 20, "datafram": [9, 19], "dataload": [4, 19], "dataset": [1, 5, 6, 8, 11, 12, 13, 14, 15, 18, 22], "date": [9, 11], "daughter": 16, "davinci": [3, 4, 11, 12, 13, 17, 20, 21], "dbmdz": 13, "deal": [5, 12, 14, 17, 19], "debat": [4, 9, 15], "debias": 16, "debiased_gener": 16, "debiased_prompt": 16, "debiased_result": 16, "debiasing_prefix": 16, "decad": 4, "decept": 5, "decis": [3, 4, 8, 10, 13], "decod": [15, 16], "deduc": 17, "deep": [2, 9, 15], "deepen": 1, "deeper": [3, 4, 17, 18, 19], "def": [3, 4, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "degre": 20, "degree_c": 20, "degree_centr": 20, "delici": 12, "delv": [4, 6, 14, 18], "demograph": [3, 15, 21], "demographic_group": 3, "demoj": 7, "demonstr": [3, 4, 8, 9, 11, 12, 22], "dens": [3, 7], "depend": [3, 4, 5, 7, 15, 17, 20], "deploy": 16, "depth": 14, "describ": [3, 12], "descript": [4, 11, 12], "design": [1, 2, 4, 5, 11, 18, 22], "desir": 12, "despit": [3, 4], "detach": 16, "detail": [5, 7, 12, 15], "detect": [1, 9, 14, 18, 19, 22], "detect_and_explain_metaphor": 17, "detect_misinform": 20, "detect_sarcasm": 17, "determin": [8, 9, 12, 17], "develop": [1, 4, 9, 12, 16, 18, 20, 21], "devic": 19, "df": [9, 19], "diagnosi": 13, "diagnost": 12, "diagram": 9, "dialogu": [5, 15], "dictionari": [8, 9, 19], "did": 12, "didn": 4, "dies": 21, "dieser": 3, "differ": [4, 8, 9, 11, 13, 14, 16], "difficult": [8, 9, 12, 17], "difficulti": 12, "digit": [3, 19, 20], "dim": [3, 4, 16, 20], "dimens": [5, 7], "dimension": 3, "direct": [1, 13, 17, 18, 22], "dirichlet": [1, 6, 19, 22], "disadvantag": 5, "disappoint": [4, 13], "discours": [3, 9, 15, 18, 21], "discov": [1, 8, 9, 20], "discoveri": [19, 20, 22], "discrimin": 12, "discuss": [2, 9, 10, 14, 18], "distant": 8, "distort": 20, "distribut": [9, 19], "div": 20, "dive": [1, 18], "divers": [4, 12, 14, 15, 17, 18, 19, 21], "do": [1, 3, 16, 19], "do_sampl": 16, "doc": [3, 8, 9, 13, 19, 20], "doc2bow": [9, 19], "doc_ent": 19, "doc_lda": 9, "doctor": [4, 16, 21], "document": [1, 3, 9, 18, 19, 22], "doe": 12, "dog": [3, 7, 8, 9, 17], "domain": [3, 8, 9, 11, 12, 15, 20, 21], "domest": 12, "domin": [3, 9], "dominant_top": 9, "don": [2, 4, 7, 21], "dot": [4, 9, 16], "down": 17, "download": [3, 7, 8, 9, 19, 21], "downstream": 7, "dr": 11, "draft": 22, "dramat": 3, "draw": [9, 20], "driven": [3, 18, 22], "drug": 12, "dt": 3, "due": [3, 12, 17, 19, 20, 21], "dure": [4, 11, 12, 18], "dynam": [1, 9, 18], "d\u00e9cision": 3, "e": [3, 4, 5, 7, 8, 9, 12, 13, 15, 20], "each": [1, 3, 4, 7, 9, 12, 13, 22], "earli": [12, 19], "earn": 4, "earth": 20, "easier": 7, "easili": [7, 9, 12], "echo": 21, "econom": [3, 4, 9, 11, 12, 13], "economi": [11, 13], "ecstat": 20, "ed": 22, "edg": [1, 2, 18, 21, 22], "educ": 11, "effect": [1, 3, 4, 5, 6, 10, 11, 12, 14, 15, 17, 19, 20, 21], "effici": [3, 6, 8, 10, 14, 19], "effort": 10, "eiffel": 20, "either": 20, "elabor": 3, "element": [7, 9], "elicit": 12, "elif": [8, 21], "elimin": [3, 16], "eliza": 3, "eliza_respons": 3, "elon": 13, "els": [3, 4, 8, 17, 19, 20, 21], "embark": [1, 2, 18], "embed": [4, 9, 11, 21], "embed_s": 4, "embedding_dim": 4, "emerg": [1, 12, 18, 22], "emili": 16, "emiss": 11, "emot": [8, 9, 14, 17, 20], "emotion_analysi": 4, "emotion_summari": 15, "emotional_languag": 20, "emphas": [1, 2, 3, 17, 21], "emphasi": [17, 21], "emploi": [5, 16], "employe": 15, "empow": 12, "en": [19, 20], "en_core_web_sm": [8, 13, 19, 20], "enabl": [3, 4, 14, 17, 21], "encapsul": 17, "encod": [3, 4, 11, 15, 16, 19], "encoded_data": 4, "encompass": [3, 8], "encount": 3, "encourag": [2, 10], "end": [1, 3, 6, 8, 10, 11, 12, 14, 15, 18, 22], "end_tim": 13, "energi": [5, 11, 12], "engag": [2, 21], "engin": [1, 3, 4, 10, 13, 16, 17, 20, 21, 22], "english": [3, 5, 7, 8, 9, 13, 17, 19, 20, 21], "enhanc": [3, 6, 9, 10, 11, 12, 14, 18, 19, 21], "enjoi": 3, "enorm": 4, "ensembl": [13, 20], "ensur": [2, 10, 14, 16, 18, 21], "ent": [8, 13, 19, 20], "ent1": 20, "ent2": 20, "entir": [5, 12, 14], "entiti": [4, 7, 20], "entity_count": 19, "entity_typ": [11, 12], "entitytyp": [11, 12], "enumer": [3, 8], "environ": [11, 17], "environment": [3, 11, 13, 21], "epoch": [4, 19], "equal": [5, 6, 16], "equip": [1, 14, 18], "equit": 16, "equival": [5, 17], "era": [3, 17, 18], "error": [13, 20], "especi": [6, 7, 14], "essenti": [6, 17, 19], "est": 3, "et": 15, "ethic": [1, 2, 3, 10, 15, 19, 20, 22], "ethicist": 5, "eu": 5, "europ": [11, 12], "evalu": [1, 18, 19, 20, 22], "evaluate_generated_text": 15, "evaluate_perform": 13, "evaluate_scal": 13, "even": [2, 4, 6, 11, 14, 15, 17], "event": [5, 7], "ever": 3, "everi": 11, "evolut": [1, 2, 18, 22], "evolv": [3, 4, 5, 9, 11, 12, 13, 16, 17, 18, 20, 21], "ex_answ": 12, "ex_context": 12, "ex_quest": 12, "exacerb": 5, "exactli": 5, "exagger": 17, "examin": [14, 16, 19, 20], "exampl": [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21], "excel": [12, 14], "except": 20, "excit": [1, 2, 17, 18, 21], "exclus": 8, "exercis": [14, 22], "exhibit": [3, 9, 20], "exist": [4, 5], "exp": [4, 13, 21], "expand": 4, "expect": [11, 12, 15, 16, 17], "experi": [1, 3, 4, 6, 9, 17], "experiment": 9, "expert": [3, 12, 13, 22], "expertis": [3, 9, 17], "explain": [4, 14, 15, 17], "explain_figurative_languag": 17, "explain_idiom": 17, "explain_inst": [13, 21], "explain_llm_predict": 13, "explain_misinform": 15, "explain_traditional_predict": 13, "explan": [1, 3, 4, 5, 13, 19, 20, 21], "explanatori": 5, "explicit": 16, "explicitli": [3, 11, 17], "explor": [1, 2, 3, 4, 6, 7, 9, 10, 12, 15, 22], "exploratori": 11, "express": [4, 7, 8, 11, 14, 15, 17, 20], "extend": [12, 19], "extens": 4, "extract": [14, 18, 22], "f": [3, 4, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "f1": [8, 13, 15], "fabric": [5, 20], "face": [3, 13, 15, 17], "facebook": [19, 20], "facilit": 4, "fact": 20, "factor": [3, 4, 13], "factual": [3, 14, 15, 20], "fail": 3, "fair": [3, 16, 21], "fake": [1, 18, 22], "fals": [15, 18, 19, 20, 21], "familiar": 22, "fantast": 3, "fascin": 1, "faster": 12, "father": 16, "favor": 5, "fc": 4, "fear": [11, 17], "featur": [8, 13, 19, 20, 21], "feature_extract": [3, 7, 8, 13, 20, 21], "feature_nam": [3, 7], "feedback": 8, "femal": [16, 21], "female_assoc": 16, "female_associ": 16, "female_prob": 16, "female_prompt": 16, "female_sim": 21, "female_term": 16, "female_vec": 21, "few": [1, 10, 11, 13, 20, 21, 22], "few_shot_aspect_senti": 12, "few_shot_classif": [12, 13], "few_shot_multi_label_classif": 12, "few_shot_n": 12, "few_shot_qa": 12, "few_shot_summar": 12, "fewer": 4, "field": [1, 2, 3, 4, 11, 12, 13, 15, 16, 18, 20, 21], "figur": [1, 14, 22], "file": [3, 9], "film": 3, "filter": [19, 21], "filtered_text": 7, "final": [1, 4, 6, 12, 18, 22], "financ": 8, "financi": [3, 19], "find": [3, 5, 14, 15, 20, 21], "findal": [13, 20], "fine": [3, 11, 13, 15], "finetun": 13, "first": [4, 7, 9, 19], "fit": [3, 8, 13, 20, 21], "fit_resampl": 13, "fit_transform": [3, 7, 8, 13, 20], "five": [1, 22], "flat": 20, "flatten": 19, "flaw": 5, "flexibl": [3, 15, 21], "float": 17, "flood": 15, "floor": 8, "flower": 8, "focu": [3, 4, 9, 11, 14, 18, 21, 22], "focus": [3, 4, 6, 15], "follow": [3, 4, 11, 12, 13, 15, 17, 20, 21], "font_siz": 20, "font_weight": 20, "food": 12, "footprint": 5, "forefront": [3, 18, 21], "foreign": 4, "forest": [3, 13, 20], "form": [3, 6, 7, 17], "formal": [3, 12], "format": [3, 7, 11, 12, 13, 15, 17], "formul": 4, "forward": 4, "foster": 5, "found": 15, "foundat": [6, 18, 19], "founder": 13, "fox": [7, 8], "frame": [2, 4, 20], "framework": [19, 21], "franc": 20, "free": 3, "freedom": 20, "french": [3, 21], "frequenc": [3, 8, 15], "frequent": 17, "friendli": 3, "from": [1, 2, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], "from_pretrain": [3, 4, 15, 16, 19, 20], "full": [3, 8, 13, 18, 21], "fulli": 21, "function": [3, 9, 16, 17, 20], "fundament": [1, 2, 6, 7, 10, 22], "furiou": 20, "further": [4, 11, 12], "futur": [1, 13, 22], "fzqarj": 20, "g": [3, 4, 5, 7, 8, 9, 12, 13, 15, 20], "gain": [1, 2, 3, 8, 9, 11, 17, 18], "game": [8, 14], "gap": [1, 2, 3, 4, 12, 15], "garcia": 15, "gaug": 3, "gdp": 12, "gdpr": 5, "gender": [3, 4, 5, 21], "gender_association_test": 16, "gender_bias_check": 21, "gener": [1, 2, 8, 9, 16, 17, 19, 20], "generate_complet": 16, "generate_research_hypothesi": [4, 15], "generate_research_quest": 4, "generate_survey_respons": 15, "generate_text": [3, 15], "generate_text_llm": 13, "generate_text_tradit": 13, "generate_text_with_param": 15, "generated_text": [3, 13, 15], "gensim": [3, 6, 7, 9, 19, 21, 22], "genuin": 20, "german": [3, 21], "germani": 12, "get": [3, 4, 8, 9, 17, 20], "get_coher": 9, "get_dominant_top": 9, "get_embed": 16, "get_feature_names_out": [3, 7], "get_scor": 15, "get_senti": 9, "get_word_embed": 7, "getorcr": 19, "gf": 17, "gibb": 9, "gigaword": [7, 21], "girl": [16, 21], "given": [8, 9, 12], "global": [3, 12, 18], "glove": [3, 7, 21], "go": [4, 8], "goal": [2, 3, 8], "good": [4, 12, 21], "googl": 22, "govern": [11, 12, 18, 19], "gpe": 20, "gpt": [3, 11, 12, 13, 17, 20, 21], "gpt2": [15, 16], "gpt2lmheadmodel": [15, 16], "gpt2token": [15, 16], "gpt3_complet": 4, "grain": 11, "gram": 3, "grammar": 3, "grammat": [3, 8], "grant": 4, "graph": 20, "grasp": [3, 4, 10], "great": [1, 3, 4, 11, 12, 17, 20], "greater": 21, "green": 12, "grew": 3, "gross": 12, "groundbreak": 11, "group": [3, 5, 7, 8, 16], "groupbi": 9, "grow": [2, 13, 19, 21], "growth": 3, "guest": 22, "guid": [16, 17], "guidelin": 1, "h": 22, "ha": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 19, 20, 21], "habit": 3, "had": [2, 21], "hallucin": 3, "hammer": 17, "hand": [1, 3, 6, 14], "handl": [9, 11, 12, 13, 15, 17, 19, 20, 21], "har": [1, 2, 3, 5], "hard": 4, "hardwar": 13, "harm": 5, "harvard": 11, "hasattr": 21, "hate": 3, "have": [1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 17, 18, 19, 20, 21], "haven": 11, "he": [4, 16], "headlin": 20, "health": [12, 15, 19, 21], "healthcar": [11, 12], "heapq": 8, "heartbroken": 20, "heat": 15, "heavi": 12, "hello": 3, "help": [3, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 18, 19, 20, 21], "here": [1, 3, 4, 7, 8, 11, 12, 13, 15, 16, 17, 19, 20], "hesit": 2, "hidden": [3, 9, 14, 18, 20], "hidden_layer_s": 21, "hidden_s": 4, "hierarch": [3, 9], "hierarchi": 9, "high": [1, 3, 5, 13, 14, 17, 22], "higher": [9, 22], "highli": [3, 17], "highlight": 15, "hill": 3, "histor": [1, 4, 5, 8, 9, 17, 19], "histori": 11, "hoax": 20, "hold": 3, "hop": 12, "hovi": 22, "how": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 22], "howev": [1, 3, 4, 6, 7, 10, 11, 12, 15, 16, 17, 21], "html": [9, 20, 21], "html_text": 7, "http": [3, 7, 20], "hug": [13, 15], "human": [1, 3, 8, 9, 10, 12, 13, 17], "human_evalu": 17, "hundr": 4, "hybrid": 13, "hyperbol": 17, "hypothes": [3, 4, 14, 15, 19], "hypothesi": [4, 15], "i": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ich": 21, "id": 19, "id2word": [9, 19], "idea": [4, 11, 14, 17], "identifi": [3, 4, 5, 8, 9, 11, 12, 17, 18, 19, 20], "idf": [3, 8, 20], "idiom": 14, "idiomat": 4, "idx": [9, 19], "ignorecas": 20, "illustr": [4, 6, 15], "imag": [3, 4, 20, 21], "image_classifi": 21, "image_cont": 21, "image_path": 21, "image_result": 21, "image_scor": 21, "imagin": 19, "imbalanc": 13, "imblearn": 13, "impact": [2, 4, 8, 12, 13, 15, 16, 17, 18, 20, 21], "imperson": 20, "implement": [4, 6, 8, 12, 15, 16, 17, 18, 19, 22], "impli": 3, "implic": [2, 3, 4, 14, 15, 16, 17, 18, 20], "import": [2, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "impos": 12, "imposs": 4, "impost": 20, "impract": 4, "impress": 17, "improv": [3, 7, 9, 12, 14, 17, 21], "inaccess": 19, "inadvert": 5, "inc": [8, 12, 13], "includ": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21], "inclus": 21, "inconsist": [5, 12, 20], "incorpor": [9, 12, 15], "incorrect": [4, 5], "increas": [3, 4, 12, 21], "increasingli": [3, 19, 20, 21], "incredibli": 15, "independ": 15, "indic": [9, 16, 20], "individu": [3, 5, 16, 17, 20], "industri": [3, 4, 11, 12], "inequ": 5, "infeas": 3, "infer": [1, 9, 13, 14, 22], "influenc": [3, 11, 17, 21], "info": 7, "inform": [1, 7, 8, 10, 14, 15, 16, 18, 20, 21], "inher": 3, "initi": [4, 19], "innov": [12, 18], "input": [3, 4, 5, 12, 15, 16, 17, 19, 20], "input_data": 13, "input_id": [4, 16, 19], "input_text": 3, "inputcol": 19, "insight": [2, 3, 4, 6, 8, 9, 14, 17, 18, 19, 22], "instanc": 3, "instant": [12, 21], "institut": [3, 5], "instruct": 11, "integr": [3, 14, 21], "intellig": [3, 4, 8], "intens": [4, 15], "inter": 8, "interact": [3, 8, 12, 17, 20, 21], "interdisciplinari": [3, 18, 20], "interest": [2, 10], "interfer": 7, "intern": [4, 5], "internet": 17, "interpret": [2, 3, 6, 11, 14, 16], "interpret_internet_slang": 17, "intersect": [1, 2], "intersection": 4, "interview": [3, 4, 15], "introduc": [3, 5, 22], "introduct": 1, "introductori": 2, "intuit": 9, "invers": 3, "invest": [4, 12], "investig": 18, "involv": [3, 4, 7, 8, 13, 14, 16, 20, 21], "iphon": 12, "iron": 17, "ironi": [3, 8], "irrelev": [3, 7], "is_avail": 19, "isalpha": [3, 19], "isn": 2, "isol": 21, "issu": [2, 3, 4, 8, 11, 16, 18, 19, 20, 21], "item": [3, 4, 12, 16, 19, 20], "iter": 4, "its": [1, 2, 5, 8, 11, 12, 15, 17, 18, 19, 20, 21, 22], "j": [3, 21, 22], "jamal": 16, "jane": [11, 12], "japanes": 17, "jeff": 13, "job": [3, 11, 15], "john": 12, "johnson": [12, 15], "joi": 11, "join": [3, 4, 7, 8, 11, 12, 13, 15, 20], "journal": 11, "journei": [1, 2], "jpg": 21, "json": 13, "judgment": 17, "judici": 15, "jump": [7, 8], "jupyt": 22, "jurafski": 22, "just": [2, 17], "k": [8, 9, 12, 15, 19], "keen": 5, "keep": [1, 17], "keepdim": 4, "kei": [2, 3, 6, 8, 9, 10, 11, 12, 13, 15, 17, 19, 20, 21, 22], "key_pap": 15, "kick": 17, "kind": 9, "king": [3, 21], "kmean": 8, "knowledg": [1, 3, 11, 12, 18], "known": 4, "l": 15, "label": [3, 4, 8, 11, 12, 13, 19, 20, 21], "label_": [8, 13, 19, 20], "labels_": 8, "lack": 20, "lack_of_sourc": 20, "lakisha": 16, "lambda": [9, 13], "landscap": 3, "lang": [19, 20], "languag": [1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22], "larg": [1, 2, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22], "large_dataset": 19, "larger": 14, "largescaletextprocess": 19, "last": [11, 12], "last_hidden_st": 16, "late": [11, 12], "latent": [1, 3, 6, 19, 22], "later": 6, "latest": [4, 16], "law": [12, 13], "lazi": [7, 8], "lda": [1, 6, 19, 22], "lda_model": [9, 19], "lda_result": 9, "lda_visu": 9, "ldamodel": 9, "ldamulticor": 19, "lead": [3, 5, 11, 12, 18, 19], "leap": 4, "learn": [1, 2, 6, 7, 8, 9, 10, 14, 18, 21, 22], "lectur": 22, "led": 4, "lee": 15, "legal": [5, 8], "lemmat": [3, 9, 20], "lemmatize_word": 7, "lemmatized_text": 7, "lemmatized_token": 3, "len": [9, 16, 19, 20], "less": [5, 8, 12], "let": [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 18, 19, 20], "level": [3, 12, 19], "leverag": [1, 2, 4, 6, 10, 11, 12, 14, 15, 17, 18, 19, 21, 22], "lexic": 3, "li": [8, 19], "librari": [1, 6, 8, 9, 15, 19, 22], "lieb": 21, "life": [11, 15, 17, 21], "lifetim": 5, "lightblu": 20, "like": [3, 5, 6, 8, 9, 12, 15, 16, 17, 18, 19, 20, 21], "lime": [5, 13, 21], "lime_text": [13, 21], "limetextexplain": [13, 21], "limit": [1, 2, 3, 5, 10, 12, 13, 18, 21, 22], "linalg": 16, "line": [3, 9], "linear": 4, "linear_model": 13, "linesent": 3, "lingual": [3, 9], "linguist": [3, 7, 8, 20], "link": 17, "list": [11, 12, 19, 20], "listen": 21, "liter": [3, 17], "literatur": [3, 4, 14, 15, 21], "literature_review_synthesi": 15, "live": [15, 20, 21], "ll": [1, 2, 4, 6, 8, 9, 10], "llm": [1, 2, 6, 14, 19, 21], "llm_bleu": 13, "llm_entiti": 13, "llm_explan": 13, "llm_gener": 13, "llm_ner": 13, "llm_perform": 13, "llm_predict": 13, "llm_relat": 13, "llm_relation_extract": 13, "llm_sent": 13, "llm_sentiment": 13, "llm_sentiment_analysi": 4, "llm_time": 13, "load": [3, 4, 7, 8, 13, 15, 19, 20, 21], "local": [3, 8, 12], "localhost": 3, "locat": [8, 12, 20], "logist": [3, 13], "logisticregress": 13, "logit": [3, 4, 16, 20], "long": [3, 4, 6, 11, 12, 15], "long_text": 11, "longer": 8, "look": [3, 4, 11, 15, 18, 19], "loss": [4, 19], "lotteri": 11, "love": [3, 4, 7, 8, 11, 13, 21], "low": [8, 12, 17, 21], "lower": [3, 4, 7, 8, 9, 19, 20], "lowercas": [3, 9, 20], "lowercased_text": 7, "lr": 4, "lstm": 3, "lyndon": 12, "m": [3, 4, 9, 13], "machin": [3, 7, 8, 9, 11, 12], "made": [1, 2], "mai": [4, 5, 7, 8, 9, 12, 13, 17, 19, 21], "main": [6, 9, 10, 11, 15, 18], "maintain": [3, 4, 5, 14, 18], "major": [11, 12], "make": [3, 4, 5, 7, 8, 10, 11, 12, 13, 20, 21], "make_pipelin": 21, "male": [16, 21], "male_assoc": 16, "male_associ": 16, "male_prob": 16, "male_prompt": 16, "male_sim": 21, "male_term": 16, "male_vec": 21, "man": [3, 16, 21], "mani": [3, 4, 6, 7, 8, 10, 13, 17, 20], "manifest": 16, "manipul": [4, 5, 20], "manual": [3, 8, 9], "map": 19, "mark": [8, 11], "market": [3, 8, 11, 12, 13], "markov": 3, "martin": 22, "mask": 4, "massiv": [3, 11, 18], "master": [6, 18], "mat": [3, 8, 9], "match": [3, 12, 13], "materi": 5, "matplotlib": 20, "matrix": 8, "max": 9, "max_it": 21, "max_length": [3, 4, 13, 15, 16, 19, 20], "max_token": [3, 4, 11, 12, 13, 17, 20, 21], "max_word": [11, 12], "me": 3, "mean": [3, 4, 7, 8, 9, 13, 16, 17, 21], "meaning": [6, 9, 14, 18, 19], "meaningless": 17, "measur": [8, 12, 20], "measure_inference_tim": 13, "mechan": 3, "media": [1, 3, 4, 5, 7, 8, 9, 12, 13, 14, 15, 18, 19, 20, 21], "medic": [8, 13, 19], "meet": 17, "meme": 17, "memor": 5, "memori": 3, "men": 4, "mental": [12, 15, 21], "metaphor": 14, "method": [1, 3, 5, 6, 8, 9, 10, 13, 15, 16, 20, 22], "methodologi": [1, 2, 3, 5, 11, 18, 21], "metric": [3, 8, 9, 15, 16, 20, 21], "microchip": 20, "midterm": 22, "might": [2, 3, 4, 5, 7, 8, 9, 10, 12, 15, 17], "million": 19, "min": 21, "min_count": 3, "mind": 1, "mine": 3, "minim": [4, 12, 15], "misinform": [1, 12, 18, 21, 22], "misinformation_top": 20, "mislead": [5, 20], "mismatch": 20, "misrepres": 5, "misus": 4, "mitig": [3, 14, 21], "mix": 12, "mixtur": 9, "ml": [12, 19, 20], "mlpclassifi": 21, "modal": 21, "model": [1, 2, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22], "model_nam": [3, 4, 7, 16, 19, 20], "model_output": 17, "model_select": [3, 8, 13, 20], "modern": [1, 2, 22], "modul": 4, "moham": 16, "monitor": 21, "month": [4, 8, 11, 13], "more": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 19, 20, 21], "most": [3, 9, 11, 12], "most_similar": 3, "mother": 16, "move": 1, "movi": [3, 7, 21], "mp": 19, "mse": 13, "much": [2, 7], "multi": [11, 12, 19], "multidisciplinari": 20, "multilingu": [3, 20], "multilingual_senti": 21, "multimod": [3, 4, 20], "multinomi": 9, "multinomialnb": [3, 8, 21], "multipl": [3, 4, 5, 8, 9, 14, 19, 21], "multiprocess": 19, "musk": 13, "must": [3, 4, 5, 16, 20], "mutual": 8, "my": [3, 4, 11], "mystream": 21, "mystreamlisten": 21, "mywot": 20, "n": [3, 4, 8, 9, 11, 12, 13, 17, 20, 21], "n_cluster": 8, "n_estim": 20, "n_run": 13, "n_sampl": 13, "n_test": 12, "nail": 17, "naiv": [3, 8], "naive_bay": [3, 8, 21], "name": [3, 4, 7, 16, 20], "name_senti": 16, "name_sentiment_analysi": 16, "nanswer": 12, "nation": 12, "natur": [1, 2, 4, 6, 7, 8, 10, 11, 14, 15, 16, 17, 18, 19, 20, 21, 22], "navig": 5, "ncategori": [3, 11, 12, 13], "necessari": [5, 6], "need": [3, 4, 7, 9, 11, 12, 19, 21], "neg": [3, 4, 8, 11, 12, 13, 15, 21], "nentiti": 12, "ner": 19, "ner_pipelin": 13, "network": [3, 4, 15, 21], "networkx": 20, "neural": [3, 4, 9, 21], "neural_network": 21, "neuro_symbolic_analysi": 21, "neutral": [3, 4, 8, 11, 12, 13, 16, 21], "never": 11, "new": [1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 15, 18, 19, 21, 22], "newer": 4, "next": [3, 4, 8, 13], "next_word": 13, "next_word_vec": 13, "nhead": 4, "nice": 13, "nking": 3, "nlargest": 8, "nllm": 4, "nlp": [1, 7, 13, 17, 18, 19, 20], "nlptown": [3, 21], "nltk": [3, 6, 7, 9, 13, 19, 20, 22], "nn": [3, 4, 20], "no_grad": [3, 4], "no_repeat_ngram_s": 15, "noam": 3, "node_color": 20, "node_s": 20, "nois": [3, 7], "non": [3, 8, 17, 19], "none": [3, 4, 11, 12, 13, 17, 20, 21], "nonstandard": 8, "norm": [16, 18], "normal": [1, 6, 19, 22], "north": [11, 12], "notabl": 5, "notat": 9, "note": [3, 15], "notebook": 22, "noth": 3, "notic": 3, "noun": 8, "novel": [3, 11, 12], "now": [2, 3, 4, 11, 18], "np": [3, 4, 13, 16, 21], "nquestion": 12, "nsentiment": [12, 13], "nsimilar": 8, "nsummari": 12, "ntext": [3, 11, 12, 13], "ntopic": 9, "nuanc": [3, 4, 8, 14, 17], "num": 7, "num_clust": 8, "num_featur": [13, 21], "num_label": [3, 4, 19, 20], "num_permut": 16, "num_process": 19, "num_quest": 4, "num_return_sequ": [15, 16], "num_sent": 8, "num_top": [9, 19], "number": [4, 9, 12, 13], "numer": 3, "numpi": [4, 13, 16, 21], "nurs": [16, 21], "nx": 20, "oauthhandl": [19, 20, 21], "object": 19, "observ": [9, 16], "observed_scor": 16, "occ": 21, "occup": [16, 21], "occur": [3, 9, 16], "off": 13, "offens": 17, "offer": [1, 3, 4, 5, 6, 10, 11, 13, 14, 15, 17, 18, 19], "offic": 17, "often": [3, 4, 5, 6, 8, 9, 10, 13, 14, 17, 20], "oh": 17, "okai": 3, "old": 15, "on_error": 21, "on_statu": 21, "onc": 3, "one": [3, 4, 7, 9, 11, 12, 13, 17, 19], "ongo": [4, 5, 9], "onli": [1, 3, 4, 12, 18, 19], "onlin": [3, 8, 19, 20, 21, 22], "open": [1, 3, 4, 8, 10, 11, 13, 15, 21], "openai": [3, 4, 11, 12, 13, 17, 20, 21], "opinion": [3, 8, 18, 20], "opportun": [1, 2, 19], "optim": [4, 9, 10, 19], "option": 17, "org": 20, "organ": [8, 9, 11, 12, 20], "origin": [3, 12, 16], "other": [5, 8, 11, 12, 14, 15], "our": [1, 2, 3, 6, 7, 9, 10, 12, 14, 18, 19, 20, 21], "out": [7, 17], "outcom": [16, 18], "outdat": 5, "outperform": [12, 17], "output": [3, 4, 7, 11, 12, 13, 14, 15, 16, 17, 19, 20], "outputcol": 19, "over": [5, 7, 8, 9, 12, 15, 18], "over_sampl": 13, "overal": [4, 13, 17], "overall_scor": 17, "overload": 18, "overpr": 12, "overst": 7, "overview": [2, 22], "overwhelm": 4, "own": [2, 3, 10, 21], "ownership": 5, "p": [7, 15, 16], "p_valu": 16, "pad": [3, 4, 19, 20], "pairwis": [8, 21], "panda": [9, 19], "pandem": [3, 15], "paper": [4, 11, 14, 15, 22], "paradigm": [11, 12, 13], "paragraph": 4, "parallel": 4, "parallel_preprocess": 19, "paramet": [4, 9, 12, 21], "paramount": 5, "paraphras": 15, "parent": 15, "park": 17, "pars": [3, 19], "parser": [3, 20], "part": [3, 11, 21], "partial": 4, "particip": 4, "particular": [4, 5, 8, 12], "particularli": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 15, 17, 20], "passion": 15, "pattern": [3, 4, 8, 9, 12, 13, 17, 18, 19, 20], "pd": [9, 19], "penalti": 12, "peopl": [7, 8, 20], "per": [3, 8, 9, 12, 13], "perform": [1, 3, 4, 7, 8, 9, 10, 11, 12, 17, 22], "perform_n": 8, "period": 12, "perm_scor": 16, "perm_target1": 16, "perm_target2": 16, "permut": 16, "permutation_scor": 16, "perpetu": [4, 5, 17], "perplex": 13, "persist": 4, "person": [3, 8, 11, 12, 13], "personif": 17, "perspect": 5, "phase": 4, "phenomena": [1, 3, 4, 12, 14, 16, 17, 18, 19], "phenomenon": 20, "phrase": 17, "piec": 8, "pil": 21, "pipe": 19, "pipelin": [7, 13, 19, 21], "place": [7, 12, 21], "placehold": 7, "plai": [7, 8, 17], "plan": [8, 13], "planet": [8, 12], "plate": 9, "platform": [17, 19, 20], "plausibl": [4, 5], "pleas": 1, "plot": [3, 9, 13], "plt": [13, 20], "po": [3, 20], "point": [2, 4, 10, 11], "polar": [4, 9, 13, 15, 21], "polarity_scor": 8, "polici": [3, 4, 8, 9, 11, 12, 13, 15], "policymak": 5, "polit": [3, 4, 8, 9, 11, 12, 13, 15, 18, 20, 21], "politifact": 20, "pool": 19, "poorli": [8, 9], "popul": [5, 19], "popular": [6, 8, 9], "porterstemm": [3, 7], "pos_tag": [3, 8], "pos_tag_text": 8, "pose": [2, 20], "posit": [3, 4, 8, 9, 11, 12, 13, 16, 18, 21], "possibl": [1, 4, 6, 10, 11, 17, 18, 19], "possibli": 19, "post": [1, 3, 4, 5, 8, 18], "potenti": [1, 3, 8, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 22], "power": [1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 21], "pp": 3, "practic": [1, 4, 6, 12, 16, 19], "pragmat": 3, "prais": 15, "pre": [2, 3, 9, 11, 12, 13, 15, 19, 20, 21], "precis": 13, "precision_recall_fscore_support": 13, "predefin": [8, 11], "predict": [3, 4, 8, 11, 12, 13, 20, 21], "predict_proba": [13, 21], "predicted_class": [3, 4, 20], "prefer": 13, "prefix": 16, "prejud": 16, "prepar": [4, 10], "preprocess": [1, 9], "preprocess_chunk": 19, "preprocess_text": [3, 9, 19, 20], "preprocessed_data": 19, "presenc": 9, "present": [4, 5, 14, 16, 17, 19], "preserv": [8, 21], "presid": [12, 13, 20], "press": [11, 18, 22], "pretty_print": 3, "preval": 9, "prevent": 5, "previou": 12, "previous": [3, 4, 18, 19], "price": 12, "primari": [3, 4, 11], "primarili": [3, 5], "principl": [2, 5, 11], "print": [3, 4, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "print_top": [9, 19], "prior": 9, "privaci": [2, 3, 4, 12, 16, 18, 21], "prob": 9, "probabilist": [3, 9], "probabl": [3, 9, 16, 20], "probe": [3, 5], "probe_model_bia": 3, "problem": [3, 4, 9], "process": [1, 2, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 18, 20, 22], "process_batch": 19, "processed_chunk": 19, "processed_doc": [9, 19], "processed_text": [7, 9, 20], "processeddf": 19, "produc": [4, 5, 7, 12], "product": [4, 12, 13, 15, 21], "produit": 21, "produkt": 21, "profess": [4, 5, 16], "profound": 13, "program": [3, 8, 21, 22], "progress": [2, 3, 10, 15, 16, 18], "prohibit": 12, "project": [1, 4, 10, 18, 22], "prolifer": 19, "promis": [13, 20], "prompt": [1, 3, 4, 10, 13, 16, 17, 20, 21, 22], "prompt_vari": 12, "propag": 20, "proper": 6, "proport": 9, "propos": [3, 12, 22], "protect": 11, "protocol": 17, "provid": [3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19, 20, 21], "psychotherapist": 3, "pt": [3, 4, 15, 16, 19, 20], "public": [3, 8, 11, 12, 15, 18, 19, 20], "publish": 11, "punkt": [3, 8, 9, 19], "purpos": [5, 8, 15], "push": [6, 18], "pyldavi": 9, "pyplot": 20, "pyspark": 19, "python": [1, 3, 4, 6, 22], "pytorch": [4, 22], "q": [19, 20], "qualit": [3, 8, 9, 14], "qualiti": [1, 9, 12, 14, 22], "quantit": 9, "queen": 21, "queri": [4, 20], "question": [1, 2, 3, 5, 7, 8, 9, 13, 14, 15, 18, 19, 22], "quick": [7, 8], "quickli": [3, 7, 8, 10, 11, 12], "quit": [3, 13], "r": [3, 7, 9, 13, 20], "race": [3, 12, 16], "racial": 5, "rain": 17, "rais": [5, 12], "ralli": [3, 11], "randint": 4, "randn": 4, "random": [3, 4, 9, 12, 13, 16, 20], "random_st": [3, 8, 9, 13, 20], "randomforestclassifi": [13, 20], "rang": [2, 3, 4, 8, 9, 11, 12, 13, 16, 19], "rapid": [3, 11, 12, 21], "rapidli": [4, 13, 16, 17, 18, 21], "rate": [17, 20], "raw": [3, 7, 13], "raw_pars": 3, "raw_text": 20, "re": [1, 2, 3, 6, 7, 9, 13, 18, 20], "reach": 13, "reaction": 15, "read": 12, "read_csv": 9, "readi": 18, "real": [1, 3, 11, 16, 20], "realist": 15, "realli": [3, 21], "reason": [3, 6, 8, 13, 21], "recal": 13, "receiv": 4, "recent": [1, 2, 6, 15, 20, 21], "recogn": 16, "recognit": [4, 7, 20], "recommend": 3, "record": 19, "recurr": 3, "reddit": [19, 20], "redefin": 21, "reduc": [3, 4, 7, 11, 12, 21], "refer": [4, 8, 12, 13, 15, 16, 17, 19, 20], "referenc": 5, "reference_explan": 17, "reflect": [5, 16, 17], "reform": 12, "regardless": [6, 16], "region": 5, "regress": [3, 13], "regular": [5, 7], "reinforc": [5, 16], "rel": 16, "relat": [12, 15, 20, 21], "relationship": [3, 7, 9, 11, 13, 15], "releas": [1, 13], "relev": [1, 3, 4, 6, 7, 9, 12, 13, 14, 15, 18, 22], "reli": [3, 20], "reliabl": 4, "religion": 12, "remain": [6, 8, 17], "remark": [3, 17], "rememb": [2, 6, 8, 9, 10, 18], "remot": [15, 21], "remov": [3, 9, 19, 20], "remove_stopword": 7, "remove_urls_email": 7, "renew": [11, 12], "renov": 20, "repeat": 9, "rephras": [3, 4], "replac": [8, 20, 21], "replace_emoji": 7, "report": 19, "repres": [3, 4, 5, 7, 9, 12, 18], "represent": [1, 3, 4, 5, 6, 22], "reproduc": 18, "request": 20, "requir": [2, 3, 9, 10, 12, 17, 20], "research": [1, 2, 6, 8, 10, 12, 13, 14, 16, 17, 19], "reshap": 21, "resourc": [8, 12, 19, 21], "respect": 14, "respond": 15, "respons": [1, 2, 3, 4, 8, 9, 11, 12, 13, 14, 15, 17, 20], "responsibli": [1, 3, 10], "result": [2, 3, 4, 6, 8, 11, 12, 13, 16, 17, 19, 20, 21], "return": [3, 4, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "return_tensor": [3, 4, 15, 16, 19, 20], "retweeted_statu": 21, "reveal": [3, 8], "revers": 9, "review": [4, 14, 15, 21], "revolut": [11, 12], "revolution": [3, 4, 10, 12, 15, 21], "revolutionari": [1, 2], "rewrit": 4, "rewrite_prompt": 4, "rf_model": 13, "rf_perform": 13, "rf_predict": 13, "rich": 17, "ride": 17, "right": [11, 12], "rigor": 5, "rise": [8, 21], "river": 3, "rnn": 3, "roberta": 4, "role": [5, 13, 17, 21], "roller": 17, "room": [4, 16], "root": [3, 7], "roug": [13, 15], "rstrip": 3, "rule": [2, 3, 21], "rule_result": 21, "run": [3, 4, 5, 7], "runner": 7, "sad": 11, "sai": [3, 20], "same": [5, 12], "sampl": [3, 7, 8, 9, 13, 15], "sample_s": 13, "sample_text": [7, 15], "sar": 15, "sarcasm": [3, 8], "sarcast": 17, "sat": [3, 8, 9], "satisfact": 15, "save": [3, 9, 20], "save_html": 9, "save_to_fil": 21, "saw": [3, 8, 11], "sc": 20, "scalabl": 3, "scale": [1, 2, 3, 9, 18, 21, 22], "scari": 17, "scenario": [4, 8, 11, 12, 13, 15], "scheme": 3, "scienc": [1, 6, 7, 8, 10, 12, 13, 16, 17, 19, 20], "scientist": [1, 2, 5, 8, 9, 10, 14, 16, 17, 19, 20, 21, 22], "scikit": [3, 6, 8, 13], "scipi": 16, "score": [3, 4, 8, 9, 13, 15, 16, 17, 21], "scorecard": 20, "scrape": [5, 7], "scratch": 2, "scrutini": 4, "search": 20, "search_tweet": [19, 20], "second": [7, 13, 19], "section": [4, 9], "sector": 11, "see": [1, 3], "seek": 1, "seen": [3, 8, 11], "select": [8, 12, 13, 19], "self": [3, 19, 21], "self_attent": 4, "semant": [7, 11, 20], "senat": 12, "sens": [4, 17], "sensation": 20, "sensational_titl": 20, "sensit": [5, 12, 14, 17], "sent_token": [7, 8], "sentenc": [3, 4, 8, 17], "sentence_bleu": 13, "sentence_scor": 8, "sentiment": [3, 7, 9, 14, 15, 16, 17, 21], "sentiment_analyz": 19, "sentiment_by_top": 9, "sentiment_scor": [3, 21], "sentimentintensityanalyz": 8, "separ": [3, 11, 12], "sequenc": [3, 4], "sequence_length": 4, "sequenti": 3, "seri": 8, "servic": [12, 13], "session": [1, 19], "set": [3, 7, 8, 9, 10, 19, 20], "set_access_token": [19, 20, 21], "setup": 22, "sever": [3, 4, 5, 6, 13, 15, 16, 17], "sex": 12, "shap": 5, "shape": 4, "share": [13, 20], "she": [4, 16], "shift": 2, "shock": 20, "shop": 3, "short": [3, 9], "shot": [1, 10, 13, 20, 21, 22], "should": [3, 5, 8, 11, 12, 13, 15, 16, 17], "show": [8, 9, 12, 13, 17, 19, 20], "shown": [16, 17, 20], "shuffl": [4, 16, 19], "sia": 8, "side": 15, "sign": [12, 13], "signific": [3, 4, 5, 8, 10, 11, 16, 20], "significantli": [3, 7, 12, 13, 14, 17, 19], "simil": 17, "similar": [3, 7, 16, 17, 21], "similar_word": 3, "similarity_matrix": 8, "simpl": [3, 4, 8, 12, 13, 15, 17, 20, 21], "simple_preprocess": 19, "simple_senti": 4, "simplemaskedlanguagemodel": 4, "simplifi": [4, 15, 19, 21], "simul": [3, 4, 15], "sinc": 3, "singl": [4, 5, 12], "sister": 16, "size": [7, 9, 13, 21], "skew": 5, "skill": [1, 6, 12, 18, 21, 22], "skip_special_token": [15, 16], "sklearn": [3, 7, 8, 13, 20, 21], "slang": [8, 17], "small": [9, 12, 13], "smaller": [6, 7, 19], "smiling_face_with_heart_ey": 7, "smith": [11, 12, 15], "smote": 13, "snippet": 6, "snope": 20, "so": [1, 8, 16], "social": [1, 6, 7, 8, 10, 12, 13, 19, 20], "social_media_data": 9, "societ": [1, 3, 16, 18, 21], "societi": [3, 5, 13, 20, 21], "socioeconom": [3, 16], "sociologi": 7, "softmax": [3, 4, 16, 20], "solar": 8, "sole": 11, "solid": [6, 10, 14], "solv": 3, "some": [4, 8, 9, 11, 12, 15, 20], "sometim": 17, "son": 16, "sophist": [3, 4, 5, 9, 11, 15, 16, 18, 19, 20], "sorri": 3, "sound": [4, 5], "soup": 20, "sourc": [4, 14, 17, 18], "source_languag": 17, "space": [3, 19], "spacex": 13, "spaci": [13, 19, 20, 22], "spam": 8, "spanish": 17, "spark": [15, 19], "sparksess": 19, "speak": 17, "speaker": 3, "special": [3, 4, 8, 9, 20, 21], "specif": [2, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22], "speech": [3, 17, 22], "speed": 13, "sphere": 20, "split": [3, 8, 11, 12, 13, 20], "spoken": 8, "sport": [3, 4, 8, 11, 12, 13], "spread": [11, 12, 15, 18, 21], "spring_layout": 20, "sql": 19, "sqrt": 4, "squar": 13, "stage": 3, "stai": [4, 16, 18, 21], "stand": 12, "standard": [3, 7], "standardize_numb": 7, "stanford": 3, "start": [12, 16, 21], "start_tim": 13, "stat": 16, "state": 1, "statement": 17, "statist": [5, 9, 16, 22], "statu": [3, 16, 21], "status_cod": 21, "stem": [3, 9, 20], "stem_word": 7, "stemmed_text": 7, "stemmed_token": 3, "stemmer": 3, "step": [3, 4, 6, 7, 13, 15, 19], "stereotyp": [5, 16], "stick": 17, "still": [4, 13], "stock": [3, 8, 11, 12, 13], "stop": [3, 4, 8, 11, 12, 13, 17, 19, 20, 21], "stop_word": [3, 7, 8, 9, 19, 20], "stopword": [3, 7, 8, 9, 19, 20], "stopwordsremov": 19, "store": [3, 8, 13], "strategi": [3, 4, 18], "stream": 21, "streamlisten": 21, "street": 4, "strength": [3, 10, 13], "strip": [3, 4, 11, 12, 13, 17, 20, 21], "strong": [6, 15, 18], "structur": [3, 8, 9, 15, 19, 20], "struggl": [3, 5, 17], "student": 22, "studi": [3, 4, 8, 11, 12, 15, 18, 19, 20, 21, 22], "sub": [7, 9, 20], "subfield": 8, "subject": 17, "sublist": 19, "substitut": 3, "subtl": 19, "subword": 3, "success": [3, 12], "suggest": [14, 17], "suitabl": 8, "sum": [4, 16], "summar": [3, 14, 19, 21], "summari": [1, 5, 8, 11, 12, 15, 19], "summarize_text": 8, "summary_sent": 8, "super": 4, "superior": 13, "supervis": [1, 10, 12, 22], "support": [3, 8, 12], "sure": 3, "surpris": 11, "surround": 4, "survei": [3, 8, 9, 11, 14, 15], "survey_respons": 11, "sven": 16, "svm": [3, 13], "syllabu": 1, "syntact": 3, "synthes": [14, 15], "synthesi": 15, "synthet": [4, 15], "system": [2, 3, 4, 5, 8, 11, 12, 13, 20, 21], "systemat": 16, "t": [2, 4, 5, 7, 9, 11, 16, 20, 21], "t5": 4, "tackl": [3, 14, 17, 18], "tactic": 20, "tag": 3, "tagged_text": 8, "tailor": 15, "takeawai": [3, 17, 19, 20], "target": 20, "target_languag": 17, "target_nam": 3, "target_set1": 16, "target_set2": 16, "task": [1, 2, 5, 6, 7, 10, 12, 17, 19, 21, 22], "teach": 1, "teacher": [16, 21], "team": [8, 12, 13], "tech": [3, 11], "technic": 16, "techniqu": [1, 2, 3, 4, 8, 10, 14, 15, 18], "technolog": [5, 21], "technologi": [1, 3, 4, 8, 11, 12, 13, 15, 17, 18, 19, 21], "telescop": 3, "temperatur": [3, 4, 11, 12, 13, 15, 17, 20, 21], "tend": 12, "tendenc": 5, "tension": 8, "tensor": [4, 19], "tensordataset": 4, "tensorflow": 22, "term": [3, 9, 12, 15, 16], "terribl": [3, 4, 8, 13], "tesla": 13, "test": [3, 12, 13], "test_result": 12, "test_siz": [3, 8, 13, 20], "text": [1, 2, 9, 14, 16, 17, 18, 20, 21], "text_classifi": 21, "text_result": 21, "text_scor": 21, "text_senti": 21, "text_to_classifi": 12, "text_to_explain": 21, "text_to_summar": 12, "textblob": [9, 13, 21], "textdataset": 19, "textual": [1, 2, 3, 4, 8, 10, 11, 14, 18, 22], "tf": [3, 8, 20], "tfidf_matrix": [3, 7, 8], "tfidf_represent": 7, "tfidfvector": [3, 7, 8, 13, 20, 21], "tfw": 17, "th": 9, "than": [3, 8, 11, 12], "thei": [2, 3, 4, 5, 8, 10, 11, 12, 15, 16, 17, 18], "them": [3, 4, 7, 8, 10, 11, 12, 14, 17], "theme": [3, 8, 9, 11], "themselv": [8, 16], "theori": [3, 20], "thi": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22], "thing": 17, "think": [1, 2, 10, 11, 21], "third": [7, 19], "thorough": 6, "those": [1, 2], "thoughtfulli": 9, "thousand": 3, "three": [1, 2, 6, 10, 14, 18], "thrill": [4, 12, 17], "through": [1, 3, 7, 9, 10, 11, 16, 18, 20], "throughout": [1, 2, 6, 10, 12, 14, 18], "thumbs_up": 7, "tiktok": 20, "tim": [8, 13], "time": [3, 8, 9, 10, 12, 13, 18, 19], "titl": [13, 20], "to_lowercas": 7, "toarrai": 7, "todai": [3, 8, 11, 13, 21], "togeth": 8, "toi": 7, "token": [3, 4, 8, 9, 15, 16, 19, 20], "tokenize_sent": 7, "tokenize_word": 7, "tone": [8, 9], "too": 4, "took": 7, "tool": [1, 2, 3, 4, 5, 6, 8, 9, 10, 14, 15, 17, 18, 19], "toolkit": 3, "top": [8, 15], "top_k": 15, "top_p": 15, "topic": [1, 4, 5, 6, 8, 10, 15, 20, 21, 22], "topic_trend": 9, "topn": 3, "torch": [3, 4, 15, 19, 20], "toward": [15, 16], "tower": 20, "track": [7, 8, 20, 21], "trad_explan": 13, "trad_rel": 13, "trad_sent": 13, "trad_tim": 13, "trade": 13, "tradit": [1, 2, 5, 10, 12, 15, 17], "tradition": [2, 10], "traditional_bleu": 13, "traditional_ent": 13, "traditional_gener": 13, "traditional_n": 13, "traditional_perform": 13, "traditional_predict": 13, "traditional_relation_extract": 13, "traditional_senti": 13, "train": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21], "train_label": 21, "train_test_split": [3, 8, 13, 20], "train_text": 21, "transcript": 4, "transfer": [4, 11], "transform": [1, 2, 7, 8, 12, 13, 15, 16, 18, 19, 20, 21, 22], "transformerencoderlay": 4, "transit": 3, "translat": [3, 11, 13, 17], "transpar": [2, 14, 18, 21], "treati": 12, "treatment": 16, "tree": 3, "trend": [1, 3, 4, 9, 12, 18, 19, 22], "trend_descript": 21, "trillion": 21, "true": [3, 15, 16, 19, 20], "truli": [4, 19], "truncat": [3, 4, 19, 20], "trust": 5, "truth": 15, "try": 20, "tune": [3, 11, 13, 15], "turn": 11, "tutori": 22, "tweepi": [19, 20, 21], "tweet": [3, 9, 19, 20, 21], "twitter": [17, 19, 20, 21], "two": [8, 9, 15, 17], "txt": 3, "type": [10, 11, 16, 17, 19, 20], "typic": [3, 4, 7, 9, 12, 19], "u": [2, 7, 16], "ultim": [6, 16], "unbeliev": 20, "uncas": [3, 4, 16, 19, 20, 21], "uncov": [3, 9, 14, 18, 19], "under": 1, "undergon": [1, 2], "underli": 2, "understand": [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 21, 22], "unfair": 16, "unfamiliar": 3, "unhelp": 12, "unimagin": 18, "unintent": 5, "unit": 7, "univers": [11, 12, 22], "unlik": [4, 17], "unlock": 3, "unpreced": [1, 3, 4, 14, 18], "unpredict": 17, "unproduct": 17, "unseen": [11, 13], "unstack": 9, "unstructur": 8, "unsupervis": [4, 9], "up": [1, 3, 8, 10, 17], "uphold": 5, "upon": 6, "url": [3, 20], "us": [1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22], "usag": [3, 4, 8, 9, 11, 12, 13, 16, 17, 19, 20, 21], "user": 20, "user_input": 3, "usual": 7, "util": [2, 4, 16, 19], "v": [8, 19], "vaccin": 20, "vader": 8, "vadersenti": 8, "valenc": 8, "valid": [2, 3, 4, 11, 12, 13, 16, 19], "valu": [4, 12, 16, 17], "valuabl": [4, 8, 9, 12, 15], "value_count": 19, "vari": [5, 13], "variabl": 15, "variant": 3, "variat": [9, 12], "varieti": 3, "variou": [3, 8, 10, 12, 13, 14, 15, 16, 17, 19, 20], "vast": [1, 3, 4, 11, 12, 14, 18, 19], "vbd": 3, "ve": [1, 3, 18], "vector": [3, 7, 8, 9, 13, 20, 21], "vector_s": 3, "verb": 8, "veri": [4, 9, 12, 13, 19, 21], "verifi": 15, "versail": 12, "version": 4, "versu": 10, "video": [20, 21], "view": 3, "viru": [15, 20], "vis_data": 9, "visibl": 19, "visual": [4, 5, 9, 20, 21], "vivid": 17, "vocab_s": 4, "vocabulari": [3, 7], "volum": [4, 8, 12, 14, 17], "vp": 3, "vulner": 5, "w": [9, 13], "wa": [0, 3, 4, 8, 9, 12, 20, 21], "wage": 4, "wai": [1, 4, 6, 13, 14, 16], "waiter": 12, "walk": [4, 16], "want": [9, 17], "war": [3, 12, 17], "wasn": 11, "wast": 3, "watch": 3, "wd": 9, "we": [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21], "weat_scor": 16, "weat_signific": 16, "weat_test": 16, "weather": [8, 12, 13], "web": [5, 7], "websit": [4, 7, 20], "week": [12, 22], "weekli": 22, "wei": 16, "weigh": 4, "weight": [3, 4, 13], "welcom": [1, 2, 6, 10, 14, 18], "well": [6, 8], "were": [3, 4, 11, 19], "western": [5, 12], "what": [1, 4, 6, 7, 11, 12, 17, 18, 20], "when": [3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "where": [9, 11, 12, 14], "which": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 19], "while": [2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17], "who": [1, 5, 12], "whole": 12, "why": [3, 4, 5, 15], "wide": [2, 3, 4, 8, 9, 11, 12], "wiki": [7, 21], "win": 13, "window": 3, "with_label": 20, "within": [8, 9, 17], "without": [3, 4, 10, 11, 12, 16], "woman": [3, 16, 21], "women": 4, "won": [8, 11, 12, 20], "word": [4, 8, 9, 11, 12, 13, 17, 19, 20, 21], "word2vec": 3, "word_freq": 8, "word_pair": 21, "word_token": [3, 7, 8, 9, 19, 20], "wordnet": [3, 9], "wordnetlemmat": [3, 7, 9, 20], "wordsdf": 19, "work": [1, 2, 4, 6, 9, 10, 15, 19, 21], "worker": [3, 19], "workflow": [8, 14], "workforc": 4, "world": [1, 3, 4, 12, 16], "worst": 3, "would": 19, "write": 3, "wv": 3, "www": [7, 20], "x": [4, 9, 13, 21], "x_subset": 13, "x_test": [3, 8, 13, 20], "x_test_tfidf": [3, 20], "x_test_vec": [3, 13], "x_test_vector": 8, "x_train": [3, 8, 13, 20], "x_train_balanc": 13, "x_train_tfidf": [3, 20], "x_train_vec": [3, 13], "x_train_vector": 8, "xlabel": 13, "y": [13, 21], "y_pred": [3, 8, 13, 20], "y_subset": 13, "y_test": [3, 8, 13, 20], "y_train": [3, 8, 13, 20], "y_train_balanc": 13, "y_true": 13, "yard": 8, "ye": 17, "year": [1, 2, 6, 15], "yesterdai": 12, "yield": 12, "ylabel": 13, "york": [8, 13, 20], "you": [1, 2, 3, 6, 10, 12, 14, 15, 18, 19, 20], "young": 4, "younger": 21, "your": [2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21], "your_access_token": [19, 21], "your_access_token_secret": [19, 21], "your_consumer_kei": [19, 21], "your_consumer_secret": [19, 21], "youtub": 20, "z": [9, 20], "z0": 7, "za": [7, 9, 20], "zd": 9, "zero": [1, 10, 12, 13, 20, 21, 22], "zero_grad": [4, 19], "zero_shot_classif": [3, 4, 11], "zero_shot_emotion_detect": 11, "zero_shot_multi_label_classif": 11, "zero_shot_n": 11, "zero_shot_qa": 11, "zero_shot_sentiment_analysi": 11, "zero_shot_summar": 11, "zhang": 16, "zip": [16, 21], "\u03b1": 9, "\u03b2": 9, "\u03b8": 9, "\u03b8d": 9, "\u03c6": 9, "\u03c6k": 9, "\u03c6zd": 9, "\u6211\u559c\u6b22\u8fd9\u4e2a\u4ea7\u54c1": 21}, "titles": ["Who made this book?", "Home", "Session 1 - Introduction to NLP for Social Science", "1.1 Fundamentals of NLP and its Evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Course Syllabus"], "titleterms": {"1": [2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "10": [3, 5, 9, 11, 12, 13, 15, 17, 20], "11": [5, 9, 12, 13, 17], "12": [9, 12, 13], "13": 9, "1950": 3, "1980": 3, "2": [3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "2000": 3, "2010": 3, "3": [3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "4": [3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22], "5": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22], "6": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "7": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "8": [3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21], "9": [3, 4, 5, 8, 9, 11, 12, 13, 15, 16, 17, 20, 21], "In": 12, "Its": 22, "The": 5, "Their": 3, "abil": 4, "about": 1, "academ": 5, "access": 5, "accuraci": [4, 5], "adapt": [4, 13], "addit": 22, "address": [5, 7], "advanc": [4, 5, 9, 18, 21, 22], "advantag": 4, "ai": [5, 21], "algorithm": 9, "alloc": 9, "ambigu": 3, "analysi": [4, 8, 11, 12, 13, 16, 17, 19, 20, 21], "analyz": [3, 16, 19], "annot": [10, 22], "answer": [4, 11, 12], "applic": [9, 11, 14, 18, 22], "approach": [3, 13, 20], "architectur": 4, "aspect": 15, "assess": [20, 22], "associ": 16, "attent": 4, "attribut": 5, "augment": 15, "bag": 7, "balanc": 5, "base": [5, 8, 15, 20], "basic": [3, 8], "bert": 4, "bia": [5, 16], "bias": 4, "black": 5, "book": 0, "bow": 7, "box": 5, "capabl": [3, 4, 5, 11, 12, 13], "categor": 19, "challeng": [3, 4, 5, 8, 9, 16, 17], "changelog": 1, "charact": 7, "characterist": 20, "class": 8, "classif": [8, 10, 11, 12, 13, 19, 22], "clean": 7, "cluster": 8, "collabor": [5, 21], "collect": [19, 20], "combin": 9, "compar": 13, "comparison": 13, "complet": 4, "complex": [3, 4], "complianc": 5, "compon": 4, "comput": [3, 4, 5, 13], "concept": [3, 4], "concern": 5, "conclus": [3, 12, 13, 15, 16, 17, 19, 20, 21], "consent": 5, "consider": [4, 5, 14, 16, 18], "consist": 5, "content": [1, 5, 15, 20], "context": [3, 4, 5, 12, 17], "continu": 5, "contribut": 1, "control": 15, "convers": 7, "copyright": 5, "core": 4, "corpora": 4, "cours": [1, 22], "creation": 15, "credibl": 20, "cross": [4, 5, 21], "cultur": [5, 17, 21], "current": 3, "data": [3, 4, 5, 9, 10, 15, 19, 20, 22], "dataset": [3, 4, 19], "date": 7, "deal": [3, 7], "decis": 5, "deep": [3, 20], "definit": [3, 4], "deploy": [4, 5], "descript": 22, "design": 12, "detect": [4, 5, 11, 16, 17, 20], "develop": [3, 5], "differ": 5, "direct": [3, 4, 9, 21], "dirichlet": 9, "disclosur": 5, "discours": 17, "dispar": 5, "distinct": 4, "divers": 5, "document": [7, 8], "domain": 4, "earli": 3, "effici": [4, 13], "email": 7, "embed": [3, 7, 16], "emerg": [3, 5, 21], "emoji": 7, "emot": [4, 11, 15], "emoticon": 7, "engin": [11, 12, 15], "enhanc": 4, "ensur": 5, "entiti": [8, 11, 12, 13, 19], "environment": 5, "equiti": 5, "ethic": [4, 5, 14, 16, 18, 21], "ethnic": 16, "evalu": [3, 5, 8, 9, 13, 15, 17], "evolut": 3, "exampl": [3, 4, 8], "explain": [5, 13, 21], "explan": [14, 15, 17, 22], "explor": [14, 18], "exposur": 5, "extract": [3, 8, 11, 12, 13, 19], "factual": [4, 5], "fake": 20, "featur": 3, "few": [3, 4, 12], "figur": 17, "fine": [4, 5], "foundat": [9, 11], "frequenc": 7, "from": [3, 4], "fundament": [3, 8, 9, 12, 15], "futur": [3, 4, 5, 9, 18, 21], "gender": 16, "gener": [3, 4, 5, 11, 12, 13, 14, 15, 22], "global": 5, "gpt": 4, "hallucin": 5, "handl": [3, 4, 7], "high": 15, "histor": 3, "home": 1, "html": 7, "human": [4, 5, 21], "identif": 5, "idf": 7, "idiom": 17, "impact": [3, 5], "implement": 9, "implic": 5, "import": [3, 5], "improv": [4, 5], "infer": 16, "inform": [4, 5, 11, 12, 13], "integr": [4, 5], "intellectu": 5, "interdisciplinari": 5, "interpret": [4, 5, 8, 9, 13, 17, 21], "introduct": [2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22], "invers": 7, "involv": 5, "ironi": 17, "issu": 5, "its": [3, 4], "kei": [4, 14, 18], "knowledg": 4, "lack": 4, "languag": [3, 4, 17, 21], "larg": [3, 4, 5, 19, 21], "larger": 3, "latent": 9, "lda": 9, "learn": [3, 4, 11, 12, 13, 20], "lectur": 1, "lemmat": 7, "lexicon": 8, "licens": 1, "like": 4, "limit": [4, 8, 9, 17], "lingual": 4, "ll": [14, 18], "llm": [3, 4, 5, 10, 11, 12, 13, 15, 16, 17, 18, 20, 22], "lowercas": 7, "machin": 20, "made": 0, "massiv": 4, "materi": 22, "mathemat": 9, "matter": [1, 14, 18], "mechan": 4, "media": 17, "metaphor": 17, "methodologi": 13, "metric": [13, 17], "mine": [12, 13], "misinform": [15, 20], "mitig": [4, 5, 16], "modal": 4, "model": [3, 4, 5, 7, 9, 19, 21], "modern": 3, "monitor": 5, "multi": [4, 8], "multilingu": 21, "multimod": 21, "name": [8, 11, 12, 13, 19], "natur": [3, 5], "need": 5, "ner": [8, 11, 12, 13], "network": 20, "neuro": 21, "new": [3, 20], "nlp": [2, 3, 4, 5, 6, 8, 9, 16, 21, 22], "nltk": 8, "normal": 7, "notabl": 4, "note": 1, "number": 7, "object": [1, 22], "ongo": 3, "opinion": [12, 13], "opportun": [3, 5], "optim": 12, "other": [4, 9], "outcom": 5, "output": 5, "overview": [1, 4], "paradigm": 3, "paramet": 15, "paraphras": 4, "part": 8, "particip": 5, "perform": 13, "person": 5, "perspect": 3, "pipelin": 3, "plagiar": 5, "po": 8, "polit": 17, "pose": 5, "possibl": 3, "potenti": [4, 5], "practic": [5, 14, 18], "pre": 4, "prepar": [9, 18], "preprocess": [3, 6, 7, 19, 20, 22], "prerequisit": 22, "present": 3, "privaci": 5, "process": [3, 4, 17, 19, 21], "progress": 4, "promin": 4, "promot": 5, "prompt": [11, 12, 15], "proper": 5, "properti": 5, "protect": 5, "proverb": 17, "purpos": 3, "qualiti": 15, "quantifi": 16, "question": [4, 11, 12], "racial": 16, "re": 5, "real": 21, "reason": 4, "recap": 13, "recent": 4, "recognit": [8, 11, 12, 13, 19], "recommend": 22, "regul": 5, "relat": [13, 19], "reliabl": 5, "remov": 7, "replac": 7, "represent": 7, "reproduc": 5, "requir": [4, 5, 13, 22], "research": [3, 4, 5, 9, 11, 15, 18, 20, 21, 22], "resourc": [4, 5, 13, 22], "respons": [5, 21], "result": [5, 9], "retriev": 4, "revolut": 3, "right": 5, "rise": 3, "risk": 5, "sarcasm": 17, "scalabl": [13, 19], "scale": [4, 5, 19], "schedul": 22, "scienc": [2, 3, 4, 5, 9, 11, 14, 15, 18, 21, 22], "scientif": 5, "scientist": 3, "self": 4, "semant": 3, "sentenc": 7, "sentiment": [4, 8, 11, 12, 13, 19], "seri": 4, "session": [2, 6, 10, 14, 18, 22], "shift": 3, "shot": [3, 4, 11, 12], "similar": 8, "size": 4, "social": [2, 3, 4, 5, 9, 11, 14, 15, 16, 17, 18, 21, 22], "societ": 5, "socioeconom": 5, "sourc": [5, 16, 19, 20], "spaci": 8, "special": 7, "specif": [3, 4], "speech": 8, "spread": 20, "state": 3, "statist": 3, "stem": 7, "stop": 7, "strategi": [5, 12], "structur": [1, 22], "studi": 5, "subject": 5, "summar": [4, 8, 11, 12, 15], "summari": [14, 22], "supervis": 13, "sustain": 5, "syllabu": 22, "symbol": 21, "tabl": 1, "tag": [7, 8], "task": [3, 4, 8, 11, 13, 15], "techniqu": [5, 6, 7, 9, 12, 16, 19, 20, 22], "technologi": 5, "term": 7, "test": 16, "text": [3, 4, 5, 6, 7, 8, 11, 12, 13, 15, 19, 22], "textbook": 22, "textual": 19, "tf": 7, "theoret": 11, "thi": [0, 1], "time": 21, "token": 7, "topic": [9, 14, 18, 19], "toward": 3, "tradit": [3, 4, 6, 13, 20, 22], "train": [3, 4, 5], "transform": [3, 4], "translat": 4, "transpar": [4, 5], "trend": 21, "true": 4, "tune": [4, 5], "type": [5, 8, 12, 15], "understand": [4, 17], "uniqu": 5, "unstructur": 3, "up": 4, "url": 7, "us": [5, 8, 15, 16], "usag": 5, "valid": 5, "variant": 4, "variou": 4, "we": [14, 18], "weat": 16, "when": 5, "who": 0, "why": [1, 14, 18], "wisdom": 17, "word": [3, 7, 16], "zero": [3, 4, 11]}})