Search.setIndex({"alltitles": {"1.1 Fundamentals of NLP and its evolution": [[3, "fundamentals-of-nlp-and-its-evolution"]], "1.1 Fundamentals of Natural Language Processing and its evolution": [[22, "fundamentals-of-natural-language-processing-and-its-evolution"]], "1.2 Overview of Generative LLMs": [[4, "overview-of-generative-llms"]], "1.2 Overview of Generative Large Language Models (LLMs)": [[22, "overview-of-generative-large-language-models-llms"]], "1.3 Ethical Considerations and Challenges in Using LLMs for Research": [[5, "ethical-considerations-and-challenges-in-using-llms-for-research"], [22, "ethical-considerations-and-challenges-in-using-llms-for-research"]], "2.1 Text Cleaning, Normalization, and Representation": [[7, "text-cleaning-normalization-and-representation"], [22, "text-cleaning-normalization-and-representation"]], "2.2 Basic NLP Tasks": [[8, "basic-nlp-tasks"], [22, "basic-nlp-tasks"]], "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)": [[9, "topic-modeling-and-latent-dirichlet-allocation-lda"], [22, "topic-modeling-and-latent-dirichlet-allocation-lda"]], "3.1 Zero-shot Learning with LLMs": [[11, "zero-shot-learning-with-llms"], [22, "zero-shot-learning-with-llms"]], "3.2 Few-shot Learning and Prompt Engineering": [[12, "few-shot-learning-and-prompt-engineering"], [22, "few-shot-learning-and-prompt-engineering"]], "3.3 Comparing LLM Performance with Traditional Supervised Learning": [[13, "comparing-llm-performance-with-traditional-supervised-learning"], [22, "comparing-llm-performance-with-traditional-supervised-learning"]], "4.1 Using LLMs for High-Quality Text Generation": [[15, "using-llms-for-high-quality-text-generation"], [22, "using-llms-for-high-quality-text-generation"]], "4.2 Social Bias Inference and Analysis": [[16, "social-bias-inference-and-analysis"], [22, "social-bias-inference-and-analysis"]], "4.3 Figurative Language Explanation and Cultural Context": [[17, "figurative-language-explanation-and-cultural-context"], [22, "figurative-language-explanation-and-cultural-context"]], "5.1 Analyzing Large-Scale Textual Data": [[19, "analyzing-large-scale-textual-data"], [22, "analyzing-large-scale-textual-data"]], "5.2 Misinformation and Fake News Detection": [[20, "misinformation-and-fake-news-detection"], [22, "misinformation-and-fake-news-detection"]], "5.3 Future Directions and Emerging Trends": [[21, "future-directions-and-emerging-trends"], [22, "future-directions-and-emerging-trends"]], "About": [[1, null]], "Changelog": [[1, "changelog"]], "Contributing": [[1, "contributing"]], "Course Objectives": [[1, "course-objectives"]], "Course Overview": [[1, "course-overview"]], "Course Structure": [[1, "course-structure"]], "Home": [[1, "home"]], "Lecture Notes": [[1, null]], "License": [[1, "license"]], "Session 1 - Introduction": [[2, "session-1-introduction"]], "Session 1: Introduction to NLP and Its Applications in Social Science": [[22, "session-1-introduction-to-nlp-and-its-applications-in-social-science"]], "Session 2: Traditional NLP Techniques and Text Preprocessing": [[6, "session-2-traditional-nlp-techniques-and-text-preprocessing"], [22, "session-2-traditional-nlp-techniques-and-text-preprocessing"]], "Session 3: LLMs for Data Annotation and Classification": [[10, "session-3-llms-for-data-annotation-and-classification"], [22, "session-3-llms-for-data-annotation-and-classification"]], "Session 4: Generative Explanations and Summaries in Social Science": [[14, "session-4-generative-explanations-and-summaries-in-social-science"], [22, "session-4-generative-explanations-and-summaries-in-social-science"]], "Session 5: Advanced Applications of LLMs in Social Science Research": [[18, "session-5-advanced-applications-of-llms-in-social-science-research"], [22, "session-5-advanced-applications-of-llms-in-social-science-research"]], "Syllabus": [[22, "syllabus"]], "Table of Contents": [[1, "table-of-contents"]], "Who made this book?": [[0, "who-made-this-book"]], "Why This Course Matters": [[1, "why-this-course-matters"]]}, "docnames": ["about/index", "index", "session01/index", "session01/lecture1", "session01/lecture2", "session01/lecture3", "session02/index", "session02/lecture1", "session02/lecture2", "session02/lecture3", "session03/index", "session03/lecture1", "session03/lecture2", "session03/lecture3", "session04/index", "session04/lecture1", "session04/lecture2", "session04/lecture3", "session05/index", "session05/lecture1", "session05/lecture2", "session05/lecture3", "syllabus/index"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["about/index.md", "index.md", "session01/index.md", "session01/lecture1.md", "session01/lecture2.md", "session01/lecture3.md", "session02/index.md", "session02/lecture1.md", "session02/lecture2.md", "session02/lecture3.md", "session03/index.md", "session03/lecture1.md", "session03/lecture2.md", "session03/lecture3.md", "session04/index.md", "session04/lecture1.md", "session04/lecture2.md", "session04/lecture3.md", "session05/index.md", "session05/lecture1.md", "session05/lecture2.md", "session05/lecture3.md", "syllabus/index.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 2], "0": 1, "1": [1, 6, 10, 14, 18], "2": [1, 2, 10, 14, 18], "3": [1, 2, 3, 6, 14, 18], "4": [1, 3], "5": 1, "As": [1, 2], "BY": 1, "By": 1, "In": 1, "It": 2, "The": [1, 2, 5, 22], "These": 1, "abil": 4, "about": 2, "abstract": 2, "academ": 5, "access": [2, 5], "accuraci": [4, 5], "adapt": [2, 4, 5], "address": 5, "advanc": [1, 2, 4, 5], "advantag": 4, "advent": 1, "ai": 5, "aim": [1, 2], "algorithm": 5, "all": 2, "alloc": [1, 6], "also": [1, 2], "alwai": 1, "ambigu": 3, "amount": 1, "an": [1, 2], "analysi": [1, 2, 4, 8, 14, 17], "analyz": [1, 3, 4, 17, 18], "annot": [1, 4, 13], "answer": [2, 4], "appli": [1, 2, 22], "applic": [1, 2, 4, 11], "approach": [1, 3, 22], "ar": 1, "architectur": [4, 22], "art": 1, "ask": 2, "aspect": [15, 22], "attent": [3, 4], "attitud": [19, 22], "attribut": 5, "awai": 2, "bag": [7, 22], "balanc": 5, "base": [1, 2, 3, 5, 15, 22], "basic": [1, 2, 3, 6], "becaus": 2, "begin": 1, "behavior": 1, "benefit": [1, 22], "bert": [3, 4], "best": [2, 5], "between": [1, 2, 21, 22], "bia": [1, 5, 14], "bias": [1, 4, 16, 22], "black": 5, "book": 1, "both": [1, 2], "box": 5, "breakthrough": 3, "bridg": [1, 2], "build": 2, "can": [1, 2], "capabl": [1, 3, 4, 5, 22], "case": [13, 22], "cc": 1, "challeng": [1, 2, 3, 4], "classif": [1, 2, 4, 8], "clean": [1, 6], "collabor": [5, 21, 22], "come": 1, "common": 2, "commun": [17, 22], "compar": [1, 10], "complet": 4, "complex": [2, 3, 4], "complianc": 5, "compon": 4, "comput": [3, 4, 5], "concept": [3, 4, 22], "concern": 5, "consent": 5, "consider": [1, 2, 4], "consist": 5, "constantli": 1, "contain": 1, "content": 5, "context": [1, 2, 3, 4, 5, 11, 14], "continu": 5, "copyright": 5, "core": 4, "corpora": 4, "cours": [2, 22], "cover": 2, "creat": [0, 5], "critic": [1, 2, 22], "cross": [4, 5, 17, 22], "cultur": [1, 5, 14], "current": 3, "cut": 1, "dall": 4, "data": [1, 2, 3, 4, 5, 13, 18], "dataset": [1, 3, 4, 22], "deal": 3, "decis": 5, "deep": 3, "deepen": 1, "definit": [3, 4], "deploy": [4, 5], "design": [1, 5, 12, 22], "detect": [1, 4, 5, 16, 18], "develop": [1, 3, 5, 21, 22], "differ": 5, "direct": [1, 3, 4, 18], "dirichlet": [1, 6], "disclosur": 5, "discov": 1, "discuss": 2, "dispar": 5, "distinct": 4, "dive": 1, "divers": 5, "do": 1, "document": [1, 19, 22], "domain": 4, "don": 2, "dynam": 1, "e": [4, 5], "each": [1, 22], "earli": 3, "edg": 1, "effect": [1, 12, 22], "effici": 4, "embark": [1, 2], "embed": [3, 7, 22], "emerg": [1, 3, 5, 18], "emot": [4, 15, 22], "emphas": [1, 2], "encourag": [2, 22], "end": 1, "engag": 2, "engin": [1, 10], "enhanc": 4, "ensur": 5, "entiti": [8, 22], "environment": 5, "equip": 1, "equiti": 5, "etc": 5, "ethic": [1, 2, 4], "evalu": [1, 3, 5, 22], "even": 2, "evolut": [1, 2], "evolv": 2, "exampl": [3, 4, 22], "excit": [1, 2], "exercis": 22, "exist": 5, "experi": 1, "explain": [5, 16, 22], "explan": [1, 4, 15], "explor": [1, 2], "exposur": 5, "extract": 3, "factual": [4, 5], "fake": [1, 18], "fals": [20, 22], "fascin": 1, "featur": 3, "few": [1, 3, 4, 10], "field": [1, 2], "figur": [1, 14], "final": 1, "financi": [19, 22], "fine": [4, 5], "five": 1, "focu": 22, "frame": 2, "framework": 5, "from": [1, 2, 3, 4], "fundament": [1, 2], "futur": [1, 3, 4, 5, 18], "g": [4, 5], "gain": [1, 2], "gap": [1, 2], "gdpr": 5, "gender": 5, "gener": [1, 2, 3, 5], "global": 5, "goal": 2, "gpt": [2, 3, 4, 22], "great": 1, "grow": 2, "guidelin": [1, 5], "ha": [1, 2], "had": 2, "hallucin": 5, "hand": [1, 22], "handl": [3, 4], "har": 1, "have": [1, 2], "here": [1, 2], "hesit": 2, "high": [1, 14], "histor": [1, 3], "how": [1, 2], "howev": 1, "human": [1, 4, 5], "i": [1, 2], "identif": 5, "identifi": [20, 22], "idf": [7, 22], "idiom": [17, 22], "impact": [3, 5, 20, 22], "implic": 5, "import": [2, 3, 5], "improv": [4, 5], "includ": [2, 22], "infer": [1, 4, 14, 19], "inform": [1, 4, 5, 20, 22], "insight": 2, "institut": 5, "integr": [4, 5, 22], "intellectu": 5, "interact": [21, 22], "interdisciplinari": 5, "interest": [2, 22], "interpret": [2, 4, 5, 21, 22], "intersect": [1, 2, 22], "introduct": [1, 3, 4, 5], "involv": 5, "isn": 2, "issu": [5, 22], "its": [1, 2, 4], "journei": [1, 2], "just": 2, "keep": 1, "kei": [2, 3, 4], "knowledg": [1, 4], "lack": 4, "languag": [1, 2, 3, 4, 14], "larg": [1, 2, 3, 4, 5, 18], "larger": 3, "latent": [1, 6], "lda": [1, 6], "learn": [1, 2, 3, 4, 10], "lectur": [2, 22], "lemmat": [7, 22], "let": [1, 2], "leverag": [1, 2], "librari": [1, 22], "like": [2, 4], "limit": [1, 4, 22], "lingual": 4, "ll": [1, 2], "llm": [1, 2, 3, 14, 20, 21], "made": [1, 2], "massiv": 4, "mean": 2, "meaning": 2, "mechan": [3, 4], "media": [1, 19, 22], "medic": [19, 22], "metaphor": [17, 22], "method": [1, 3], "methodologi": [1, 2, 21, 22], "might": 2, "mind": 1, "misinform": [1, 15, 18], "mitig": [4, 5], "modal": 4, "model": [1, 2, 3, 4, 5, 6], "modern": [1, 2, 3, 22], "monitor": 5, "more": [1, 2], "move": 1, "much": 2, "multi": 4, "name": [8, 22], "natur": [1, 2, 5], "need": [2, 5], "new": [1, 2, 3, 18, 21], "nlp": [1, 2, 4, 5, 21], "normal": [1, 6], "notabl": 4, "now": 2, "offer": 1, "ongo": 3, "onli": 1, "open": 1, "opinion": [19, 22], "opportun": [1, 2, 3, 5], "other": 4, "our": [1, 2], "outcom": 5, "output": 5, "overview": 2, "own": [2, 22], "paradigm": 3, "paraphras": 4, "particip": 5, "particularli": 1, "pattern": [4, 20, 22], "perform": [1, 10], "person": 5, "perspect": 3, "phenomena": 1, "pipelin": [2, 3], "plagiar": 5, "pleas": 1, "point": 2, "polici": 5, "pose": 5, "posit": [16, 22], "possibl": [1, 3], "post": [1, 19, 22], "potenti": [1, 3, 4, 5], "power": [1, 2], "practic": [1, 2, 5, 22], "pre": [2, 4], "prepar": 2, "preprocess": [1, 2, 3], "principl": [2, 5, 11, 22], "privaci": [5, 22], "process": [1, 2, 4, 19], "progress": [2, 4], "project": 1, "promin": 4, "promot": 5, "prompt": [1, 10], "proper": 5, "properti": 5, "protect": 5, "provid": 2, "public": [19, 22], "purpos": 3, "python": [1, 22], "qualiti": [1, 14], "question": [1, 2, 4], "racial": 5, "raw": 2, "re": [1, 5], "real": 1, "reason": 4, "recent": [1, 2, 4], "recognit": [8, 22], "record": [19, 22], "refram": [16, 22], "regul": 5, "releas": 1, "relev": [1, 22], "reliabl": 5, "rememb": 2, "represent": [1, 6], "reproduc": 5, "requir": [4, 5], "research": [1, 2, 3, 4, 21], "resourc": [4, 5], "respons": [1, 4, 5, 22], "responsibli": 1, "result": [2, 5, 21, 22], "retriev": 4, "review": 5, "revolutionari": 1, "right": 5, "rise": 3, "risk": 5, "rule": 3, "scale": [1, 4, 5, 18], "scienc": [1, 2, 3, 4, 5, 11, 12, 13], "scientif": 5, "scientist": [1, 3, 21, 22], "scratch": 2, "see": 1, "seek": 1, "self": [3, 4], "semant": 3, "sentiment": [2, 4, 8, 22], "seri": 4, "session": 1, "shift": 3, "shot": [1, 3, 4, 10], "significantli": 2, "size": 4, "skill": 1, "so": 1, "social": [1, 2, 3, 4, 5, 11, 12, 13, 17, 19, 21], "societ": [1, 5], "socioeconom": 5, "sourc": 5, "specif": [2, 3, 4], "spread": [20, 22], "state": [1, 3], "statist": 3, "stem": [7, 22], "strategi": 5, "student": 22, "studi": [2, 5, 13, 20, 21, 22], "subject": 5, "summar": [4, 15, 22], "summari": [1, 4], "supervis": [1, 10], "sustain": 5, "syllabu": 1, "system": 3, "t": 2, "t5": 4, "task": [1, 2, 3, 4, 6, 12], "teach": 1, "techniqu": [1, 2, 5, 16], "technologi": [1, 5], "text": [1, 2, 3, 4, 5, 8, 14, 16], "textual": [1, 4, 18], "tf": [7, 22], "theoret": 22, "thi": 2, "think": [1, 2], "those": 1, "three": 1, "through": 1, "throughout": [1, 2, 22], "token": [7, 22], "tool": [1, 2], "topic": [1, 2, 6], "toward": 3, "tradit": [1, 3, 4, 10], "tradition": 2, "train": [2, 3, 4, 5], "transcript": 2, "transform": [1, 3, 4, 22], "transit": 3, "translat": 4, "transpar": [4, 5], "trend": [1, 4, 18], "trendi": 2, "true": 4, "tune": [4, 5], "type": 5, "under": 1, "undergon": 1, "underli": 2, "understand": [1, 2, 4], "uniqu": 5, "unpreced": 1, "unstructur": 3, "up": [1, 4], "us": [1, 2, 4, 14, 20], "usag": 5, "util": 2, "v": 22, "valid": [2, 5, 21, 22], "variant": 4, "variou": 4, "vast": 1, "ve": 1, "wa": 0, "wai": 1, "we": [1, 2], "welcom": [1, 2], "what": 1, "when": 5, "while": [2, 22], "who": 1, "word": [3, 7, 22], "work": 1, "world": 1, "year": [1, 2], "you": [1, 2], "your": 2, "zero": [1, 3, 4, 10]}, "titles": ["Who made this book?", "Home", "Session 1 - Introduction", "1.1 Fundamentals of NLP and its evolution", "1.2 Overview of Generative LLMs", "1.3 Ethical Considerations and Challenges in Using LLMs for Research", "Session 2: Traditional NLP Techniques and Text Preprocessing", "2.1 Text Cleaning, Normalization, and Representation", "2.2 Basic NLP Tasks", "2.3 Topic Modeling and Latent Dirichlet Allocation (LDA)", "Session 3: LLMs for Data Annotation and Classification", "3.1 Zero-shot Learning with LLMs", "3.2 Few-shot Learning and Prompt Engineering", "3.3 Comparing LLM Performance with Traditional Supervised Learning", "Session 4: Generative Explanations and Summaries in Social Science", "4.1 Using LLMs for High-Quality Text Generation", "4.2 Social Bias Inference and Analysis", "4.3 Figurative Language Explanation and Cultural Context", "Session 5: Advanced Applications of LLMs in Social Science Research", "5.1 Analyzing Large-Scale Textual Data", "5.2 Misinformation and Fake News Detection", "5.3 Future Directions and Emerging Trends", "Syllabus"], "titleterms": {"1": [2, 3, 4, 5, 7, 11, 15, 19, 22], "2": [4, 6, 7, 8, 9, 12, 16, 20, 22], "3": [5, 9, 10, 11, 12, 13, 17, 21, 22], "4": [14, 15, 16, 17, 22], "5": [18, 19, 20, 21, 22], "Its": 22, "about": 1, "advanc": [18, 22], "alloc": [9, 22], "analysi": [16, 22], "analyz": [19, 22], "annot": [10, 22], "applic": [18, 22], "basic": [8, 22], "bia": [16, 22], "book": 0, "challeng": [5, 22], "changelog": 1, "classif": [10, 22], "clean": [7, 22], "compar": [13, 22], "consider": [5, 22], "content": 1, "context": [17, 22], "contribut": 1, "cours": 1, "cultur": [17, 22], "data": [10, 19, 22], "detect": [20, 22], "direct": [21, 22], "dirichlet": [9, 22], "emerg": [21, 22], "engin": [12, 22], "ethic": [5, 22], "evolut": [3, 22], "explan": [14, 17, 22], "fake": [20, 22], "few": [12, 22], "figur": [17, 22], "fundament": [3, 22], "futur": [21, 22], "gener": [4, 14, 15, 22], "high": [15, 22], "home": 1, "infer": [16, 22], "introduct": [2, 22], "its": [3, 22], "languag": [17, 22], "larg": [19, 22], "latent": [9, 22], "lda": [9, 22], "learn": [11, 12, 13, 22], "lectur": 1, "licens": 1, "llm": [4, 5, 10, 11, 13, 15, 18, 22], "made": 0, "matter": 1, "misinform": [20, 22], "model": [9, 22], "natur": 22, "new": [20, 22], "nlp": [3, 6, 8, 22], "normal": [7, 22], "note": 1, "object": 1, "overview": [1, 4, 22], "perform": [13, 22], "preprocess": [6, 22], "process": 22, "prompt": [12, 22], "qualiti": [15, 22], "represent": [7, 22], "research": [5, 18, 22], "scale": [19, 22], "scienc": [14, 18, 22], "session": [2, 6, 10, 14, 18, 22], "shot": [11, 12, 22], "social": [14, 16, 18, 22], "structur": 1, "summari": [14, 22], "supervis": [13, 22], "syllabu": 22, "tabl": 1, "task": [8, 22], "techniqu": [6, 22], "text": [6, 7, 15, 22], "textual": [19, 22], "thi": [0, 1], "topic": [9, 22], "tradit": [6, 13, 22], "trend": [21, 22], "us": [5, 15, 22], "who": 0, "why": 1, "zero": [11, 22]}})